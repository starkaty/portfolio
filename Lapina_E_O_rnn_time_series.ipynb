{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQnDWSn8TEOl"
   },
   "source": [
    "# Усовершенствование работы рекуррентной нейронной сети для ограниченного набора обучающих данных на примере прогнозирования медианной заработной платы женщин (анализ временного ряда за последние 50 лет)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 00:59:48.423289: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-11 00:59:48.424553: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 00:59:48.452271: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 00:59:48.452832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 00:59:48.975932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Dropout,  SimpleRNN, SimpleRNNCell\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vWKxQzctTEO2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gender_wage_gap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'men_median', 'men_average', 'women_median', 'women_average',\n",
       "       'white_men_median', 'white_men_average', 'black_men_median',\n",
       "       'black_men_average', 'hispanic_men_median', 'hispanic_men_average',\n",
       "       'white_women_median', 'white_women_average', 'black_women_median',\n",
       "       'black_women_average', 'hispanic_women_median',\n",
       "       'hispanic_women_average'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['year', 'men_median', 'men_average', 'women_median', 'women_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>men_median</th>\n",
       "      <th>men_average</th>\n",
       "      <th>women_median</th>\n",
       "      <th>women_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1973</td>\n",
       "      <td>24.00</td>\n",
       "      <td>26.96</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1974</td>\n",
       "      <td>23.70</td>\n",
       "      <td>26.48</td>\n",
       "      <td>14.88</td>\n",
       "      <td>17.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1975</td>\n",
       "      <td>24.08</td>\n",
       "      <td>26.46</td>\n",
       "      <td>15.08</td>\n",
       "      <td>17.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1976</td>\n",
       "      <td>23.69</td>\n",
       "      <td>26.73</td>\n",
       "      <td>15.22</td>\n",
       "      <td>17.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1977</td>\n",
       "      <td>23.92</td>\n",
       "      <td>26.73</td>\n",
       "      <td>15.11</td>\n",
       "      <td>17.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1978</td>\n",
       "      <td>24.27</td>\n",
       "      <td>26.86</td>\n",
       "      <td>15.17</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1979</td>\n",
       "      <td>24.11</td>\n",
       "      <td>27.08</td>\n",
       "      <td>15.28</td>\n",
       "      <td>17.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1980</td>\n",
       "      <td>23.88</td>\n",
       "      <td>26.54</td>\n",
       "      <td>15.21</td>\n",
       "      <td>17.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1981</td>\n",
       "      <td>23.38</td>\n",
       "      <td>26.38</td>\n",
       "      <td>15.29</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1982</td>\n",
       "      <td>23.39</td>\n",
       "      <td>26.60</td>\n",
       "      <td>15.12</td>\n",
       "      <td>17.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  men_median  men_average  women_median  women_average\n",
       "49  1973       24.00        26.96         15.10          17.31\n",
       "48  1974       23.70        26.48         14.88          17.01\n",
       "47  1975       24.08        26.46         15.08          17.24\n",
       "46  1976       23.69        26.73         15.22          17.64\n",
       "45  1977       23.92        26.73         15.11          17.44\n",
       "44  1978       24.27        26.86         15.17          17.50\n",
       "43  1979       24.11        27.08         15.28          17.73\n",
       "42  1980       23.88        26.54         15.21          17.54\n",
       "41  1981       23.38        26.38         15.29          17.55\n",
       "40  1982       23.39        26.60         15.12          17.85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спрогнозируем медианную заработную плату женщин на базе анализа временного ряда по признакам средняя и медианная заработная плата мужчин и женщин, возьмем период предыдущие 10 лет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50 entries, 49 to 0\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   year           50 non-null     int64  \n",
      " 1   men_median     50 non-null     float64\n",
      " 2   men_average    50 non-null     float64\n",
      " 3   women_median   50 non-null     float64\n",
      " 4   women_average  50 non-null     float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 2.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='year', ylabel='women_median'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#посмотрим графики изменения средней и медианной заработной платы\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,7\n",
    "sns.lineplot(df['year'], df['women_median'])\n",
    "sns.lineplot(df['year'], df['women_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983,\n",
       "       1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994,\n",
       "       1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005,\n",
       "       2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016,\n",
       "       2017, 2018, 2019, 2020, 2021, 2022])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 10 #анализируем 10 точек предыдущего периода\n",
    "for i in range(1, x_len+1):\n",
    "    df['women_median'+str(i)+'years_back'] = df['women_median'].shift(i, axis = 0)\n",
    "    df['women_average'+str(i)+'years_back'] = df['women_average'].shift(i, axis = 0)\n",
    "    df['men_median'+str(i)+'years_back'] = df['men_median'].shift(i, axis = 0)\n",
    "    df['men_average'+str(i)+'years_back'] = df['men_average'].shift(i, axis = 0)    \n",
    "    df['year'+str(i)+'years_back'] = df['year'].shift(i, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>men_median</th>\n",
       "      <th>men_average</th>\n",
       "      <th>women_median</th>\n",
       "      <th>women_average</th>\n",
       "      <th>women_median1years_back</th>\n",
       "      <th>women_average1years_back</th>\n",
       "      <th>men_median1years_back</th>\n",
       "      <th>men_average1years_back</th>\n",
       "      <th>year1years_back</th>\n",
       "      <th>...</th>\n",
       "      <th>women_median9years_back</th>\n",
       "      <th>women_average9years_back</th>\n",
       "      <th>men_median9years_back</th>\n",
       "      <th>men_average9years_back</th>\n",
       "      <th>year9years_back</th>\n",
       "      <th>women_median10years_back</th>\n",
       "      <th>women_average10years_back</th>\n",
       "      <th>men_median10years_back</th>\n",
       "      <th>men_average10years_back</th>\n",
       "      <th>year10years_back</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1973</td>\n",
       "      <td>24.00</td>\n",
       "      <td>26.96</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1974</td>\n",
       "      <td>23.70</td>\n",
       "      <td>26.48</td>\n",
       "      <td>14.88</td>\n",
       "      <td>17.01</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.31</td>\n",
       "      <td>24.00</td>\n",
       "      <td>26.96</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1975</td>\n",
       "      <td>24.08</td>\n",
       "      <td>26.46</td>\n",
       "      <td>15.08</td>\n",
       "      <td>17.24</td>\n",
       "      <td>14.88</td>\n",
       "      <td>17.01</td>\n",
       "      <td>23.70</td>\n",
       "      <td>26.48</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1976</td>\n",
       "      <td>23.69</td>\n",
       "      <td>26.73</td>\n",
       "      <td>15.22</td>\n",
       "      <td>17.64</td>\n",
       "      <td>15.08</td>\n",
       "      <td>17.24</td>\n",
       "      <td>24.08</td>\n",
       "      <td>26.46</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1977</td>\n",
       "      <td>23.92</td>\n",
       "      <td>26.73</td>\n",
       "      <td>15.11</td>\n",
       "      <td>17.44</td>\n",
       "      <td>15.22</td>\n",
       "      <td>17.64</td>\n",
       "      <td>23.69</td>\n",
       "      <td>26.73</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1978</td>\n",
       "      <td>24.27</td>\n",
       "      <td>26.86</td>\n",
       "      <td>15.17</td>\n",
       "      <td>17.50</td>\n",
       "      <td>15.11</td>\n",
       "      <td>17.44</td>\n",
       "      <td>23.92</td>\n",
       "      <td>26.73</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1979</td>\n",
       "      <td>24.11</td>\n",
       "      <td>27.08</td>\n",
       "      <td>15.28</td>\n",
       "      <td>17.73</td>\n",
       "      <td>15.17</td>\n",
       "      <td>17.50</td>\n",
       "      <td>24.27</td>\n",
       "      <td>26.86</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1980</td>\n",
       "      <td>23.88</td>\n",
       "      <td>26.54</td>\n",
       "      <td>15.21</td>\n",
       "      <td>17.54</td>\n",
       "      <td>15.28</td>\n",
       "      <td>17.73</td>\n",
       "      <td>24.11</td>\n",
       "      <td>27.08</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1981</td>\n",
       "      <td>23.38</td>\n",
       "      <td>26.38</td>\n",
       "      <td>15.29</td>\n",
       "      <td>17.55</td>\n",
       "      <td>15.21</td>\n",
       "      <td>17.54</td>\n",
       "      <td>23.88</td>\n",
       "      <td>26.54</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1982</td>\n",
       "      <td>23.39</td>\n",
       "      <td>26.60</td>\n",
       "      <td>15.12</td>\n",
       "      <td>17.85</td>\n",
       "      <td>15.29</td>\n",
       "      <td>17.55</td>\n",
       "      <td>23.38</td>\n",
       "      <td>26.38</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.31</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.96</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  men_median  men_average  women_median  women_average  \\\n",
       "49  1973       24.00        26.96         15.10          17.31   \n",
       "48  1974       23.70        26.48         14.88          17.01   \n",
       "47  1975       24.08        26.46         15.08          17.24   \n",
       "46  1976       23.69        26.73         15.22          17.64   \n",
       "45  1977       23.92        26.73         15.11          17.44   \n",
       "44  1978       24.27        26.86         15.17          17.50   \n",
       "43  1979       24.11        27.08         15.28          17.73   \n",
       "42  1980       23.88        26.54         15.21          17.54   \n",
       "41  1981       23.38        26.38         15.29          17.55   \n",
       "40  1982       23.39        26.60         15.12          17.85   \n",
       "\n",
       "    women_median1years_back  women_average1years_back  men_median1years_back  \\\n",
       "49                      NaN                       NaN                    NaN   \n",
       "48                    15.10                     17.31                  24.00   \n",
       "47                    14.88                     17.01                  23.70   \n",
       "46                    15.08                     17.24                  24.08   \n",
       "45                    15.22                     17.64                  23.69   \n",
       "44                    15.11                     17.44                  23.92   \n",
       "43                    15.17                     17.50                  24.27   \n",
       "42                    15.28                     17.73                  24.11   \n",
       "41                    15.21                     17.54                  23.88   \n",
       "40                    15.29                     17.55                  23.38   \n",
       "\n",
       "    men_average1years_back  year1years_back  ...  women_median9years_back  \\\n",
       "49                     NaN              NaN  ...                      NaN   \n",
       "48                   26.96           1973.0  ...                      NaN   \n",
       "47                   26.48           1974.0  ...                      NaN   \n",
       "46                   26.46           1975.0  ...                      NaN   \n",
       "45                   26.73           1976.0  ...                      NaN   \n",
       "44                   26.73           1977.0  ...                      NaN   \n",
       "43                   26.86           1978.0  ...                      NaN   \n",
       "42                   27.08           1979.0  ...                      NaN   \n",
       "41                   26.54           1980.0  ...                      NaN   \n",
       "40                   26.38           1981.0  ...                     15.1   \n",
       "\n",
       "    women_average9years_back  men_median9years_back  men_average9years_back  \\\n",
       "49                       NaN                    NaN                     NaN   \n",
       "48                       NaN                    NaN                     NaN   \n",
       "47                       NaN                    NaN                     NaN   \n",
       "46                       NaN                    NaN                     NaN   \n",
       "45                       NaN                    NaN                     NaN   \n",
       "44                       NaN                    NaN                     NaN   \n",
       "43                       NaN                    NaN                     NaN   \n",
       "42                       NaN                    NaN                     NaN   \n",
       "41                       NaN                    NaN                     NaN   \n",
       "40                     17.31                   24.0                   26.96   \n",
       "\n",
       "    year9years_back  women_median10years_back  women_average10years_back  \\\n",
       "49              NaN                       NaN                        NaN   \n",
       "48              NaN                       NaN                        NaN   \n",
       "47              NaN                       NaN                        NaN   \n",
       "46              NaN                       NaN                        NaN   \n",
       "45              NaN                       NaN                        NaN   \n",
       "44              NaN                       NaN                        NaN   \n",
       "43              NaN                       NaN                        NaN   \n",
       "42              NaN                       NaN                        NaN   \n",
       "41              NaN                       NaN                        NaN   \n",
       "40           1973.0                       NaN                        NaN   \n",
       "\n",
       "    men_median10years_back  men_average10years_back  year10years_back  \n",
       "49                     NaN                      NaN               NaN  \n",
       "48                     NaN                      NaN               NaN  \n",
       "47                     NaN                      NaN               NaN  \n",
       "46                     NaN                      NaN               NaN  \n",
       "45                     NaN                      NaN               NaN  \n",
       "44                     NaN                      NaN               NaN  \n",
       "43                     NaN                      NaN               NaN  \n",
       "42                     NaN                      NaN               NaN  \n",
       "41                     NaN                      NaN               NaN  \n",
       "40                     NaN                      NaN               NaN  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'men_median', 'men_average', 'women_median', 'women_average',\n",
       "       'women_median1years_back', 'women_average1years_back',\n",
       "       'men_median1years_back', 'men_average1years_back', 'year1years_back',\n",
       "       'women_median2years_back', 'women_average2years_back',\n",
       "       'men_median2years_back', 'men_average2years_back', 'year2years_back',\n",
       "       'women_median3years_back', 'women_average3years_back',\n",
       "       'men_median3years_back', 'men_average3years_back', 'year3years_back',\n",
       "       'women_median4years_back', 'women_average4years_back',\n",
       "       'men_median4years_back', 'men_average4years_back', 'year4years_back',\n",
       "       'women_median5years_back', 'women_average5years_back',\n",
       "       'men_median5years_back', 'men_average5years_back', 'year5years_back',\n",
       "       'women_median6years_back', 'women_average6years_back',\n",
       "       'men_median6years_back', 'men_average6years_back', 'year6years_back',\n",
       "       'women_median7years_back', 'women_average7years_back',\n",
       "       'men_median7years_back', 'men_average7years_back', 'year7years_back',\n",
       "       'women_median8years_back', 'women_average8years_back',\n",
       "       'men_median8years_back', 'men_average8years_back', 'year8years_back',\n",
       "       'women_median9years_back', 'women_average9years_back',\n",
       "       'men_median9years_back', 'men_average9years_back', 'year9years_back',\n",
       "       'women_median10years_back', 'women_average10years_back',\n",
       "       'men_median10years_back', 'men_average10years_back',\n",
       "       'year10years_back'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 55)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[df['year']<2018][x_len:]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 55)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.loc[df['year']>=2018]\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 51)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[['year',\n",
    "       'women_median1years_back', 'women_average1years_back',\n",
    "       'men_median1years_back', 'men_average1years_back', 'year1years_back',\n",
    "       'women_median2years_back', 'women_average2years_back',\n",
    "       'men_median2years_back', 'men_average2years_back', 'year2years_back',\n",
    "       'women_median3years_back', 'women_average3years_back',\n",
    "       'men_median3years_back', 'men_average3years_back', 'year3years_back',\n",
    "       'women_median4years_back', 'women_average4years_back',\n",
    "       'men_median4years_back', 'men_average4years_back', 'year4years_back',\n",
    "       'women_median5years_back', 'women_average5years_back',\n",
    "       'men_median5years_back', 'men_average5years_back', 'year5years_back',\n",
    "       'women_median6years_back', 'women_average6years_back',\n",
    "       'men_median6years_back', 'men_average6years_back', 'year6years_back',\n",
    "       'women_median7years_back', 'women_average7years_back',\n",
    "       'men_median7years_back', 'men_average7years_back', 'year7years_back',\n",
    "       'women_median8years_back', 'women_average8years_back',\n",
    "       'men_median8years_back', 'men_average8years_back', 'year8years_back',\n",
    "       'women_median9years_back', 'women_average9years_back',\n",
    "       'men_median9years_back', 'men_average9years_back', 'year9years_back',\n",
    "       'women_median10years_back', 'women_average10years_back',\n",
    "       'men_median10years_back', 'men_average10years_back',\n",
    "       'year10years_back']]\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.90217391, 0.19689119,\n",
       "        0.        ],\n",
       "       [0.02941176, 0.06292135, 0.01552393, ..., 0.79347826, 0.07253886,\n",
       "        0.02941176],\n",
       "       [0.05882353, 0.12134831, 0.03622251, ..., 0.93115942, 0.06735751,\n",
       "        0.05882353],\n",
       "       ...,\n",
       "       [0.94117647, 0.78876404, 0.8538163 , ..., 0.48913043, 0.87305699,\n",
       "        0.94117647],\n",
       "       [0.97058824, 0.88764045, 0.93919793, ..., 0.59782609, 0.89378238,\n",
       "        0.97058824],\n",
       "       [1.        , 0.97078652, 1.        , ..., 0.63768116, 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['women_median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.4 , 15.66, 15.77, 16.05, 16.25, 16.59, 16.49, 16.45, 16.7 ,\n",
       "       16.67, 16.96, 16.83, 16.8 , 16.8 , 17.12, 17.83, 17.75, 18.02,\n",
       "       18.39, 18.94, 19.13, 18.87, 18.75, 18.88, 18.95, 19.12, 19.57,\n",
       "       19.47, 19.34, 19.01, 18.87, 18.63, 19.07, 19.44, 19.69])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 51)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test[['year',\n",
    "       'women_median1years_back', 'women_average1years_back',\n",
    "       'men_median1years_back', 'men_average1years_back', 'year1years_back',\n",
    "       'women_median2years_back', 'women_average2years_back',\n",
    "       'men_median2years_back', 'men_average2years_back', 'year2years_back',\n",
    "       'women_median3years_back', 'women_average3years_back',\n",
    "       'men_median3years_back', 'men_average3years_back', 'year3years_back',\n",
    "       'women_median4years_back', 'women_average4years_back',\n",
    "       'men_median4years_back', 'men_average4years_back', 'year4years_back',\n",
    "       'women_median5years_back', 'women_average5years_back',\n",
    "       'men_median5years_back', 'men_average5years_back', 'year5years_back',\n",
    "       'women_median6years_back', 'women_average6years_back',\n",
    "       'men_median6years_back', 'men_average6years_back', 'year6years_back',\n",
    "       'women_median7years_back', 'women_average7years_back',\n",
    "       'men_median7years_back', 'men_average7years_back', 'year7years_back',\n",
    "       'women_median8years_back', 'women_average8years_back',\n",
    "       'men_median8years_back', 'men_average8years_back', 'year8years_back',\n",
    "       'women_median9years_back', 'women_average9years_back',\n",
    "       'men_median9years_back', 'men_average9years_back', 'year9years_back',\n",
    "       'women_median10years_back', 'women_average10years_back',\n",
    "       'men_median10years_back', 'men_average10years_back',\n",
    "       'year10years_back']]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(df_test['women_median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.73, 20.42, 21.72, 21.46, 20.74])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим, как с этой задачей справляется XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBreg = XGBRegressor(random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[500, 1000, 1500, 2000, 5000],\n",
    "          'max_depth':[3, 5, 7], 'learning_rate':[0.01,0.1, 0.5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=3, random_state=21, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ekaterina/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=21, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    inte...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=21, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.5, 1],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [500, 1000, 1500, 2000, 5000]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = GridSearchCV(XGBreg, params, scoring='f1', cv=cv, n_jobs=-1)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_test 2.754596856556042, mae_test 1.4506931915283203\n"
     ]
    }
   ],
   "source": [
    "XGBreg = XGBRegressor(n_estimators=500, max_depth=3, eta=1, random_state=21)\n",
    "\n",
    "XGBreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = XGBreg.predict(X_train)\n",
    "y_test_pred = XGBreg.predict(X_test)\n",
    "\n",
    "print(f'mse_test {mse(y_test, y_test_pred)}, mae_test {mae(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f013cadb490>]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(y_train))\n",
    "plt.plot(y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На трейне модель XGboostRegressor очень хорошо обучилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f00ac7d2790>]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(y_test))\n",
    "plt.plot(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тесте модель XGboostRegressor не уловила тренд (присутствует переобучение), требуются дополнительные настройки параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полносвязная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "31/31 - 0s - loss: 53519.5000 - mae: 130.6255 - val_loss: 4090.1025 - val_mae: 63.9486 - 267ms/epoch - 9ms/step\n",
      "Epoch 2/5000\n",
      "31/31 - 0s - loss: 35772.6953 - mae: 177.1655 - val_loss: 39226.8047 - val_mae: 198.0564 - 38ms/epoch - 1ms/step\n",
      "Epoch 3/5000\n",
      "31/31 - 0s - loss: 37194.0391 - mae: 191.3554 - val_loss: 37219.4414 - val_mae: 192.9212 - 37ms/epoch - 1ms/step\n",
      "Epoch 4/5000\n",
      "31/31 - 0s - loss: 35418.3398 - mae: 187.5055 - val_loss: 29409.8887 - val_mae: 171.4918 - 38ms/epoch - 1ms/step\n",
      "Epoch 5/5000\n",
      "31/31 - 0s - loss: 32705.7051 - mae: 180.1860 - val_loss: 41106.7812 - val_mae: 202.7459 - 34ms/epoch - 1ms/step\n",
      "Epoch 6/5000\n",
      "31/31 - 0s - loss: 32988.7891 - mae: 180.7060 - val_loss: 26675.0000 - val_mae: 163.3234 - 36ms/epoch - 1ms/step\n",
      "Epoch 7/5000\n",
      "31/31 - 0s - loss: 29556.3613 - mae: 171.6754 - val_loss: 35669.2891 - val_mae: 188.8609 - 36ms/epoch - 1ms/step\n",
      "Epoch 8/5000\n",
      "31/31 - 0s - loss: 30525.4043 - mae: 173.9416 - val_loss: 26037.9062 - val_mae: 161.3612 - 38ms/epoch - 1ms/step\n",
      "Epoch 9/5000\n",
      "31/31 - 0s - loss: 28159.9336 - mae: 167.0656 - val_loss: 28023.4941 - val_mae: 167.3999 - 33ms/epoch - 1ms/step\n",
      "Epoch 10/5000\n",
      "31/31 - 0s - loss: 28357.6035 - mae: 168.2651 - val_loss: 20030.7754 - val_mae: 141.5285 - 38ms/epoch - 1ms/step\n",
      "Epoch 11/5000\n",
      "31/31 - 0s - loss: 26853.5215 - mae: 162.7896 - val_loss: 22058.2949 - val_mae: 148.5179 - 36ms/epoch - 1ms/step\n",
      "Epoch 12/5000\n",
      "31/31 - 0s - loss: 26605.2715 - mae: 162.6259 - val_loss: 24427.8809 - val_mae: 156.2929 - 35ms/epoch - 1ms/step\n",
      "Epoch 13/5000\n",
      "31/31 - 0s - loss: 25611.7539 - mae: 159.4604 - val_loss: 28093.9219 - val_mae: 167.6103 - 36ms/epoch - 1ms/step\n",
      "Epoch 14/5000\n",
      "31/31 - 0s - loss: 25206.7500 - mae: 157.7891 - val_loss: 28185.9258 - val_mae: 167.8855 - 38ms/epoch - 1ms/step\n",
      "Epoch 15/5000\n",
      "31/31 - 0s - loss: 24131.1738 - mae: 155.0035 - val_loss: 29533.6074 - val_mae: 171.8514 - 37ms/epoch - 1ms/step\n",
      "Epoch 16/5000\n",
      "31/31 - 0s - loss: 24354.3984 - mae: 155.5217 - val_loss: 23866.5352 - val_mae: 154.4868 - 37ms/epoch - 1ms/step\n",
      "Epoch 17/5000\n",
      "31/31 - 0s - loss: 23218.8359 - mae: 152.1932 - val_loss: 23133.8477 - val_mae: 152.0962 - 34ms/epoch - 1ms/step\n",
      "Epoch 18/5000\n",
      "31/31 - 0s - loss: 22139.3574 - mae: 148.5192 - val_loss: 27230.4238 - val_mae: 165.0155 - 36ms/epoch - 1ms/step\n",
      "Epoch 19/5000\n",
      "31/31 - 0s - loss: 22269.9238 - mae: 148.9579 - val_loss: 23855.3770 - val_mae: 154.4500 - 37ms/epoch - 1ms/step\n",
      "Epoch 20/5000\n",
      "31/31 - 0s - loss: 21085.3418 - mae: 144.9327 - val_loss: 18770.6074 - val_mae: 137.0046 - 34ms/epoch - 1ms/step\n",
      "Epoch 21/5000\n",
      "31/31 - 0s - loss: 20484.4668 - mae: 142.7532 - val_loss: 18877.8086 - val_mae: 137.3945 - 36ms/epoch - 1ms/step\n",
      "Epoch 22/5000\n",
      "31/31 - 0s - loss: 20823.0625 - mae: 144.1824 - val_loss: 18885.7793 - val_mae: 137.4243 - 33ms/epoch - 1ms/step\n",
      "Epoch 23/5000\n",
      "31/31 - 0s - loss: 19579.0059 - mae: 139.4553 - val_loss: 14899.4785 - val_mae: 122.0611 - 40ms/epoch - 1ms/step\n",
      "Epoch 24/5000\n",
      "31/31 - 0s - loss: 19655.4785 - mae: 139.5665 - val_loss: 23736.0996 - val_mae: 154.0641 - 37ms/epoch - 1ms/step\n",
      "Epoch 25/5000\n",
      "31/31 - 0s - loss: 19167.2793 - mae: 138.1452 - val_loss: 14532.1758 - val_mae: 120.5471 - 37ms/epoch - 1ms/step\n",
      "Epoch 26/5000\n",
      "31/31 - 0s - loss: 18546.0293 - mae: 135.8297 - val_loss: 18229.4570 - val_mae: 135.0152 - 33ms/epoch - 1ms/step\n",
      "Epoch 27/5000\n",
      "31/31 - 0s - loss: 18389.0215 - mae: 135.4888 - val_loss: 19483.9980 - val_mae: 139.5830 - 40ms/epoch - 1ms/step\n",
      "Epoch 28/5000\n",
      "31/31 - 0s - loss: 18118.4512 - mae: 134.3839 - val_loss: 14129.1504 - val_mae: 118.8646 - 37ms/epoch - 1ms/step\n",
      "Epoch 29/5000\n",
      "31/31 - 0s - loss: 17319.1797 - mae: 131.2913 - val_loss: 20529.4316 - val_mae: 143.2788 - 32ms/epoch - 1ms/step\n",
      "Epoch 30/5000\n",
      "31/31 - 0s - loss: 17128.1758 - mae: 130.6388 - val_loss: 17690.1113 - val_mae: 133.0028 - 36ms/epoch - 1ms/step\n",
      "Epoch 31/5000\n",
      "31/31 - 0s - loss: 16638.0820 - mae: 128.8775 - val_loss: 21430.5449 - val_mae: 146.3897 - 33ms/epoch - 1ms/step\n",
      "Epoch 32/5000\n",
      "31/31 - 0s - loss: 16256.1963 - mae: 127.1181 - val_loss: 22643.9277 - val_mae: 150.4778 - 35ms/epoch - 1ms/step\n",
      "Epoch 33/5000\n",
      "31/31 - 0s - loss: 16267.7686 - mae: 127.0303 - val_loss: 17127.6289 - val_mae: 130.8702 - 34ms/epoch - 1ms/step\n",
      "Epoch 34/5000\n",
      "31/31 - 0s - loss: 15588.9346 - mae: 124.6374 - val_loss: 18551.8867 - val_mae: 136.2039 - 37ms/epoch - 1ms/step\n",
      "Epoch 35/5000\n",
      "31/31 - 0s - loss: 15622.4482 - mae: 123.6869 - val_loss: 22290.8262 - val_mae: 149.2990 - 35ms/epoch - 1ms/step\n",
      "Epoch 36/5000\n",
      "31/31 - 0s - loss: 15345.0918 - mae: 123.4822 - val_loss: 16669.1777 - val_mae: 129.1077 - 33ms/epoch - 1ms/step\n",
      "Epoch 37/5000\n",
      "31/31 - 0s - loss: 15080.1201 - mae: 122.3957 - val_loss: 18610.6152 - val_mae: 136.4185 - 35ms/epoch - 1ms/step\n",
      "Epoch 38/5000\n",
      "31/31 - 0s - loss: 14502.7979 - mae: 119.9044 - val_loss: 19472.0176 - val_mae: 139.5409 - 34ms/epoch - 1ms/step\n",
      "Epoch 39/5000\n",
      "31/31 - 0s - loss: 14311.9150 - mae: 119.0170 - val_loss: 15578.0684 - val_mae: 124.8098 - 34ms/epoch - 1ms/step\n",
      "Epoch 40/5000\n",
      "31/31 - 0s - loss: 13756.8984 - mae: 117.1376 - val_loss: 11702.4629 - val_mae: 108.1761 - 33ms/epoch - 1ms/step\n",
      "Epoch 41/5000\n",
      "31/31 - 0s - loss: 13698.1367 - mae: 116.7531 - val_loss: 11494.6494 - val_mae: 107.2105 - 35ms/epoch - 1ms/step\n",
      "Epoch 42/5000\n",
      "31/31 - 0s - loss: 13432.5098 - mae: 115.6309 - val_loss: 12255.9824 - val_mae: 110.7051 - 36ms/epoch - 1ms/step\n",
      "Epoch 43/5000\n",
      "31/31 - 0s - loss: 13370.4492 - mae: 115.3623 - val_loss: 11652.1514 - val_mae: 107.9427 - 36ms/epoch - 1ms/step\n",
      "Epoch 44/5000\n",
      "31/31 - 0s - loss: 12685.1797 - mae: 112.1269 - val_loss: 10906.1016 - val_mae: 104.4307 - 33ms/epoch - 1ms/step\n",
      "Epoch 45/5000\n",
      "31/31 - 0s - loss: 12527.2637 - mae: 111.8343 - val_loss: 11126.0410 - val_mae: 105.4777 - 36ms/epoch - 1ms/step\n",
      "Epoch 46/5000\n",
      "31/31 - 0s - loss: 12140.7500 - mae: 109.8915 - val_loss: 12550.7393 - val_mae: 112.0287 - 36ms/epoch - 1ms/step\n",
      "Epoch 47/5000\n",
      "31/31 - 0s - loss: 11920.8096 - mae: 108.7830 - val_loss: 10576.6191 - val_mae: 102.8404 - 36ms/epoch - 1ms/step\n",
      "Epoch 48/5000\n",
      "31/31 - 0s - loss: 12035.5527 - mae: 109.4523 - val_loss: 12118.5449 - val_mae: 110.0829 - 37ms/epoch - 1ms/step\n",
      "Epoch 49/5000\n",
      "31/31 - 0s - loss: 11645.6875 - mae: 107.7798 - val_loss: 11460.7715 - val_mae: 107.0528 - 38ms/epoch - 1ms/step\n",
      "Epoch 50/5000\n",
      "31/31 - 0s - loss: 11327.6289 - mae: 105.9595 - val_loss: 11395.5400 - val_mae: 106.7485 - 33ms/epoch - 1ms/step\n",
      "Epoch 51/5000\n",
      "31/31 - 0s - loss: 11494.7695 - mae: 106.8765 - val_loss: 11088.7539 - val_mae: 105.3010 - 37ms/epoch - 1ms/step\n",
      "Epoch 52/5000\n",
      "31/31 - 0s - loss: 11097.0596 - mae: 105.0943 - val_loss: 9028.9893 - val_mae: 95.0193 - 38ms/epoch - 1ms/step\n",
      "Epoch 53/5000\n",
      "31/31 - 0s - loss: 10546.9082 - mae: 102.5796 - val_loss: 12087.4014 - val_mae: 109.9404 - 33ms/epoch - 1ms/step\n",
      "Epoch 54/5000\n",
      "31/31 - 0s - loss: 10398.6670 - mae: 101.8419 - val_loss: 12923.8721 - val_mae: 113.6818 - 36ms/epoch - 1ms/step\n",
      "Epoch 55/5000\n",
      "31/31 - 0s - loss: 10586.5957 - mae: 102.6581 - val_loss: 12546.5352 - val_mae: 112.0091 - 32ms/epoch - 1ms/step\n",
      "Epoch 56/5000\n",
      "31/31 - 0s - loss: 10102.6982 - mae: 100.3830 - val_loss: 12221.9668 - val_mae: 110.5515 - 35ms/epoch - 1ms/step\n",
      "Epoch 57/5000\n",
      "31/31 - 0s - loss: 9951.4385 - mae: 99.5910 - val_loss: 12505.4785 - val_mae: 111.8255 - 35ms/epoch - 1ms/step\n",
      "Epoch 58/5000\n",
      "31/31 - 0s - loss: 9957.6123 - mae: 99.6736 - val_loss: 7529.8682 - val_mae: 86.7727 - 34ms/epoch - 1ms/step\n",
      "Epoch 59/5000\n",
      "31/31 - 0s - loss: 9647.2910 - mae: 98.0052 - val_loss: 7319.2188 - val_mae: 85.5495 - 34ms/epoch - 1ms/step\n",
      "Epoch 60/5000\n",
      "31/31 - 0s - loss: 9344.6172 - mae: 96.3242 - val_loss: 12470.4180 - val_mae: 111.6695 - 36ms/epoch - 1ms/step\n",
      "Epoch 61/5000\n",
      "31/31 - 0s - loss: 9566.7197 - mae: 97.0227 - val_loss: 12456.8203 - val_mae: 111.6078 - 35ms/epoch - 1ms/step\n",
      "Epoch 62/5000\n",
      "31/31 - 0s - loss: 9083.5039 - mae: 94.6765 - val_loss: 11058.5293 - val_mae: 105.1580 - 32ms/epoch - 1ms/step\n",
      "Epoch 63/5000\n",
      "31/31 - 0s - loss: 9126.2109 - mae: 94.9456 - val_loss: 10164.1553 - val_mae: 100.8150 - 34ms/epoch - 1ms/step\n",
      "Epoch 64/5000\n",
      "31/31 - 0s - loss: 8800.7148 - mae: 93.4526 - val_loss: 7029.3359 - val_mae: 83.8391 - 31ms/epoch - 1ms/step\n",
      "Epoch 65/5000\n",
      "31/31 - 0s - loss: 8854.4248 - mae: 93.8659 - val_loss: 7242.0996 - val_mae: 85.0978 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/5000\n",
      "31/31 - 0s - loss: 8416.7373 - mae: 91.3304 - val_loss: 8980.0791 - val_mae: 94.7616 - 33ms/epoch - 1ms/step\n",
      "Epoch 67/5000\n",
      "31/31 - 0s - loss: 8189.2559 - mae: 90.3439 - val_loss: 8289.4688 - val_mae: 91.0440 - 33ms/epoch - 1ms/step\n",
      "Epoch 68/5000\n",
      "31/31 - 0s - loss: 8260.9385 - mae: 90.7236 - val_loss: 10634.5498 - val_mae: 103.1225 - 32ms/epoch - 1ms/step\n",
      "Epoch 69/5000\n",
      "31/31 - 0s - loss: 8206.6074 - mae: 90.2715 - val_loss: 7287.4268 - val_mae: 85.3638 - 33ms/epoch - 1ms/step\n",
      "Epoch 70/5000\n",
      "31/31 - 0s - loss: 7634.1021 - mae: 87.3004 - val_loss: 7783.2588 - val_mae: 88.2211 - 33ms/epoch - 1ms/step\n",
      "Epoch 71/5000\n",
      "31/31 - 0s - loss: 7634.5952 - mae: 87.1705 - val_loss: 8306.0352 - val_mae: 91.1350 - 33ms/epoch - 1ms/step\n",
      "Epoch 72/5000\n",
      "31/31 - 0s - loss: 7428.2227 - mae: 85.9143 - val_loss: 8988.2051 - val_mae: 94.8046 - 33ms/epoch - 1ms/step\n",
      "Epoch 73/5000\n",
      "31/31 - 0s - loss: 7413.7827 - mae: 85.9522 - val_loss: 7471.3115 - val_mae: 86.4344 - 32ms/epoch - 1ms/step\n",
      "Epoch 74/5000\n",
      "31/31 - 0s - loss: 6962.0156 - mae: 83.2426 - val_loss: 7175.9121 - val_mae: 84.7091 - 33ms/epoch - 1ms/step\n",
      "Epoch 75/5000\n",
      "31/31 - 0s - loss: 7111.2065 - mae: 84.2376 - val_loss: 5853.8672 - val_mae: 76.5080 - 33ms/epoch - 1ms/step\n",
      "Epoch 76/5000\n",
      "31/31 - 0s - loss: 6868.1074 - mae: 82.6559 - val_loss: 6662.4077 - val_mae: 81.6219 - 33ms/epoch - 1ms/step\n",
      "Epoch 77/5000\n",
      "31/31 - 0s - loss: 6617.2432 - mae: 80.9800 - val_loss: 7128.8535 - val_mae: 84.4303 - 32ms/epoch - 1ms/step\n",
      "Epoch 78/5000\n",
      "31/31 - 0s - loss: 6376.8335 - mae: 79.5437 - val_loss: 7571.6592 - val_mae: 87.0138 - 33ms/epoch - 1ms/step\n",
      "Epoch 79/5000\n",
      "31/31 - 0s - loss: 6360.1304 - mae: 79.3480 - val_loss: 7698.2388 - val_mae: 87.7375 - 33ms/epoch - 1ms/step\n",
      "Epoch 80/5000\n",
      "31/31 - 0s - loss: 6196.3608 - mae: 78.1385 - val_loss: 6211.7422 - val_mae: 78.8131 - 33ms/epoch - 1ms/step\n",
      "Epoch 81/5000\n",
      "31/31 - 0s - loss: 5854.7725 - mae: 76.3078 - val_loss: 7212.7734 - val_mae: 84.9260 - 33ms/epoch - 1ms/step\n",
      "Epoch 82/5000\n",
      "31/31 - 0s - loss: 5736.7480 - mae: 75.3640 - val_loss: 7704.6226 - val_mae: 87.7747 - 35ms/epoch - 1ms/step\n",
      "Epoch 83/5000\n",
      "31/31 - 0s - loss: 5798.7700 - mae: 75.5660 - val_loss: 6310.9277 - val_mae: 79.4394 - 35ms/epoch - 1ms/step\n",
      "Epoch 84/5000\n",
      "31/31 - 0s - loss: 5615.7144 - mae: 74.5844 - val_loss: 4843.8428 - val_mae: 69.5961 - 38ms/epoch - 1ms/step\n",
      "Epoch 85/5000\n",
      "31/31 - 0s - loss: 5427.4570 - mae: 73.3479 - val_loss: 4710.5732 - val_mae: 68.6315 - 36ms/epoch - 1ms/step\n",
      "Epoch 86/5000\n",
      "31/31 - 0s - loss: 5299.7485 - mae: 72.1870 - val_loss: 4035.1790 - val_mae: 63.5215 - 38ms/epoch - 1ms/step\n",
      "Epoch 87/5000\n",
      "31/31 - 0s - loss: 5169.4077 - mae: 71.6925 - val_loss: 4801.5352 - val_mae: 69.2910 - 35ms/epoch - 1ms/step\n",
      "Epoch 88/5000\n",
      "31/31 - 0s - loss: 5074.7686 - mae: 70.8626 - val_loss: 3982.8828 - val_mae: 63.1085 - 33ms/epoch - 1ms/step\n",
      "Epoch 89/5000\n",
      "31/31 - 0s - loss: 4843.3892 - mae: 69.0855 - val_loss: 4257.9111 - val_mae: 65.2505 - 35ms/epoch - 1ms/step\n",
      "Epoch 90/5000\n",
      "31/31 - 0s - loss: 4741.5806 - mae: 68.2985 - val_loss: 4013.9568 - val_mae: 63.3543 - 46ms/epoch - 1ms/step\n",
      "Epoch 91/5000\n",
      "31/31 - 0s - loss: 4753.0796 - mae: 68.5932 - val_loss: 3275.1934 - val_mae: 57.2271 - 39ms/epoch - 1ms/step\n",
      "Epoch 92/5000\n",
      "31/31 - 0s - loss: 4565.8755 - mae: 67.2664 - val_loss: 3749.2949 - val_mae: 61.2300 - 37ms/epoch - 1ms/step\n",
      "Epoch 93/5000\n",
      "31/31 - 0s - loss: 4457.4556 - mae: 66.4331 - val_loss: 4171.9619 - val_mae: 64.5888 - 37ms/epoch - 1ms/step\n",
      "Epoch 94/5000\n",
      "31/31 - 0s - loss: 4363.6240 - mae: 65.9286 - val_loss: 4908.2891 - val_mae: 70.0579 - 36ms/epoch - 1ms/step\n",
      "Epoch 95/5000\n",
      "31/31 - 0s - loss: 4325.8501 - mae: 65.5560 - val_loss: 4978.0737 - val_mae: 70.5537 - 35ms/epoch - 1ms/step\n",
      "Epoch 96/5000\n",
      "31/31 - 0s - loss: 4042.4517 - mae: 63.2926 - val_loss: 4588.9922 - val_mae: 67.7409 - 37ms/epoch - 1ms/step\n",
      "Epoch 97/5000\n",
      "31/31 - 0s - loss: 3941.8770 - mae: 62.4495 - val_loss: 5302.4116 - val_mae: 72.8160 - 35ms/epoch - 1ms/step\n",
      "Epoch 98/5000\n",
      "31/31 - 0s - loss: 3958.4688 - mae: 62.5331 - val_loss: 4053.2764 - val_mae: 63.6641 - 35ms/epoch - 1ms/step\n",
      "Epoch 99/5000\n",
      "31/31 - 0s - loss: 3835.8606 - mae: 61.2894 - val_loss: 3668.1831 - val_mae: 60.5636 - 34ms/epoch - 1ms/step\n",
      "Epoch 100/5000\n",
      "31/31 - 0s - loss: 3838.8142 - mae: 61.7126 - val_loss: 2652.6562 - val_mae: 51.5024 - 34ms/epoch - 1ms/step\n",
      "Epoch 101/5000\n",
      "31/31 - 0s - loss: 3690.6309 - mae: 60.5057 - val_loss: 2594.2598 - val_mae: 50.9318 - 38ms/epoch - 1ms/step\n",
      "Epoch 102/5000\n",
      "31/31 - 0s - loss: 3652.7935 - mae: 60.0515 - val_loss: 3109.7019 - val_mae: 55.7633 - 36ms/epoch - 1ms/step\n",
      "Epoch 103/5000\n",
      "31/31 - 0s - loss: 3525.4324 - mae: 58.7874 - val_loss: 3433.6335 - val_mae: 58.5954 - 35ms/epoch - 1ms/step\n",
      "Epoch 104/5000\n",
      "31/31 - 0s - loss: 3355.7805 - mae: 57.3364 - val_loss: 3868.0593 - val_mae: 62.1925 - 37ms/epoch - 1ms/step\n",
      "Epoch 105/5000\n",
      "31/31 - 0s - loss: 3278.3909 - mae: 56.9962 - val_loss: 4330.7593 - val_mae: 65.8069 - 41ms/epoch - 1ms/step\n",
      "Epoch 106/5000\n",
      "31/31 - 0s - loss: 3135.4092 - mae: 55.5234 - val_loss: 3789.4517 - val_mae: 61.5574 - 42ms/epoch - 1ms/step\n",
      "Epoch 107/5000\n",
      "31/31 - 0s - loss: 3252.7341 - mae: 56.4184 - val_loss: 2138.2598 - val_mae: 46.2392 - 40ms/epoch - 1ms/step\n",
      "Epoch 108/5000\n",
      "31/31 - 0s - loss: 3199.1519 - mae: 56.2423 - val_loss: 2199.1714 - val_mae: 46.8937 - 38ms/epoch - 1ms/step\n",
      "Epoch 109/5000\n",
      "31/31 - 0s - loss: 3021.6206 - mae: 54.7905 - val_loss: 4011.5479 - val_mae: 63.3352 - 41ms/epoch - 1ms/step\n",
      "Epoch 110/5000\n",
      "31/31 - 0s - loss: 2890.2871 - mae: 53.3846 - val_loss: 3676.8875 - val_mae: 60.6362 - 38ms/epoch - 1ms/step\n",
      "Epoch 111/5000\n",
      "31/31 - 0s - loss: 2876.8376 - mae: 53.0707 - val_loss: 2698.2441 - val_mae: 51.9427 - 38ms/epoch - 1ms/step\n",
      "Epoch 112/5000\n",
      "31/31 - 0s - loss: 2866.0325 - mae: 52.8907 - val_loss: 1873.3042 - val_mae: 43.2800 - 42ms/epoch - 1ms/step\n",
      "Epoch 113/5000\n",
      "31/31 - 0s - loss: 2760.7571 - mae: 51.9171 - val_loss: 1871.1321 - val_mae: 43.2544 - 34ms/epoch - 1ms/step\n",
      "Epoch 114/5000\n",
      "31/31 - 0s - loss: 2761.6829 - mae: 52.1482 - val_loss: 3173.3892 - val_mae: 56.3316 - 34ms/epoch - 1ms/step\n",
      "Epoch 115/5000\n",
      "31/31 - 0s - loss: 2536.6960 - mae: 50.0371 - val_loss: 3591.8098 - val_mae: 59.9301 - 33ms/epoch - 1ms/step\n",
      "Epoch 116/5000\n",
      "31/31 - 0s - loss: 2545.4036 - mae: 49.8919 - val_loss: 3266.7192 - val_mae: 57.1540 - 33ms/epoch - 1ms/step\n",
      "Epoch 117/5000\n",
      "31/31 - 0s - loss: 2518.6389 - mae: 49.4057 - val_loss: 1867.5325 - val_mae: 43.2128 - 33ms/epoch - 1ms/step\n",
      "Epoch 118/5000\n",
      "31/31 - 0s - loss: 2535.7310 - mae: 49.7777 - val_loss: 1167.9824 - val_mae: 34.1736 - 34ms/epoch - 1ms/step\n",
      "Epoch 119/5000\n",
      "31/31 - 0s - loss: 2471.6873 - mae: 49.1133 - val_loss: 2497.5129 - val_mae: 49.9733 - 33ms/epoch - 1ms/step\n",
      "Epoch 120/5000\n",
      "31/31 - 0s - loss: 2273.5305 - mae: 47.2415 - val_loss: 2735.5405 - val_mae: 52.3011 - 32ms/epoch - 1ms/step\n",
      "Epoch 121/5000\n",
      "31/31 - 0s - loss: 2181.9746 - mae: 46.3689 - val_loss: 3212.1755 - val_mae: 56.6744 - 33ms/epoch - 1ms/step\n",
      "Epoch 122/5000\n",
      "31/31 - 0s - loss: 2210.6333 - mae: 46.4393 - val_loss: 1617.3035 - val_mae: 40.2140 - 33ms/epoch - 1ms/step\n",
      "Epoch 123/5000\n",
      "31/31 - 0s - loss: 2261.3352 - mae: 47.3436 - val_loss: 2040.3003 - val_mae: 45.1677 - 32ms/epoch - 1ms/step\n",
      "Epoch 124/5000\n",
      "31/31 - 0s - loss: 2001.1975 - mae: 44.1951 - val_loss: 3054.4766 - val_mae: 55.2661 - 31ms/epoch - 1ms/step\n",
      "Epoch 125/5000\n",
      "31/31 - 0s - loss: 1982.5420 - mae: 43.9793 - val_loss: 2470.8198 - val_mae: 49.7055 - 35ms/epoch - 1ms/step\n",
      "Epoch 126/5000\n",
      "31/31 - 0s - loss: 1896.3081 - mae: 42.9588 - val_loss: 1530.5356 - val_mae: 39.1203 - 32ms/epoch - 1ms/step\n",
      "Epoch 127/5000\n",
      "31/31 - 0s - loss: 1926.5092 - mae: 43.5143 - val_loss: 1170.2637 - val_mae: 34.2066 - 34ms/epoch - 1ms/step\n",
      "Epoch 128/5000\n",
      "31/31 - 0s - loss: 1822.8590 - mae: 41.9560 - val_loss: 1298.6982 - val_mae: 36.0355 - 31ms/epoch - 1ms/step\n",
      "Epoch 129/5000\n",
      "31/31 - 0s - loss: 1741.3408 - mae: 40.9537 - val_loss: 1746.7545 - val_mae: 41.7921 - 34ms/epoch - 1ms/step\n",
      "Epoch 130/5000\n",
      "31/31 - 0s - loss: 1706.2107 - mae: 40.5484 - val_loss: 2353.1074 - val_mae: 48.5076 - 32ms/epoch - 1ms/step\n",
      "Epoch 131/5000\n",
      "31/31 - 0s - loss: 1562.1650 - mae: 39.0043 - val_loss: 2023.9161 - val_mae: 44.9860 - 34ms/epoch - 1ms/step\n",
      "Epoch 132/5000\n",
      "31/31 - 0s - loss: 1559.0470 - mae: 38.8036 - val_loss: 1328.6521 - val_mae: 36.4488 - 34ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/5000\n",
      "31/31 - 0s - loss: 1593.0658 - mae: 39.5282 - val_loss: 756.8394 - val_mae: 27.5076 - 32ms/epoch - 1ms/step\n",
      "Epoch 134/5000\n",
      "31/31 - 0s - loss: 1495.5107 - mae: 37.4276 - val_loss: 1229.9929 - val_mae: 35.0693 - 33ms/epoch - 1ms/step\n",
      "Epoch 135/5000\n",
      "31/31 - 0s - loss: 1411.0663 - mae: 36.7293 - val_loss: 2093.5610 - val_mae: 45.7535 - 33ms/epoch - 1ms/step\n",
      "Epoch 136/5000\n",
      "31/31 - 0s - loss: 1356.0789 - mae: 36.4561 - val_loss: 1408.4471 - val_mae: 37.5276 - 33ms/epoch - 1ms/step\n",
      "Epoch 137/5000\n",
      "31/31 - 0s - loss: 1388.5083 - mae: 36.4615 - val_loss: 481.3908 - val_mae: 21.9371 - 34ms/epoch - 1ms/step\n",
      "Epoch 138/5000\n",
      "31/31 - 0s - loss: 1442.1437 - mae: 37.2545 - val_loss: 1217.4424 - val_mae: 34.8901 - 33ms/epoch - 1ms/step\n",
      "Epoch 139/5000\n",
      "31/31 - 0s - loss: 1198.1558 - mae: 33.6311 - val_loss: 1603.8475 - val_mae: 40.0461 - 34ms/epoch - 1ms/step\n",
      "Epoch 140/5000\n",
      "31/31 - 0s - loss: 1190.3516 - mae: 33.8072 - val_loss: 1350.4709 - val_mae: 36.7471 - 34ms/epoch - 1ms/step\n",
      "Epoch 141/5000\n",
      "31/31 - 0s - loss: 1275.4213 - mae: 35.2980 - val_loss: 732.0756 - val_mae: 27.0542 - 33ms/epoch - 1ms/step\n",
      "Epoch 142/5000\n",
      "31/31 - 0s - loss: 1148.2926 - mae: 33.3705 - val_loss: 1285.2480 - val_mae: 35.8487 - 32ms/epoch - 1ms/step\n",
      "Epoch 143/5000\n",
      "31/31 - 0s - loss: 1099.6757 - mae: 32.6301 - val_loss: 1753.8197 - val_mae: 41.8769 - 33ms/epoch - 1ms/step\n",
      "Epoch 144/5000\n",
      "31/31 - 0s - loss: 1083.7958 - mae: 31.5748 - val_loss: 648.0179 - val_mae: 25.4539 - 32ms/epoch - 1ms/step\n",
      "Epoch 145/5000\n",
      "31/31 - 0s - loss: 1166.5886 - mae: 33.5650 - val_loss: 448.1653 - val_mae: 21.1667 - 34ms/epoch - 1ms/step\n",
      "Epoch 146/5000\n",
      "31/31 - 0s - loss: 1121.4493 - mae: 32.4931 - val_loss: 1075.2556 - val_mae: 32.7893 - 31ms/epoch - 1ms/step\n",
      "Epoch 147/5000\n",
      "31/31 - 0s - loss: 995.8038 - mae: 29.9070 - val_loss: 1578.2922 - val_mae: 39.7258 - 34ms/epoch - 1ms/step\n",
      "Epoch 148/5000\n",
      "31/31 - 0s - loss: 919.4144 - mae: 29.2433 - val_loss: 2086.7080 - val_mae: 45.6793 - 31ms/epoch - 1ms/step\n",
      "Epoch 149/5000\n",
      "31/31 - 0s - loss: 1008.5169 - mae: 30.7414 - val_loss: 402.3764 - val_mae: 20.0559 - 33ms/epoch - 1ms/step\n",
      "Epoch 150/5000\n",
      "31/31 - 0s - loss: 1018.1985 - mae: 31.2703 - val_loss: 386.1208 - val_mae: 19.6469 - 32ms/epoch - 1ms/step\n",
      "Epoch 151/5000\n",
      "31/31 - 0s - loss: 905.2268 - mae: 28.2723 - val_loss: 789.9969 - val_mae: 28.1043 - 34ms/epoch - 1ms/step\n",
      "Epoch 152/5000\n",
      "31/31 - 0s - loss: 835.2335 - mae: 28.3608 - val_loss: 1616.3492 - val_mae: 40.2024 - 31ms/epoch - 1ms/step\n",
      "Epoch 153/5000\n",
      "31/31 - 0s - loss: 945.4705 - mae: 29.3685 - val_loss: 974.4203 - val_mae: 31.2134 - 33ms/epoch - 1ms/step\n",
      "Epoch 154/5000\n",
      "31/31 - 0s - loss: 899.4374 - mae: 29.1533 - val_loss: 322.1942 - val_mae: 17.9464 - 31ms/epoch - 989us/step\n",
      "Epoch 155/5000\n",
      "31/31 - 0s - loss: 890.9255 - mae: 28.5467 - val_loss: 764.8163 - val_mae: 27.6528 - 34ms/epoch - 1ms/step\n",
      "Epoch 156/5000\n",
      "31/31 - 0s - loss: 815.4553 - mae: 27.0828 - val_loss: 851.1539 - val_mae: 29.1726 - 31ms/epoch - 1ms/step\n",
      "Epoch 157/5000\n",
      "31/31 - 0s - loss: 813.0281 - mae: 27.7557 - val_loss: 930.7970 - val_mae: 30.5065 - 34ms/epoch - 1ms/step\n",
      "Epoch 158/5000\n",
      "31/31 - 0s - loss: 742.5837 - mae: 26.2888 - val_loss: 976.0740 - val_mae: 31.2403 - 31ms/epoch - 1ms/step\n",
      "Epoch 159/5000\n",
      "31/31 - 0s - loss: 868.3514 - mae: 28.6907 - val_loss: 184.4843 - val_mae: 13.5775 - 35ms/epoch - 1ms/step\n",
      "Epoch 160/5000\n",
      "31/31 - 0s - loss: 782.4704 - mae: 27.0267 - val_loss: 1526.4148 - val_mae: 39.0679 - 32ms/epoch - 1ms/step\n",
      "Epoch 161/5000\n",
      "31/31 - 0s - loss: 726.4634 - mae: 25.6743 - val_loss: 685.7048 - val_mae: 26.1832 - 34ms/epoch - 1ms/step\n",
      "Epoch 162/5000\n",
      "31/31 - 0s - loss: 667.9699 - mae: 25.2452 - val_loss: 1187.6499 - val_mae: 34.4607 - 35ms/epoch - 1ms/step\n",
      "Epoch 163/5000\n",
      "31/31 - 0s - loss: 693.0107 - mae: 25.3202 - val_loss: 800.1323 - val_mae: 28.2840 - 35ms/epoch - 1ms/step\n",
      "Epoch 164/5000\n",
      "31/31 - 0s - loss: 745.3373 - mae: 26.6811 - val_loss: 343.7018 - val_mae: 18.5358 - 33ms/epoch - 1ms/step\n",
      "Epoch 165/5000\n",
      "31/31 - 0s - loss: 721.9415 - mae: 25.2720 - val_loss: 610.7628 - val_mae: 24.7108 - 33ms/epoch - 1ms/step\n",
      "Epoch 166/5000\n",
      "31/31 - 0s - loss: 600.9734 - mae: 22.8686 - val_loss: 1501.4342 - val_mae: 38.7469 - 33ms/epoch - 1ms/step\n",
      "Epoch 167/5000\n",
      "31/31 - 0s - loss: 628.5378 - mae: 23.4295 - val_loss: 136.1725 - val_mae: 11.6636 - 34ms/epoch - 1ms/step\n",
      "Epoch 168/5000\n",
      "31/31 - 0s - loss: 704.5547 - mae: 24.8289 - val_loss: 119.7063 - val_mae: 10.9354 - 33ms/epoch - 1ms/step\n",
      "Epoch 169/5000\n",
      "31/31 - 0s - loss: 602.5987 - mae: 23.6417 - val_loss: 1273.9353 - val_mae: 35.6903 - 34ms/epoch - 1ms/step\n",
      "Epoch 170/5000\n",
      "31/31 - 0s - loss: 536.5554 - mae: 21.3768 - val_loss: 705.0486 - val_mae: 26.5505 - 32ms/epoch - 1ms/step\n",
      "Epoch 171/5000\n",
      "31/31 - 0s - loss: 631.3021 - mae: 22.5728 - val_loss: 261.3262 - val_mae: 16.1613 - 34ms/epoch - 1ms/step\n",
      "Epoch 172/5000\n",
      "31/31 - 0s - loss: 631.6989 - mae: 23.9060 - val_loss: 364.0403 - val_mae: 19.0766 - 35ms/epoch - 1ms/step\n",
      "Epoch 173/5000\n",
      "31/31 - 0s - loss: 485.7953 - mae: 19.8461 - val_loss: 1251.5022 - val_mae: 35.3747 - 34ms/epoch - 1ms/step\n",
      "Epoch 174/5000\n",
      "31/31 - 0s - loss: 487.2380 - mae: 20.0565 - val_loss: 390.3499 - val_mae: 19.7542 - 33ms/epoch - 1ms/step\n",
      "Epoch 175/5000\n",
      "31/31 - 0s - loss: 547.2955 - mae: 22.1748 - val_loss: 375.0017 - val_mae: 19.3614 - 33ms/epoch - 1ms/step\n",
      "Epoch 176/5000\n",
      "31/31 - 0s - loss: 522.0074 - mae: 21.8901 - val_loss: 302.4421 - val_mae: 17.3873 - 33ms/epoch - 1ms/step\n",
      "Epoch 177/5000\n",
      "31/31 - 0s - loss: 420.1492 - mae: 18.6709 - val_loss: 1137.8254 - val_mae: 33.7295 - 34ms/epoch - 1ms/step\n",
      "Epoch 178/5000\n",
      "31/31 - 0s - loss: 493.9563 - mae: 20.8215 - val_loss: 14.5565 - val_mae: 3.7983 - 33ms/epoch - 1ms/step\n",
      "Epoch 179/5000\n",
      "31/31 - 0s - loss: 476.5881 - mae: 19.3010 - val_loss: 605.5808 - val_mae: 24.6057 - 34ms/epoch - 1ms/step\n",
      "Epoch 180/5000\n",
      "31/31 - 0s - loss: 357.6729 - mae: 17.1360 - val_loss: 605.1706 - val_mae: 24.5977 - 33ms/epoch - 1ms/step\n",
      "Epoch 181/5000\n",
      "31/31 - 0s - loss: 398.4827 - mae: 16.9047 - val_loss: 52.3545 - val_mae: 7.2263 - 33ms/epoch - 1ms/step\n",
      "Epoch 182/5000\n",
      "31/31 - 0s - loss: 441.3984 - mae: 19.3481 - val_loss: 155.7473 - val_mae: 12.4748 - 31ms/epoch - 1ms/step\n",
      "Epoch 183/5000\n",
      "31/31 - 0s - loss: 330.0790 - mae: 16.7059 - val_loss: 656.7028 - val_mae: 25.6235 - 35ms/epoch - 1ms/step\n",
      "Epoch 184/5000\n",
      "31/31 - 0s - loss: 352.6828 - mae: 17.3411 - val_loss: 327.1077 - val_mae: 18.0826 - 32ms/epoch - 1ms/step\n",
      "Epoch 185/5000\n",
      "31/31 - 0s - loss: 408.2958 - mae: 16.9536 - val_loss: 34.8912 - val_mae: 5.8956 - 34ms/epoch - 1ms/step\n",
      "Epoch 186/5000\n",
      "31/31 - 0s - loss: 286.8536 - mae: 14.5114 - val_loss: 516.6932 - val_mae: 22.7277 - 35ms/epoch - 1ms/step\n",
      "Epoch 187/5000\n",
      "31/31 - 0s - loss: 338.5807 - mae: 17.2667 - val_loss: 61.5592 - val_mae: 7.8373 - 34ms/epoch - 1ms/step\n",
      "Epoch 188/5000\n",
      "31/31 - 0s - loss: 335.5257 - mae: 15.8726 - val_loss: 247.1327 - val_mae: 15.7159 - 34ms/epoch - 1ms/step\n",
      "Epoch 189/5000\n",
      "31/31 - 0s - loss: 238.3251 - mae: 11.5402 - val_loss: 881.7599 - val_mae: 29.6923 - 34ms/epoch - 1ms/step\n",
      "Epoch 190/5000\n",
      "31/31 - 0s - loss: 370.1151 - mae: 16.0072 - val_loss: 36.0940 - val_mae: 5.9960 - 33ms/epoch - 1ms/step\n",
      "Epoch 191/5000\n",
      "31/31 - 0s - loss: 348.5005 - mae: 16.4167 - val_loss: 300.1108 - val_mae: 17.3199 - 33ms/epoch - 1ms/step\n",
      "Epoch 192/5000\n",
      "31/31 - 0s - loss: 216.4404 - mae: 13.5673 - val_loss: 719.6641 - val_mae: 26.8238 - 33ms/epoch - 1ms/step\n",
      "Epoch 193/5000\n",
      "31/31 - 0s - loss: 246.1660 - mae: 13.4354 - val_loss: 294.6246 - val_mae: 17.1606 - 32ms/epoch - 1ms/step\n",
      "Epoch 194/5000\n",
      "31/31 - 0s - loss: 303.8807 - mae: 15.1090 - val_loss: 82.1321 - val_mae: 9.0544 - 32ms/epoch - 1ms/step\n",
      "Epoch 195/5000\n",
      "31/31 - 0s - loss: 245.5094 - mae: 14.2966 - val_loss: 159.6523 - val_mae: 12.6298 - 34ms/epoch - 1ms/step\n",
      "Epoch 196/5000\n",
      "31/31 - 0s - loss: 239.4859 - mae: 14.0795 - val_loss: 255.3269 - val_mae: 15.9739 - 33ms/epoch - 1ms/step\n",
      "Epoch 197/5000\n",
      "31/31 - 0s - loss: 260.9352 - mae: 14.5083 - val_loss: 14.1008 - val_mae: 3.7349 - 33ms/epoch - 1ms/step\n",
      "Epoch 198/5000\n",
      "31/31 - 0s - loss: 200.6132 - mae: 9.0527 - val_loss: 302.3614 - val_mae: 17.3839 - 31ms/epoch - 1ms/step\n",
      "Epoch 199/5000\n",
      "31/31 - 0s - loss: 204.3227 - mae: 12.5324 - val_loss: 8.2002 - val_mae: 2.8371 - 34ms/epoch - 1ms/step\n",
      "Epoch 200/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 - 0s - loss: 259.4500 - mae: 12.4168 - val_loss: 139.5098 - val_mae: 11.8048 - 32ms/epoch - 1ms/step\n",
      "Epoch 201/5000\n",
      "31/31 - 0s - loss: 174.4029 - mae: 9.9544 - val_loss: 0.1564 - val_mae: 0.3561 - 34ms/epoch - 1ms/step\n",
      "Epoch 202/5000\n",
      "31/31 - 0s - loss: 240.9443 - mae: 11.5416 - val_loss: 115.0577 - val_mae: 10.7196 - 31ms/epoch - 1ms/step\n",
      "Epoch 203/5000\n",
      "31/31 - 0s - loss: 167.1726 - mae: 9.7870 - val_loss: 274.1435 - val_mae: 16.5525 - 33ms/epoch - 1ms/step\n",
      "Epoch 204/5000\n",
      "31/31 - 0s - loss: 218.8835 - mae: 12.7711 - val_loss: 15.1087 - val_mae: 3.8672 - 31ms/epoch - 1ms/step\n",
      "Epoch 205/5000\n",
      "31/31 - 0s - loss: 185.6738 - mae: 12.8173 - val_loss: 454.5124 - val_mae: 21.3152 - 34ms/epoch - 1ms/step\n",
      "Epoch 206/5000\n",
      "31/31 - 0s - loss: 169.9216 - mae: 10.0925 - val_loss: 3.0750 - val_mae: 1.7078 - 31ms/epoch - 1ms/step\n",
      "Epoch 207/5000\n",
      "31/31 - 0s - loss: 137.5623 - mae: 9.7096 - val_loss: 697.9440 - val_mae: 26.4153 - 34ms/epoch - 1ms/step\n",
      "Epoch 208/5000\n",
      "31/31 - 0s - loss: 188.9465 - mae: 10.5074 - val_loss: 30.9444 - val_mae: 5.5483 - 33ms/epoch - 1ms/step\n",
      "Epoch 209/5000\n",
      "31/31 - 0s - loss: 184.2146 - mae: 12.1264 - val_loss: 249.8356 - val_mae: 15.8006 - 32ms/epoch - 1ms/step\n",
      "Epoch 210/5000\n",
      "31/31 - 0s - loss: 154.8595 - mae: 9.1257 - val_loss: 0.9088 - val_mae: 0.8637 - 33ms/epoch - 1ms/step\n",
      "Epoch 211/5000\n",
      "31/31 - 0s - loss: 170.7774 - mae: 10.4743 - val_loss: 237.8144 - val_mae: 15.4163 - 33ms/epoch - 1ms/step\n",
      "Epoch 212/5000\n",
      "31/31 - 0s - loss: 141.9218 - mae: 8.3098 - val_loss: 9.5677 - val_mae: 3.0670 - 35ms/epoch - 1ms/step\n",
      "Epoch 213/5000\n",
      "31/31 - 0s - loss: 162.5142 - mae: 11.3602 - val_loss: 3.8572 - val_mae: 1.9225 - 33ms/epoch - 1ms/step\n",
      "Epoch 214/5000\n",
      "31/31 - 0s - loss: 128.9265 - mae: 8.7882 - val_loss: 786.3848 - val_mae: 28.0392 - 34ms/epoch - 1ms/step\n",
      "Epoch 215/5000\n",
      "31/31 - 0s - loss: 163.8521 - mae: 8.8454 - val_loss: 24.3188 - val_mae: 4.9152 - 34ms/epoch - 1ms/step\n",
      "Epoch 216/5000\n",
      "31/31 - 0s - loss: 135.3672 - mae: 9.2124 - val_loss: 314.0158 - val_mae: 17.7162 - 34ms/epoch - 1ms/step\n",
      "Epoch 217/5000\n",
      "31/31 - 0s - loss: 224.3045 - mae: 10.5524 - val_loss: 3.4669 - val_mae: 1.8167 - 33ms/epoch - 1ms/step\n",
      "Epoch 218/5000\n",
      "31/31 - 0s - loss: 77.5191 - mae: 7.3815 - val_loss: 115.9490 - val_mae: 10.7601 - 32ms/epoch - 1ms/step\n",
      "Epoch 219/5000\n",
      "31/31 - 0s - loss: 180.5987 - mae: 11.4278 - val_loss: 23.8007 - val_mae: 4.8620 - 33ms/epoch - 1ms/step\n",
      "Epoch 220/5000\n",
      "31/31 - 0s - loss: 82.1359 - mae: 7.5385 - val_loss: 63.0334 - val_mae: 7.9288 - 33ms/epoch - 1ms/step\n",
      "Epoch 221/5000\n",
      "31/31 - 0s - loss: 159.9020 - mae: 9.6728 - val_loss: 31.5762 - val_mae: 5.6049 - 33ms/epoch - 1ms/step\n",
      "Epoch 222/5000\n",
      "31/31 - 0s - loss: 100.6794 - mae: 7.8796 - val_loss: 210.2040 - val_mae: 14.4925 - 31ms/epoch - 997us/step\n",
      "Epoch 223/5000\n",
      "31/31 - 0s - loss: 138.1323 - mae: 9.1741 - val_loss: 4.5982 - val_mae: 2.1052 - 33ms/epoch - 1ms/step\n",
      "Epoch 224/5000\n",
      "31/31 - 0s - loss: 131.4642 - mae: 9.4726 - val_loss: 72.4739 - val_mae: 8.5039 - 32ms/epoch - 1ms/step\n",
      "Epoch 225/5000\n",
      "31/31 - 0s - loss: 78.0139 - mae: 7.8398 - val_loss: 112.9456 - val_mae: 10.6195 - 33ms/epoch - 1ms/step\n",
      "Epoch 226/5000\n",
      "31/31 - 0s - loss: 135.4343 - mae: 9.3179 - val_loss: 105.1113 - val_mae: 10.2447 - 32ms/epoch - 1ms/step\n",
      "Epoch 227/5000\n",
      "31/31 - 0s - loss: 108.3538 - mae: 8.7009 - val_loss: 5.1528 - val_mae: 2.2329 - 33ms/epoch - 1ms/step\n",
      "Epoch 228/5000\n",
      "31/31 - 0s - loss: 136.1016 - mae: 10.0474 - val_loss: 27.5896 - val_mae: 5.2373 - 33ms/epoch - 1ms/step\n",
      "Epoch 229/5000\n",
      "31/31 - 0s - loss: 82.2653 - mae: 7.7815 - val_loss: 166.3053 - val_mae: 12.8893 - 44ms/epoch - 1ms/step\n",
      "Epoch 230/5000\n",
      "31/31 - 0s - loss: 84.7602 - mae: 6.8550 - val_loss: 33.6785 - val_mae: 5.7891 - 33ms/epoch - 1ms/step\n",
      "Epoch 231/5000\n",
      "31/31 - 0s - loss: 123.8684 - mae: 9.7833 - val_loss: 2.1275 - val_mae: 1.4007 - 32ms/epoch - 1ms/step\n",
      "Epoch 232/5000\n",
      "31/31 - 0s - loss: 73.4216 - mae: 6.6997 - val_loss: 631.5553 - val_mae: 25.1278 - 34ms/epoch - 1ms/step\n",
      "Epoch 233/5000\n",
      "31/31 - 0s - loss: 76.6325 - mae: 7.0564 - val_loss: 66.0549 - val_mae: 8.1171 - 32ms/epoch - 1ms/step\n",
      "Epoch 234/5000\n",
      "31/31 - 0s - loss: 103.2803 - mae: 7.7061 - val_loss: 0.2023 - val_mae: 0.3917 - 33ms/epoch - 1ms/step\n",
      "Epoch 235/5000\n",
      "31/31 - 0s - loss: 85.2631 - mae: 6.8851 - val_loss: 203.4677 - val_mae: 14.2583 - 31ms/epoch - 1ms/step\n",
      "Epoch 236/5000\n",
      "31/31 - 0s - loss: 87.1303 - mae: 7.3462 - val_loss: 1.2928 - val_mae: 1.0617 - 33ms/epoch - 1ms/step\n",
      "Epoch 237/5000\n",
      "31/31 - 0s - loss: 104.7741 - mae: 7.5880 - val_loss: 2.2838 - val_mae: 1.4550 - 31ms/epoch - 1ms/step\n",
      "Epoch 238/5000\n",
      "31/31 - 0s - loss: 44.2684 - mae: 4.5925 - val_loss: 23.0810 - val_mae: 4.7876 - 33ms/epoch - 1ms/step\n",
      "Epoch 239/5000\n",
      "31/31 - 0s - loss: 88.1693 - mae: 8.2265 - val_loss: 373.5238 - val_mae: 19.3227 - 31ms/epoch - 995us/step\n",
      "Epoch 240/5000\n",
      "31/31 - 0s - loss: 60.5826 - mae: 5.5817 - val_loss: 2.4047 - val_mae: 1.4975 - 33ms/epoch - 1ms/step\n",
      "Epoch 241/5000\n",
      "31/31 - 0s - loss: 59.3439 - mae: 6.4186 - val_loss: 110.8273 - val_mae: 10.5194 - 31ms/epoch - 1ms/step\n",
      "Epoch 242/5000\n",
      "31/31 - 0s - loss: 99.5801 - mae: 7.7438 - val_loss: 1.4982 - val_mae: 1.1560 - 33ms/epoch - 1ms/step\n",
      "Epoch 243/5000\n",
      "31/31 - 0s - loss: 39.3535 - mae: 4.4473 - val_loss: 0.8370 - val_mae: 0.8205 - 32ms/epoch - 1ms/step\n",
      "Epoch 244/5000\n",
      "31/31 - 0s - loss: 46.1085 - mae: 5.1650 - val_loss: 2.7366 - val_mae: 1.6038 - 34ms/epoch - 1ms/step\n",
      "Epoch 245/5000\n",
      "31/31 - 0s - loss: 54.3115 - mae: 5.5606 - val_loss: 56.2872 - val_mae: 7.4912 - 32ms/epoch - 1ms/step\n",
      "Epoch 246/5000\n",
      "31/31 - 0s - loss: 65.7803 - mae: 5.4153 - val_loss: 7.3435 - val_mae: 2.6788 - 33ms/epoch - 1ms/step\n",
      "Epoch 247/5000\n",
      "31/31 - 0s - loss: 68.3399 - mae: 6.8908 - val_loss: 10.0895 - val_mae: 3.1498 - 34ms/epoch - 1ms/step\n",
      "Epoch 248/5000\n",
      "31/31 - 0s - loss: 43.8832 - mae: 4.3373 - val_loss: 4.5015 - val_mae: 2.0816 - 33ms/epoch - 1ms/step\n",
      "Epoch 249/5000\n",
      "31/31 - 0s - loss: 47.4086 - mae: 5.8808 - val_loss: 0.3963 - val_mae: 0.4818 - 33ms/epoch - 1ms/step\n",
      "Epoch 250/5000\n",
      "31/31 - 0s - loss: 46.9128 - mae: 5.0253 - val_loss: 25.4571 - val_mae: 5.0291 - 35ms/epoch - 1ms/step\n",
      "Epoch 251/5000\n",
      "31/31 - 0s - loss: 49.8863 - mae: 4.6944 - val_loss: 3.0105 - val_mae: 1.6874 - 34ms/epoch - 1ms/step\n",
      "Epoch 252/5000\n",
      "31/31 - 0s - loss: 36.1670 - mae: 5.4548 - val_loss: 960.2375 - val_mae: 30.9851 - 34ms/epoch - 1ms/step\n",
      "Epoch 253/5000\n",
      "31/31 - 0s - loss: 58.6167 - mae: 4.4947 - val_loss: 13.4961 - val_mae: 3.6512 - 33ms/epoch - 1ms/step\n",
      "Epoch 254/5000\n",
      "31/31 - 0s - loss: 62.3295 - mae: 6.6948 - val_loss: 11.3162 - val_mae: 3.3402 - 33ms/epoch - 1ms/step\n",
      "Epoch 255/5000\n",
      "31/31 - 0s - loss: 29.4437 - mae: 3.6362 - val_loss: 0.8673 - val_mae: 0.8404 - 33ms/epoch - 1ms/step\n",
      "Epoch 256/5000\n",
      "31/31 - 0s - loss: 37.6056 - mae: 4.9893 - val_loss: 3.8931 - val_mae: 1.9327 - 32ms/epoch - 1ms/step\n",
      "Epoch 257/5000\n",
      "31/31 - 0s - loss: 16.2969 - mae: 3.3994 - val_loss: 7.1280 - val_mae: 2.6393 - 34ms/epoch - 1ms/step\n",
      "Epoch 258/5000\n",
      "31/31 - 0s - loss: 94.0839 - mae: 5.7027 - val_loss: 1.6082 - val_mae: 1.2013 - 32ms/epoch - 1ms/step\n",
      "Epoch 259/5000\n",
      "31/31 - 0s - loss: 30.6132 - mae: 4.0360 - val_loss: 1.7586 - val_mae: 1.2641 - 33ms/epoch - 1ms/step\n",
      "Epoch 260/5000\n",
      "31/31 - 0s - loss: 38.5644 - mae: 4.0587 - val_loss: 5.2235 - val_mae: 2.2507 - 31ms/epoch - 1ms/step\n",
      "Epoch 261/5000\n",
      "31/31 - 0s - loss: 29.1455 - mae: 4.8994 - val_loss: 125.9540 - val_mae: 11.2161 - 32ms/epoch - 1ms/step\n",
      "Epoch 262/5000\n",
      "31/31 - 0s - loss: 44.3221 - mae: 4.0124 - val_loss: 2.0619 - val_mae: 1.3790 - 32ms/epoch - 1ms/step\n",
      "Epoch 263/5000\n",
      "31/31 - 0s - loss: 26.0619 - mae: 4.1590 - val_loss: 3.3032 - val_mae: 1.7731 - 32ms/epoch - 1ms/step\n",
      "Epoch 264/5000\n",
      "31/31 - 0s - loss: 39.8513 - mae: 4.6460 - val_loss: 23.1682 - val_mae: 4.7966 - 32ms/epoch - 1ms/step\n",
      "Epoch 265/5000\n",
      "31/31 - 0s - loss: 40.0031 - mae: 4.8930 - val_loss: 16.1050 - val_mae: 3.9928 - 34ms/epoch - 1ms/step\n",
      "Epoch 266/5000\n",
      "31/31 - 0s - loss: 21.5460 - mae: 3.7954 - val_loss: 162.4404 - val_mae: 12.7392 - 31ms/epoch - 1ms/step\n",
      "Epoch 267/5000\n",
      "31/31 - 0s - loss: 23.0276 - mae: 3.3663 - val_loss: 22.2593 - val_mae: 4.7008 - 33ms/epoch - 1ms/step\n",
      "Epoch 268/5000\n",
      "31/31 - 0s - loss: 42.7872 - mae: 4.8703 - val_loss: 32.9127 - val_mae: 5.7229 - 32ms/epoch - 1ms/step\n",
      "Epoch 269/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 - 0s - loss: 24.5723 - mae: 4.3398 - val_loss: 0.2196 - val_mae: 0.3677 - 34ms/epoch - 1ms/step\n",
      "Epoch 270/5000\n",
      "31/31 - 0s - loss: 44.2455 - mae: 4.1207 - val_loss: 10.5114 - val_mae: 3.2179 - 32ms/epoch - 1ms/step\n",
      "Epoch 271/5000\n",
      "31/31 - 0s - loss: 21.7859 - mae: 3.9716 - val_loss: 8.5755 - val_mae: 2.9015 - 33ms/epoch - 1ms/step\n",
      "Epoch 272/5000\n",
      "31/31 - 0s - loss: 25.5389 - mae: 4.0024 - val_loss: 55.8531 - val_mae: 7.4626 - 32ms/epoch - 1ms/step\n",
      "Epoch 273/5000\n",
      "31/31 - 0s - loss: 43.7871 - mae: 4.5354 - val_loss: 2.9325 - val_mae: 1.6651 - 33ms/epoch - 1ms/step\n",
      "Epoch 274/5000\n",
      "31/31 - 0s - loss: 11.0021 - mae: 2.6406 - val_loss: 7.1362 - val_mae: 2.6410 - 32ms/epoch - 1ms/step\n",
      "Epoch 275/5000\n",
      "31/31 - 0s - loss: 34.8496 - mae: 4.4159 - val_loss: 4.6857 - val_mae: 2.1280 - 33ms/epoch - 1ms/step\n",
      "Epoch 276/5000\n",
      "31/31 - 0s - loss: 24.9489 - mae: 3.6334 - val_loss: 5.3144 - val_mae: 2.2704 - 35ms/epoch - 1ms/step\n",
      "Epoch 277/5000\n",
      "31/31 - 0s - loss: 45.1288 - mae: 4.4201 - val_loss: 3.9779 - val_mae: 1.9549 - 34ms/epoch - 1ms/step\n",
      "Epoch 278/5000\n",
      "31/31 - 0s - loss: 11.9056 - mae: 2.5372 - val_loss: 15.7542 - val_mae: 3.9489 - 34ms/epoch - 1ms/step\n",
      "Epoch 279/5000\n",
      "31/31 - 0s - loss: 49.2546 - mae: 4.7584 - val_loss: 0.6167 - val_mae: 0.6785 - 33ms/epoch - 1ms/step\n",
      "Epoch 280/5000\n",
      "31/31 - 0s - loss: 10.1115 - mae: 2.5898 - val_loss: 4.5315 - val_mae: 2.0912 - 33ms/epoch - 1ms/step\n",
      "Epoch 281/5000\n",
      "31/31 - 0s - loss: 25.5811 - mae: 4.0493 - val_loss: 0.1955 - val_mae: 0.3569 - 34ms/epoch - 1ms/step\n",
      "Epoch 282/5000\n",
      "31/31 - 0s - loss: 41.6192 - mae: 4.4384 - val_loss: 4.8997 - val_mae: 2.1792 - 33ms/epoch - 1ms/step\n",
      "Epoch 283/5000\n",
      "31/31 - 0s - loss: 15.1776 - mae: 3.2926 - val_loss: 44.8335 - val_mae: 6.6839 - 36ms/epoch - 1ms/step\n",
      "Epoch 284/5000\n",
      "31/31 - 0s - loss: 30.6874 - mae: 3.6676 - val_loss: 10.9595 - val_mae: 3.2866 - 35ms/epoch - 1ms/step\n",
      "Epoch 285/5000\n",
      "31/31 - 0s - loss: 31.9658 - mae: 4.1549 - val_loss: 0.1758 - val_mae: 0.3574 - 32ms/epoch - 1ms/step\n",
      "Epoch 286/5000\n",
      "31/31 - 0s - loss: 8.8166 - mae: 2.4283 - val_loss: 7.0656 - val_mae: 2.6274 - 32ms/epoch - 1ms/step\n",
      "Epoch 287/5000\n",
      "31/31 - 0s - loss: 41.4162 - mae: 4.2575 - val_loss: 2.0430 - val_mae: 1.3719 - 32ms/epoch - 1ms/step\n",
      "Epoch 288/5000\n",
      "31/31 - 0s - loss: 27.2683 - mae: 3.7573 - val_loss: 7.3450 - val_mae: 2.6801 - 34ms/epoch - 1ms/step\n",
      "Epoch 289/5000\n",
      "31/31 - 0s - loss: 8.9382 - mae: 2.5596 - val_loss: 50.8829 - val_mae: 7.1225 - 32ms/epoch - 1ms/step\n",
      "Epoch 290/5000\n",
      "31/31 - 0s - loss: 41.4696 - mae: 3.9393 - val_loss: 2.6045 - val_mae: 1.5638 - 33ms/epoch - 1ms/step\n",
      "Epoch 291/5000\n",
      "31/31 - 0s - loss: 22.9042 - mae: 3.6166 - val_loss: 2.2187 - val_mae: 1.4357 - 33ms/epoch - 1ms/step\n",
      "Epoch 292/5000\n",
      "31/31 - 0s - loss: 41.4115 - mae: 4.2403 - val_loss: 0.1737 - val_mae: 0.3543 - 35ms/epoch - 1ms/step\n",
      "Epoch 293/5000\n",
      "31/31 - 0s - loss: 9.2471 - mae: 2.3372 - val_loss: 1.1943 - val_mae: 1.0168 - 33ms/epoch - 1ms/step\n",
      "Epoch 294/5000\n",
      "31/31 - 0s - loss: 17.1304 - mae: 3.3997 - val_loss: 7.0561 - val_mae: 2.6261 - 35ms/epoch - 1ms/step\n",
      "Epoch 295/5000\n",
      "31/31 - 0s - loss: 33.2396 - mae: 3.6740 - val_loss: 5.3254 - val_mae: 2.2720 - 34ms/epoch - 1ms/step\n",
      "Epoch 296/5000\n",
      "31/31 - 0s - loss: 8.9807 - mae: 2.2432 - val_loss: 15.0287 - val_mae: 3.8555 - 32ms/epoch - 1ms/step\n",
      "Epoch 297/5000\n",
      "31/31 - 0s - loss: 45.9512 - mae: 3.8356 - val_loss: 3.2702 - val_mae: 1.7628 - 33ms/epoch - 1ms/step\n",
      "Epoch 298/5000\n",
      "31/31 - 0s - loss: 10.3182 - mae: 2.7995 - val_loss: 1.0257 - val_mae: 0.9302 - 33ms/epoch - 1ms/step\n",
      "Epoch 299/5000\n",
      "31/31 - 0s - loss: 33.6620 - mae: 3.9066 - val_loss: 0.7243 - val_mae: 0.7514 - 32ms/epoch - 1ms/step\n",
      "Epoch 300/5000\n",
      "31/31 - 0s - loss: 22.5814 - mae: 3.6467 - val_loss: 50.3447 - val_mae: 7.0837 - 35ms/epoch - 1ms/step\n",
      "Epoch 301/5000\n",
      "31/31 - 0s - loss: 7.3732 - mae: 2.1369 - val_loss: 9.1157 - val_mae: 2.9921 - 32ms/epoch - 1ms/step\n",
      "Epoch 302/5000\n",
      "31/31 - 0s - loss: 33.1854 - mae: 3.7000 - val_loss: 10.5841 - val_mae: 3.2283 - 32ms/epoch - 1ms/step\n",
      "Epoch 303/5000\n",
      "31/31 - 0s - loss: 5.2329 - mae: 1.8873 - val_loss: 12.0917 - val_mae: 3.4546 - 32ms/epoch - 1ms/step\n",
      "Epoch 304/5000\n",
      "31/31 - 0s - loss: 28.1132 - mae: 3.5630 - val_loss: 0.5687 - val_mae: 0.6409 - 34ms/epoch - 1ms/step\n",
      "Epoch 305/5000\n",
      "31/31 - 0s - loss: 37.6047 - mae: 3.6025 - val_loss: 2.2578 - val_mae: 1.4495 - 32ms/epoch - 1ms/step\n",
      "Epoch 306/5000\n",
      "31/31 - 0s - loss: 9.0869 - mae: 2.4607 - val_loss: 2.2324 - val_mae: 1.4403 - 31ms/epoch - 1ms/step\n",
      "Epoch 307/5000\n",
      "31/31 - 0s - loss: 24.5812 - mae: 3.2562 - val_loss: 0.1608 - val_mae: 0.3540 - 33ms/epoch - 1ms/step\n",
      "Epoch 308/5000\n",
      "31/31 - 0s - loss: 33.2721 - mae: 3.8345 - val_loss: 34.0740 - val_mae: 5.8237 - 34ms/epoch - 1ms/step\n",
      "Epoch 309/5000\n",
      "31/31 - 0s - loss: 9.7371 - mae: 2.4655 - val_loss: 2.8394 - val_mae: 1.6378 - 33ms/epoch - 1ms/step\n",
      "Epoch 310/5000\n",
      "31/31 - 0s - loss: 12.9030 - mae: 2.8633 - val_loss: 135.7066 - val_mae: 11.6431 - 33ms/epoch - 1ms/step\n",
      "Epoch 311/5000\n",
      "31/31 - 0s - loss: 28.0491 - mae: 3.2415 - val_loss: 20.0689 - val_mae: 4.4621 - 33ms/epoch - 1ms/step\n",
      "Epoch 312/5000\n",
      "31/31 - 0s - loss: 39.4405 - mae: 4.0426 - val_loss: 0.1538 - val_mae: 0.3513 - 33ms/epoch - 1ms/step\n",
      "Epoch 313/5000\n",
      "31/31 - 0s - loss: 7.9947 - mae: 2.0394 - val_loss: 14.6601 - val_mae: 3.8087 - 33ms/epoch - 1ms/step\n",
      "Epoch 314/5000\n",
      "31/31 - 0s - loss: 15.8239 - mae: 3.2526 - val_loss: 0.2143 - val_mae: 0.3623 - 35ms/epoch - 1ms/step\n",
      "Epoch 315/5000\n",
      "31/31 - 0s - loss: 26.1097 - mae: 3.4514 - val_loss: 10.0958 - val_mae: 3.1517 - 35ms/epoch - 1ms/step\n",
      "Epoch 316/5000\n",
      "31/31 - 0s - loss: 8.7788 - mae: 2.3865 - val_loss: 6.1408 - val_mae: 2.4466 - 34ms/epoch - 1ms/step\n",
      "Epoch 317/5000\n",
      "31/31 - 0s - loss: 35.4845 - mae: 3.7929 - val_loss: 3.1915 - val_mae: 1.7420 - 31ms/epoch - 1ms/step\n",
      "Epoch 318/5000\n",
      "31/31 - 0s - loss: 5.7016 - mae: 2.0066 - val_loss: 0.9236 - val_mae: 0.8759 - 34ms/epoch - 1ms/step\n",
      "Epoch 319/5000\n",
      "31/31 - 0s - loss: 24.7903 - mae: 3.7228 - val_loss: 20.8369 - val_mae: 4.5471 - 32ms/epoch - 1ms/step\n",
      "Epoch 320/5000\n",
      "31/31 - 0s - loss: 33.8957 - mae: 3.1157 - val_loss: 153.7297 - val_mae: 12.3926 - 33ms/epoch - 1ms/step\n",
      "Epoch 321/5000\n",
      "31/31 - 0s - loss: 10.6428 - mae: 2.3441 - val_loss: 2.5696 - val_mae: 1.5539 - 32ms/epoch - 1ms/step\n",
      "Epoch 322/5000\n",
      "31/31 - 0s - loss: 12.6633 - mae: 2.8930 - val_loss: 0.6408 - val_mae: 0.6960 - 34ms/epoch - 1ms/step\n",
      "Epoch 323/5000\n",
      "31/31 - 0s - loss: 29.2475 - mae: 3.3851 - val_loss: 1.0565 - val_mae: 0.9475 - 33ms/epoch - 1ms/step\n",
      "Epoch 324/5000\n",
      "31/31 - 0s - loss: 6.3074 - mae: 2.0430 - val_loss: 0.3036 - val_mae: 0.4745 - 34ms/epoch - 1ms/step\n",
      "Epoch 325/5000\n",
      "31/31 - 0s - loss: 18.0154 - mae: 2.8117 - val_loss: 1.0492 - val_mae: 0.9456 - 33ms/epoch - 1ms/step\n",
      "Epoch 326/5000\n",
      "31/31 - 0s - loss: 24.3325 - mae: 3.7291 - val_loss: 2.1710 - val_mae: 1.4187 - 36ms/epoch - 1ms/step\n",
      "Epoch 327/5000\n",
      "31/31 - 0s - loss: 6.6535 - mae: 2.2457 - val_loss: 49.6736 - val_mae: 7.0374 - 34ms/epoch - 1ms/step\n",
      "Epoch 328/5000\n",
      "31/31 - 0s - loss: 24.4474 - mae: 3.5412 - val_loss: 2.2268 - val_mae: 1.4399 - 35ms/epoch - 1ms/step\n",
      "Epoch 329/5000\n",
      "31/31 - 0s - loss: 18.7029 - mae: 3.3293 - val_loss: 6.0161 - val_mae: 2.4210 - 32ms/epoch - 1ms/step\n",
      "Epoch 330/5000\n",
      "31/31 - 0s - loss: 4.1860 - mae: 1.6818 - val_loss: 13.1114 - val_mae: 3.5994 - 32ms/epoch - 1ms/step\n",
      "Epoch 331/5000\n",
      "31/31 - 0s - loss: 25.7934 - mae: 3.3348 - val_loss: 4.3591 - val_mae: 2.0504 - 33ms/epoch - 1ms/step\n",
      "Epoch 332/5000\n",
      "31/31 - 0s - loss: 25.4053 - mae: 3.4882 - val_loss: 4.2177 - val_mae: 2.0153 - 31ms/epoch - 1ms/step\n",
      "Epoch 333/5000\n",
      "31/31 - 0s - loss: 3.4287 - mae: 1.5821 - val_loss: 6.0788 - val_mae: 2.4346 - 32ms/epoch - 1ms/step\n",
      "Epoch 334/5000\n",
      "31/31 - 0s - loss: 29.1787 - mae: 3.2426 - val_loss: 1.0090 - val_mae: 0.9259 - 31ms/epoch - 1ms/step\n",
      "Epoch 335/5000\n",
      "31/31 - 0s - loss: 5.4900 - mae: 1.7742 - val_loss: 5.1722 - val_mae: 2.2405 - 34ms/epoch - 1ms/step\n",
      "Epoch 336/5000\n",
      "31/31 - 0s - loss: 19.1293 - mae: 3.2510 - val_loss: 0.1520 - val_mae: 0.3480 - 32ms/epoch - 1ms/step\n",
      "Epoch 337/5000\n",
      "31/31 - 0s - loss: 21.1118 - mae: 3.0057 - val_loss: 4.8487 - val_mae: 2.1666 - 44ms/epoch - 1ms/step\n",
      "Epoch 338/5000\n",
      "31/31 - 0s - loss: 5.2858 - mae: 1.9606 - val_loss: 26.2717 - val_mae: 5.1111 - 33ms/epoch - 1ms/step\n",
      "Epoch 339/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 - 0s - loss: 32.6084 - mae: 3.4778 - val_loss: 32.8791 - val_mae: 5.7207 - 34ms/epoch - 1ms/step\n",
      "Epoch 340/5000\n",
      "31/31 - 0s - loss: 11.8681 - mae: 2.8500 - val_loss: 114.4941 - val_mae: 10.6941 - 36ms/epoch - 1ms/step\n",
      "Epoch 341/5000\n",
      "31/31 - 0s - loss: 11.1135 - mae: 2.2953 - val_loss: 5.1931 - val_mae: 2.2456 - 34ms/epoch - 1ms/step\n",
      "Epoch 342/5000\n",
      "31/31 - 0s - loss: 27.2346 - mae: 3.4602 - val_loss: 4.6757 - val_mae: 2.1268 - 32ms/epoch - 1ms/step\n",
      "Epoch 343/5000\n",
      "31/31 - 0s - loss: 6.2536 - mae: 2.0370 - val_loss: 0.1552 - val_mae: 0.3508 - 34ms/epoch - 1ms/step\n",
      "Epoch 344/5000\n",
      "31/31 - 0s - loss: 8.0339 - mae: 2.4796 - val_loss: 21.9049 - val_mae: 4.6633 - 36ms/epoch - 1ms/step\n",
      "Epoch 345/5000\n",
      "31/31 - 0s - loss: 33.3385 - mae: 3.7562 - val_loss: 2.0361 - val_mae: 1.3741 - 33ms/epoch - 1ms/step\n",
      "Epoch 346/5000\n",
      "31/31 - 0s - loss: 11.5642 - mae: 2.4912 - val_loss: 30.8358 - val_mae: 5.5401 - 33ms/epoch - 1ms/step\n",
      "Epoch 347/5000\n",
      "31/31 - 0s - loss: 13.0012 - mae: 2.4670 - val_loss: 0.2844 - val_mae: 0.4186 - 34ms/epoch - 1ms/step\n",
      "Epoch 348/5000\n",
      "31/31 - 0s - loss: 12.4152 - mae: 2.7516 - val_loss: 3.7065 - val_mae: 1.8853 - 35ms/epoch - 1ms/step\n",
      "Epoch 349/5000\n",
      "31/31 - 0s - loss: 19.8579 - mae: 2.8461 - val_loss: 51.0769 - val_mae: 7.1365 - 33ms/epoch - 1ms/step\n",
      "Epoch 350/5000\n",
      "31/31 - 0s - loss: 6.2463 - mae: 1.8644 - val_loss: 23.0751 - val_mae: 4.7880 - 33ms/epoch - 1ms/step\n",
      "Epoch 351/5000\n",
      "31/31 - 0s - loss: 11.2323 - mae: 2.5725 - val_loss: 5.4028 - val_mae: 2.2916 - 33ms/epoch - 1ms/step\n",
      "Epoch 352/5000\n",
      "31/31 - 0s - loss: 25.3559 - mae: 2.9651 - val_loss: 1.8651 - val_mae: 1.3104 - 33ms/epoch - 1ms/step\n",
      "Epoch 353/5000\n",
      "31/31 - 0s - loss: 4.1972 - mae: 1.7789 - val_loss: 1.9418 - val_mae: 1.3395 - 32ms/epoch - 1ms/step\n",
      "Epoch 354/5000\n",
      "31/31 - 0s - loss: 15.0534 - mae: 2.7463 - val_loss: 53.1032 - val_mae: 7.2761 - 33ms/epoch - 1ms/step\n",
      "Epoch 355/5000\n",
      "31/31 - 0s - loss: 6.3874 - mae: 1.9267 - val_loss: 0.7336 - val_mae: 0.7640 - 31ms/epoch - 1ms/step\n",
      "Epoch 356/5000\n",
      "31/31 - 0s - loss: 23.3444 - mae: 2.9438 - val_loss: 4.6731 - val_mae: 2.1268 - 32ms/epoch - 1ms/step\n",
      "Epoch 357/5000\n",
      "31/31 - 0s - loss: 2.2510 - mae: 1.2283 - val_loss: 30.8119 - val_mae: 5.5365 - 33ms/epoch - 1ms/step\n",
      "Epoch 358/5000\n",
      "31/31 - 0s - loss: 28.4688 - mae: 3.3979 - val_loss: 0.2981 - val_mae: 0.4715 - 32ms/epoch - 1ms/step\n",
      "Epoch 359/5000\n",
      "31/31 - 0s - loss: 5.6115 - mae: 1.7405 - val_loss: 13.3980 - val_mae: 3.6390 - 34ms/epoch - 1ms/step\n",
      "Epoch 360/5000\n",
      "31/31 - 0s - loss: 12.5768 - mae: 2.7774 - val_loss: 4.5102 - val_mae: 2.0879 - 31ms/epoch - 1ms/step\n",
      "Epoch 361/5000\n",
      "31/31 - 0s - loss: 21.3163 - mae: 3.0144 - val_loss: 1.9069 - val_mae: 1.3257 - 32ms/epoch - 1ms/step\n",
      "Epoch 362/5000\n",
      "31/31 - 0s - loss: 4.3643 - mae: 1.7847 - val_loss: 4.9313 - val_mae: 2.1862 - 31ms/epoch - 984us/step\n",
      "Epoch 363/5000\n",
      "31/31 - 0s - loss: 16.6402 - mae: 2.5275 - val_loss: 1.0528 - val_mae: 0.9505 - 33ms/epoch - 1ms/step\n",
      "Epoch 364/5000\n",
      "31/31 - 0s - loss: 2.9170 - mae: 1.3265 - val_loss: 3.3922 - val_mae: 1.8008 - 33ms/epoch - 1ms/step\n",
      "Epoch 365/5000\n",
      "31/31 - 0s - loss: 19.0673 - mae: 2.9620 - val_loss: 1.1089 - val_mae: 0.9779 - 33ms/epoch - 1ms/step\n",
      "Epoch 366/5000\n",
      "31/31 - 0s - loss: 4.3459 - mae: 1.7077 - val_loss: 0.3734 - val_mae: 0.4756 - 31ms/epoch - 1ms/step\n",
      "Epoch 367/5000\n",
      "31/31 - 0s - loss: 12.2306 - mae: 2.4655 - val_loss: 6.7595 - val_mae: 2.5718 - 33ms/epoch - 1ms/step\n",
      "Epoch 368/5000\n",
      "31/31 - 0s - loss: 10.5903 - mae: 2.4623 - val_loss: 0.2695 - val_mae: 0.4050 - 33ms/epoch - 1ms/step\n",
      "Epoch 369/5000\n",
      "31/31 - 0s - loss: 6.3368 - mae: 1.8654 - val_loss: 9.5749 - val_mae: 3.0690 - 33ms/epoch - 1ms/step\n",
      "Epoch 370/5000\n",
      "31/31 - 0s - loss: 8.4453 - mae: 2.2399 - val_loss: 0.6804 - val_mae: 0.7267 - 33ms/epoch - 1ms/step\n",
      "Epoch 371/5000\n",
      "31/31 - 0s - loss: 15.7048 - mae: 2.5438 - val_loss: 1.8070 - val_mae: 1.2846 - 33ms/epoch - 1ms/step\n",
      "Epoch 372/5000\n",
      "31/31 - 0s - loss: 4.9171 - mae: 1.6517 - val_loss: 9.5888 - val_mae: 3.0721 - 31ms/epoch - 1ms/step\n",
      "Epoch 373/5000\n",
      "31/31 - 0s - loss: 9.3190 - mae: 2.3120 - val_loss: 4.8097 - val_mae: 2.1580 - 34ms/epoch - 1ms/step\n",
      "Epoch 374/5000\n",
      "31/31 - 0s - loss: 15.0328 - mae: 2.8000 - val_loss: 2.0862 - val_mae: 1.3899 - 31ms/epoch - 1ms/step\n",
      "Epoch 375/5000\n",
      "31/31 - 0s - loss: 10.8153 - mae: 2.3277 - val_loss: 18.0488 - val_mae: 4.2306 - 35ms/epoch - 1ms/step\n",
      "Epoch 376/5000\n",
      "31/31 - 0s - loss: 4.0794 - mae: 1.5311 - val_loss: 3.0365 - val_mae: 1.6984 - 32ms/epoch - 1ms/step\n",
      "Epoch 377/5000\n",
      "31/31 - 0s - loss: 16.8582 - mae: 2.7027 - val_loss: 3.0551 - val_mae: 1.7035 - 34ms/epoch - 1ms/step\n",
      "Epoch 378/5000\n",
      "31/31 - 0s - loss: 5.8020 - mae: 1.9034 - val_loss: 12.1562 - val_mae: 3.4651 - 33ms/epoch - 1ms/step\n",
      "Epoch 379/5000\n",
      "31/31 - 0s - loss: 12.1110 - mae: 2.4534 - val_loss: 5.8663 - val_mae: 2.3901 - 35ms/epoch - 1ms/step\n",
      "Epoch 380/5000\n",
      "31/31 - 0s - loss: 5.8007 - mae: 2.0972 - val_loss: 15.1401 - val_mae: 3.8713 - 35ms/epoch - 1ms/step\n",
      "Epoch 381/5000\n",
      "31/31 - 0s - loss: 9.1743 - mae: 2.3998 - val_loss: 0.1609 - val_mae: 0.3465 - 32ms/epoch - 1ms/step\n",
      "Epoch 382/5000\n",
      "31/31 - 0s - loss: 14.3625 - mae: 2.6996 - val_loss: 11.2625 - val_mae: 3.3338 - 33ms/epoch - 1ms/step\n",
      "Epoch 383/5000\n",
      "31/31 - 0s - loss: 9.2536 - mae: 2.1311 - val_loss: 4.8959 - val_mae: 2.1771 - 34ms/epoch - 1ms/step\n",
      "Epoch 384/5000\n",
      "31/31 - 0s - loss: 4.3612 - mae: 1.6935 - val_loss: 5.0648 - val_mae: 2.2167 - 35ms/epoch - 1ms/step\n",
      "Epoch 385/5000\n",
      "31/31 - 0s - loss: 28.0001 - mae: 2.5473 - val_loss: 6.5541 - val_mae: 2.5297 - 33ms/epoch - 1ms/step\n",
      "Epoch 386/5000\n",
      "31/31 - 0s - loss: 2.4863 - mae: 1.2056 - val_loss: 2.1128 - val_mae: 1.3999 - 31ms/epoch - 1ms/step\n",
      "Epoch 387/5000\n",
      "31/31 - 0s - loss: 7.5199 - mae: 2.3513 - val_loss: 40.0443 - val_mae: 6.3156 - 33ms/epoch - 1ms/step\n",
      "Epoch 388/5000\n",
      "31/31 - 0s - loss: 12.6496 - mae: 2.4812 - val_loss: 10.0292 - val_mae: 3.1430 - 32ms/epoch - 1ms/step\n",
      "Epoch 389/5000\n",
      "31/31 - 0s - loss: 7.6336 - mae: 2.1590 - val_loss: 4.8070 - val_mae: 2.1574 - 33ms/epoch - 1ms/step\n",
      "Epoch 390/5000\n",
      "31/31 - 0s - loss: 11.0897 - mae: 2.2648 - val_loss: 1.3528 - val_mae: 1.0944 - 32ms/epoch - 1ms/step\n",
      "Epoch 391/5000\n",
      "31/31 - 0s - loss: 3.4632 - mae: 1.6588 - val_loss: 5.5462 - val_mae: 2.3227 - 32ms/epoch - 1ms/step\n",
      "Epoch 392/5000\n",
      "31/31 - 0s - loss: 20.0188 - mae: 2.7568 - val_loss: 3.9078 - val_mae: 1.9387 - 32ms/epoch - 1ms/step\n",
      "Epoch 393/5000\n",
      "31/31 - 0s - loss: 3.7485 - mae: 1.6236 - val_loss: 61.0170 - val_mae: 7.8008 - 33ms/epoch - 1ms/step\n",
      "Epoch 394/5000\n",
      "31/31 - 0s - loss: 14.5100 - mae: 2.4419 - val_loss: 3.6581 - val_mae: 1.8731 - 32ms/epoch - 1ms/step\n",
      "Epoch 395/5000\n",
      "31/31 - 0s - loss: 11.3828 - mae: 2.3715 - val_loss: 1.5495 - val_mae: 1.1844 - 33ms/epoch - 1ms/step\n",
      "Epoch 396/5000\n",
      "31/31 - 0s - loss: 3.6065 - mae: 1.5661 - val_loss: 5.4866 - val_mae: 2.3101 - 33ms/epoch - 1ms/step\n",
      "Epoch 397/5000\n",
      "31/31 - 0s - loss: 7.9846 - mae: 2.1372 - val_loss: 1.4643 - val_mae: 1.1481 - 33ms/epoch - 1ms/step\n",
      "Epoch 398/5000\n",
      "31/31 - 0s - loss: 8.2184 - mae: 2.0423 - val_loss: 0.2089 - val_mae: 0.3567 - 34ms/epoch - 1ms/step\n",
      "Epoch 399/5000\n",
      "31/31 - 0s - loss: 2.7340 - mae: 1.3255 - val_loss: 14.3427 - val_mae: 3.7677 - 33ms/epoch - 1ms/step\n",
      "Epoch 400/5000\n",
      "31/31 - 0s - loss: 16.5410 - mae: 2.7344 - val_loss: 0.2870 - val_mae: 0.4641 - 33ms/epoch - 1ms/step\n",
      "Epoch 401/5000\n",
      "31/31 - 0s - loss: 3.5605 - mae: 1.7367 - val_loss: 5.3795 - val_mae: 2.2870 - 33ms/epoch - 1ms/step\n",
      "Epoch 402/5000\n",
      "31/31 - 0s - loss: 13.5328 - mae: 2.7104 - val_loss: 0.1531 - val_mae: 0.3439 - 33ms/epoch - 1ms/step\n",
      "Epoch 403/5000\n",
      "31/31 - 0s - loss: 3.7546 - mae: 1.5609 - val_loss: 27.6184 - val_mae: 5.2407 - 33ms/epoch - 1ms/step\n",
      "Epoch 404/5000\n",
      "31/31 - 0s - loss: 7.0427 - mae: 1.9853 - val_loss: 4.6879 - val_mae: 2.1301 - 33ms/epoch - 1ms/step\n",
      "Epoch 405/5000\n",
      "31/31 - 0s - loss: 12.0655 - mae: 2.4534 - val_loss: 0.3082 - val_mae: 0.4345 - 34ms/epoch - 1ms/step\n",
      "Epoch 406/5000\n",
      "31/31 - 0s - loss: 14.8747 - mae: 2.4991 - val_loss: 1.7844 - val_mae: 1.2805 - 33ms/epoch - 1ms/step\n",
      "Epoch 407/5000\n",
      "31/31 - 0s - loss: 2.8084 - mae: 1.3180 - val_loss: 2.9263 - val_mae: 1.6659 - 33ms/epoch - 1ms/step\n",
      "Epoch 408/5000\n",
      "31/31 - 0s - loss: 17.4355 - mae: 2.5369 - val_loss: 4.3893 - val_mae: 2.0584 - 35ms/epoch - 1ms/step\n",
      "Epoch 409/5000\n",
      "31/31 - 0s - loss: 3.4508 - mae: 1.4396 - val_loss: 1.3222 - val_mae: 1.0826 - 32ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/5000\n",
      "31/31 - 0s - loss: 15.3164 - mae: 2.3694 - val_loss: 5.9629 - val_mae: 2.4113 - 36ms/epoch - 1ms/step\n",
      "Epoch 411/5000\n",
      "31/31 - 0s - loss: 3.2322 - mae: 1.4722 - val_loss: 3.3688 - val_mae: 1.7945 - 32ms/epoch - 1ms/step\n",
      "Epoch 412/5000\n",
      "31/31 - 0s - loss: 19.6403 - mae: 2.9073 - val_loss: 0.1832 - val_mae: 0.3387 - 32ms/epoch - 1ms/step\n",
      "Epoch 413/5000\n",
      "31/31 - 0s - loss: 2.4708 - mae: 1.3675 - val_loss: 2.3667 - val_mae: 1.4884 - 32ms/epoch - 1ms/step\n",
      "Epoch 414/5000\n",
      "31/31 - 0s - loss: 5.4770 - mae: 1.7204 - val_loss: 9.1040 - val_mae: 2.9929 - 33ms/epoch - 1ms/step\n",
      "Epoch 415/5000\n",
      "31/31 - 0s - loss: 15.9631 - mae: 2.8158 - val_loss: 5.9850 - val_mae: 2.4155 - 33ms/epoch - 1ms/step\n",
      "Epoch 416/5000\n",
      "31/31 - 0s - loss: 2.8312 - mae: 1.4149 - val_loss: 0.2969 - val_mae: 0.4702 - 33ms/epoch - 1ms/step\n",
      "Epoch 417/5000\n",
      "31/31 - 0s - loss: 9.3530 - mae: 2.3212 - val_loss: 3.4021 - val_mae: 1.8045 - 35ms/epoch - 1ms/step\n",
      "Epoch 418/5000\n",
      "31/31 - 0s - loss: 5.5768 - mae: 1.7946 - val_loss: 0.5208 - val_mae: 0.6113 - 33ms/epoch - 1ms/step\n",
      "Epoch 419/5000\n",
      "31/31 - 0s - loss: 5.1872 - mae: 1.6740 - val_loss: 0.2117 - val_mae: 0.3591 - 33ms/epoch - 1ms/step\n",
      "Epoch 420/5000\n",
      "31/31 - 0s - loss: 19.6913 - mae: 2.5836 - val_loss: 0.1487 - val_mae: 0.3392 - 33ms/epoch - 1ms/step\n",
      "Epoch 421/5000\n",
      "31/31 - 0s - loss: 3.4614 - mae: 1.4592 - val_loss: 0.2155 - val_mae: 0.3625 - 33ms/epoch - 1ms/step\n",
      "Epoch 422/5000\n",
      "31/31 - 0s - loss: 11.4997 - mae: 2.1931 - val_loss: 6.7868 - val_mae: 2.5762 - 33ms/epoch - 1ms/step\n",
      "Epoch 423/5000\n",
      "31/31 - 0s - loss: 2.4313 - mae: 1.3165 - val_loss: 0.1544 - val_mae: 0.3397 - 33ms/epoch - 1ms/step\n",
      "Epoch 424/5000\n",
      "31/31 - 0s - loss: 13.3731 - mae: 2.5780 - val_loss: 0.1504 - val_mae: 0.3415 - 34ms/epoch - 1ms/step\n",
      "Epoch 425/5000\n",
      "31/31 - 0s - loss: 2.7739 - mae: 1.3119 - val_loss: 5.2819 - val_mae: 2.2662 - 34ms/epoch - 1ms/step\n",
      "Epoch 426/5000\n",
      "31/31 - 0s - loss: 10.5901 - mae: 2.2224 - val_loss: 3.6823 - val_mae: 1.8805 - 31ms/epoch - 1ms/step\n",
      "Epoch 427/5000\n",
      "31/31 - 0s - loss: 14.9604 - mae: 2.3848 - val_loss: 1.2248 - val_mae: 1.0379 - 31ms/epoch - 993us/step\n",
      "Epoch 428/5000\n",
      "31/31 - 0s - loss: 2.0853 - mae: 1.1522 - val_loss: 3.8132 - val_mae: 1.9143 - 33ms/epoch - 1ms/step\n",
      "Epoch 429/5000\n",
      "31/31 - 0s - loss: 11.1764 - mae: 2.2456 - val_loss: 2.9504 - val_mae: 1.6742 - 33ms/epoch - 1ms/step\n",
      "Epoch 430/5000\n",
      "31/31 - 0s - loss: 4.0996 - mae: 1.6424 - val_loss: 3.2359 - val_mae: 1.7552 - 34ms/epoch - 1ms/step\n",
      "Epoch 431/5000\n",
      "31/31 - 0s - loss: 10.7981 - mae: 2.3550 - val_loss: 1.6039 - val_mae: 1.2091 - 33ms/epoch - 1ms/step\n",
      "Epoch 432/5000\n",
      "31/31 - 0s - loss: 6.1090 - mae: 1.7565 - val_loss: 0.9044 - val_mae: 0.8705 - 34ms/epoch - 1ms/step\n",
      "Epoch 433/5000\n",
      "31/31 - 0s - loss: 8.2844 - mae: 1.9566 - val_loss: 1.6752 - val_mae: 1.2383 - 33ms/epoch - 1ms/step\n",
      "Epoch 434/5000\n",
      "31/31 - 0s - loss: 2.1807 - mae: 1.1342 - val_loss: 4.9033 - val_mae: 2.1807 - 33ms/epoch - 1ms/step\n",
      "Epoch 435/5000\n",
      "31/31 - 0s - loss: 12.8387 - mae: 2.3924 - val_loss: 4.4496 - val_mae: 2.0755 - 33ms/epoch - 1ms/step\n",
      "Epoch 436/5000\n",
      "31/31 - 0s - loss: 4.2874 - mae: 1.5932 - val_loss: 62.4532 - val_mae: 7.8926 - 34ms/epoch - 1ms/step\n",
      "Epoch 437/5000\n",
      "31/31 - 0s - loss: 5.3169 - mae: 1.7511 - val_loss: 0.9922 - val_mae: 0.9195 - 32ms/epoch - 1ms/step\n",
      "Epoch 438/5000\n",
      "31/31 - 0s - loss: 13.4725 - mae: 2.4938 - val_loss: 7.9886 - val_mae: 2.7999 - 33ms/epoch - 1ms/step\n",
      "Epoch 439/5000\n",
      "31/31 - 0s - loss: 2.7273 - mae: 1.3334 - val_loss: 18.7722 - val_mae: 4.3158 - 33ms/epoch - 1ms/step\n",
      "Epoch 440/5000\n",
      "31/31 - 0s - loss: 9.4942 - mae: 2.4929 - val_loss: 4.8951 - val_mae: 2.1784 - 33ms/epoch - 1ms/step\n",
      "Epoch 441/5000\n",
      "31/31 - 0s - loss: 11.3903 - mae: 2.1173 - val_loss: 0.4829 - val_mae: 0.5787 - 33ms/epoch - 1ms/step\n",
      "Epoch 442/5000\n",
      "31/31 - 0s - loss: 2.8869 - mae: 1.4151 - val_loss: 0.1674 - val_mae: 0.3487 - 33ms/epoch - 1ms/step\n",
      "Epoch 443/5000\n",
      "31/31 - 0s - loss: 9.7905 - mae: 2.2047 - val_loss: 9.1437 - val_mae: 2.9997 - 33ms/epoch - 1ms/step\n",
      "Epoch 444/5000\n",
      "31/31 - 0s - loss: 21.4412 - mae: 2.5698 - val_loss: 0.8697 - val_mae: 0.8504 - 33ms/epoch - 1ms/step\n",
      "Epoch 445/5000\n",
      "31/31 - 0s - loss: 2.9042 - mae: 1.4409 - val_loss: 0.3292 - val_mae: 0.4419 - 34ms/epoch - 1ms/step\n",
      "Epoch 446/5000\n",
      "31/31 - 0s - loss: 8.1010 - mae: 2.2616 - val_loss: 0.2162 - val_mae: 0.4101 - 33ms/epoch - 1ms/step\n",
      "Epoch 447/5000\n",
      "31/31 - 0s - loss: 13.4585 - mae: 2.0396 - val_loss: 0.3328 - val_mae: 0.4918 - 32ms/epoch - 1ms/step\n",
      "Epoch 448/5000\n",
      "31/31 - 0s - loss: 4.0360 - mae: 1.6713 - val_loss: 1.4663 - val_mae: 1.1495 - 34ms/epoch - 1ms/step\n",
      "Epoch 449/5000\n",
      "31/31 - 0s - loss: 10.9650 - mae: 1.7005 - val_loss: 108.0961 - val_mae: 10.3896 - 32ms/epoch - 1ms/step\n",
      "Epoch 450/5000\n",
      "31/31 - 0s - loss: 4.4246 - mae: 1.6674 - val_loss: 0.5102 - val_mae: 0.6041 - 33ms/epoch - 1ms/step\n",
      "Epoch 451/5000\n",
      "31/31 - 0s - loss: 8.4034 - mae: 2.0189 - val_loss: 11.6558 - val_mae: 3.3931 - 32ms/epoch - 1ms/step\n",
      "Epoch 452/5000\n",
      "31/31 - 0s - loss: 3.3641 - mae: 1.4840 - val_loss: 0.4447 - val_mae: 0.5521 - 34ms/epoch - 1ms/step\n",
      "Epoch 453/5000\n",
      "31/31 - 0s - loss: 7.3527 - mae: 1.9294 - val_loss: 0.1485 - val_mae: 0.3376 - 33ms/epoch - 1ms/step\n",
      "Epoch 454/5000\n",
      "31/31 - 0s - loss: 13.1744 - mae: 2.3226 - val_loss: 16.1227 - val_mae: 3.9970 - 32ms/epoch - 1ms/step\n",
      "Epoch 455/5000\n",
      "31/31 - 0s - loss: 5.0675 - mae: 1.6166 - val_loss: 6.4630 - val_mae: 2.5140 - 42ms/epoch - 1ms/step\n",
      "Epoch 456/5000\n",
      "31/31 - 0s - loss: 12.8239 - mae: 2.3880 - val_loss: 1.6095 - val_mae: 1.2100 - 33ms/epoch - 1ms/step\n",
      "Epoch 457/5000\n",
      "31/31 - 0s - loss: 9.5927 - mae: 2.1838 - val_loss: 0.1728 - val_mae: 0.3328 - 34ms/epoch - 1ms/step\n",
      "Epoch 458/5000\n",
      "31/31 - 0s - loss: 3.5458 - mae: 1.5178 - val_loss: 0.8839 - val_mae: 0.8584 - 33ms/epoch - 1ms/step\n",
      "Epoch 459/5000\n",
      "31/31 - 0s - loss: 11.4398 - mae: 2.3750 - val_loss: 1.4518 - val_mae: 1.1402 - 34ms/epoch - 1ms/step\n",
      "Epoch 460/5000\n",
      "31/31 - 0s - loss: 2.7418 - mae: 1.3357 - val_loss: 3.1876 - val_mae: 1.7468 - 32ms/epoch - 1ms/step\n",
      "Epoch 461/5000\n",
      "31/31 - 0s - loss: 11.5307 - mae: 2.2810 - val_loss: 0.2238 - val_mae: 0.4169 - 33ms/epoch - 1ms/step\n",
      "Epoch 462/5000\n",
      "31/31 - 0s - loss: 1.6664 - mae: 1.0386 - val_loss: 5.0151 - val_mae: 2.2051 - 32ms/epoch - 1ms/step\n",
      "Epoch 463/5000\n",
      "31/31 - 0s - loss: 20.2172 - mae: 2.1887 - val_loss: 34.7996 - val_mae: 5.8864 - 33ms/epoch - 1ms/step\n",
      "Epoch 464/5000\n",
      "31/31 - 0s - loss: 5.1577 - mae: 1.7044 - val_loss: 7.0875 - val_mae: 2.6344 - 32ms/epoch - 1ms/step\n",
      "Epoch 465/5000\n",
      "31/31 - 0s - loss: 8.7257 - mae: 2.0886 - val_loss: 0.3216 - val_mae: 0.4401 - 33ms/epoch - 1ms/step\n",
      "Epoch 466/5000\n",
      "31/31 - 0s - loss: 7.0272 - mae: 1.9803 - val_loss: 4.0154 - val_mae: 1.9657 - 32ms/epoch - 1ms/step\n",
      "Epoch 467/5000\n",
      "31/31 - 0s - loss: 2.1851 - mae: 1.2122 - val_loss: 0.1738 - val_mae: 0.3650 - 33ms/epoch - 1ms/step\n",
      "Epoch 468/5000\n",
      "31/31 - 0s - loss: 9.1703 - mae: 2.2205 - val_loss: 3.2317 - val_mae: 1.7567 - 32ms/epoch - 1ms/step\n",
      "Epoch 469/5000\n",
      "31/31 - 0s - loss: 21.4270 - mae: 3.0519 - val_loss: 5.1501 - val_mae: 2.2346 - 33ms/epoch - 1ms/step\n",
      "Epoch 470/5000\n",
      "31/31 - 0s - loss: 3.9015 - mae: 1.7451 - val_loss: 11.2017 - val_mae: 3.3246 - 32ms/epoch - 1ms/step\n",
      "Epoch 471/5000\n",
      "31/31 - 0s - loss: 5.8682 - mae: 1.9439 - val_loss: 0.3145 - val_mae: 0.4830 - 33ms/epoch - 1ms/step\n",
      "Epoch 472/5000\n",
      "31/31 - 0s - loss: 5.3673 - mae: 1.8332 - val_loss: 5.9292 - val_mae: 2.4051 - 32ms/epoch - 1ms/step\n",
      "Epoch 473/5000\n",
      "31/31 - 0s - loss: 7.2270 - mae: 1.9057 - val_loss: 5.4864 - val_mae: 2.3111 - 34ms/epoch - 1ms/step\n",
      "Epoch 474/5000\n",
      "31/31 - 0s - loss: 3.2758 - mae: 1.3471 - val_loss: 36.1296 - val_mae: 5.9984 - 34ms/epoch - 1ms/step\n",
      "Epoch 475/5000\n",
      "31/31 - 0s - loss: 7.5297 - mae: 2.2482 - val_loss: 4.1758 - val_mae: 2.0072 - 33ms/epoch - 1ms/step\n",
      "Epoch 476/5000\n",
      "31/31 - 0s - loss: 18.4094 - mae: 2.3876 - val_loss: 9.5320 - val_mae: 3.0641 - 33ms/epoch - 1ms/step\n",
      "Epoch 477/5000\n",
      "31/31 - 0s - loss: 2.3648 - mae: 1.1988 - val_loss: 0.1767 - val_mae: 0.3664 - 35ms/epoch - 1ms/step\n",
      "Epoch 478/5000\n",
      "31/31 - 0s - loss: 24.7063 - mae: 2.5951 - val_loss: 5.8593 - val_mae: 2.3894 - 32ms/epoch - 1ms/step\n",
      "Epoch 479/5000\n",
      "31/31 - 0s - loss: 3.3364 - mae: 1.4688 - val_loss: 3.5174 - val_mae: 1.8368 - 33ms/epoch - 1ms/step\n",
      "Epoch 480/5000\n",
      "31/31 - 0s - loss: 7.4063 - mae: 1.8418 - val_loss: 3.9440 - val_mae: 1.9471 - 33ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/5000\n",
      "31/31 - 0s - loss: 2.9568 - mae: 1.5038 - val_loss: 4.5051 - val_mae: 2.0870 - 31ms/epoch - 1ms/step\n",
      "Epoch 482/5000\n",
      "31/31 - 0s - loss: 8.2547 - mae: 1.9939 - val_loss: 9.7761 - val_mae: 3.1041 - 33ms/epoch - 1ms/step\n",
      "Epoch 483/5000\n",
      "31/31 - 0s - loss: 8.6615 - mae: 2.1145 - val_loss: 0.3505 - val_mae: 0.5035 - 34ms/epoch - 1ms/step\n",
      "Epoch 484/5000\n",
      "31/31 - 0s - loss: 2.5332 - mae: 1.3156 - val_loss: 6.8093 - val_mae: 2.5815 - 33ms/epoch - 1ms/step\n",
      "Epoch 485/5000\n",
      "31/31 - 0s - loss: 21.9552 - mae: 2.6440 - val_loss: 3.5159 - val_mae: 1.8359 - 34ms/epoch - 1ms/step\n",
      "Epoch 486/5000\n",
      "31/31 - 0s - loss: 5.7861 - mae: 2.0485 - val_loss: 8.1312 - val_mae: 2.8254 - 34ms/epoch - 1ms/step\n",
      "Epoch 487/5000\n",
      "31/31 - 0s - loss: 3.8459 - mae: 1.4913 - val_loss: 3.5606 - val_mae: 1.8476 - 32ms/epoch - 1ms/step\n",
      "Epoch 488/5000\n",
      "31/31 - 0s - loss: 20.2491 - mae: 2.7248 - val_loss: 5.1025 - val_mae: 2.2259 - 34ms/epoch - 1ms/step\n",
      "Epoch 489/5000\n",
      "31/31 - 0s - loss: 2.4156 - mae: 1.2114 - val_loss: 1.3668 - val_mae: 1.1042 - 32ms/epoch - 1ms/step\n",
      "Epoch 490/5000\n",
      "31/31 - 0s - loss: 8.3847 - mae: 2.4834 - val_loss: 6.8882 - val_mae: 2.5974 - 34ms/epoch - 1ms/step\n",
      "Epoch 491/5000\n",
      "31/31 - 0s - loss: 4.9429 - mae: 1.6078 - val_loss: 56.2458 - val_mae: 7.4906 - 35ms/epoch - 1ms/step\n",
      "Epoch 492/5000\n",
      "31/31 - 0s - loss: 16.5889 - mae: 2.3170 - val_loss: 3.1641 - val_mae: 1.7384 - 33ms/epoch - 1ms/step\n",
      "Epoch 493/5000\n",
      "31/31 - 0s - loss: 7.3644 - mae: 1.9253 - val_loss: 6.6452 - val_mae: 2.5503 - 34ms/epoch - 1ms/step\n",
      "Epoch 494/5000\n",
      "31/31 - 0s - loss: 4.9093 - mae: 1.7804 - val_loss: 3.3657 - val_mae: 1.7947 - 34ms/epoch - 1ms/step\n",
      "Epoch 495/5000\n",
      "31/31 - 0s - loss: 10.3870 - mae: 2.3759 - val_loss: 2.5066 - val_mae: 1.5369 - 33ms/epoch - 1ms/step\n",
      "Epoch 496/5000\n",
      "31/31 - 0s - loss: 1.9745 - mae: 1.1297 - val_loss: 7.3881 - val_mae: 2.6901 - 33ms/epoch - 1ms/step\n",
      "Epoch 497/5000\n",
      "31/31 - 0s - loss: 14.0580 - mae: 2.5975 - val_loss: 0.9058 - val_mae: 0.8754 - 34ms/epoch - 1ms/step\n",
      "Epoch 498/5000\n",
      "31/31 - 0s - loss: 3.7671 - mae: 1.6087 - val_loss: 42.5387 - val_mae: 6.5107 - 32ms/epoch - 1ms/step\n",
      "Epoch 499/5000\n",
      "31/31 - 0s - loss: 10.0057 - mae: 2.2606 - val_loss: 0.2791 - val_mae: 0.4096 - 34ms/epoch - 1ms/step\n",
      "Epoch 500/5000\n",
      "31/31 - 0s - loss: 16.2793 - mae: 2.4460 - val_loss: 1.7198 - val_mae: 1.2546 - 33ms/epoch - 1ms/step\n",
      "Epoch 501/5000\n",
      "31/31 - 0s - loss: 3.6252 - mae: 1.6520 - val_loss: 2.6171 - val_mae: 1.5734 - 32ms/epoch - 1ms/step\n",
      "Epoch 502/5000\n",
      "31/31 - 0s - loss: 4.7558 - mae: 1.5651 - val_loss: 6.9837 - val_mae: 2.6160 - 33ms/epoch - 1ms/step\n",
      "Epoch 503/5000\n",
      "31/31 - 0s - loss: 3.5959 - mae: 1.3640 - val_loss: 1.7499 - val_mae: 1.2666 - 31ms/epoch - 1ms/step\n",
      "Epoch 504/5000\n",
      "31/31 - 0s - loss: 13.0350 - mae: 2.4509 - val_loss: 25.0420 - val_mae: 4.9897 - 32ms/epoch - 1ms/step\n",
      "Epoch 505/5000\n",
      "31/31 - 0s - loss: 3.6203 - mae: 1.6678 - val_loss: 1.8092 - val_mae: 1.2900 - 31ms/epoch - 1ms/step\n",
      "Epoch 506/5000\n",
      "31/31 - 0s - loss: 12.3797 - mae: 2.3391 - val_loss: 2.0196 - val_mae: 1.3707 - 34ms/epoch - 1ms/step\n",
      "Epoch 507/5000\n",
      "31/31 - 0s - loss: 9.7813 - mae: 2.2608 - val_loss: 5.4200 - val_mae: 2.2980 - 31ms/epoch - 993us/step\n",
      "Epoch 508/5000\n",
      "31/31 - 0s - loss: 2.8671 - mae: 1.3392 - val_loss: 0.3197 - val_mae: 0.4854 - 32ms/epoch - 1ms/step\n",
      "Epoch 509/5000\n",
      "31/31 - 0s - loss: 6.2706 - mae: 2.1423 - val_loss: 0.1719 - val_mae: 0.3623 - 32ms/epoch - 1ms/step\n",
      "Epoch 510/5000\n",
      "31/31 - 0s - loss: 7.7362 - mae: 2.1942 - val_loss: 0.3964 - val_mae: 0.5047 - 33ms/epoch - 1ms/step\n",
      "Epoch 511/5000\n",
      "31/31 - 0s - loss: 1.7660 - mae: 1.1110 - val_loss: 8.0033 - val_mae: 2.8033 - 32ms/epoch - 1ms/step\n",
      "Epoch 512/5000\n",
      "31/31 - 0s - loss: 18.5843 - mae: 2.6788 - val_loss: 2.9448 - val_mae: 1.6738 - 33ms/epoch - 1ms/step\n",
      "Epoch 513/5000\n",
      "31/31 - 0s - loss: 4.8968 - mae: 1.6247 - val_loss: 25.1895 - val_mae: 5.0050 - 31ms/epoch - 998us/step\n",
      "Epoch 514/5000\n",
      "31/31 - 0s - loss: 4.2735 - mae: 1.7446 - val_loss: 0.1564 - val_mae: 0.3376 - 34ms/epoch - 1ms/step\n",
      "Epoch 515/5000\n",
      "31/31 - 0s - loss: 15.3635 - mae: 2.1962 - val_loss: 0.3289 - val_mae: 0.4906 - 31ms/epoch - 1ms/step\n",
      "Epoch 516/5000\n",
      "31/31 - 0s - loss: 7.2781 - mae: 1.8916 - val_loss: 13.3341 - val_mae: 3.6325 - 32ms/epoch - 1ms/step\n",
      "Epoch 517/5000\n",
      "31/31 - 0s - loss: 2.8762 - mae: 1.2882 - val_loss: 5.3092 - val_mae: 2.2733 - 31ms/epoch - 1ms/step\n",
      "Epoch 518/5000\n",
      "31/31 - 0s - loss: 3.6650 - mae: 1.5909 - val_loss: 1.6544 - val_mae: 1.2296 - 33ms/epoch - 1ms/step\n",
      "Epoch 519/5000\n",
      "31/31 - 0s - loss: 7.6653 - mae: 1.9792 - val_loss: 3.6421 - val_mae: 1.8708 - 34ms/epoch - 1ms/step\n",
      "Epoch 520/5000\n",
      "31/31 - 0s - loss: 7.0413 - mae: 1.8312 - val_loss: 6.2791 - val_mae: 2.4775 - 33ms/epoch - 1ms/step\n",
      "Epoch 521/5000\n",
      "31/31 - 0s - loss: 2.8377 - mae: 1.2488 - val_loss: 6.6550 - val_mae: 2.5523 - 33ms/epoch - 1ms/step\n",
      "Epoch 522/5000\n",
      "31/31 - 0s - loss: 11.9539 - mae: 2.5796 - val_loss: 1.2439 - val_mae: 1.0529 - 33ms/epoch - 1ms/step\n",
      "Epoch 523/5000\n",
      "31/31 - 0s - loss: 8.6220 - mae: 2.1067 - val_loss: 0.3380 - val_mae: 0.4954 - 32ms/epoch - 1ms/step\n",
      "Epoch 524/5000\n",
      "31/31 - 0s - loss: 3.6680 - mae: 1.5441 - val_loss: 0.1383 - val_mae: 0.3308 - 35ms/epoch - 1ms/step\n",
      "Epoch 525/5000\n",
      "31/31 - 0s - loss: 10.5601 - mae: 2.0971 - val_loss: 5.1528 - val_mae: 2.2389 - 34ms/epoch - 1ms/step\n",
      "Epoch 526/5000\n",
      "31/31 - 0s - loss: 5.8057 - mae: 1.8882 - val_loss: 12.5505 - val_mae: 3.5243 - 32ms/epoch - 1ms/step\n",
      "Epoch 527/5000\n",
      "31/31 - 0s - loss: 8.8278 - mae: 2.1369 - val_loss: 18.9809 - val_mae: 4.3391 - 33ms/epoch - 1ms/step\n",
      "Epoch 528/5000\n",
      "31/31 - 0s - loss: 4.6895 - mae: 1.6535 - val_loss: 14.2418 - val_mae: 3.7542 - 33ms/epoch - 1ms/step\n",
      "Epoch 529/5000\n",
      "31/31 - 0s - loss: 13.1651 - mae: 2.4317 - val_loss: 0.3347 - val_mae: 0.4938 - 32ms/epoch - 1ms/step\n",
      "Epoch 530/5000\n",
      "31/31 - 0s - loss: 6.5705 - mae: 1.8462 - val_loss: 0.2380 - val_mae: 0.3811 - 33ms/epoch - 1ms/step\n",
      "Epoch 531/5000\n",
      "31/31 - 0s - loss: 9.1397 - mae: 1.7563 - val_loss: 2.7714 - val_mae: 1.6201 - 32ms/epoch - 1ms/step\n",
      "Epoch 532/5000\n",
      "31/31 - 0s - loss: 3.1798 - mae: 1.4351 - val_loss: 0.1579 - val_mae: 0.3413 - 31ms/epoch - 985us/step\n",
      "Epoch 533/5000\n",
      "31/31 - 0s - loss: 6.3814 - mae: 2.0334 - val_loss: 0.1394 - val_mae: 0.3320 - 33ms/epoch - 1ms/step\n",
      "Epoch 534/5000\n",
      "31/31 - 0s - loss: 12.0456 - mae: 2.4208 - val_loss: 0.7393 - val_mae: 0.7749 - 32ms/epoch - 1ms/step\n",
      "Epoch 535/5000\n",
      "31/31 - 0s - loss: 2.3850 - mae: 1.3262 - val_loss: 3.0984 - val_mae: 1.7200 - 33ms/epoch - 1ms/step\n",
      "Epoch 536/5000\n",
      "31/31 - 0s - loss: 12.8412 - mae: 2.3193 - val_loss: 1.7865 - val_mae: 1.2833 - 35ms/epoch - 1ms/step\n",
      "Epoch 537/5000\n",
      "31/31 - 0s - loss: 6.4572 - mae: 1.9477 - val_loss: 11.1123 - val_mae: 3.3121 - 34ms/epoch - 1ms/step\n",
      "Epoch 538/5000\n",
      "31/31 - 0s - loss: 1.4873 - mae: 1.0098 - val_loss: 6.8976 - val_mae: 2.5996 - 34ms/epoch - 1ms/step\n",
      "Epoch 539/5000\n",
      "31/31 - 0s - loss: 28.0920 - mae: 2.7962 - val_loss: 3.8947 - val_mae: 1.9369 - 33ms/epoch - 1ms/step\n",
      "Epoch 540/5000\n",
      "31/31 - 0s - loss: 1.7590 - mae: 1.0298 - val_loss: 0.2606 - val_mae: 0.4462 - 32ms/epoch - 1ms/step\n",
      "Epoch 541/5000\n",
      "31/31 - 0s - loss: 11.4464 - mae: 2.2082 - val_loss: 0.1400 - val_mae: 0.3286 - 32ms/epoch - 1ms/step\n",
      "Epoch 542/5000\n",
      "31/31 - 0s - loss: 4.6702 - mae: 1.8641 - val_loss: 3.0269 - val_mae: 1.6977 - 34ms/epoch - 1ms/step\n",
      "Epoch 543/5000\n",
      "31/31 - 0s - loss: 3.7047 - mae: 1.3895 - val_loss: 2.7791 - val_mae: 1.6239 - 33ms/epoch - 1ms/step\n",
      "Epoch 544/5000\n",
      "31/31 - 0s - loss: 12.7697 - mae: 2.4011 - val_loss: 1.9353 - val_mae: 1.3401 - 34ms/epoch - 1ms/step\n",
      "Epoch 545/5000\n",
      "31/31 - 0s - loss: 6.6397 - mae: 1.4353 - val_loss: 50.7000 - val_mae: 7.1103 - 33ms/epoch - 1ms/step\n",
      "Epoch 546/5000\n",
      "31/31 - 0s - loss: 6.5922 - mae: 2.0028 - val_loss: 0.5354 - val_mae: 0.6313 - 32ms/epoch - 1ms/step\n",
      "Epoch 547/5000\n",
      "31/31 - 0s - loss: 11.5613 - mae: 2.3323 - val_loss: 0.3793 - val_mae: 0.5170 - 34ms/epoch - 1ms/step\n",
      "Epoch 548/5000\n",
      "31/31 - 0s - loss: 2.8642 - mae: 1.3835 - val_loss: 0.4233 - val_mae: 0.5358 - 38ms/epoch - 1ms/step\n",
      "Epoch 549/5000\n",
      "31/31 - 0s - loss: 8.5033 - mae: 2.1918 - val_loss: 1.3754 - val_mae: 1.1130 - 38ms/epoch - 1ms/step\n",
      "Epoch 550/5000\n",
      "31/31 - 0s - loss: 1.6491 - mae: 0.9977 - val_loss: 0.5729 - val_mae: 0.6551 - 34ms/epoch - 1ms/step\n",
      "Epoch 551/5000\n",
      "31/31 - 0s - loss: 15.5986 - mae: 2.5574 - val_loss: 0.6679 - val_mae: 0.7245 - 34ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/5000\n",
      "31/31 - 0s - loss: 2.7796 - mae: 1.4679 - val_loss: 1.9245 - val_mae: 1.3386 - 41ms/epoch - 1ms/step\n",
      "Epoch 553/5000\n",
      "31/31 - 0s - loss: 18.8126 - mae: 2.5547 - val_loss: 5.0184 - val_mae: 2.2106 - 37ms/epoch - 1ms/step\n",
      "Epoch 554/5000\n",
      "31/31 - 0s - loss: 1.9827 - mae: 1.1641 - val_loss: 1.5627 - val_mae: 1.1934 - 36ms/epoch - 1ms/step\n",
      "Epoch 555/5000\n",
      "31/31 - 0s - loss: 7.9212 - mae: 1.9540 - val_loss: 3.9526 - val_mae: 1.9532 - 37ms/epoch - 1ms/step\n",
      "Epoch 556/5000\n",
      "31/31 - 0s - loss: 18.6681 - mae: 2.5113 - val_loss: 2.3149 - val_mae: 1.4734 - 37ms/epoch - 1ms/step\n",
      "Epoch 557/5000\n",
      "31/31 - 0s - loss: 1.8686 - mae: 0.9568 - val_loss: 0.2714 - val_mae: 0.4029 - 38ms/epoch - 1ms/step\n",
      "Epoch 558/5000\n",
      "31/31 - 0s - loss: 17.6783 - mae: 2.5777 - val_loss: 5.5957 - val_mae: 2.3345 - 40ms/epoch - 1ms/step\n",
      "Epoch 559/5000\n",
      "31/31 - 0s - loss: 2.0596 - mae: 1.1769 - val_loss: 2.5917 - val_mae: 1.5664 - 49ms/epoch - 2ms/step\n",
      "Epoch 560/5000\n",
      "31/31 - 0s - loss: 9.1652 - mae: 2.1064 - val_loss: 4.3560 - val_mae: 2.0543 - 35ms/epoch - 1ms/step\n",
      "Epoch 561/5000\n",
      "31/31 - 0s - loss: 2.8065 - mae: 1.4416 - val_loss: 0.1410 - val_mae: 0.3282 - 35ms/epoch - 1ms/step\n",
      "Epoch 562/5000\n",
      "31/31 - 0s - loss: 12.7526 - mae: 2.0789 - val_loss: 7.5688 - val_mae: 2.7255 - 35ms/epoch - 1ms/step\n",
      "Epoch 563/5000\n",
      "31/31 - 0s - loss: 1.8516 - mae: 1.0975 - val_loss: 0.3557 - val_mae: 0.4688 - 32ms/epoch - 1ms/step\n",
      "Epoch 564/5000\n",
      "31/31 - 0s - loss: 19.0395 - mae: 2.0878 - val_loss: 2.8768 - val_mae: 1.6524 - 36ms/epoch - 1ms/step\n",
      "Epoch 565/5000\n",
      "31/31 - 0s - loss: 2.6362 - mae: 1.3292 - val_loss: 13.4277 - val_mae: 3.6456 - 36ms/epoch - 1ms/step\n",
      "Epoch 566/5000\n",
      "31/31 - 0s - loss: 13.3148 - mae: 2.2503 - val_loss: 2.4017 - val_mae: 1.5055 - 38ms/epoch - 1ms/step\n",
      "Epoch 567/5000\n",
      "31/31 - 0s - loss: 3.6222 - mae: 1.5244 - val_loss: 5.4288 - val_mae: 2.3002 - 40ms/epoch - 1ms/step\n",
      "Epoch 568/5000\n",
      "31/31 - 0s - loss: 5.2463 - mae: 1.8936 - val_loss: 4.2302 - val_mae: 2.0218 - 36ms/epoch - 1ms/step\n",
      "Epoch 569/5000\n",
      "31/31 - 0s - loss: 8.9043 - mae: 2.0483 - val_loss: 1.4489 - val_mae: 1.1456 - 38ms/epoch - 1ms/step\n",
      "Epoch 570/5000\n",
      "31/31 - 0s - loss: 3.1780 - mae: 1.5043 - val_loss: 1.5589 - val_mae: 1.1932 - 58ms/epoch - 2ms/step\n",
      "Epoch 571/5000\n",
      "31/31 - 0s - loss: 17.6196 - mae: 2.3450 - val_loss: 2.8363 - val_mae: 1.6429 - 39ms/epoch - 1ms/step\n",
      "Epoch 572/5000\n",
      "31/31 - 0s - loss: 2.4402 - mae: 1.3428 - val_loss: 1.7060 - val_mae: 1.2519 - 40ms/epoch - 1ms/step\n",
      "Epoch 573/5000\n",
      "31/31 - 0s - loss: 8.6982 - mae: 2.1644 - val_loss: 0.1341 - val_mae: 0.3243 - 40ms/epoch - 1ms/step\n",
      "Epoch 574/5000\n",
      "31/31 - 0s - loss: 19.2878 - mae: 2.5119 - val_loss: 0.2642 - val_mae: 0.3960 - 51ms/epoch - 2ms/step\n",
      "Epoch 575/5000\n",
      "31/31 - 0s - loss: 2.1932 - mae: 1.1770 - val_loss: 2.5935 - val_mae: 1.5672 - 32ms/epoch - 1ms/step\n",
      "Epoch 576/5000\n",
      "31/31 - 0s - loss: 7.2496 - mae: 1.9555 - val_loss: 27.3826 - val_mae: 5.2192 - 34ms/epoch - 1ms/step\n",
      "Epoch 577/5000\n",
      "31/31 - 0s - loss: 3.8939 - mae: 1.5888 - val_loss: 2.3695 - val_mae: 1.4927 - 33ms/epoch - 1ms/step\n",
      "Epoch 578/5000\n",
      "31/31 - 0s - loss: 9.5446 - mae: 1.8186 - val_loss: 11.2570 - val_mae: 3.3343 - 33ms/epoch - 1ms/step\n",
      "Epoch 579/5000\n",
      "31/31 - 0s - loss: 4.9195 - mae: 1.7980 - val_loss: 1.1506 - val_mae: 1.0077 - 33ms/epoch - 1ms/step\n",
      "Epoch 580/5000\n",
      "31/31 - 0s - loss: 11.4558 - mae: 2.6251 - val_loss: 7.4874 - val_mae: 2.7104 - 34ms/epoch - 1ms/step\n",
      "Epoch 581/5000\n",
      "31/31 - 0s - loss: 11.1942 - mae: 1.9073 - val_loss: 16.0487 - val_mae: 3.9869 - 32ms/epoch - 1ms/step\n",
      "Epoch 582/5000\n",
      "31/31 - 0s - loss: 5.1248 - mae: 1.8531 - val_loss: 2.9357 - val_mae: 1.6728 - 32ms/epoch - 1ms/step\n",
      "Epoch 583/5000\n",
      "31/31 - 0s - loss: 6.1696 - mae: 1.7722 - val_loss: 81.8307 - val_mae: 9.0386 - 33ms/epoch - 1ms/step\n",
      "Epoch 584/5000\n",
      "31/31 - 0s - loss: 4.8418 - mae: 1.3544 - val_loss: 1.5140 - val_mae: 1.1739 - 35ms/epoch - 1ms/step\n",
      "Epoch 585/5000\n",
      "31/31 - 0s - loss: 19.4735 - mae: 2.3074 - val_loss: 0.2549 - val_mae: 0.3938 - 33ms/epoch - 1ms/step\n",
      "Epoch 586/5000\n",
      "31/31 - 0s - loss: 2.3180 - mae: 1.2435 - val_loss: 0.3473 - val_mae: 0.4590 - 33ms/epoch - 1ms/step\n",
      "Epoch 587/5000\n",
      "31/31 - 0s - loss: 12.6542 - mae: 1.7626 - val_loss: 23.6095 - val_mae: 4.8444 - 32ms/epoch - 1ms/step\n",
      "Epoch 588/5000\n",
      "31/31 - 0s - loss: 2.9805 - mae: 1.3244 - val_loss: 4.5472 - val_mae: 2.1002 - 34ms/epoch - 1ms/step\n",
      "Epoch 589/5000\n",
      "31/31 - 0s - loss: 5.9343 - mae: 1.5726 - val_loss: 23.5499 - val_mae: 4.8389 - 31ms/epoch - 1ms/step\n",
      "Epoch 590/5000\n",
      "31/31 - 0s - loss: 3.6466 - mae: 1.5462 - val_loss: 3.9945 - val_mae: 1.9640 - 33ms/epoch - 1ms/step\n",
      "Epoch 591/5000\n",
      "31/31 - 0s - loss: 6.9609 - mae: 1.8770 - val_loss: 0.2947 - val_mae: 0.4689 - 32ms/epoch - 1ms/step\n",
      "Epoch 592/5000\n",
      "31/31 - 0s - loss: 5.2383 - mae: 1.5897 - val_loss: 0.1643 - val_mae: 0.3272 - 33ms/epoch - 1ms/step\n",
      "Epoch 593/5000\n",
      "31/31 - 0s - loss: 2.7610 - mae: 1.4176 - val_loss: 34.9339 - val_mae: 5.8973 - 34ms/epoch - 1ms/step\n",
      "Epoch 594/5000\n",
      "31/31 - 0s - loss: 6.9173 - mae: 2.0641 - val_loss: 0.1703 - val_mae: 0.3263 - 34ms/epoch - 1ms/step\n",
      "Epoch 595/5000\n",
      "31/31 - 0s - loss: 15.6554 - mae: 2.5694 - val_loss: 2.7392 - val_mae: 1.6144 - 33ms/epoch - 1ms/step\n",
      "Epoch 596/5000\n",
      "31/31 - 0s - loss: 3.0473 - mae: 1.3152 - val_loss: 7.2160 - val_mae: 2.6599 - 33ms/epoch - 1ms/step\n",
      "Epoch 597/5000\n",
      "31/31 - 0s - loss: 6.1879 - mae: 1.8352 - val_loss: 3.4124 - val_mae: 1.8098 - 34ms/epoch - 1ms/step\n",
      "Epoch 598/5000\n",
      "31/31 - 0s - loss: 15.1579 - mae: 2.2658 - val_loss: 0.6332 - val_mae: 0.7004 - 34ms/epoch - 1ms/step\n",
      "Epoch 599/5000\n",
      "31/31 - 0s - loss: 3.7488 - mae: 1.5796 - val_loss: 6.1593 - val_mae: 2.4542 - 35ms/epoch - 1ms/step\n",
      "Epoch 600/5000\n",
      "31/31 - 0s - loss: 14.3364 - mae: 2.5045 - val_loss: 2.2715 - val_mae: 1.4610 - 33ms/epoch - 1ms/step\n",
      "Epoch 601/5000\n",
      "31/31 - 0s - loss: 1.8505 - mae: 1.1430 - val_loss: 0.3440 - val_mae: 0.4980 - 33ms/epoch - 1ms/step\n",
      "Epoch 602/5000\n",
      "31/31 - 0s - loss: 8.6007 - mae: 2.0358 - val_loss: 0.1695 - val_mae: 0.3617 - 34ms/epoch - 1ms/step\n",
      "Epoch 603/5000\n",
      "31/31 - 0s - loss: 9.7295 - mae: 2.1040 - val_loss: 14.2557 - val_mae: 3.7567 - 35ms/epoch - 1ms/step\n",
      "Epoch 604/5000\n",
      "31/31 - 0s - loss: 3.8851 - mae: 1.6792 - val_loss: 4.9907 - val_mae: 2.2037 - 34ms/epoch - 1ms/step\n",
      "Epoch 605/5000\n",
      "31/31 - 0s - loss: 8.4646 - mae: 2.0994 - val_loss: 0.2349 - val_mae: 0.3730 - 34ms/epoch - 1ms/step\n",
      "Epoch 606/5000\n",
      "31/31 - 0s - loss: 13.4495 - mae: 2.2874 - val_loss: 0.1738 - val_mae: 0.3301 - 32ms/epoch - 1ms/step\n",
      "Epoch 607/5000\n",
      "31/31 - 0s - loss: 2.2750 - mae: 1.2291 - val_loss: 5.4831 - val_mae: 2.3117 - 33ms/epoch - 1ms/step\n",
      "Epoch 608/5000\n",
      "31/31 - 0s - loss: 7.4206 - mae: 2.0628 - val_loss: 3.8878 - val_mae: 1.9367 - 33ms/epoch - 1ms/step\n",
      "Epoch 609/5000\n",
      "31/31 - 0s - loss: 3.0730 - mae: 1.3183 - val_loss: 87.4508 - val_mae: 9.3438 - 34ms/epoch - 1ms/step\n",
      "Epoch 610/5000\n",
      "31/31 - 0s - loss: 10.7564 - mae: 2.4314 - val_loss: 3.5593 - val_mae: 1.8502 - 33ms/epoch - 1ms/step\n",
      "Epoch 611/5000\n",
      "31/31 - 0s - loss: 9.9113 - mae: 1.8569 - val_loss: 40.3271 - val_mae: 6.3397 - 33ms/epoch - 1ms/step\n",
      "Epoch 612/5000\n",
      "31/31 - 0s - loss: 2.8804 - mae: 1.3535 - val_loss: 0.2856 - val_mae: 0.4142 - 33ms/epoch - 1ms/step\n",
      "Epoch 613/5000\n",
      "31/31 - 0s - loss: 8.3398 - mae: 2.0103 - val_loss: 3.6482 - val_mae: 1.8730 - 34ms/epoch - 1ms/step\n",
      "Epoch 614/5000\n",
      "31/31 - 0s - loss: 3.4830 - mae: 1.5470 - val_loss: 0.3480 - val_mae: 0.4629 - 35ms/epoch - 1ms/step\n",
      "Epoch 615/5000\n",
      "31/31 - 0s - loss: 26.6165 - mae: 2.1634 - val_loss: 4.5811 - val_mae: 2.1092 - 35ms/epoch - 1ms/step\n",
      "Epoch 616/5000\n",
      "31/31 - 0s - loss: 2.4807 - mae: 1.3054 - val_loss: 1.9591 - val_mae: 1.3544 - 33ms/epoch - 1ms/step\n",
      "Epoch 617/5000\n",
      "31/31 - 0s - loss: 11.0052 - mae: 2.0649 - val_loss: 23.9034 - val_mae: 4.8747 - 33ms/epoch - 1ms/step\n",
      "Epoch 618/5000\n",
      "31/31 - 0s - loss: 3.8879 - mae: 1.3327 - val_loss: 2.9390 - val_mae: 1.6762 - 33ms/epoch - 1ms/step\n",
      "Epoch 619/5000\n",
      "31/31 - 0s - loss: 26.9836 - mae: 2.5464 - val_loss: 0.1524 - val_mae: 0.3326 - 32ms/epoch - 1ms/step\n",
      "Epoch 620/5000\n",
      "31/31 - 0s - loss: 2.3965 - mae: 1.2959 - val_loss: 1.3161 - val_mae: 1.0890 - 34ms/epoch - 1ms/step\n",
      "Epoch 621/5000\n",
      "31/31 - 0s - loss: 4.1609 - mae: 1.4393 - val_loss: 20.5294 - val_mae: 4.5157 - 35ms/epoch - 1ms/step\n",
      "Epoch 622/5000\n",
      "31/31 - 0s - loss: 4.2552 - mae: 1.4648 - val_loss: 0.3560 - val_mae: 0.4726 - 33ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 623/5000\n",
      "31/31 - 0s - loss: 17.4704 - mae: 2.1134 - val_loss: 3.5001 - val_mae: 1.8362 - 35ms/epoch - 1ms/step\n",
      "Epoch 624/5000\n",
      "31/31 - 0s - loss: 2.1475 - mae: 1.0584 - val_loss: 12.8611 - val_mae: 3.5673 - 33ms/epoch - 1ms/step\n",
      "Epoch 625/5000\n",
      "31/31 - 0s - loss: 4.5488 - mae: 1.6500 - val_loss: 1.8242 - val_mae: 1.2999 - 33ms/epoch - 1ms/step\n",
      "Epoch 626/5000\n",
      "31/31 - 0s - loss: 14.4012 - mae: 2.0724 - val_loss: 3.4719 - val_mae: 1.8231 - 35ms/epoch - 1ms/step\n",
      "Epoch 627/5000\n",
      "31/31 - 0s - loss: 2.6834 - mae: 1.2609 - val_loss: 0.1920 - val_mae: 0.3367 - 34ms/epoch - 1ms/step\n",
      "Epoch 628/5000\n",
      "31/31 - 0s - loss: 10.7012 - mae: 2.1756 - val_loss: 0.1406 - val_mae: 0.3228 - 36ms/epoch - 1ms/step\n",
      "Epoch 629/5000\n",
      "31/31 - 0s - loss: 2.1646 - mae: 1.2385 - val_loss: 0.1279 - val_mae: 0.3122 - 32ms/epoch - 1ms/step\n",
      "Epoch 630/5000\n",
      "31/31 - 0s - loss: 11.3510 - mae: 2.3961 - val_loss: 1.8726 - val_mae: 1.3188 - 35ms/epoch - 1ms/step\n",
      "Epoch 631/5000\n",
      "31/31 - 0s - loss: 8.0539 - mae: 2.0545 - val_loss: 0.8077 - val_mae: 0.8233 - 33ms/epoch - 1ms/step\n",
      "Epoch 632/5000\n",
      "31/31 - 0s - loss: 3.1112 - mae: 1.4243 - val_loss: 1.8441 - val_mae: 1.3092 - 34ms/epoch - 1ms/step\n",
      "Epoch 633/5000\n",
      "31/31 - 0s - loss: 9.5594 - mae: 2.1234 - val_loss: 6.2135 - val_mae: 2.4658 - 34ms/epoch - 1ms/step\n",
      "Epoch 634/5000\n",
      "31/31 - 0s - loss: 10.0784 - mae: 2.0484 - val_loss: 6.3315 - val_mae: 2.4893 - 34ms/epoch - 1ms/step\n",
      "Epoch 635/5000\n",
      "31/31 - 0s - loss: 2.4889 - mae: 1.2892 - val_loss: 1.3166 - val_mae: 1.0885 - 33ms/epoch - 1ms/step\n",
      "Epoch 636/5000\n",
      "31/31 - 0s - loss: 13.9312 - mae: 2.1018 - val_loss: 1.8832 - val_mae: 1.3235 - 34ms/epoch - 1ms/step\n",
      "Epoch 637/5000\n",
      "31/31 - 0s - loss: 1.5322 - mae: 1.0175 - val_loss: 0.9246 - val_mae: 0.8882 - 34ms/epoch - 1ms/step\n",
      "Epoch 638/5000\n",
      "31/31 - 0s - loss: 13.1340 - mae: 2.2927 - val_loss: 2.9492 - val_mae: 1.6783 - 34ms/epoch - 1ms/step\n",
      "Epoch 639/5000\n",
      "31/31 - 0s - loss: 2.8632 - mae: 1.1830 - val_loss: 41.6874 - val_mae: 6.4466 - 35ms/epoch - 1ms/step\n",
      "Epoch 640/5000\n",
      "31/31 - 0s - loss: 13.0043 - mae: 2.4637 - val_loss: 3.4709 - val_mae: 1.8266 - 33ms/epoch - 1ms/step\n",
      "Epoch 641/5000\n",
      "31/31 - 0s - loss: 17.3454 - mae: 2.6072 - val_loss: 2.4986 - val_mae: 1.5372 - 34ms/epoch - 1ms/step\n",
      "Epoch 642/5000\n",
      "31/31 - 0s - loss: 2.0649 - mae: 1.1845 - val_loss: 1.0505 - val_mae: 0.9581 - 34ms/epoch - 1ms/step\n",
      "Epoch 643/5000\n",
      "31/31 - 0s - loss: 18.5767 - mae: 2.0432 - val_loss: 0.3738 - val_mae: 0.5139 - 33ms/epoch - 1ms/step\n",
      "Epoch 644/5000\n",
      "31/31 - 0s - loss: 3.4068 - mae: 1.3535 - val_loss: 0.1767 - val_mae: 0.3724 - 33ms/epoch - 1ms/step\n",
      "Epoch 645/5000\n",
      "31/31 - 0s - loss: 6.0973 - mae: 1.5868 - val_loss: 377.4631 - val_mae: 19.4248 - 35ms/epoch - 1ms/step\n",
      "Epoch 646/5000\n",
      "31/31 - 0s - loss: 17.6874 - mae: 2.1907 - val_loss: 7.8210 - val_mae: 2.7726 - 34ms/epoch - 1ms/step\n",
      "Epoch 647/5000\n",
      "31/31 - 0s - loss: 7.0287 - mae: 1.7750 - val_loss: 24.2247 - val_mae: 4.9084 - 32ms/epoch - 1ms/step\n",
      "Epoch 648/5000\n",
      "31/31 - 0s - loss: 3.2066 - mae: 1.4100 - val_loss: 0.4992 - val_mae: 0.6058 - 36ms/epoch - 1ms/step\n",
      "Epoch 649/5000\n",
      "31/31 - 0s - loss: 5.9073 - mae: 1.7129 - val_loss: 2.9633 - val_mae: 1.6830 - 34ms/epoch - 1ms/step\n",
      "Epoch 650/5000\n",
      "31/31 - 0s - loss: 11.7769 - mae: 2.1727 - val_loss: 0.1993 - val_mae: 0.3981 - 33ms/epoch - 1ms/step\n",
      "Epoch 651/5000\n",
      "31/31 - 0s - loss: 3.3507 - mae: 1.5021 - val_loss: 0.1980 - val_mae: 0.3429 - 33ms/epoch - 1ms/step\n",
      "Epoch 652/5000\n",
      "31/31 - 0s - loss: 7.1241 - mae: 2.0974 - val_loss: 1.9498 - val_mae: 1.3480 - 34ms/epoch - 1ms/step\n",
      "Epoch 653/5000\n",
      "31/31 - 0s - loss: 9.4209 - mae: 2.0813 - val_loss: 0.8999 - val_mae: 0.8769 - 32ms/epoch - 1ms/step\n",
      "Epoch 654/5000\n",
      "31/31 - 0s - loss: 1.7790 - mae: 1.0605 - val_loss: 2.9199 - val_mae: 1.6694 - 34ms/epoch - 1ms/step\n",
      "Epoch 655/5000\n",
      "31/31 - 0s - loss: 13.1132 - mae: 2.3837 - val_loss: 3.5782 - val_mae: 1.8554 - 35ms/epoch - 1ms/step\n",
      "Epoch 656/5000\n",
      "31/31 - 0s - loss: 6.4601 - mae: 1.9851 - val_loss: 0.3490 - val_mae: 0.5003 - 33ms/epoch - 1ms/step\n",
      "Epoch 657/5000\n",
      "31/31 - 0s - loss: 19.2161 - mae: 2.1756 - val_loss: 0.2616 - val_mae: 0.4475 - 34ms/epoch - 1ms/step\n",
      "Epoch 658/5000\n",
      "31/31 - 0s - loss: 3.2189 - mae: 1.3378 - val_loss: 1.4759 - val_mae: 1.1605 - 36ms/epoch - 1ms/step\n",
      "Epoch 659/5000\n",
      "31/31 - 0s - loss: 2.0012 - mae: 1.1632 - val_loss: 0.1468 - val_mae: 0.3377 - 33ms/epoch - 1ms/step\n",
      "Epoch 660/5000\n",
      "31/31 - 0s - loss: 12.0762 - mae: 2.5128 - val_loss: 0.6991 - val_mae: 0.7537 - 33ms/epoch - 1ms/step\n",
      "Epoch 661/5000\n",
      "31/31 - 0s - loss: 14.5729 - mae: 2.2733 - val_loss: 13.8620 - val_mae: 3.7039 - 33ms/epoch - 1ms/step\n",
      "Epoch 662/5000\n",
      "31/31 - 0s - loss: 3.5687 - mae: 1.4823 - val_loss: 0.2408 - val_mae: 0.3834 - 33ms/epoch - 1ms/step\n",
      "Epoch 663/5000\n",
      "31/31 - 0s - loss: 8.2700 - mae: 2.0244 - val_loss: 1.4526 - val_mae: 1.1457 - 34ms/epoch - 1ms/step\n",
      "Epoch 664/5000\n",
      "31/31 - 0s - loss: 2.0007 - mae: 1.1416 - val_loss: 0.8732 - val_mae: 0.8614 - 34ms/epoch - 1ms/step\n",
      "Epoch 665/5000\n",
      "31/31 - 0s - loss: 5.1220 - mae: 1.6516 - val_loss: 3.6454 - val_mae: 1.8752 - 34ms/epoch - 1ms/step\n",
      "Epoch 666/5000\n",
      "31/31 - 0s - loss: 12.6786 - mae: 2.1687 - val_loss: 0.1586 - val_mae: 0.3245 - 33ms/epoch - 1ms/step\n",
      "Epoch 667/5000\n",
      "31/31 - 0s - loss: 1.7917 - mae: 0.9548 - val_loss: 21.8108 - val_mae: 4.6555 - 33ms/epoch - 1ms/step\n",
      "Epoch 668/5000\n",
      "31/31 - 0s - loss: 7.9390 - mae: 1.8970 - val_loss: 0.1341 - val_mae: 0.3226 - 33ms/epoch - 1ms/step\n",
      "Epoch 669/5000\n",
      "31/31 - 0s - loss: 11.9657 - mae: 2.3675 - val_loss: 0.6803 - val_mae: 0.7395 - 32ms/epoch - 1ms/step\n",
      "Epoch 670/5000\n",
      "31/31 - 0s - loss: 3.2425 - mae: 1.4954 - val_loss: 0.3155 - val_mae: 0.4814 - 35ms/epoch - 1ms/step\n",
      "Epoch 671/5000\n",
      "31/31 - 0s - loss: 13.9788 - mae: 2.0084 - val_loss: 1.9931 - val_mae: 1.3658 - 33ms/epoch - 1ms/step\n",
      "Epoch 672/5000\n",
      "31/31 - 0s - loss: 1.5398 - mae: 1.0127 - val_loss: 0.2859 - val_mae: 0.4633 - 33ms/epoch - 1ms/step\n",
      "Epoch 673/5000\n",
      "31/31 - 0s - loss: 7.6992 - mae: 2.0234 - val_loss: 4.8325 - val_mae: 2.1683 - 32ms/epoch - 1ms/step\n",
      "Epoch 674/5000\n",
      "31/31 - 0s - loss: 1.8641 - mae: 1.1366 - val_loss: 49.5968 - val_mae: 7.0322 - 32ms/epoch - 1ms/step\n",
      "Epoch 675/5000\n",
      "31/31 - 0s - loss: 13.6382 - mae: 2.2707 - val_loss: 2.6309 - val_mae: 1.5820 - 35ms/epoch - 1ms/step\n",
      "Epoch 676/5000\n",
      "31/31 - 0s - loss: 5.9229 - mae: 1.6015 - val_loss: 36.2052 - val_mae: 6.0064 - 36ms/epoch - 1ms/step\n",
      "Epoch 677/5000\n",
      "31/31 - 0s - loss: 3.8538 - mae: 1.4751 - val_loss: 0.3293 - val_mae: 0.4449 - 34ms/epoch - 1ms/step\n",
      "Epoch 678/5000\n",
      "31/31 - 0s - loss: 12.3990 - mae: 2.4096 - val_loss: 1.1179 - val_mae: 0.9927 - 34ms/epoch - 1ms/step\n",
      "Epoch 679/5000\n",
      "31/31 - 0s - loss: 2.1574 - mae: 1.2121 - val_loss: 1.7945 - val_mae: 1.2901 - 37ms/epoch - 1ms/step\n",
      "Epoch 680/5000\n",
      "31/31 - 0s - loss: 19.9178 - mae: 2.0927 - val_loss: 0.8615 - val_mae: 0.8568 - 38ms/epoch - 1ms/step\n",
      "Epoch 681/5000\n",
      "31/31 - 0s - loss: 1.6543 - mae: 0.9830 - val_loss: 1.5478 - val_mae: 1.1903 - 36ms/epoch - 1ms/step\n",
      "Epoch 682/5000\n",
      "31/31 - 0s - loss: 7.7523 - mae: 2.1866 - val_loss: 2.0073 - val_mae: 1.3698 - 37ms/epoch - 1ms/step\n",
      "Epoch 683/5000\n",
      "31/31 - 0s - loss: 32.7427 - mae: 2.6682 - val_loss: 1.7794 - val_mae: 1.2806 - 37ms/epoch - 1ms/step\n",
      "Epoch 684/5000\n",
      "31/31 - 0s - loss: 1.6125 - mae: 1.0648 - val_loss: 0.3544 - val_mae: 0.5038 - 39ms/epoch - 1ms/step\n",
      "Epoch 685/5000\n",
      "31/31 - 0s - loss: 2.1894 - mae: 1.1179 - val_loss: 0.1888 - val_mae: 0.3870 - 38ms/epoch - 1ms/step\n",
      "Epoch 686/5000\n",
      "31/31 - 0s - loss: 31.2023 - mae: 2.6746 - val_loss: 3.3198 - val_mae: 1.7856 - 39ms/epoch - 1ms/step\n",
      "Epoch 687/5000\n",
      "31/31 - 0s - loss: 2.9597 - mae: 1.3930 - val_loss: 2.9056 - val_mae: 1.6661 - 38ms/epoch - 1ms/step\n",
      "Epoch 688/5000\n",
      "31/31 - 0s - loss: 6.4711 - mae: 2.0894 - val_loss: 12.4716 - val_mae: 3.5124 - 39ms/epoch - 1ms/step\n",
      "Epoch 689/5000\n",
      "31/31 - 0s - loss: 9.0935 - mae: 2.1433 - val_loss: 0.1574 - val_mae: 0.3413 - 39ms/epoch - 1ms/step\n",
      "Epoch 690/5000\n",
      "31/31 - 0s - loss: 1.7934 - mae: 1.0792 - val_loss: 0.2943 - val_mae: 0.4223 - 40ms/epoch - 1ms/step\n",
      "Epoch 691/5000\n",
      "31/31 - 0s - loss: 6.7457 - mae: 1.9005 - val_loss: 1.8147 - val_mae: 1.2982 - 38ms/epoch - 1ms/step\n",
      "Epoch 692/5000\n",
      "31/31 - 0s - loss: 7.4870 - mae: 1.9072 - val_loss: 0.2018 - val_mae: 0.3449 - 42ms/epoch - 1ms/step\n",
      "Epoch 693/5000\n",
      "31/31 - 0s - loss: 10.4268 - mae: 1.7244 - val_loss: 18.0012 - val_mae: 4.2272 - 41ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/5000\n",
      "31/31 - 0s - loss: 4.3571 - mae: 1.7230 - val_loss: 0.6144 - val_mae: 0.6996 - 48ms/epoch - 2ms/step\n",
      "Epoch 695/5000\n",
      "31/31 - 0s - loss: 11.0772 - mae: 1.9744 - val_loss: 19.3830 - val_mae: 4.3889 - 36ms/epoch - 1ms/step\n",
      "Epoch 696/5000\n",
      "31/31 - 0s - loss: 2.8112 - mae: 1.3221 - val_loss: 0.2178 - val_mae: 0.3595 - 38ms/epoch - 1ms/step\n",
      "Epoch 697/5000\n",
      "31/31 - 0s - loss: 20.0904 - mae: 2.1494 - val_loss: 2.7571 - val_mae: 1.6195 - 39ms/epoch - 1ms/step\n",
      "Epoch 698/5000\n",
      "31/31 - 0s - loss: 1.8207 - mae: 1.1036 - val_loss: 4.7908 - val_mae: 2.1588 - 37ms/epoch - 1ms/step\n",
      "Epoch 699/5000\n",
      "31/31 - 0s - loss: 3.6083 - mae: 1.5087 - val_loss: 6.7179 - val_mae: 2.5644 - 38ms/epoch - 1ms/step\n",
      "Epoch 700/5000\n",
      "31/31 - 0s - loss: 3.8909 - mae: 1.6353 - val_loss: 0.1547 - val_mae: 0.3439 - 40ms/epoch - 1ms/step\n",
      "Epoch 701/5000\n",
      "31/31 - 0s - loss: 16.2090 - mae: 2.3214 - val_loss: 0.4627 - val_mae: 0.5783 - 38ms/epoch - 1ms/step\n",
      "Epoch 702/5000\n",
      "31/31 - 0s - loss: 1.0457 - mae: 0.8312 - val_loss: 3.2360 - val_mae: 1.7623 - 36ms/epoch - 1ms/step\n",
      "Epoch 703/5000\n",
      "31/31 - 0s - loss: 7.2146 - mae: 1.8139 - val_loss: 0.1540 - val_mae: 0.3164 - 36ms/epoch - 1ms/step\n",
      "Epoch 704/5000\n",
      "31/31 - 0s - loss: 17.2028 - mae: 2.2980 - val_loss: 0.1885 - val_mae: 0.3332 - 35ms/epoch - 1ms/step\n",
      "Epoch 705/5000\n",
      "31/31 - 0s - loss: 1.5416 - mae: 0.9596 - val_loss: 0.4087 - val_mae: 0.5277 - 37ms/epoch - 1ms/step\n",
      "Epoch 706/5000\n",
      "31/31 - 0s - loss: 11.6457 - mae: 2.2985 - val_loss: 0.2320 - val_mae: 0.3702 - 39ms/epoch - 1ms/step\n",
      "Epoch 707/5000\n",
      "31/31 - 0s - loss: 2.3627 - mae: 1.2007 - val_loss: 0.6335 - val_mae: 0.7193 - 37ms/epoch - 1ms/step\n",
      "Epoch 708/5000\n",
      "31/31 - 0s - loss: 9.7864 - mae: 2.1224 - val_loss: 1.8039 - val_mae: 1.2939 - 37ms/epoch - 1ms/step\n",
      "Epoch 709/5000\n",
      "31/31 - 0s - loss: 8.7950 - mae: 1.9760 - val_loss: 0.4008 - val_mae: 0.5293 - 35ms/epoch - 1ms/step\n",
      "Epoch 710/5000\n",
      "31/31 - 0s - loss: 1.7629 - mae: 1.1313 - val_loss: 1.0255 - val_mae: 0.9454 - 37ms/epoch - 1ms/step\n",
      "Epoch 711/5000\n",
      "31/31 - 0s - loss: 16.9995 - mae: 2.0429 - val_loss: 0.7262 - val_mae: 0.7719 - 37ms/epoch - 1ms/step\n",
      "Epoch 712/5000\n",
      "31/31 - 0s - loss: 2.3993 - mae: 1.3199 - val_loss: 1.4134 - val_mae: 1.1338 - 38ms/epoch - 1ms/step\n",
      "Epoch 713/5000\n",
      "31/31 - 0s - loss: 19.3027 - mae: 2.1055 - val_loss: 1.9821 - val_mae: 1.3580 - 37ms/epoch - 1ms/step\n",
      "Epoch 714/5000\n",
      "31/31 - 0s - loss: 1.2593 - mae: 0.8606 - val_loss: 8.9895 - val_mae: 2.9766 - 37ms/epoch - 1ms/step\n",
      "Epoch 715/5000\n",
      "31/31 - 0s - loss: 13.8068 - mae: 2.3346 - val_loss: 1.4131 - val_mae: 1.1325 - 38ms/epoch - 1ms/step\n",
      "Epoch 716/5000\n",
      "31/31 - 0s - loss: 2.5290 - mae: 1.2674 - val_loss: 1.8871 - val_mae: 1.3246 - 39ms/epoch - 1ms/step\n",
      "Epoch 717/5000\n",
      "31/31 - 0s - loss: 11.4205 - mae: 2.1583 - val_loss: 0.1333 - val_mae: 0.3190 - 40ms/epoch - 1ms/step\n",
      "Epoch 718/5000\n",
      "31/31 - 0s - loss: 0.9863 - mae: 0.8563 - val_loss: 0.6292 - val_mae: 0.7055 - 36ms/epoch - 1ms/step\n",
      "Epoch 719/5000\n",
      "31/31 - 0s - loss: 14.2804 - mae: 2.4662 - val_loss: 4.5626 - val_mae: 2.1062 - 38ms/epoch - 1ms/step\n",
      "Epoch 720/5000\n",
      "31/31 - 0s - loss: 6.9988 - mae: 2.0087 - val_loss: 24.6719 - val_mae: 4.9559 - 39ms/epoch - 1ms/step\n",
      "Epoch 721/5000\n",
      "31/31 - 0s - loss: 3.1359 - mae: 1.3509 - val_loss: 0.1430 - val_mae: 0.3137 - 40ms/epoch - 1ms/step\n",
      "Epoch 722/5000\n",
      "31/31 - 0s - loss: 22.4157 - mae: 2.2660 - val_loss: 1.7227 - val_mae: 1.2590 - 40ms/epoch - 1ms/step\n",
      "Epoch 723/5000\n",
      "31/31 - 0s - loss: 1.9292 - mae: 1.1452 - val_loss: 1.0255 - val_mae: 0.9471 - 40ms/epoch - 1ms/step\n",
      "Epoch 724/5000\n",
      "31/31 - 0s - loss: 25.2496 - mae: 2.4717 - val_loss: 0.1785 - val_mae: 0.3735 - 40ms/epoch - 1ms/step\n",
      "Epoch 725/5000\n",
      "31/31 - 0s - loss: 2.1849 - mae: 1.1901 - val_loss: 5.0753 - val_mae: 2.2245 - 41ms/epoch - 1ms/step\n",
      "Epoch 726/5000\n",
      "31/31 - 0s - loss: 6.2203 - mae: 1.6865 - val_loss: 0.1669 - val_mae: 0.3138 - 39ms/epoch - 1ms/step\n",
      "Epoch 727/5000\n",
      "31/31 - 0s - loss: 2.0356 - mae: 0.9895 - val_loss: 0.1360 - val_mae: 0.3276 - 38ms/epoch - 1ms/step\n",
      "Epoch 728/5000\n",
      "31/31 - 0s - loss: 10.3822 - mae: 2.1479 - val_loss: 1.3123 - val_mae: 1.0880 - 42ms/epoch - 1ms/step\n",
      "Epoch 729/5000\n",
      "31/31 - 0s - loss: 5.1162 - mae: 1.6184 - val_loss: 2.0097 - val_mae: 1.3699 - 38ms/epoch - 1ms/step\n",
      "Epoch 730/5000\n",
      "31/31 - 0s - loss: 5.6930 - mae: 1.7183 - val_loss: 2.2003 - val_mae: 1.4397 - 38ms/epoch - 1ms/step\n",
      "Epoch 731/5000\n",
      "31/31 - 0s - loss: 2.9685 - mae: 1.3090 - val_loss: 10.3891 - val_mae: 3.2047 - 39ms/epoch - 1ms/step\n",
      "Epoch 732/5000\n",
      "31/31 - 0s - loss: 5.4222 - mae: 1.7591 - val_loss: 0.1625 - val_mae: 0.3038 - 37ms/epoch - 1ms/step\n",
      "Epoch 733/5000\n",
      "31/31 - 0s - loss: 11.8850 - mae: 2.1253 - val_loss: 0.4438 - val_mae: 0.5640 - 37ms/epoch - 1ms/step\n",
      "Epoch 734/5000\n",
      "31/31 - 0s - loss: 10.8012 - mae: 2.1773 - val_loss: 3.5056 - val_mae: 1.8399 - 39ms/epoch - 1ms/step\n",
      "Epoch 735/5000\n",
      "31/31 - 0s - loss: 1.6402 - mae: 1.0845 - val_loss: 0.1675 - val_mae: 0.3166 - 40ms/epoch - 1ms/step\n",
      "Epoch 736/5000\n",
      "31/31 - 0s - loss: 8.3807 - mae: 1.9532 - val_loss: 10.3848 - val_mae: 3.2026 - 40ms/epoch - 1ms/step\n",
      "Epoch 737/5000\n",
      "31/31 - 0s - loss: 2.3797 - mae: 1.2650 - val_loss: 2.5657 - val_mae: 1.5600 - 41ms/epoch - 1ms/step\n",
      "Epoch 738/5000\n",
      "31/31 - 0s - loss: 23.1874 - mae: 2.2393 - val_loss: 4.8657 - val_mae: 2.1759 - 41ms/epoch - 1ms/step\n",
      "Epoch 739/5000\n",
      "31/31 - 0s - loss: 1.9480 - mae: 1.1277 - val_loss: 2.3398 - val_mae: 1.4875 - 38ms/epoch - 1ms/step\n",
      "Epoch 740/5000\n",
      "31/31 - 0s - loss: 12.2914 - mae: 2.4389 - val_loss: 2.2825 - val_mae: 1.4682 - 38ms/epoch - 1ms/step\n",
      "Epoch 741/5000\n",
      "31/31 - 0s - loss: 3.5556 - mae: 1.5133 - val_loss: 0.1384 - val_mae: 0.3286 - 39ms/epoch - 1ms/step\n",
      "Epoch 742/5000\n",
      "31/31 - 0s - loss: 5.4513 - mae: 1.8652 - val_loss: 0.9776 - val_mae: 0.9251 - 38ms/epoch - 1ms/step\n",
      "Epoch 743/5000\n",
      "31/31 - 0s - loss: 13.8092 - mae: 2.2950 - val_loss: 0.6469 - val_mae: 0.7187 - 38ms/epoch - 1ms/step\n",
      "Epoch 744/5000\n",
      "31/31 - 0s - loss: 2.5349 - mae: 1.3491 - val_loss: 6.6078 - val_mae: 2.5457 - 37ms/epoch - 1ms/step\n",
      "Epoch 745/5000\n",
      "31/31 - 0s - loss: 11.6293 - mae: 2.3547 - val_loss: 0.7681 - val_mae: 0.8014 - 37ms/epoch - 1ms/step\n",
      "Epoch 746/5000\n",
      "31/31 - 0s - loss: 10.4247 - mae: 1.9723 - val_loss: 0.8207 - val_mae: 0.8226 - 37ms/epoch - 1ms/step\n",
      "Epoch 747/5000\n",
      "31/31 - 0s - loss: 3.3660 - mae: 1.5837 - val_loss: 0.9733 - val_mae: 0.9176 - 41ms/epoch - 1ms/step\n",
      "Epoch 748/5000\n",
      "31/31 - 0s - loss: 6.6860 - mae: 1.7914 - val_loss: 0.2090 - val_mae: 0.3515 - 37ms/epoch - 1ms/step\n",
      "Epoch 749/5000\n",
      "31/31 - 0s - loss: 12.3523 - mae: 2.2999 - val_loss: 0.3302 - val_mae: 0.4880 - 40ms/epoch - 1ms/step\n",
      "Epoch 750/5000\n",
      "31/31 - 0s - loss: 3.7061 - mae: 1.4505 - val_loss: 0.6172 - val_mae: 0.7017 - 37ms/epoch - 1ms/step\n",
      "Epoch 751/5000\n",
      "31/31 - 0s - loss: 12.5013 - mae: 2.1919 - val_loss: 0.1669 - val_mae: 0.3265 - 38ms/epoch - 1ms/step\n",
      "Epoch 752/5000\n",
      "31/31 - 0s - loss: 1.6718 - mae: 1.0576 - val_loss: 0.4692 - val_mae: 0.5841 - 39ms/epoch - 1ms/step\n",
      "Epoch 753/5000\n",
      "31/31 - 0s - loss: 9.6591 - mae: 2.4112 - val_loss: 13.4555 - val_mae: 3.6505 - 38ms/epoch - 1ms/step\n",
      "Epoch 754/5000\n",
      "31/31 - 0s - loss: 2.8324 - mae: 1.2881 - val_loss: 1.0477 - val_mae: 0.9516 - 39ms/epoch - 1ms/step\n",
      "Epoch 755/5000\n",
      "31/31 - 0s - loss: 9.3716 - mae: 2.3777 - val_loss: 1.2554 - val_mae: 1.0625 - 41ms/epoch - 1ms/step\n",
      "Epoch 756/5000\n",
      "31/31 - 0s - loss: 12.1970 - mae: 1.8045 - val_loss: 42.0121 - val_mae: 6.4718 - 38ms/epoch - 1ms/step\n",
      "Epoch 757/5000\n",
      "31/31 - 0s - loss: 5.4812 - mae: 1.8917 - val_loss: 9.5675 - val_mae: 3.0728 - 38ms/epoch - 1ms/step\n",
      "Epoch 758/5000\n",
      "31/31 - 0s - loss: 8.2997 - mae: 2.0585 - val_loss: 2.3299 - val_mae: 1.4838 - 39ms/epoch - 1ms/step\n",
      "Epoch 759/5000\n",
      "31/31 - 0s - loss: 3.6566 - mae: 1.3970 - val_loss: 15.9176 - val_mae: 3.9718 - 38ms/epoch - 1ms/step\n",
      "Epoch 760/5000\n",
      "31/31 - 0s - loss: 18.7163 - mae: 2.2762 - val_loss: 1.3087 - val_mae: 1.0881 - 39ms/epoch - 1ms/step\n",
      "Epoch 761/5000\n",
      "31/31 - 0s - loss: 3.8397 - mae: 1.4545 - val_loss: 18.7505 - val_mae: 4.3154 - 38ms/epoch - 1ms/step\n",
      "Epoch 762/5000\n",
      "31/31 - 0s - loss: 3.7066 - mae: 1.5376 - val_loss: 4.3959 - val_mae: 2.0663 - 40ms/epoch - 1ms/step\n",
      "Epoch 763/5000\n",
      "31/31 - 0s - loss: 11.8672 - mae: 2.3161 - val_loss: 15.4558 - val_mae: 3.9154 - 40ms/epoch - 1ms/step\n",
      "Epoch 764/5000\n",
      "31/31 - 0s - loss: 1.7413 - mae: 1.1051 - val_loss: 1.8142 - val_mae: 1.3004 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/5000\n",
      "31/31 - 0s - loss: 16.5059 - mae: 2.2500 - val_loss: 1.5444 - val_mae: 1.1917 - 39ms/epoch - 1ms/step\n",
      "Epoch 766/5000\n",
      "31/31 - 0s - loss: 2.0337 - mae: 1.2617 - val_loss: 0.1634 - val_mae: 0.3198 - 38ms/epoch - 1ms/step\n",
      "Epoch 767/5000\n",
      "31/31 - 0s - loss: 5.5179 - mae: 1.5531 - val_loss: 0.8815 - val_mae: 0.8708 - 38ms/epoch - 1ms/step\n",
      "Epoch 768/5000\n",
      "31/31 - 0s - loss: 36.0199 - mae: 2.4164 - val_loss: 0.6330 - val_mae: 0.7142 - 37ms/epoch - 1ms/step\n",
      "Epoch 769/5000\n",
      "31/31 - 0s - loss: 1.6948 - mae: 1.0430 - val_loss: 1.0409 - val_mae: 0.9594 - 38ms/epoch - 1ms/step\n",
      "Epoch 770/5000\n",
      "31/31 - 0s - loss: 6.0267 - mae: 1.6817 - val_loss: 2.8189 - val_mae: 1.6407 - 38ms/epoch - 1ms/step\n",
      "Epoch 771/5000\n",
      "31/31 - 0s - loss: 3.0976 - mae: 1.4587 - val_loss: 0.9592 - val_mae: 0.9083 - 38ms/epoch - 1ms/step\n",
      "Epoch 772/5000\n",
      "31/31 - 0s - loss: 6.0837 - mae: 1.7175 - val_loss: 1.6409 - val_mae: 1.2327 - 37ms/epoch - 1ms/step\n",
      "Epoch 773/5000\n",
      "31/31 - 0s - loss: 13.0469 - mae: 2.0990 - val_loss: 4.8827 - val_mae: 2.1801 - 39ms/epoch - 1ms/step\n",
      "Epoch 774/5000\n",
      "31/31 - 0s - loss: 1.9427 - mae: 1.1727 - val_loss: 0.6362 - val_mae: 0.7135 - 39ms/epoch - 1ms/step\n",
      "Epoch 775/5000\n",
      "31/31 - 0s - loss: 21.1413 - mae: 2.5087 - val_loss: 3.0153 - val_mae: 1.6986 - 38ms/epoch - 1ms/step\n",
      "Epoch 776/5000\n",
      "31/31 - 0s - loss: 2.0335 - mae: 1.2483 - val_loss: 0.4274 - val_mae: 0.5513 - 38ms/epoch - 1ms/step\n",
      "Epoch 777/5000\n",
      "31/31 - 0s - loss: 21.7659 - mae: 2.3594 - val_loss: 0.4965 - val_mae: 0.6084 - 41ms/epoch - 1ms/step\n",
      "Epoch 778/5000\n",
      "31/31 - 0s - loss: 2.1125 - mae: 1.2216 - val_loss: 0.9075 - val_mae: 0.8835 - 39ms/epoch - 1ms/step\n",
      "Epoch 779/5000\n",
      "31/31 - 0s - loss: 5.7984 - mae: 1.5763 - val_loss: 1.9573 - val_mae: 1.3491 - 37ms/epoch - 1ms/step\n",
      "Epoch 780/5000\n",
      "31/31 - 0s - loss: 2.0425 - mae: 1.0825 - val_loss: 0.1486 - val_mae: 0.3379 - 38ms/epoch - 1ms/step\n",
      "Epoch 781/5000\n",
      "31/31 - 0s - loss: 11.5594 - mae: 2.3767 - val_loss: 0.5204 - val_mae: 0.6297 - 37ms/epoch - 1ms/step\n",
      "Epoch 782/5000\n",
      "31/31 - 0s - loss: 4.9365 - mae: 1.4945 - val_loss: 69.4287 - val_mae: 8.3238 - 38ms/epoch - 1ms/step\n",
      "Epoch 783/5000\n",
      "31/31 - 0s - loss: 5.6938 - mae: 1.4015 - val_loss: 0.4189 - val_mae: 0.5420 - 39ms/epoch - 1ms/step\n",
      "Epoch 784/5000\n",
      "31/31 - 0s - loss: 31.4689 - mae: 2.4595 - val_loss: 0.1264 - val_mae: 0.3118 - 37ms/epoch - 1ms/step\n",
      "Epoch 785/5000\n",
      "31/31 - 0s - loss: 1.3876 - mae: 1.0400 - val_loss: 5.2410 - val_mae: 2.2637 - 39ms/epoch - 1ms/step\n",
      "Epoch 786/5000\n",
      "31/31 - 0s - loss: 4.1630 - mae: 1.4918 - val_loss: 155.0490 - val_mae: 12.4460 - 39ms/epoch - 1ms/step\n",
      "Epoch 787/5000\n",
      "31/31 - 0s - loss: 7.9663 - mae: 1.5800 - val_loss: 0.8667 - val_mae: 0.8629 - 37ms/epoch - 1ms/step\n",
      "Epoch 788/5000\n",
      "31/31 - 0s - loss: 15.3115 - mae: 2.0267 - val_loss: 6.7671 - val_mae: 2.5763 - 37ms/epoch - 1ms/step\n",
      "Epoch 789/5000\n",
      "31/31 - 0s - loss: 1.1263 - mae: 0.8877 - val_loss: 4.0381 - val_mae: 1.9787 - 40ms/epoch - 1ms/step\n",
      "Epoch 790/5000\n",
      "31/31 - 0s - loss: 10.5935 - mae: 2.0352 - val_loss: 1.8487 - val_mae: 1.3149 - 37ms/epoch - 1ms/step\n",
      "Epoch 791/5000\n",
      "31/31 - 0s - loss: 5.7179 - mae: 1.4875 - val_loss: 6.2715 - val_mae: 2.4805 - 40ms/epoch - 1ms/step\n",
      "Epoch 792/5000\n",
      "31/31 - 0s - loss: 3.7325 - mae: 1.5149 - val_loss: 0.5618 - val_mae: 0.6625 - 40ms/epoch - 1ms/step\n",
      "Epoch 793/5000\n",
      "31/31 - 0s - loss: 28.3615 - mae: 2.0756 - val_loss: 2.4338 - val_mae: 1.5190 - 39ms/epoch - 1ms/step\n",
      "Epoch 794/5000\n",
      "31/31 - 0s - loss: 1.6058 - mae: 0.9749 - val_loss: 2.8771 - val_mae: 1.6586 - 36ms/epoch - 1ms/step\n",
      "Epoch 795/5000\n",
      "31/31 - 0s - loss: 1.4957 - mae: 1.0158 - val_loss: 1.7781 - val_mae: 1.2851 - 36ms/epoch - 1ms/step\n",
      "Epoch 796/5000\n",
      "31/31 - 0s - loss: 12.8076 - mae: 2.1485 - val_loss: 7.1332 - val_mae: 2.6461 - 38ms/epoch - 1ms/step\n",
      "Epoch 797/5000\n",
      "31/31 - 0s - loss: 1.6866 - mae: 1.0148 - val_loss: 0.7509 - val_mae: 0.7853 - 38ms/epoch - 1ms/step\n",
      "Epoch 798/5000\n",
      "31/31 - 0s - loss: 10.1825 - mae: 2.2550 - val_loss: 3.1882 - val_mae: 1.7469 - 38ms/epoch - 1ms/step\n",
      "Epoch 799/5000\n",
      "31/31 - 0s - loss: 1.1663 - mae: 0.8278 - val_loss: 4.6574 - val_mae: 2.1294 - 38ms/epoch - 1ms/step\n",
      "Epoch 800/5000\n",
      "31/31 - 0s - loss: 19.3723 - mae: 2.5087 - val_loss: 7.5720 - val_mae: 2.7285 - 39ms/epoch - 1ms/step\n",
      "Epoch 801/5000\n",
      "31/31 - 0s - loss: 1.6750 - mae: 1.1522 - val_loss: 0.6366 - val_mae: 0.7155 - 38ms/epoch - 1ms/step\n",
      "Epoch 802/5000\n",
      "31/31 - 0s - loss: 8.0277 - mae: 1.8012 - val_loss: 0.3917 - val_mae: 0.5210 - 38ms/epoch - 1ms/step\n",
      "Epoch 803/5000\n",
      "31/31 - 0s - loss: 16.5953 - mae: 2.3607 - val_loss: 0.4838 - val_mae: 0.6030 - 37ms/epoch - 1ms/step\n",
      "Epoch 804/5000\n",
      "31/31 - 0s - loss: 2.2219 - mae: 1.2623 - val_loss: 2.6047 - val_mae: 1.5739 - 38ms/epoch - 1ms/step\n",
      "Epoch 805/5000\n",
      "31/31 - 0s - loss: 11.6841 - mae: 2.3554 - val_loss: 0.9448 - val_mae: 0.9079 - 38ms/epoch - 1ms/step\n",
      "Epoch 806/5000\n",
      "31/31 - 0s - loss: 1.6229 - mae: 1.0421 - val_loss: 2.4613 - val_mae: 1.5300 - 36ms/epoch - 1ms/step\n",
      "Epoch 807/5000\n",
      "31/31 - 0s - loss: 10.9983 - mae: 2.0842 - val_loss: 1.4711 - val_mae: 1.1600 - 38ms/epoch - 1ms/step\n",
      "Epoch 808/5000\n",
      "31/31 - 0s - loss: 10.0002 - mae: 2.1502 - val_loss: 0.1663 - val_mae: 0.3178 - 40ms/epoch - 1ms/step\n",
      "Epoch 809/5000\n",
      "31/31 - 0s - loss: 1.8414 - mae: 1.0738 - val_loss: 0.1833 - val_mae: 0.3259 - 37ms/epoch - 1ms/step\n",
      "Epoch 810/5000\n",
      "31/31 - 0s - loss: 10.1307 - mae: 1.9464 - val_loss: 0.2412 - val_mae: 0.3766 - 38ms/epoch - 1ms/step\n",
      "Epoch 811/5000\n",
      "31/31 - 0s - loss: 1.3750 - mae: 0.8960 - val_loss: 10.3092 - val_mae: 3.1944 - 40ms/epoch - 1ms/step\n",
      "Epoch 812/5000\n",
      "31/31 - 0s - loss: 15.3388 - mae: 1.7625 - val_loss: 4.4510 - val_mae: 2.0790 - 37ms/epoch - 1ms/step\n",
      "Epoch 813/5000\n",
      "31/31 - 0s - loss: 1.3631 - mae: 0.9511 - val_loss: 0.6573 - val_mae: 0.7268 - 37ms/epoch - 1ms/step\n",
      "Epoch 814/5000\n",
      "31/31 - 0s - loss: 16.2554 - mae: 2.2071 - val_loss: 0.7989 - val_mae: 0.8251 - 38ms/epoch - 1ms/step\n",
      "Epoch 815/5000\n",
      "31/31 - 0s - loss: 1.4370 - mae: 0.9529 - val_loss: 0.1366 - val_mae: 0.3180 - 38ms/epoch - 1ms/step\n",
      "Epoch 816/5000\n",
      "31/31 - 0s - loss: 12.5232 - mae: 2.1141 - val_loss: 2.4846 - val_mae: 1.5345 - 38ms/epoch - 1ms/step\n",
      "Epoch 817/5000\n",
      "31/31 - 0s - loss: 1.4807 - mae: 1.0007 - val_loss: 1.0078 - val_mae: 0.9426 - 38ms/epoch - 1ms/step\n",
      "Epoch 818/5000\n",
      "31/31 - 0s - loss: 10.4481 - mae: 2.1950 - val_loss: 0.9209 - val_mae: 0.8949 - 38ms/epoch - 1ms/step\n",
      "Epoch 819/5000\n",
      "31/31 - 0s - loss: 10.1583 - mae: 1.8927 - val_loss: 3.8552 - val_mae: 1.9308 - 38ms/epoch - 1ms/step\n",
      "Epoch 820/5000\n",
      "31/31 - 0s - loss: 1.8687 - mae: 1.1098 - val_loss: 1.5862 - val_mae: 1.2117 - 35ms/epoch - 1ms/step\n",
      "Epoch 821/5000\n",
      "31/31 - 0s - loss: 11.8388 - mae: 2.0291 - val_loss: 5.4784 - val_mae: 2.3153 - 38ms/epoch - 1ms/step\n",
      "Epoch 822/5000\n",
      "31/31 - 0s - loss: 9.0409 - mae: 2.2346 - val_loss: 0.1479 - val_mae: 0.3054 - 37ms/epoch - 1ms/step\n",
      "Epoch 823/5000\n",
      "31/31 - 0s - loss: 1.0092 - mae: 0.8220 - val_loss: 0.6084 - val_mae: 0.6978 - 38ms/epoch - 1ms/step\n",
      "Epoch 824/5000\n",
      "31/31 - 0s - loss: 10.6989 - mae: 1.8690 - val_loss: 0.7562 - val_mae: 0.7893 - 40ms/epoch - 1ms/step\n",
      "Epoch 825/5000\n",
      "31/31 - 0s - loss: 2.3585 - mae: 1.2668 - val_loss: 0.2562 - val_mae: 0.3886 - 39ms/epoch - 1ms/step\n",
      "Epoch 826/5000\n",
      "31/31 - 0s - loss: 7.3025 - mae: 1.9546 - val_loss: 3.0123 - val_mae: 1.6983 - 38ms/epoch - 1ms/step\n",
      "Epoch 827/5000\n",
      "31/31 - 0s - loss: 15.2302 - mae: 2.1880 - val_loss: 0.3206 - val_mae: 0.4844 - 38ms/epoch - 1ms/step\n",
      "Epoch 828/5000\n",
      "31/31 - 0s - loss: 1.8690 - mae: 1.0443 - val_loss: 1.5144 - val_mae: 1.1800 - 38ms/epoch - 1ms/step\n",
      "Epoch 829/5000\n",
      "31/31 - 0s - loss: 5.3848 - mae: 1.4299 - val_loss: 14.3193 - val_mae: 3.7665 - 39ms/epoch - 1ms/step\n",
      "Epoch 830/5000\n",
      "31/31 - 0s - loss: 4.4876 - mae: 1.6639 - val_loss: 64.8149 - val_mae: 8.0421 - 39ms/epoch - 1ms/step\n",
      "Epoch 831/5000\n",
      "31/31 - 0s - loss: 7.9960 - mae: 1.7879 - val_loss: 2.1072 - val_mae: 1.4107 - 38ms/epoch - 1ms/step\n",
      "Epoch 832/5000\n",
      "31/31 - 0s - loss: 7.2570 - mae: 1.8107 - val_loss: 7.9899 - val_mae: 2.8038 - 39ms/epoch - 1ms/step\n",
      "Epoch 833/5000\n",
      "31/31 - 0s - loss: 2.1175 - mae: 1.1543 - val_loss: 3.7801 - val_mae: 1.9093 - 51ms/epoch - 2ms/step\n",
      "Epoch 834/5000\n",
      "31/31 - 0s - loss: 11.9770 - mae: 2.3948 - val_loss: 0.3362 - val_mae: 0.4910 - 40ms/epoch - 1ms/step\n",
      "Epoch 835/5000\n",
      "31/31 - 0s - loss: 4.1295 - mae: 1.4442 - val_loss: 39.8189 - val_mae: 6.2993 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/5000\n",
      "31/31 - 0s - loss: 3.2039 - mae: 1.2665 - val_loss: 0.1846 - val_mae: 0.3298 - 39ms/epoch - 1ms/step\n",
      "Epoch 837/5000\n",
      "31/31 - 0s - loss: 8.6050 - mae: 2.0289 - val_loss: 0.1166 - val_mae: 0.3002 - 38ms/epoch - 1ms/step\n",
      "Epoch 838/5000\n",
      "31/31 - 0s - loss: 1.9215 - mae: 1.0654 - val_loss: 0.2504 - val_mae: 0.4386 - 38ms/epoch - 1ms/step\n",
      "Epoch 839/5000\n",
      "31/31 - 0s - loss: 15.7297 - mae: 2.3012 - val_loss: 0.3887 - val_mae: 0.5136 - 39ms/epoch - 1ms/step\n",
      "Epoch 840/5000\n",
      "31/31 - 0s - loss: 7.6607 - mae: 1.6991 - val_loss: 1.8228 - val_mae: 1.3073 - 37ms/epoch - 1ms/step\n",
      "Epoch 841/5000\n",
      "31/31 - 0s - loss: 2.1869 - mae: 1.1167 - val_loss: 0.2893 - val_mae: 0.4637 - 36ms/epoch - 1ms/step\n",
      "Epoch 842/5000\n",
      "31/31 - 0s - loss: 9.0004 - mae: 1.9452 - val_loss: 0.7245 - val_mae: 0.7715 - 36ms/epoch - 1ms/step\n",
      "Epoch 843/5000\n",
      "31/31 - 0s - loss: 1.7659 - mae: 1.0845 - val_loss: 1.8041 - val_mae: 1.2890 - 37ms/epoch - 1ms/step\n",
      "Epoch 844/5000\n",
      "31/31 - 0s - loss: 10.7176 - mae: 2.0384 - val_loss: 2.4158 - val_mae: 1.5158 - 37ms/epoch - 1ms/step\n",
      "Epoch 845/5000\n",
      "31/31 - 0s - loss: 14.2827 - mae: 2.4605 - val_loss: 5.0144 - val_mae: 2.2091 - 38ms/epoch - 1ms/step\n",
      "Epoch 846/5000\n",
      "31/31 - 0s - loss: 2.2241 - mae: 1.2035 - val_loss: 0.6605 - val_mae: 0.7352 - 36ms/epoch - 1ms/step\n",
      "Epoch 847/5000\n",
      "31/31 - 0s - loss: 16.6771 - mae: 2.0101 - val_loss: 1.1678 - val_mae: 1.0167 - 35ms/epoch - 1ms/step\n",
      "Epoch 848/5000\n",
      "31/31 - 0s - loss: 1.2033 - mae: 0.8849 - val_loss: 0.2150 - val_mae: 0.4123 - 37ms/epoch - 1ms/step\n",
      "Epoch 849/5000\n",
      "31/31 - 0s - loss: 7.1742 - mae: 1.8143 - val_loss: 0.8524 - val_mae: 0.8529 - 37ms/epoch - 1ms/step\n",
      "Epoch 850/5000\n",
      "31/31 - 0s - loss: 1.2302 - mae: 0.8597 - val_loss: 0.3771 - val_mae: 0.5042 - 37ms/epoch - 1ms/step\n",
      "Epoch 851/5000\n",
      "31/31 - 0s - loss: 18.3511 - mae: 2.2234 - val_loss: 1.3730 - val_mae: 1.1166 - 36ms/epoch - 1ms/step\n",
      "Epoch 852/5000\n",
      "31/31 - 0s - loss: 1.6299 - mae: 1.0813 - val_loss: 0.1243 - val_mae: 0.3114 - 34ms/epoch - 1ms/step\n",
      "Epoch 853/5000\n",
      "31/31 - 0s - loss: 11.5728 - mae: 2.3748 - val_loss: 0.4490 - val_mae: 0.5735 - 36ms/epoch - 1ms/step\n",
      "Epoch 854/5000\n",
      "31/31 - 0s - loss: 5.5759 - mae: 1.7653 - val_loss: 19.9060 - val_mae: 4.4464 - 35ms/epoch - 1ms/step\n",
      "Epoch 855/5000\n",
      "31/31 - 0s - loss: 2.8467 - mae: 1.2126 - val_loss: 0.1443 - val_mae: 0.3323 - 35ms/epoch - 1ms/step\n",
      "Epoch 856/5000\n",
      "31/31 - 0s - loss: 15.4447 - mae: 2.3973 - val_loss: 1.2294 - val_mae: 1.0511 - 35ms/epoch - 1ms/step\n",
      "Epoch 857/5000\n",
      "31/31 - 0s - loss: 2.1349 - mae: 1.2718 - val_loss: 5.4975 - val_mae: 2.3212 - 35ms/epoch - 1ms/step\n",
      "Epoch 858/5000\n",
      "31/31 - 0s - loss: 5.2668 - mae: 1.7455 - val_loss: 0.1302 - val_mae: 0.3100 - 36ms/epoch - 1ms/step\n",
      "Epoch 859/5000\n",
      "31/31 - 0s - loss: 26.3505 - mae: 2.5024 - val_loss: 3.5384 - val_mae: 1.8457 - 35ms/epoch - 1ms/step\n",
      "Epoch 860/5000\n",
      "31/31 - 0s - loss: 2.1660 - mae: 1.2757 - val_loss: 0.8854 - val_mae: 0.8749 - 38ms/epoch - 1ms/step\n",
      "Epoch 861/5000\n",
      "31/31 - 0s - loss: 3.6732 - mae: 1.2690 - val_loss: 0.2847 - val_mae: 0.4619 - 36ms/epoch - 1ms/step\n",
      "Epoch 862/5000\n",
      "31/31 - 0s - loss: 3.0135 - mae: 1.3210 - val_loss: 1.2872 - val_mae: 1.0809 - 38ms/epoch - 1ms/step\n",
      "Epoch 863/5000\n",
      "31/31 - 0s - loss: 8.8088 - mae: 2.0336 - val_loss: 1.0098 - val_mae: 0.9402 - 38ms/epoch - 1ms/step\n",
      "Epoch 864/5000\n",
      "31/31 - 0s - loss: 5.8041 - mae: 1.9587 - val_loss: 0.4579 - val_mae: 0.5792 - 38ms/epoch - 1ms/step\n",
      "Epoch 865/5000\n",
      "31/31 - 0s - loss: 1.7369 - mae: 1.0311 - val_loss: 2.7240 - val_mae: 1.6114 - 38ms/epoch - 1ms/step\n",
      "Epoch 866/5000\n",
      "31/31 - 0s - loss: 25.6386 - mae: 2.2964 - val_loss: 0.6702 - val_mae: 0.7416 - 39ms/epoch - 1ms/step\n",
      "Epoch 867/5000\n",
      "31/31 - 0s - loss: 2.5614 - mae: 1.1590 - val_loss: 0.6637 - val_mae: 0.7360 - 38ms/epoch - 1ms/step\n",
      "Epoch 868/5000\n",
      "31/31 - 0s - loss: 15.5607 - mae: 2.3624 - val_loss: 0.2298 - val_mae: 0.3681 - 36ms/epoch - 1ms/step\n",
      "Epoch 869/5000\n",
      "31/31 - 0s - loss: 0.8352 - mae: 0.7028 - val_loss: 0.3362 - val_mae: 0.4662 - 38ms/epoch - 1ms/step\n",
      "Epoch 870/5000\n",
      "31/31 - 0s - loss: 6.6306 - mae: 1.7358 - val_loss: 1.1094 - val_mae: 0.9951 - 37ms/epoch - 1ms/step\n",
      "Epoch 871/5000\n",
      "31/31 - 0s - loss: 19.7940 - mae: 2.0297 - val_loss: 0.6635 - val_mae: 0.7361 - 36ms/epoch - 1ms/step\n",
      "Epoch 872/5000\n",
      "31/31 - 0s - loss: 2.3444 - mae: 1.2536 - val_loss: 0.3077 - val_mae: 0.4327 - 39ms/epoch - 1ms/step\n",
      "Epoch 873/5000\n",
      "31/31 - 0s - loss: 2.2749 - mae: 1.3171 - val_loss: 14.5505 - val_mae: 3.7978 - 37ms/epoch - 1ms/step\n",
      "Epoch 874/5000\n",
      "31/31 - 0s - loss: 14.0632 - mae: 2.2434 - val_loss: 1.1167 - val_mae: 0.9961 - 37ms/epoch - 1ms/step\n",
      "Epoch 875/5000\n",
      "31/31 - 0s - loss: 1.4179 - mae: 0.9998 - val_loss: 2.2362 - val_mae: 1.4551 - 37ms/epoch - 1ms/step\n",
      "Epoch 876/5000\n",
      "31/31 - 0s - loss: 21.3293 - mae: 2.4082 - val_loss: 0.1538 - val_mae: 0.3024 - 37ms/epoch - 1ms/step\n",
      "Epoch 877/5000\n",
      "31/31 - 0s - loss: 3.0881 - mae: 1.3410 - val_loss: 0.9492 - val_mae: 0.9140 - 38ms/epoch - 1ms/step\n",
      "Epoch 878/5000\n",
      "31/31 - 0s - loss: 1.1356 - mae: 0.7989 - val_loss: 5.9095 - val_mae: 2.4068 - 37ms/epoch - 1ms/step\n",
      "Epoch 879/5000\n",
      "31/31 - 0s - loss: 10.9615 - mae: 2.0025 - val_loss: 0.1269 - val_mae: 0.3109 - 38ms/epoch - 1ms/step\n",
      "Epoch 880/5000\n",
      "31/31 - 0s - loss: 8.7418 - mae: 1.7953 - val_loss: 1.0338 - val_mae: 0.9526 - 38ms/epoch - 1ms/step\n",
      "Epoch 881/5000\n",
      "31/31 - 0s - loss: 0.9994 - mae: 0.8106 - val_loss: 2.1350 - val_mae: 1.4177 - 38ms/epoch - 1ms/step\n",
      "Epoch 882/5000\n",
      "31/31 - 0s - loss: 15.4227 - mae: 2.2037 - val_loss: 0.1327 - val_mae: 0.3140 - 39ms/epoch - 1ms/step\n",
      "Epoch 883/5000\n",
      "31/31 - 0s - loss: 2.8251 - mae: 1.3429 - val_loss: 4.5073 - val_mae: 2.0951 - 39ms/epoch - 1ms/step\n",
      "Epoch 884/5000\n",
      "31/31 - 0s - loss: 11.4589 - mae: 2.2390 - val_loss: 1.6318 - val_mae: 1.2302 - 37ms/epoch - 1ms/step\n",
      "Epoch 885/5000\n",
      "31/31 - 0s - loss: 13.6620 - mae: 2.2502 - val_loss: 1.9974 - val_mae: 1.3675 - 37ms/epoch - 1ms/step\n",
      "Epoch 886/5000\n",
      "31/31 - 0s - loss: 0.9895 - mae: 0.8032 - val_loss: 0.2726 - val_mae: 0.3966 - 38ms/epoch - 1ms/step\n",
      "Epoch 887/5000\n",
      "31/31 - 0s - loss: 13.3870 - mae: 2.1451 - val_loss: 2.9797 - val_mae: 1.6887 - 37ms/epoch - 1ms/step\n",
      "Epoch 888/5000\n",
      "31/31 - 0s - loss: 1.8392 - mae: 1.1462 - val_loss: 3.7992 - val_mae: 1.9173 - 38ms/epoch - 1ms/step\n",
      "Epoch 889/5000\n",
      "31/31 - 0s - loss: 14.0803 - mae: 2.3356 - val_loss: 0.3228 - val_mae: 0.4821 - 36ms/epoch - 1ms/step\n",
      "Epoch 890/5000\n",
      "31/31 - 0s - loss: 5.2480 - mae: 1.7058 - val_loss: 0.5676 - val_mae: 0.6775 - 37ms/epoch - 1ms/step\n",
      "Epoch 891/5000\n",
      "31/31 - 0s - loss: 17.0473 - mae: 2.0581 - val_loss: 0.8537 - val_mae: 0.8609 - 35ms/epoch - 1ms/step\n",
      "Epoch 892/5000\n",
      "31/31 - 0s - loss: 2.4376 - mae: 1.1095 - val_loss: 8.0141 - val_mae: 2.8104 - 37ms/epoch - 1ms/step\n",
      "Epoch 893/5000\n",
      "31/31 - 0s - loss: 2.7534 - mae: 1.3270 - val_loss: 15.6054 - val_mae: 3.9349 - 37ms/epoch - 1ms/step\n",
      "Epoch 894/5000\n",
      "31/31 - 0s - loss: 8.0477 - mae: 1.8682 - val_loss: 0.4782 - val_mae: 0.5987 - 37ms/epoch - 1ms/step\n",
      "Epoch 895/5000\n",
      "31/31 - 0s - loss: 6.7153 - mae: 1.6960 - val_loss: 50.7666 - val_mae: 7.1158 - 37ms/epoch - 1ms/step\n",
      "Epoch 896/5000\n",
      "31/31 - 0s - loss: 3.5307 - mae: 1.3392 - val_loss: 3.2763 - val_mae: 1.7761 - 37ms/epoch - 1ms/step\n",
      "Epoch 897/5000\n",
      "31/31 - 0s - loss: 6.2447 - mae: 1.6267 - val_loss: 0.7722 - val_mae: 0.8109 - 37ms/epoch - 1ms/step\n",
      "Epoch 898/5000\n",
      "31/31 - 0s - loss: 8.5631 - mae: 1.6564 - val_loss: 4.1837 - val_mae: 2.0136 - 37ms/epoch - 1ms/step\n",
      "Epoch 899/5000\n",
      "31/31 - 0s - loss: 1.8873 - mae: 1.0632 - val_loss: 9.5407 - val_mae: 3.0701 - 38ms/epoch - 1ms/step\n",
      "Epoch 900/5000\n",
      "31/31 - 0s - loss: 5.6407 - mae: 1.9668 - val_loss: 0.4602 - val_mae: 0.5827 - 37ms/epoch - 1ms/step\n",
      "Epoch 901/5000\n",
      "31/31 - 0s - loss: 6.5668 - mae: 1.7573 - val_loss: 0.7263 - val_mae: 0.7775 - 39ms/epoch - 1ms/step\n",
      "Epoch 902/5000\n",
      "31/31 - 0s - loss: 8.1479 - mae: 1.8867 - val_loss: 0.3204 - val_mae: 0.4822 - 37ms/epoch - 1ms/step\n",
      "Epoch 903/5000\n",
      "31/31 - 0s - loss: 1.2464 - mae: 0.9967 - val_loss: 6.2806 - val_mae: 2.4814 - 37ms/epoch - 1ms/step\n",
      "Epoch 904/5000\n",
      "31/31 - 0s - loss: 6.0539 - mae: 1.7722 - val_loss: 3.4224 - val_mae: 1.8194 - 36ms/epoch - 1ms/step\n",
      "Epoch 905/5000\n",
      "31/31 - 0s - loss: 9.1858 - mae: 2.1422 - val_loss: 0.7159 - val_mae: 0.7724 - 39ms/epoch - 1ms/step\n",
      "Epoch 906/5000\n",
      "31/31 - 0s - loss: 1.9889 - mae: 1.2445 - val_loss: 0.2865 - val_mae: 0.4622 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/5000\n",
      "31/31 - 0s - loss: 15.7772 - mae: 2.0865 - val_loss: 8.5060 - val_mae: 2.8941 - 40ms/epoch - 1ms/step\n",
      "Epoch 908/5000\n",
      "31/31 - 0s - loss: 1.9758 - mae: 1.1039 - val_loss: 21.8486 - val_mae: 4.6603 - 36ms/epoch - 1ms/step\n",
      "Epoch 909/5000\n",
      "31/31 - 0s - loss: 10.7000 - mae: 2.0722 - val_loss: 2.1710 - val_mae: 1.4337 - 37ms/epoch - 1ms/step\n",
      "Epoch 910/5000\n",
      "31/31 - 0s - loss: 11.9724 - mae: 1.9056 - val_loss: 0.3430 - val_mae: 0.4784 - 38ms/epoch - 1ms/step\n",
      "Epoch 911/5000\n",
      "31/31 - 0s - loss: 1.2129 - mae: 0.8737 - val_loss: 0.1257 - val_mae: 0.3008 - 39ms/epoch - 1ms/step\n",
      "Epoch 912/5000\n",
      "31/31 - 0s - loss: 13.0170 - mae: 2.1052 - val_loss: 1.1480 - val_mae: 1.0156 - 38ms/epoch - 1ms/step\n",
      "Epoch 913/5000\n",
      "31/31 - 0s - loss: 1.7867 - mae: 1.1110 - val_loss: 1.8366 - val_mae: 1.3113 - 37ms/epoch - 1ms/step\n",
      "Epoch 914/5000\n",
      "31/31 - 0s - loss: 11.8136 - mae: 2.3236 - val_loss: 2.8120 - val_mae: 1.6408 - 37ms/epoch - 1ms/step\n",
      "Epoch 915/5000\n",
      "31/31 - 0s - loss: 11.2269 - mae: 2.1170 - val_loss: 0.5456 - val_mae: 0.6548 - 38ms/epoch - 1ms/step\n",
      "Epoch 916/5000\n",
      "31/31 - 0s - loss: 2.1895 - mae: 1.1184 - val_loss: 4.7377 - val_mae: 2.1486 - 38ms/epoch - 1ms/step\n",
      "Epoch 917/5000\n",
      "31/31 - 0s - loss: 7.5201 - mae: 1.7730 - val_loss: 0.3309 - val_mae: 0.4867 - 37ms/epoch - 1ms/step\n",
      "Epoch 918/5000\n",
      "31/31 - 0s - loss: 2.4619 - mae: 1.0780 - val_loss: 1.1497 - val_mae: 1.0164 - 39ms/epoch - 1ms/step\n",
      "Epoch 919/5000\n",
      "31/31 - 0s - loss: 7.3783 - mae: 2.0304 - val_loss: 0.2462 - val_mae: 0.4354 - 38ms/epoch - 1ms/step\n",
      "Epoch 920/5000\n",
      "31/31 - 0s - loss: 1.2920 - mae: 0.8482 - val_loss: 0.1266 - val_mae: 0.3070 - 39ms/epoch - 1ms/step\n",
      "Epoch 921/5000\n",
      "31/31 - 0s - loss: 13.2460 - mae: 2.2691 - val_loss: 0.1739 - val_mae: 0.3153 - 37ms/epoch - 1ms/step\n",
      "Epoch 922/5000\n",
      "31/31 - 0s - loss: 1.6449 - mae: 1.0147 - val_loss: 16.4710 - val_mae: 4.0439 - 36ms/epoch - 1ms/step\n",
      "Epoch 923/5000\n",
      "31/31 - 0s - loss: 9.4615 - mae: 1.7364 - val_loss: 1.2646 - val_mae: 1.0708 - 38ms/epoch - 1ms/step\n",
      "Epoch 924/5000\n",
      "31/31 - 0s - loss: 1.8231 - mae: 1.0865 - val_loss: 303.1729 - val_mae: 17.4074 - 37ms/epoch - 1ms/step\n",
      "Epoch 925/5000\n",
      "31/31 - 0s - loss: 16.5363 - mae: 2.1431 - val_loss: 0.6198 - val_mae: 0.7054 - 35ms/epoch - 1ms/step\n",
      "Epoch 926/5000\n",
      "31/31 - 0s - loss: 1.4910 - mae: 1.0153 - val_loss: 1.8483 - val_mae: 1.3108 - 36ms/epoch - 1ms/step\n",
      "Epoch 927/5000\n",
      "31/31 - 0s - loss: 21.7166 - mae: 1.9456 - val_loss: 0.1884 - val_mae: 0.3899 - 38ms/epoch - 1ms/step\n",
      "Epoch 928/5000\n",
      "31/31 - 0s - loss: 0.9251 - mae: 0.8505 - val_loss: 0.5738 - val_mae: 0.6778 - 38ms/epoch - 1ms/step\n",
      "Epoch 929/5000\n",
      "31/31 - 0s - loss: 7.9062 - mae: 1.9289 - val_loss: 0.1356 - val_mae: 0.3032 - 38ms/epoch - 1ms/step\n",
      "Epoch 930/5000\n",
      "31/31 - 0s - loss: 14.6088 - mae: 2.1685 - val_loss: 6.2433 - val_mae: 2.4733 - 37ms/epoch - 1ms/step\n",
      "Epoch 931/5000\n",
      "31/31 - 0s - loss: 2.3006 - mae: 1.3389 - val_loss: 2.6593 - val_mae: 1.5956 - 38ms/epoch - 1ms/step\n",
      "Epoch 932/5000\n",
      "31/31 - 0s - loss: 17.5076 - mae: 2.2777 - val_loss: 0.1527 - val_mae: 0.3116 - 38ms/epoch - 1ms/step\n",
      "Epoch 933/5000\n",
      "31/31 - 0s - loss: 1.1760 - mae: 0.9005 - val_loss: 1.7300 - val_mae: 1.2701 - 36ms/epoch - 1ms/step\n",
      "Epoch 934/5000\n",
      "31/31 - 0s - loss: 13.5011 - mae: 2.0885 - val_loss: 0.6756 - val_mae: 0.7461 - 37ms/epoch - 1ms/step\n",
      "Epoch 935/5000\n",
      "31/31 - 0s - loss: 1.2941 - mae: 1.0103 - val_loss: 1.1811 - val_mae: 1.0321 - 38ms/epoch - 1ms/step\n",
      "Epoch 936/5000\n",
      "31/31 - 0s - loss: 17.4684 - mae: 2.3538 - val_loss: 0.1333 - val_mae: 0.3037 - 36ms/epoch - 1ms/step\n",
      "Epoch 937/5000\n",
      "31/31 - 0s - loss: 1.2912 - mae: 0.9289 - val_loss: 2.0191 - val_mae: 1.3790 - 37ms/epoch - 1ms/step\n",
      "Epoch 938/5000\n",
      "31/31 - 0s - loss: 12.7767 - mae: 2.2229 - val_loss: 3.6738 - val_mae: 1.8826 - 37ms/epoch - 1ms/step\n",
      "Epoch 939/5000\n",
      "31/31 - 0s - loss: 2.1670 - mae: 1.2855 - val_loss: 0.6108 - val_mae: 0.6989 - 37ms/epoch - 1ms/step\n",
      "Epoch 940/5000\n",
      "31/31 - 0s - loss: 11.0602 - mae: 2.1200 - val_loss: 0.1669 - val_mae: 0.3105 - 38ms/epoch - 1ms/step\n",
      "Epoch 941/5000\n",
      "31/31 - 0s - loss: 1.8483 - mae: 1.0583 - val_loss: 4.2181 - val_mae: 2.0238 - 40ms/epoch - 1ms/step\n",
      "Epoch 942/5000\n",
      "31/31 - 0s - loss: 10.7504 - mae: 2.0199 - val_loss: 0.1202 - val_mae: 0.3032 - 38ms/epoch - 1ms/step\n",
      "Epoch 943/5000\n",
      "31/31 - 0s - loss: 1.8313 - mae: 1.1003 - val_loss: 1.0852 - val_mae: 0.9808 - 38ms/epoch - 1ms/step\n",
      "Epoch 944/5000\n",
      "31/31 - 0s - loss: 7.4100 - mae: 1.8278 - val_loss: 0.1253 - val_mae: 0.3090 - 38ms/epoch - 1ms/step\n",
      "Epoch 945/5000\n",
      "31/31 - 0s - loss: 13.6678 - mae: 2.3948 - val_loss: 12.6494 - val_mae: 3.5402 - 38ms/epoch - 1ms/step\n",
      "Epoch 946/5000\n",
      "31/31 - 0s - loss: 1.5328 - mae: 1.0452 - val_loss: 2.4190 - val_mae: 1.5181 - 38ms/epoch - 1ms/step\n",
      "Epoch 947/5000\n",
      "31/31 - 0s - loss: 19.3864 - mae: 2.0783 - val_loss: 1.7549 - val_mae: 1.2803 - 38ms/epoch - 1ms/step\n",
      "Epoch 948/5000\n",
      "31/31 - 0s - loss: 2.3778 - mae: 1.1996 - val_loss: 2.7424 - val_mae: 1.6205 - 37ms/epoch - 1ms/step\n",
      "Epoch 949/5000\n",
      "31/31 - 0s - loss: 7.1963 - mae: 2.0665 - val_loss: 1.7193 - val_mae: 1.2651 - 36ms/epoch - 1ms/step\n",
      "Epoch 950/5000\n",
      "31/31 - 0s - loss: 10.0286 - mae: 2.0107 - val_loss: 3.2714 - val_mae: 1.7715 - 37ms/epoch - 1ms/step\n",
      "Epoch 951/5000\n",
      "31/31 - 0s - loss: 2.5729 - mae: 1.2481 - val_loss: 3.0846 - val_mae: 1.7204 - 39ms/epoch - 1ms/step\n",
      "Epoch 952/5000\n",
      "31/31 - 0s - loss: 4.9375 - mae: 1.2904 - val_loss: 59.2345 - val_mae: 7.6880 - 39ms/epoch - 1ms/step\n",
      "Epoch 953/5000\n",
      "31/31 - 0s - loss: 10.8509 - mae: 1.7225 - val_loss: 1.7139 - val_mae: 1.2636 - 38ms/epoch - 1ms/step\n",
      "Epoch 954/5000\n",
      "31/31 - 0s - loss: 4.9796 - mae: 1.6462 - val_loss: 1.3314 - val_mae: 1.0989 - 36ms/epoch - 1ms/step\n",
      "Epoch 955/5000\n",
      "31/31 - 0s - loss: 1.9526 - mae: 0.9992 - val_loss: 310.7642 - val_mae: 17.6241 - 35ms/epoch - 1ms/step\n",
      "Epoch 956/5000\n",
      "31/31 - 0s - loss: 12.7316 - mae: 2.1228 - val_loss: 0.7324 - val_mae: 0.7907 - 37ms/epoch - 1ms/step\n",
      "Epoch 957/5000\n",
      "31/31 - 0s - loss: 1.1138 - mae: 0.8392 - val_loss: 3.1718 - val_mae: 1.7497 - 38ms/epoch - 1ms/step\n",
      "Epoch 958/5000\n",
      "31/31 - 0s - loss: 11.2906 - mae: 2.1327 - val_loss: 4.5034 - val_mae: 2.0953 - 38ms/epoch - 1ms/step\n",
      "Epoch 959/5000\n",
      "31/31 - 0s - loss: 4.5403 - mae: 1.6273 - val_loss: 26.7556 - val_mae: 5.1608 - 36ms/epoch - 1ms/step\n",
      "Epoch 960/5000\n",
      "31/31 - 0s - loss: 2.5418 - mae: 1.1325 - val_loss: 0.3763 - val_mae: 0.5068 - 36ms/epoch - 1ms/step\n",
      "Epoch 961/5000\n",
      "31/31 - 0s - loss: 12.0068 - mae: 2.1196 - val_loss: 0.6486 - val_mae: 0.7294 - 38ms/epoch - 1ms/step\n",
      "Epoch 962/5000\n",
      "31/31 - 0s - loss: 4.6139 - mae: 1.4077 - val_loss: 76.0884 - val_mae: 8.7164 - 35ms/epoch - 1ms/step\n",
      "Epoch 963/5000\n",
      "31/31 - 0s - loss: 5.9179 - mae: 1.4731 - val_loss: 10.9288 - val_mae: 3.2880 - 36ms/epoch - 1ms/step\n",
      "Epoch 964/5000\n",
      "31/31 - 0s - loss: 6.8177 - mae: 1.8567 - val_loss: 0.5686 - val_mae: 0.6704 - 38ms/epoch - 1ms/step\n",
      "Epoch 965/5000\n",
      "31/31 - 0s - loss: 10.9221 - mae: 2.0615 - val_loss: 1.6928 - val_mae: 1.2550 - 36ms/epoch - 1ms/step\n",
      "Epoch 966/5000\n",
      "31/31 - 0s - loss: 2.7128 - mae: 1.3567 - val_loss: 0.7008 - val_mae: 0.7607 - 38ms/epoch - 1ms/step\n",
      "Epoch 967/5000\n",
      "31/31 - 0s - loss: 8.2540 - mae: 1.8382 - val_loss: 0.3364 - val_mae: 0.4649 - 41ms/epoch - 1ms/step\n",
      "Epoch 968/5000\n",
      "31/31 - 0s - loss: 12.6706 - mae: 1.7737 - val_loss: 52.1722 - val_mae: 7.2150 - 42ms/epoch - 1ms/step\n",
      "Epoch 969/5000\n",
      "31/31 - 0s - loss: 3.8775 - mae: 1.3507 - val_loss: 0.2230 - val_mae: 0.4190 - 45ms/epoch - 1ms/step\n",
      "Epoch 970/5000\n",
      "31/31 - 0s - loss: 7.8383 - mae: 1.9962 - val_loss: 0.3475 - val_mae: 0.4967 - 41ms/epoch - 1ms/step\n",
      "Epoch 971/5000\n",
      "31/31 - 0s - loss: 1.5881 - mae: 1.0153 - val_loss: 0.6554 - val_mae: 0.7344 - 40ms/epoch - 1ms/step\n",
      "Epoch 972/5000\n",
      "31/31 - 0s - loss: 24.5170 - mae: 2.1154 - val_loss: 1.2912 - val_mae: 1.0826 - 42ms/epoch - 1ms/step\n",
      "Epoch 973/5000\n",
      "31/31 - 0s - loss: 2.0788 - mae: 1.0255 - val_loss: 0.1271 - val_mae: 0.3019 - 46ms/epoch - 1ms/step\n",
      "Epoch 974/5000\n",
      "31/31 - 0s - loss: 1.4404 - mae: 0.9472 - val_loss: 0.1402 - val_mae: 0.3041 - 60ms/epoch - 2ms/step\n",
      "Epoch 975/5000\n",
      "31/31 - 0s - loss: 27.9818 - mae: 2.2053 - val_loss: 0.7931 - val_mae: 0.8210 - 48ms/epoch - 2ms/step\n",
      "Epoch 976/5000\n",
      "31/31 - 0s - loss: 1.8856 - mae: 1.0869 - val_loss: 0.5880 - val_mae: 0.6881 - 49ms/epoch - 2ms/step\n",
      "Epoch 977/5000\n",
      "31/31 - 0s - loss: 18.7618 - mae: 1.8512 - val_loss: 1.7295 - val_mae: 1.2672 - 45ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978/5000\n",
      "31/31 - 0s - loss: 2.7604 - mae: 1.2058 - val_loss: 1.8969 - val_mae: 1.3354 - 47ms/epoch - 2ms/step\n",
      "Epoch 979/5000\n",
      "31/31 - 0s - loss: 1.0698 - mae: 0.8785 - val_loss: 0.7166 - val_mae: 0.7722 - 49ms/epoch - 2ms/step\n",
      "Epoch 980/5000\n",
      "31/31 - 0s - loss: 17.6011 - mae: 2.1491 - val_loss: 0.5704 - val_mae: 0.6774 - 44ms/epoch - 1ms/step\n",
      "Epoch 981/5000\n",
      "31/31 - 0s - loss: 1.5521 - mae: 1.0910 - val_loss: 2.8082 - val_mae: 1.6417 - 43ms/epoch - 1ms/step\n",
      "Epoch 982/5000\n",
      "31/31 - 0s - loss: 10.4027 - mae: 2.2188 - val_loss: 1.1513 - val_mae: 1.0174 - 45ms/epoch - 1ms/step\n",
      "Epoch 983/5000\n",
      "31/31 - 0s - loss: 14.1688 - mae: 2.2444 - val_loss: 0.2519 - val_mae: 0.4396 - 43ms/epoch - 1ms/step\n",
      "Epoch 984/5000\n",
      "31/31 - 0s - loss: 1.5174 - mae: 0.9720 - val_loss: 2.3769 - val_mae: 1.5038 - 48ms/epoch - 2ms/step\n",
      "Epoch 985/5000\n",
      "31/31 - 0s - loss: 10.1977 - mae: 1.7970 - val_loss: 0.1756 - val_mae: 0.3785 - 42ms/epoch - 1ms/step\n",
      "Epoch 986/5000\n",
      "31/31 - 0s - loss: 0.9621 - mae: 0.7786 - val_loss: 1.9263 - val_mae: 1.3472 - 41ms/epoch - 1ms/step\n",
      "Epoch 987/5000\n",
      "31/31 - 0s - loss: 8.6795 - mae: 2.1165 - val_loss: 0.1463 - val_mae: 0.3050 - 43ms/epoch - 1ms/step\n",
      "Epoch 988/5000\n",
      "31/31 - 0s - loss: 0.8699 - mae: 0.7694 - val_loss: 0.8902 - val_mae: 0.8822 - 45ms/epoch - 1ms/step\n",
      "Epoch 989/5000\n",
      "31/31 - 0s - loss: 20.8966 - mae: 2.1292 - val_loss: 3.6543 - val_mae: 1.8795 - 55ms/epoch - 2ms/step\n",
      "Epoch 990/5000\n",
      "31/31 - 0s - loss: 1.9219 - mae: 1.1310 - val_loss: 2.4157 - val_mae: 1.5182 - 45ms/epoch - 1ms/step\n",
      "Epoch 991/5000\n",
      "31/31 - 0s - loss: 11.4066 - mae: 2.1015 - val_loss: 7.7142 - val_mae: 2.7582 - 43ms/epoch - 1ms/step\n",
      "Epoch 992/5000\n",
      "31/31 - 0s - loss: 6.3030 - mae: 1.7838 - val_loss: 36.1097 - val_mae: 5.9982 - 44ms/epoch - 1ms/step\n",
      "Epoch 993/5000\n",
      "31/31 - 0s - loss: 4.0453 - mae: 1.6753 - val_loss: 0.4066 - val_mae: 0.5374 - 56ms/epoch - 2ms/step\n",
      "Epoch 994/5000\n",
      "31/31 - 0s - loss: 9.4716 - mae: 1.8771 - val_loss: 1.3685 - val_mae: 1.1153 - 43ms/epoch - 1ms/step\n",
      "Epoch 995/5000\n",
      "31/31 - 0s - loss: 1.8972 - mae: 1.1224 - val_loss: 0.1824 - val_mae: 0.3810 - 42ms/epoch - 1ms/step\n",
      "Epoch 996/5000\n",
      "31/31 - 0s - loss: 23.6263 - mae: 2.2457 - val_loss: 0.1879 - val_mae: 0.3894 - 38ms/epoch - 1ms/step\n",
      "Epoch 997/5000\n",
      "31/31 - 0s - loss: 1.3828 - mae: 0.9546 - val_loss: 1.5272 - val_mae: 1.1869 - 38ms/epoch - 1ms/step\n",
      "Epoch 998/5000\n",
      "31/31 - 0s - loss: 18.1777 - mae: 1.9036 - val_loss: 0.2694 - val_mae: 0.4509 - 38ms/epoch - 1ms/step\n",
      "Epoch 999/5000\n",
      "31/31 - 0s - loss: 1.5619 - mae: 1.0452 - val_loss: 0.1479 - val_mae: 0.2946 - 38ms/epoch - 1ms/step\n",
      "Epoch 1000/5000\n",
      "31/31 - 0s - loss: 14.7932 - mae: 2.0292 - val_loss: 0.6250 - val_mae: 0.7112 - 39ms/epoch - 1ms/step\n",
      "Epoch 1001/5000\n",
      "31/31 - 0s - loss: 2.6683 - mae: 1.4141 - val_loss: 0.1280 - val_mae: 0.3088 - 38ms/epoch - 1ms/step\n",
      "Epoch 1002/5000\n",
      "31/31 - 0s - loss: 11.1306 - mae: 2.0447 - val_loss: 0.1204 - val_mae: 0.2998 - 37ms/epoch - 1ms/step\n",
      "Epoch 1003/5000\n",
      "31/31 - 0s - loss: 1.9609 - mae: 1.0041 - val_loss: 1.8092 - val_mae: 1.2977 - 39ms/epoch - 1ms/step\n",
      "Epoch 1004/5000\n",
      "31/31 - 0s - loss: 5.1550 - mae: 1.5877 - val_loss: 0.1172 - val_mae: 0.3006 - 38ms/epoch - 1ms/step\n",
      "Epoch 1005/5000\n",
      "31/31 - 0s - loss: 13.0611 - mae: 2.2187 - val_loss: 0.4535 - val_mae: 0.5830 - 36ms/epoch - 1ms/step\n",
      "Epoch 1006/5000\n",
      "31/31 - 0s - loss: 1.8559 - mae: 0.9009 - val_loss: 0.1801 - val_mae: 0.3817 - 38ms/epoch - 1ms/step\n",
      "Epoch 1007/5000\n",
      "31/31 - 0s - loss: 17.7664 - mae: 2.1233 - val_loss: 0.6608 - val_mae: 0.7367 - 37ms/epoch - 1ms/step\n",
      "Epoch 1008/5000\n",
      "31/31 - 0s - loss: 2.8263 - mae: 1.4562 - val_loss: 3.0462 - val_mae: 1.7104 - 38ms/epoch - 1ms/step\n",
      "Epoch 1009/5000\n",
      "31/31 - 0s - loss: 9.2861 - mae: 2.1129 - val_loss: 0.4701 - val_mae: 0.5934 - 36ms/epoch - 1ms/step\n",
      "Epoch 1010/5000\n",
      "31/31 - 0s - loss: 1.4795 - mae: 0.9438 - val_loss: 210.0889 - val_mae: 14.4893 - 37ms/epoch - 1ms/step\n",
      "Epoch 1011/5000\n",
      "31/31 - 0s - loss: 9.4236 - mae: 1.8385 - val_loss: 8.8880 - val_mae: 2.9629 - 38ms/epoch - 1ms/step\n",
      "Epoch 1012/5000\n",
      "31/31 - 0s - loss: 12.8993 - mae: 2.0137 - val_loss: 3.3583 - val_mae: 1.7979 - 36ms/epoch - 1ms/step\n",
      "Epoch 1013/5000\n",
      "31/31 - 0s - loss: 3.5650 - mae: 1.4078 - val_loss: 0.8287 - val_mae: 0.8443 - 37ms/epoch - 1ms/step\n",
      "Epoch 1014/5000\n",
      "31/31 - 0s - loss: 7.5183 - mae: 1.6804 - val_loss: 1.2508 - val_mae: 1.0679 - 38ms/epoch - 1ms/step\n",
      "Epoch 1015/5000\n",
      "31/31 - 0s - loss: 1.2876 - mae: 0.9364 - val_loss: 4.5403 - val_mae: 2.1034 - 36ms/epoch - 1ms/step\n",
      "Epoch 1016/5000\n",
      "31/31 - 0s - loss: 10.9361 - mae: 1.7436 - val_loss: 1.2831 - val_mae: 1.0818 - 37ms/epoch - 1ms/step\n",
      "Epoch 1017/5000\n",
      "31/31 - 0s - loss: 4.6967 - mae: 1.5027 - val_loss: 13.2598 - val_mae: 3.6268 - 38ms/epoch - 1ms/step\n",
      "Epoch 1018/5000\n",
      "31/31 - 0s - loss: 4.6927 - mae: 1.5080 - val_loss: 1.3594 - val_mae: 1.1174 - 36ms/epoch - 1ms/step\n",
      "Epoch 1019/5000\n",
      "31/31 - 0s - loss: 13.5538 - mae: 1.9812 - val_loss: 0.3994 - val_mae: 0.5326 - 36ms/epoch - 1ms/step\n",
      "Epoch 1020/5000\n",
      "31/31 - 0s - loss: 1.6347 - mae: 1.0130 - val_loss: 0.1243 - val_mae: 0.3022 - 37ms/epoch - 1ms/step\n",
      "Epoch 1021/5000\n",
      "31/31 - 0s - loss: 12.2799 - mae: 2.0032 - val_loss: 0.1327 - val_mae: 0.3181 - 36ms/epoch - 1ms/step\n",
      "Epoch 1022/5000\n",
      "31/31 - 0s - loss: 1.4889 - mae: 0.9829 - val_loss: 3.0847 - val_mae: 1.7245 - 35ms/epoch - 1ms/step\n",
      "Epoch 1023/5000\n",
      "31/31 - 0s - loss: 20.1701 - mae: 2.0961 - val_loss: 0.1989 - val_mae: 0.3988 - 36ms/epoch - 1ms/step\n",
      "Epoch 1024/5000\n",
      "31/31 - 0s - loss: 1.2476 - mae: 0.8465 - val_loss: 0.6755 - val_mae: 0.7463 - 37ms/epoch - 1ms/step\n",
      "Epoch 1025/5000\n",
      "31/31 - 0s - loss: 14.7400 - mae: 2.1355 - val_loss: 0.1539 - val_mae: 0.3069 - 37ms/epoch - 1ms/step\n",
      "Epoch 1026/5000\n",
      "31/31 - 0s - loss: 1.0877 - mae: 0.7504 - val_loss: 0.8501 - val_mae: 0.8576 - 35ms/epoch - 1ms/step\n",
      "Epoch 1027/5000\n",
      "31/31 - 0s - loss: 11.6550 - mae: 2.0294 - val_loss: 2.3047 - val_mae: 1.4796 - 38ms/epoch - 1ms/step\n",
      "Epoch 1028/5000\n",
      "31/31 - 0s - loss: 3.2966 - mae: 1.0896 - val_loss: 7.7176 - val_mae: 2.7552 - 37ms/epoch - 1ms/step\n",
      "Epoch 1029/5000\n",
      "31/31 - 0s - loss: 4.1699 - mae: 1.3537 - val_loss: 0.4899 - val_mae: 0.6175 - 39ms/epoch - 1ms/step\n",
      "Epoch 1030/5000\n",
      "31/31 - 0s - loss: 14.4050 - mae: 2.0327 - val_loss: 0.4109 - val_mae: 0.5415 - 37ms/epoch - 1ms/step\n",
      "Epoch 1031/5000\n",
      "31/31 - 0s - loss: 0.7937 - mae: 0.7707 - val_loss: 0.8699 - val_mae: 0.8693 - 37ms/epoch - 1ms/step\n",
      "Epoch 1032/5000\n",
      "31/31 - 0s - loss: 10.4630 - mae: 1.9770 - val_loss: 5.6634 - val_mae: 2.3559 - 39ms/epoch - 1ms/step\n",
      "Epoch 1033/5000\n",
      "31/31 - 0s - loss: 1.3501 - mae: 0.9792 - val_loss: 0.2855 - val_mae: 0.4612 - 36ms/epoch - 1ms/step\n",
      "Epoch 1034/5000\n",
      "31/31 - 0s - loss: 5.5281 - mae: 1.6617 - val_loss: 0.9898 - val_mae: 0.9379 - 37ms/epoch - 1ms/step\n",
      "Epoch 1035/5000\n",
      "31/31 - 0s - loss: 9.9631 - mae: 1.9822 - val_loss: 0.1261 - val_mae: 0.3078 - 38ms/epoch - 1ms/step\n",
      "Epoch 1036/5000\n",
      "31/31 - 0s - loss: 1.5409 - mae: 0.9822 - val_loss: 3.6972 - val_mae: 1.8882 - 36ms/epoch - 1ms/step\n",
      "Epoch 1037/5000\n",
      "31/31 - 0s - loss: 7.2889 - mae: 1.6360 - val_loss: 0.2199 - val_mae: 0.4161 - 37ms/epoch - 1ms/step\n",
      "Epoch 1038/5000\n",
      "31/31 - 0s - loss: 10.3837 - mae: 1.9256 - val_loss: 12.4172 - val_mae: 3.5065 - 37ms/epoch - 1ms/step\n",
      "Epoch 1039/5000\n",
      "31/31 - 0s - loss: 1.8248 - mae: 1.1200 - val_loss: 6.0506 - val_mae: 2.4364 - 38ms/epoch - 1ms/step\n",
      "Epoch 1040/5000\n",
      "31/31 - 0s - loss: 10.9297 - mae: 2.2555 - val_loss: 3.3281 - val_mae: 1.7928 - 37ms/epoch - 1ms/step\n",
      "Epoch 1041/5000\n",
      "31/31 - 0s - loss: 8.1836 - mae: 2.0113 - val_loss: 1.4191 - val_mae: 1.1442 - 38ms/epoch - 1ms/step\n",
      "Epoch 1042/5000\n",
      "31/31 - 0s - loss: 2.1005 - mae: 1.1629 - val_loss: 2.8265 - val_mae: 1.6451 - 35ms/epoch - 1ms/step\n",
      "Epoch 1043/5000\n",
      "31/31 - 0s - loss: 20.9048 - mae: 1.9971 - val_loss: 0.1368 - val_mae: 0.3267 - 36ms/epoch - 1ms/step\n",
      "Epoch 1044/5000\n",
      "31/31 - 0s - loss: 1.1366 - mae: 0.9010 - val_loss: 0.7716 - val_mae: 0.8082 - 37ms/epoch - 1ms/step\n",
      "Epoch 1045/5000\n",
      "31/31 - 0s - loss: 3.0227 - mae: 1.1784 - val_loss: 1.0442 - val_mae: 0.9584 - 38ms/epoch - 1ms/step\n",
      "Epoch 1046/5000\n",
      "31/31 - 0s - loss: 7.0950 - mae: 1.5218 - val_loss: 0.1403 - val_mae: 0.3031 - 34ms/epoch - 1ms/step\n",
      "Epoch 1047/5000\n",
      "31/31 - 0s - loss: 11.3211 - mae: 1.9192 - val_loss: 0.7289 - val_mae: 0.7921 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1048/5000\n",
      "31/31 - 0s - loss: 2.2438 - mae: 1.1787 - val_loss: 2.0491 - val_mae: 1.3915 - 38ms/epoch - 1ms/step\n",
      "Epoch 1049/5000\n",
      "31/31 - 0s - loss: 3.8971 - mae: 1.4244 - val_loss: 0.9855 - val_mae: 0.9314 - 37ms/epoch - 1ms/step\n",
      "Epoch 1050/5000\n",
      "31/31 - 0s - loss: 8.0415 - mae: 1.7723 - val_loss: 0.1908 - val_mae: 0.3310 - 34ms/epoch - 1ms/step\n",
      "Epoch 1051/5000\n",
      "31/31 - 0s - loss: 0.7451 - mae: 0.6957 - val_loss: 6.1210 - val_mae: 2.4483 - 37ms/epoch - 1ms/step\n",
      "Epoch 1052/5000\n",
      "31/31 - 0s - loss: 12.4273 - mae: 1.9094 - val_loss: 0.4147 - val_mae: 0.5522 - 37ms/epoch - 1ms/step\n",
      "Epoch 1053/5000\n",
      "31/31 - 0s - loss: 11.4990 - mae: 1.8836 - val_loss: 2.2282 - val_mae: 1.4559 - 36ms/epoch - 1ms/step\n",
      "Epoch 1054/5000\n",
      "31/31 - 0s - loss: 3.7067 - mae: 1.4948 - val_loss: 0.9188 - val_mae: 0.8940 - 36ms/epoch - 1ms/step\n",
      "Epoch 1055/5000\n",
      "31/31 - 0s - loss: 0.9170 - mae: 0.7724 - val_loss: 10.5418 - val_mae: 3.2309 - 36ms/epoch - 1ms/step\n",
      "Epoch 1056/5000\n",
      "31/31 - 0s - loss: 16.2167 - mae: 2.4431 - val_loss: 0.5786 - val_mae: 0.6805 - 36ms/epoch - 1ms/step\n",
      "Epoch 1057/5000\n",
      "31/31 - 0s - loss: 1.1725 - mae: 0.8572 - val_loss: 0.5573 - val_mae: 0.6660 - 37ms/epoch - 1ms/step\n",
      "Epoch 1058/5000\n",
      "31/31 - 0s - loss: 11.7232 - mae: 2.2263 - val_loss: 0.5522 - val_mae: 0.6554 - 35ms/epoch - 1ms/step\n",
      "Epoch 1059/5000\n",
      "31/31 - 0s - loss: 2.2693 - mae: 1.3546 - val_loss: 0.1491 - val_mae: 0.3460 - 36ms/epoch - 1ms/step\n",
      "Epoch 1060/5000\n",
      "31/31 - 0s - loss: 13.5224 - mae: 2.1004 - val_loss: 3.7496 - val_mae: 1.9062 - 38ms/epoch - 1ms/step\n",
      "Epoch 1061/5000\n",
      "31/31 - 0s - loss: 7.1908 - mae: 1.9167 - val_loss: 0.2431 - val_mae: 0.4340 - 35ms/epoch - 1ms/step\n",
      "Epoch 1062/5000\n",
      "31/31 - 0s - loss: 2.4578 - mae: 1.2313 - val_loss: 1.3206 - val_mae: 1.0908 - 38ms/epoch - 1ms/step\n",
      "Epoch 1063/5000\n",
      "31/31 - 0s - loss: 7.9097 - mae: 1.7640 - val_loss: 1.6361 - val_mae: 1.2360 - 37ms/epoch - 1ms/step\n",
      "Epoch 1064/5000\n",
      "31/31 - 0s - loss: 18.4778 - mae: 2.1620 - val_loss: 2.2805 - val_mae: 1.4750 - 38ms/epoch - 1ms/step\n",
      "Epoch 1065/5000\n",
      "31/31 - 0s - loss: 2.3812 - mae: 1.0268 - val_loss: 0.1912 - val_mae: 0.3316 - 37ms/epoch - 1ms/step\n",
      "Epoch 1066/5000\n",
      "31/31 - 0s - loss: 10.1999 - mae: 2.0523 - val_loss: 4.7616 - val_mae: 2.1572 - 37ms/epoch - 1ms/step\n",
      "Epoch 1067/5000\n",
      "31/31 - 0s - loss: 1.7098 - mae: 1.1518 - val_loss: 0.2018 - val_mae: 0.4017 - 36ms/epoch - 1ms/step\n",
      "Epoch 1068/5000\n",
      "31/31 - 0s - loss: 9.6582 - mae: 1.9263 - val_loss: 1.1582 - val_mae: 1.0225 - 38ms/epoch - 1ms/step\n",
      "Epoch 1069/5000\n",
      "31/31 - 0s - loss: 11.7986 - mae: 2.1071 - val_loss: 0.1773 - val_mae: 0.3764 - 37ms/epoch - 1ms/step\n",
      "Epoch 1070/5000\n",
      "31/31 - 0s - loss: 0.8425 - mae: 0.7372 - val_loss: 0.1604 - val_mae: 0.3004 - 37ms/epoch - 1ms/step\n",
      "Epoch 1071/5000\n",
      "31/31 - 0s - loss: 13.1353 - mae: 1.9708 - val_loss: 0.1888 - val_mae: 0.3301 - 36ms/epoch - 1ms/step\n",
      "Epoch 1072/5000\n",
      "31/31 - 0s - loss: 1.2860 - mae: 0.7864 - val_loss: 0.1314 - val_mae: 0.3173 - 37ms/epoch - 1ms/step\n",
      "Epoch 1073/5000\n",
      "31/31 - 0s - loss: 8.7360 - mae: 1.5195 - val_loss: 0.1868 - val_mae: 0.3892 - 35ms/epoch - 1ms/step\n",
      "Epoch 1074/5000\n",
      "31/31 - 0s - loss: 0.8922 - mae: 0.7561 - val_loss: 1.8970 - val_mae: 1.3334 - 37ms/epoch - 1ms/step\n",
      "Epoch 1075/5000\n",
      "31/31 - 0s - loss: 9.3329 - mae: 1.9753 - val_loss: 1.8354 - val_mae: 1.3142 - 36ms/epoch - 1ms/step\n",
      "Epoch 1076/5000\n",
      "31/31 - 0s - loss: 7.9900 - mae: 1.7802 - val_loss: 2.3032 - val_mae: 1.4785 - 35ms/epoch - 1ms/step\n",
      "Epoch 1077/5000\n",
      "31/31 - 0s - loss: 1.6151 - mae: 1.0858 - val_loss: 1.3737 - val_mae: 1.1192 - 37ms/epoch - 1ms/step\n",
      "Epoch 1078/5000\n",
      "31/31 - 0s - loss: 8.3832 - mae: 1.5523 - val_loss: 11.2152 - val_mae: 3.3321 - 38ms/epoch - 1ms/step\n",
      "Epoch 1079/5000\n",
      "31/31 - 0s - loss: 1.0741 - mae: 0.8138 - val_loss: 0.6433 - val_mae: 0.7301 - 39ms/epoch - 1ms/step\n",
      "Epoch 1080/5000\n",
      "31/31 - 0s - loss: 12.9971 - mae: 2.1056 - val_loss: 0.4040 - val_mae: 0.5407 - 37ms/epoch - 1ms/step\n",
      "Epoch 1081/5000\n",
      "31/31 - 0s - loss: 5.4668 - mae: 1.7714 - val_loss: 31.4589 - val_mae: 5.5981 - 36ms/epoch - 1ms/step\n",
      "Epoch 1082/5000\n",
      "31/31 - 0s - loss: 2.0595 - mae: 0.9612 - val_loss: 0.5532 - val_mae: 0.6635 - 37ms/epoch - 1ms/step\n",
      "Epoch 1083/5000\n",
      "31/31 - 0s - loss: 12.7179 - mae: 1.9302 - val_loss: 0.5882 - val_mae: 0.6922 - 37ms/epoch - 1ms/step\n",
      "Epoch 1084/5000\n",
      "31/31 - 0s - loss: 2.2141 - mae: 1.3128 - val_loss: 0.1260 - val_mae: 0.2963 - 37ms/epoch - 1ms/step\n",
      "Epoch 1085/5000\n",
      "31/31 - 0s - loss: 22.5207 - mae: 2.3282 - val_loss: 0.2139 - val_mae: 0.3520 - 37ms/epoch - 1ms/step\n",
      "Epoch 1086/5000\n",
      "31/31 - 0s - loss: 1.2021 - mae: 0.8087 - val_loss: 7.8835 - val_mae: 2.7871 - 36ms/epoch - 1ms/step\n",
      "Epoch 1087/5000\n",
      "31/31 - 0s - loss: 6.5762 - mae: 1.7147 - val_loss: 4.7297 - val_mae: 2.1471 - 37ms/epoch - 1ms/step\n",
      "Epoch 1088/5000\n",
      "31/31 - 0s - loss: 1.6690 - mae: 1.0350 - val_loss: 12.9416 - val_mae: 3.5830 - 36ms/epoch - 1ms/step\n",
      "Epoch 1089/5000\n",
      "31/31 - 0s - loss: 17.7839 - mae: 2.1136 - val_loss: 0.9216 - val_mae: 0.8999 - 36ms/epoch - 1ms/step\n",
      "Epoch 1090/5000\n",
      "31/31 - 0s - loss: 0.7658 - mae: 0.7121 - val_loss: 0.4258 - val_mae: 0.5538 - 35ms/epoch - 1ms/step\n",
      "Epoch 1091/5000\n",
      "31/31 - 0s - loss: 22.7053 - mae: 1.7641 - val_loss: 0.2128 - val_mae: 0.3530 - 36ms/epoch - 1ms/step\n",
      "Epoch 1092/5000\n",
      "31/31 - 0s - loss: 2.3274 - mae: 1.0571 - val_loss: 3.2544 - val_mae: 1.7722 - 38ms/epoch - 1ms/step\n",
      "Epoch 1093/5000\n",
      "31/31 - 0s - loss: 24.2586 - mae: 2.1101 - val_loss: 36.7905 - val_mae: 6.0564 - 38ms/epoch - 1ms/step\n",
      "Epoch 1094/5000\n",
      "31/31 - 0s - loss: 2.2364 - mae: 0.9293 - val_loss: 0.2369 - val_mae: 0.3705 - 37ms/epoch - 1ms/step\n",
      "Epoch 1095/5000\n",
      "31/31 - 0s - loss: 1.9050 - mae: 1.2020 - val_loss: 5.1567 - val_mae: 2.2437 - 36ms/epoch - 1ms/step\n",
      "Epoch 1096/5000\n",
      "31/31 - 0s - loss: 8.9502 - mae: 2.0244 - val_loss: 0.3951 - val_mae: 0.5343 - 38ms/epoch - 1ms/step\n",
      "Epoch 1097/5000\n",
      "31/31 - 0s - loss: 14.4498 - mae: 1.9596 - val_loss: 169.9990 - val_mae: 13.0333 - 35ms/epoch - 1ms/step\n",
      "Epoch 1098/5000\n",
      "31/31 - 0s - loss: 5.5830 - mae: 1.0663 - val_loss: 0.2159 - val_mae: 0.4119 - 36ms/epoch - 1ms/step\n",
      "Epoch 1099/5000\n",
      "31/31 - 0s - loss: 2.8062 - mae: 1.1728 - val_loss: 0.7661 - val_mae: 0.8063 - 35ms/epoch - 1ms/step\n",
      "Epoch 1100/5000\n",
      "31/31 - 0s - loss: 8.4462 - mae: 1.7290 - val_loss: 1.3219 - val_mae: 1.0988 - 35ms/epoch - 1ms/step\n",
      "Epoch 1101/5000\n",
      "31/31 - 0s - loss: 7.5060 - mae: 1.7315 - val_loss: 16.9156 - val_mae: 4.0990 - 38ms/epoch - 1ms/step\n",
      "Epoch 1102/5000\n",
      "31/31 - 0s - loss: 1.5993 - mae: 0.8722 - val_loss: 0.2493 - val_mae: 0.4370 - 35ms/epoch - 1ms/step\n",
      "Epoch 1103/5000\n",
      "31/31 - 0s - loss: 19.3942 - mae: 1.9669 - val_loss: 0.9855 - val_mae: 0.9338 - 39ms/epoch - 1ms/step\n",
      "Epoch 1104/5000\n",
      "31/31 - 0s - loss: 1.7052 - mae: 1.0437 - val_loss: 0.1199 - val_mae: 0.3031 - 37ms/epoch - 1ms/step\n",
      "Epoch 1105/5000\n",
      "31/31 - 0s - loss: 1.0925 - mae: 0.8607 - val_loss: 4.4447 - val_mae: 2.0820 - 37ms/epoch - 1ms/step\n",
      "Epoch 1106/5000\n",
      "31/31 - 0s - loss: 16.9276 - mae: 1.8713 - val_loss: 5.1896 - val_mae: 2.2521 - 38ms/epoch - 1ms/step\n",
      "Epoch 1107/5000\n",
      "31/31 - 0s - loss: 1.6180 - mae: 1.0764 - val_loss: 0.6272 - val_mae: 0.7098 - 36ms/epoch - 1ms/step\n",
      "Epoch 1108/5000\n",
      "31/31 - 0s - loss: 18.1085 - mae: 2.0070 - val_loss: 1.3779 - val_mae: 1.1239 - 36ms/epoch - 1ms/step\n",
      "Epoch 1109/5000\n",
      "31/31 - 0s - loss: 2.9136 - mae: 1.4453 - val_loss: 0.9249 - val_mae: 0.9013 - 37ms/epoch - 1ms/step\n",
      "Epoch 1110/5000\n",
      "31/31 - 0s - loss: 2.9183 - mae: 1.2423 - val_loss: 1.1743 - val_mae: 1.0321 - 37ms/epoch - 1ms/step\n",
      "Epoch 1111/5000\n",
      "31/31 - 0s - loss: 14.4396 - mae: 1.6756 - val_loss: 0.1912 - val_mae: 0.3270 - 38ms/epoch - 1ms/step\n",
      "Epoch 1112/5000\n",
      "31/31 - 0s - loss: 2.6147 - mae: 1.2441 - val_loss: 0.3135 - val_mae: 0.4757 - 37ms/epoch - 1ms/step\n",
      "Epoch 1113/5000\n",
      "31/31 - 0s - loss: 6.9199 - mae: 1.6349 - val_loss: 9.3420 - val_mae: 3.0374 - 37ms/epoch - 1ms/step\n",
      "Epoch 1114/5000\n",
      "31/31 - 0s - loss: 6.2906 - mae: 1.8143 - val_loss: 2.0451 - val_mae: 1.3906 - 36ms/epoch - 1ms/step\n",
      "Epoch 1115/5000\n",
      "31/31 - 0s - loss: 1.0256 - mae: 0.8071 - val_loss: 1.9911 - val_mae: 1.3723 - 36ms/epoch - 1ms/step\n",
      "Epoch 1116/5000\n",
      "31/31 - 0s - loss: 8.9132 - mae: 1.8756 - val_loss: 2.3584 - val_mae: 1.4967 - 37ms/epoch - 1ms/step\n",
      "Epoch 1117/5000\n",
      "31/31 - 0s - loss: 0.7760 - mae: 0.7416 - val_loss: 1.9289 - val_mae: 1.3471 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118/5000\n",
      "31/31 - 0s - loss: 31.8026 - mae: 2.4874 - val_loss: 0.2508 - val_mae: 0.3762 - 37ms/epoch - 1ms/step\n",
      "Epoch 1119/5000\n",
      "31/31 - 0s - loss: 1.9477 - mae: 1.1658 - val_loss: 0.5029 - val_mae: 0.6217 - 38ms/epoch - 1ms/step\n",
      "Epoch 1120/5000\n",
      "31/31 - 0s - loss: 13.8177 - mae: 2.1871 - val_loss: 13.0611 - val_mae: 3.5972 - 37ms/epoch - 1ms/step\n",
      "Epoch 1121/5000\n",
      "31/31 - 0s - loss: 1.4593 - mae: 0.9206 - val_loss: 0.5429 - val_mae: 0.6555 - 46ms/epoch - 1ms/step\n",
      "Epoch 1122/5000\n",
      "31/31 - 0s - loss: 7.6819 - mae: 1.6111 - val_loss: 0.2414 - val_mae: 0.3736 - 38ms/epoch - 1ms/step\n",
      "Epoch 1123/5000\n",
      "31/31 - 0s - loss: 12.6704 - mae: 1.8837 - val_loss: 1.0495 - val_mae: 0.9710 - 37ms/epoch - 1ms/step\n",
      "Epoch 1124/5000\n",
      "31/31 - 0s - loss: 0.9526 - mae: 0.7284 - val_loss: 1.9627 - val_mae: 1.3595 - 37ms/epoch - 1ms/step\n",
      "Epoch 1125/5000\n",
      "31/31 - 0s - loss: 13.7079 - mae: 2.0921 - val_loss: 0.1333 - val_mae: 0.3219 - 36ms/epoch - 1ms/step\n",
      "Epoch 1126/5000\n",
      "31/31 - 0s - loss: 1.6173 - mae: 1.0485 - val_loss: 0.6831 - val_mae: 0.7541 - 38ms/epoch - 1ms/step\n",
      "Epoch 1127/5000\n",
      "31/31 - 0s - loss: 16.1853 - mae: 2.0673 - val_loss: 0.2944 - val_mae: 0.4111 - 36ms/epoch - 1ms/step\n",
      "Epoch 1128/5000\n",
      "31/31 - 0s - loss: 1.2073 - mae: 0.9680 - val_loss: 3.8086 - val_mae: 1.9214 - 37ms/epoch - 1ms/step\n",
      "Epoch 1129/5000\n",
      "31/31 - 0s - loss: 6.6280 - mae: 1.9712 - val_loss: 0.1134 - val_mae: 0.2963 - 38ms/epoch - 1ms/step\n",
      "Epoch 1130/5000\n",
      "31/31 - 0s - loss: 12.8294 - mae: 2.0037 - val_loss: 0.8105 - val_mae: 0.8353 - 37ms/epoch - 1ms/step\n",
      "Epoch 1131/5000\n",
      "31/31 - 0s - loss: 0.9188 - mae: 0.7590 - val_loss: 0.2986 - val_mae: 0.4690 - 38ms/epoch - 1ms/step\n",
      "Epoch 1132/5000\n",
      "31/31 - 0s - loss: 11.9602 - mae: 2.0608 - val_loss: 0.7024 - val_mae: 0.7671 - 36ms/epoch - 1ms/step\n",
      "Epoch 1133/5000\n",
      "31/31 - 0s - loss: 2.6264 - mae: 1.3771 - val_loss: 0.2955 - val_mae: 0.4290 - 35ms/epoch - 1ms/step\n",
      "Epoch 1134/5000\n",
      "31/31 - 0s - loss: 18.8584 - mae: 2.2191 - val_loss: 0.6370 - val_mae: 0.7229 - 36ms/epoch - 1ms/step\n",
      "Epoch 1135/5000\n",
      "31/31 - 0s - loss: 1.4057 - mae: 0.8829 - val_loss: 3.9854 - val_mae: 1.9687 - 37ms/epoch - 1ms/step\n",
      "Epoch 1136/5000\n",
      "31/31 - 0s - loss: 8.7696 - mae: 1.7386 - val_loss: 0.7731 - val_mae: 0.8128 - 38ms/epoch - 1ms/step\n",
      "Epoch 1137/5000\n",
      "31/31 - 0s - loss: 20.1892 - mae: 2.1254 - val_loss: 0.3225 - val_mae: 0.4849 - 37ms/epoch - 1ms/step\n",
      "Epoch 1138/5000\n",
      "31/31 - 0s - loss: 2.2902 - mae: 1.2783 - val_loss: 0.1471 - val_mae: 0.3021 - 35ms/epoch - 1ms/step\n",
      "Epoch 1139/5000\n",
      "31/31 - 0s - loss: 0.7660 - mae: 0.7386 - val_loss: 0.1207 - val_mae: 0.3044 - 36ms/epoch - 1ms/step\n",
      "Epoch 1140/5000\n",
      "31/31 - 0s - loss: 16.7139 - mae: 2.1711 - val_loss: 0.1189 - val_mae: 0.3020 - 36ms/epoch - 1ms/step\n",
      "Epoch 1141/5000\n",
      "31/31 - 0s - loss: 2.7056 - mae: 1.3693 - val_loss: 0.1361 - val_mae: 0.3354 - 36ms/epoch - 1ms/step\n",
      "Epoch 1142/5000\n",
      "31/31 - 0s - loss: 4.2173 - mae: 1.4022 - val_loss: 0.1802 - val_mae: 0.3821 - 36ms/epoch - 1ms/step\n",
      "Epoch 1143/5000\n",
      "31/31 - 0s - loss: 11.2361 - mae: 1.6432 - val_loss: 1.1931 - val_mae: 1.0394 - 35ms/epoch - 1ms/step\n",
      "Epoch 1144/5000\n",
      "31/31 - 0s - loss: 1.1709 - mae: 0.8625 - val_loss: 1.2955 - val_mae: 1.0865 - 35ms/epoch - 1ms/step\n",
      "Epoch 1145/5000\n",
      "31/31 - 0s - loss: 16.9190 - mae: 2.1836 - val_loss: 0.4681 - val_mae: 0.5904 - 36ms/epoch - 1ms/step\n",
      "Epoch 1146/5000\n",
      "31/31 - 0s - loss: 1.4233 - mae: 0.9750 - val_loss: 6.8485 - val_mae: 2.5961 - 35ms/epoch - 1ms/step\n",
      "Epoch 1147/5000\n",
      "31/31 - 0s - loss: 9.5361 - mae: 2.0822 - val_loss: 0.8550 - val_mae: 0.8634 - 35ms/epoch - 1ms/step\n",
      "Epoch 1148/5000\n",
      "31/31 - 0s - loss: 9.1176 - mae: 1.8349 - val_loss: 0.5147 - val_mae: 0.6341 - 37ms/epoch - 1ms/step\n",
      "Epoch 1149/5000\n",
      "31/31 - 0s - loss: 1.0899 - mae: 0.8994 - val_loss: 0.4101 - val_mae: 0.5466 - 37ms/epoch - 1ms/step\n",
      "Epoch 1150/5000\n",
      "31/31 - 0s - loss: 3.1670 - mae: 1.4641 - val_loss: 1.2200 - val_mae: 1.0548 - 37ms/epoch - 1ms/step\n",
      "Epoch 1151/5000\n",
      "31/31 - 0s - loss: 16.1514 - mae: 1.8178 - val_loss: 0.5401 - val_mae: 0.6589 - 37ms/epoch - 1ms/step\n",
      "Epoch 1152/5000\n",
      "31/31 - 0s - loss: 2.7907 - mae: 1.3231 - val_loss: 0.9718 - val_mae: 0.9276 - 36ms/epoch - 1ms/step\n",
      "Epoch 1153/5000\n",
      "31/31 - 0s - loss: 7.6850 - mae: 1.5659 - val_loss: 326.4742 - val_mae: 18.0655 - 37ms/epoch - 1ms/step\n",
      "Epoch 1154/5000\n",
      "31/31 - 0s - loss: 12.2886 - mae: 1.1789 - val_loss: 0.1390 - val_mae: 0.3318 - 36ms/epoch - 1ms/step\n",
      "Epoch 1155/5000\n",
      "31/31 - 0s - loss: 6.7885 - mae: 1.5241 - val_loss: 49.3456 - val_mae: 7.0163 - 37ms/epoch - 1ms/step\n",
      "Epoch 1156/5000\n",
      "31/31 - 0s - loss: 3.2770 - mae: 1.2550 - val_loss: 0.1848 - val_mae: 0.3223 - 37ms/epoch - 1ms/step\n",
      "Epoch 1157/5000\n",
      "31/31 - 0s - loss: 12.5465 - mae: 2.0062 - val_loss: 0.3045 - val_mae: 0.4720 - 36ms/epoch - 1ms/step\n",
      "Epoch 1158/5000\n",
      "31/31 - 0s - loss: 0.7427 - mae: 0.7412 - val_loss: 0.4742 - val_mae: 0.6011 - 39ms/epoch - 1ms/step\n",
      "Epoch 1159/5000\n",
      "31/31 - 0s - loss: 12.6486 - mae: 2.0133 - val_loss: 0.7073 - val_mae: 0.7658 - 37ms/epoch - 1ms/step\n",
      "Epoch 1160/5000\n",
      "31/31 - 0s - loss: 1.8579 - mae: 0.8977 - val_loss: 4.0989 - val_mae: 1.9974 - 37ms/epoch - 1ms/step\n",
      "Epoch 1161/5000\n",
      "31/31 - 0s - loss: 6.5808 - mae: 1.7025 - val_loss: 0.2020 - val_mae: 0.3390 - 37ms/epoch - 1ms/step\n",
      "Epoch 1162/5000\n",
      "31/31 - 0s - loss: 13.3272 - mae: 1.9193 - val_loss: 0.8724 - val_mae: 0.8709 - 35ms/epoch - 1ms/step\n",
      "Epoch 1163/5000\n",
      "31/31 - 0s - loss: 1.1462 - mae: 0.7872 - val_loss: 0.5091 - val_mae: 0.6277 - 37ms/epoch - 1ms/step\n",
      "Epoch 1164/5000\n",
      "31/31 - 0s - loss: 9.4687 - mae: 1.7113 - val_loss: 1.5469 - val_mae: 1.1940 - 36ms/epoch - 1ms/step\n",
      "Epoch 1165/5000\n",
      "31/31 - 0s - loss: 0.5877 - mae: 0.5929 - val_loss: 1.2019 - val_mae: 1.0446 - 38ms/epoch - 1ms/step\n",
      "Epoch 1166/5000\n",
      "31/31 - 0s - loss: 6.5303 - mae: 1.6703 - val_loss: 0.3187 - val_mae: 0.4521 - 36ms/epoch - 1ms/step\n",
      "Epoch 1167/5000\n",
      "31/31 - 0s - loss: 10.5295 - mae: 1.8429 - val_loss: 12.4451 - val_mae: 3.5136 - 38ms/epoch - 1ms/step\n",
      "Epoch 1168/5000\n",
      "31/31 - 0s - loss: 2.1463 - mae: 1.1010 - val_loss: 0.4829 - val_mae: 0.6104 - 36ms/epoch - 1ms/step\n",
      "Epoch 1169/5000\n",
      "31/31 - 0s - loss: 19.7350 - mae: 2.0168 - val_loss: 49.3669 - val_mae: 7.0183 - 37ms/epoch - 1ms/step\n",
      "Epoch 1170/5000\n",
      "31/31 - 0s - loss: 2.1819 - mae: 0.9269 - val_loss: 0.7240 - val_mae: 0.7809 - 36ms/epoch - 1ms/step\n",
      "Epoch 1171/5000\n",
      "31/31 - 0s - loss: 0.9460 - mae: 0.7869 - val_loss: 0.8558 - val_mae: 0.8640 - 38ms/epoch - 1ms/step\n",
      "Epoch 1172/5000\n",
      "31/31 - 0s - loss: 15.7471 - mae: 2.1609 - val_loss: 1.8824 - val_mae: 1.3301 - 37ms/epoch - 1ms/step\n",
      "Epoch 1173/5000\n",
      "31/31 - 0s - loss: 2.1563 - mae: 1.2170 - val_loss: 0.5726 - val_mae: 0.6744 - 37ms/epoch - 1ms/step\n",
      "Epoch 1174/5000\n",
      "31/31 - 0s - loss: 9.5986 - mae: 1.9049 - val_loss: 0.3320 - val_mae: 0.4879 - 37ms/epoch - 1ms/step\n",
      "Epoch 1175/5000\n",
      "31/31 - 0s - loss: 0.9113 - mae: 0.6758 - val_loss: 1.0854 - val_mae: 0.9781 - 37ms/epoch - 1ms/step\n",
      "Epoch 1176/5000\n",
      "31/31 - 0s - loss: 20.8310 - mae: 2.1650 - val_loss: 12.3717 - val_mae: 3.5005 - 34ms/epoch - 1ms/step\n",
      "Epoch 1177/5000\n",
      "31/31 - 0s - loss: 1.6842 - mae: 1.0187 - val_loss: 1.4025 - val_mae: 1.1328 - 39ms/epoch - 1ms/step\n",
      "Epoch 1178/5000\n",
      "31/31 - 0s - loss: 12.6211 - mae: 1.9904 - val_loss: 0.2110 - val_mae: 0.3496 - 38ms/epoch - 1ms/step\n",
      "Epoch 1179/5000\n",
      "31/31 - 0s - loss: 3.2378 - mae: 1.3398 - val_loss: 1.0103 - val_mae: 0.9462 - 37ms/epoch - 1ms/step\n",
      "Epoch 1180/5000\n",
      "31/31 - 0s - loss: 15.1059 - mae: 2.4518 - val_loss: 0.4776 - val_mae: 0.6047 - 39ms/epoch - 1ms/step\n",
      "Epoch 1181/5000\n",
      "31/31 - 0s - loss: 0.6818 - mae: 0.6660 - val_loss: 1.5147 - val_mae: 1.1847 - 37ms/epoch - 1ms/step\n",
      "Epoch 1182/5000\n",
      "31/31 - 0s - loss: 9.9495 - mae: 2.0798 - val_loss: 2.7960 - val_mae: 1.6406 - 37ms/epoch - 1ms/step\n",
      "Epoch 1183/5000\n",
      "31/31 - 0s - loss: 13.8555 - mae: 2.4650 - val_loss: 7.1838 - val_mae: 2.6610 - 38ms/epoch - 1ms/step\n",
      "Epoch 1184/5000\n",
      "31/31 - 0s - loss: 2.2439 - mae: 1.1213 - val_loss: 0.4704 - val_mae: 0.5970 - 37ms/epoch - 1ms/step\n",
      "Epoch 1185/5000\n",
      "31/31 - 0s - loss: 9.3448 - mae: 1.7627 - val_loss: 1.3316 - val_mae: 1.0986 - 36ms/epoch - 1ms/step\n",
      "Epoch 1186/5000\n",
      "31/31 - 0s - loss: 2.1214 - mae: 1.1892 - val_loss: 5.6115 - val_mae: 2.3420 - 37ms/epoch - 1ms/step\n",
      "Epoch 1187/5000\n",
      "31/31 - 0s - loss: 8.4454 - mae: 1.8276 - val_loss: 0.9354 - val_mae: 0.9062 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188/5000\n",
      "31/31 - 0s - loss: 0.6233 - mae: 0.6271 - val_loss: 1.1348 - val_mae: 1.0118 - 37ms/epoch - 1ms/step\n",
      "Epoch 1189/5000\n",
      "31/31 - 0s - loss: 35.7049 - mae: 2.2841 - val_loss: 1.0172 - val_mae: 0.9560 - 36ms/epoch - 1ms/step\n",
      "Epoch 1190/5000\n",
      "31/31 - 0s - loss: 2.5639 - mae: 1.1314 - val_loss: 0.4429 - val_mae: 0.5736 - 36ms/epoch - 1ms/step\n",
      "Epoch 1191/5000\n",
      "31/31 - 0s - loss: 7.7188 - mae: 1.6693 - val_loss: 1.6779 - val_mae: 1.2523 - 37ms/epoch - 1ms/step\n",
      "Epoch 1192/5000\n",
      "31/31 - 0s - loss: 1.2707 - mae: 0.9465 - val_loss: 0.2052 - val_mae: 0.4040 - 37ms/epoch - 1ms/step\n",
      "Epoch 1193/5000\n",
      "31/31 - 0s - loss: 8.9396 - mae: 1.9770 - val_loss: 0.4513 - val_mae: 0.5822 - 37ms/epoch - 1ms/step\n",
      "Epoch 1194/5000\n",
      "31/31 - 0s - loss: 13.9142 - mae: 2.3044 - val_loss: 0.2682 - val_mae: 0.3971 - 38ms/epoch - 1ms/step\n",
      "Epoch 1195/5000\n",
      "31/31 - 0s - loss: 0.8426 - mae: 0.7317 - val_loss: 0.6841 - val_mae: 0.7529 - 39ms/epoch - 1ms/step\n",
      "Epoch 1196/5000\n",
      "31/31 - 0s - loss: 13.8342 - mae: 1.9883 - val_loss: 0.5482 - val_mae: 0.6607 - 37ms/epoch - 1ms/step\n",
      "Epoch 1197/5000\n",
      "31/31 - 0s - loss: 1.0926 - mae: 0.8460 - val_loss: 0.9460 - val_mae: 0.9122 - 37ms/epoch - 1ms/step\n",
      "Epoch 1198/5000\n",
      "31/31 - 0s - loss: 8.3463 - mae: 1.6814 - val_loss: 0.6561 - val_mae: 0.7394 - 39ms/epoch - 1ms/step\n",
      "Epoch 1199/5000\n",
      "31/31 - 0s - loss: 5.2127 - mae: 1.5055 - val_loss: 3.9480 - val_mae: 1.9575 - 36ms/epoch - 1ms/step\n",
      "Epoch 1200/5000\n",
      "31/31 - 0s - loss: 2.0875 - mae: 1.0614 - val_loss: 13.2078 - val_mae: 3.6152 - 36ms/epoch - 1ms/step\n",
      "Epoch 1201/5000\n",
      "31/31 - 0s - loss: 14.1276 - mae: 1.9171 - val_loss: 5.1923 - val_mae: 2.2536 - 37ms/epoch - 1ms/step\n",
      "Epoch 1202/5000\n",
      "31/31 - 0s - loss: 3.2744 - mae: 1.4242 - val_loss: 1.9287 - val_mae: 1.3446 - 36ms/epoch - 1ms/step\n",
      "Epoch 1203/5000\n",
      "31/31 - 0s - loss: 10.2054 - mae: 1.6438 - val_loss: 22.7066 - val_mae: 4.7515 - 38ms/epoch - 1ms/step\n",
      "Epoch 1204/5000\n",
      "31/31 - 0s - loss: 4.0297 - mae: 1.5034 - val_loss: 7.5230 - val_mae: 2.7207 - 37ms/epoch - 1ms/step\n",
      "Epoch 1205/5000\n",
      "31/31 - 0s - loss: 2.5097 - mae: 1.2964 - val_loss: 4.8728 - val_mae: 2.1800 - 37ms/epoch - 1ms/step\n",
      "Epoch 1206/5000\n",
      "31/31 - 0s - loss: 8.0507 - mae: 1.9053 - val_loss: 0.4693 - val_mae: 0.5983 - 36ms/epoch - 1ms/step\n",
      "Epoch 1207/5000\n",
      "31/31 - 0s - loss: 1.7964 - mae: 0.8151 - val_loss: 38.5635 - val_mae: 6.2003 - 37ms/epoch - 1ms/step\n",
      "Epoch 1208/5000\n",
      "31/31 - 0s - loss: 12.4334 - mae: 2.4788 - val_loss: 2.5927 - val_mae: 1.5719 - 37ms/epoch - 1ms/step\n",
      "Epoch 1209/5000\n",
      "31/31 - 0s - loss: 8.8897 - mae: 1.8258 - val_loss: 0.2010 - val_mae: 0.4000 - 36ms/epoch - 1ms/step\n",
      "Epoch 1210/5000\n",
      "31/31 - 0s - loss: 2.4342 - mae: 1.2887 - val_loss: 2.2616 - val_mae: 1.4682 - 39ms/epoch - 1ms/step\n",
      "Epoch 1211/5000\n",
      "31/31 - 0s - loss: 4.1553 - mae: 1.6572 - val_loss: 4.2656 - val_mae: 2.0382 - 36ms/epoch - 1ms/step\n",
      "Epoch 1212/5000\n",
      "31/31 - 0s - loss: 0.8696 - mae: 0.7607 - val_loss: 3.9901 - val_mae: 1.9656 - 37ms/epoch - 1ms/step\n",
      "Epoch 1213/5000\n",
      "31/31 - 0s - loss: 34.0944 - mae: 2.4175 - val_loss: 0.1735 - val_mae: 0.3122 - 38ms/epoch - 1ms/step\n",
      "Epoch 1214/5000\n",
      "31/31 - 0s - loss: 2.0436 - mae: 1.1274 - val_loss: 0.8547 - val_mae: 0.8627 - 38ms/epoch - 1ms/step\n",
      "Epoch 1215/5000\n",
      "31/31 - 0s - loss: 8.2467 - mae: 1.8323 - val_loss: 1.3049 - val_mae: 1.0893 - 37ms/epoch - 1ms/step\n",
      "Epoch 1216/5000\n",
      "31/31 - 0s - loss: 0.8906 - mae: 0.7042 - val_loss: 0.1132 - val_mae: 0.2940 - 37ms/epoch - 1ms/step\n",
      "Epoch 1217/5000\n",
      "31/31 - 0s - loss: 15.8104 - mae: 2.1130 - val_loss: 0.1298 - val_mae: 0.3187 - 38ms/epoch - 1ms/step\n",
      "Epoch 1218/5000\n",
      "31/31 - 0s - loss: 1.1467 - mae: 0.8725 - val_loss: 0.5328 - val_mae: 0.6479 - 38ms/epoch - 1ms/step\n",
      "Epoch 1219/5000\n",
      "31/31 - 0s - loss: 15.5959 - mae: 2.1650 - val_loss: 0.1387 - val_mae: 0.2938 - 36ms/epoch - 1ms/step\n",
      "Epoch 1220/5000\n",
      "31/31 - 0s - loss: 1.1200 - mae: 0.8593 - val_loss: 0.1333 - val_mae: 0.2888 - 39ms/epoch - 1ms/step\n",
      "Epoch 1221/5000\n",
      "31/31 - 0s - loss: 11.8045 - mae: 1.9104 - val_loss: 0.7363 - val_mae: 0.7886 - 39ms/epoch - 1ms/step\n",
      "Epoch 1222/5000\n",
      "31/31 - 0s - loss: 1.0762 - mae: 0.8266 - val_loss: 0.4852 - val_mae: 0.6081 - 38ms/epoch - 1ms/step\n",
      "Epoch 1223/5000\n",
      "31/31 - 0s - loss: 26.7142 - mae: 2.4254 - val_loss: 1.3054 - val_mae: 1.0894 - 38ms/epoch - 1ms/step\n",
      "Epoch 1224/5000\n",
      "31/31 - 0s - loss: 3.1700 - mae: 1.4147 - val_loss: 0.2893 - val_mae: 0.4110 - 37ms/epoch - 1ms/step\n",
      "Epoch 1225/5000\n",
      "31/31 - 0s - loss: 3.2699 - mae: 1.1248 - val_loss: 56.7037 - val_mae: 7.5213 - 38ms/epoch - 1ms/step\n",
      "Epoch 1226/5000\n",
      "31/31 - 0s - loss: 7.6074 - mae: 1.8284 - val_loss: 0.9515 - val_mae: 0.9104 - 36ms/epoch - 1ms/step\n",
      "Epoch 1227/5000\n",
      "31/31 - 0s - loss: 1.6912 - mae: 1.0326 - val_loss: 0.6999 - val_mae: 0.7637 - 37ms/epoch - 1ms/step\n",
      "Epoch 1228/5000\n",
      "31/31 - 0s - loss: 8.0940 - mae: 1.6322 - val_loss: 0.5133 - val_mae: 0.6334 - 37ms/epoch - 1ms/step\n",
      "Epoch 1229/5000\n",
      "31/31 - 0s - loss: 10.7546 - mae: 1.9373 - val_loss: 0.1105 - val_mae: 0.2752 - 35ms/epoch - 1ms/step\n",
      "Epoch 1230/5000\n",
      "31/31 - 0s - loss: 1.2571 - mae: 0.8648 - val_loss: 0.4541 - val_mae: 0.5826 - 37ms/epoch - 1ms/step\n",
      "Epoch 1231/5000\n",
      "31/31 - 0s - loss: 13.6375 - mae: 2.0981 - val_loss: 2.1084 - val_mae: 1.4095 - 36ms/epoch - 1ms/step\n",
      "Epoch 1232/5000\n",
      "31/31 - 0s - loss: 2.8900 - mae: 1.4242 - val_loss: 0.1472 - val_mae: 0.3084 - 36ms/epoch - 1ms/step\n",
      "Epoch 1233/5000\n",
      "31/31 - 0s - loss: 22.6183 - mae: 2.2256 - val_loss: 0.9509 - val_mae: 0.9136 - 37ms/epoch - 1ms/step\n",
      "Epoch 1234/5000\n",
      "31/31 - 0s - loss: 1.3272 - mae: 0.9280 - val_loss: 0.3110 - val_mae: 0.4457 - 38ms/epoch - 1ms/step\n",
      "Epoch 1235/5000\n",
      "31/31 - 0s - loss: 0.8845 - mae: 0.7959 - val_loss: 1.0319 - val_mae: 0.9590 - 39ms/epoch - 1ms/step\n",
      "Epoch 1236/5000\n",
      "31/31 - 0s - loss: 25.3666 - mae: 2.3591 - val_loss: 1.2390 - val_mae: 1.0638 - 38ms/epoch - 1ms/step\n",
      "Epoch 1237/5000\n",
      "31/31 - 0s - loss: 0.6585 - mae: 0.6824 - val_loss: 0.4805 - val_mae: 0.6096 - 36ms/epoch - 1ms/step\n",
      "Epoch 1238/5000\n",
      "31/31 - 0s - loss: 10.6479 - mae: 1.9716 - val_loss: 0.1901 - val_mae: 0.3905 - 38ms/epoch - 1ms/step\n",
      "Epoch 1239/5000\n",
      "31/31 - 0s - loss: 10.4700 - mae: 1.8154 - val_loss: 15.8649 - val_mae: 3.9682 - 37ms/epoch - 1ms/step\n",
      "Epoch 1240/5000\n",
      "31/31 - 0s - loss: 1.2289 - mae: 0.6779 - val_loss: 0.4439 - val_mae: 0.5698 - 38ms/epoch - 1ms/step\n",
      "Epoch 1241/5000\n",
      "31/31 - 0s - loss: 11.1586 - mae: 2.0871 - val_loss: 0.3201 - val_mae: 0.4632 - 37ms/epoch - 1ms/step\n",
      "Epoch 1242/5000\n",
      "31/31 - 0s - loss: 1.0942 - mae: 0.7596 - val_loss: 0.1438 - val_mae: 0.2924 - 36ms/epoch - 1ms/step\n",
      "Epoch 1243/5000\n",
      "31/31 - 0s - loss: 14.0091 - mae: 2.0689 - val_loss: 0.1994 - val_mae: 0.3988 - 38ms/epoch - 1ms/step\n",
      "Epoch 1244/5000\n",
      "31/31 - 0s - loss: 1.3999 - mae: 0.9492 - val_loss: 0.5333 - val_mae: 0.6454 - 37ms/epoch - 1ms/step\n",
      "Epoch 1245/5000\n",
      "31/31 - 0s - loss: 10.9810 - mae: 1.8252 - val_loss: 1.4840 - val_mae: 1.1745 - 40ms/epoch - 1ms/step\n",
      "Epoch 1246/5000\n",
      "31/31 - 0s - loss: 1.8039 - mae: 1.0838 - val_loss: 0.1116 - val_mae: 0.2912 - 37ms/epoch - 1ms/step\n",
      "Epoch 1247/5000\n",
      "31/31 - 0s - loss: 15.1661 - mae: 2.2143 - val_loss: 3.3799 - val_mae: 1.8080 - 37ms/epoch - 1ms/step\n",
      "Epoch 1248/5000\n",
      "31/31 - 0s - loss: 1.1129 - mae: 0.8710 - val_loss: 1.2613 - val_mae: 1.0730 - 37ms/epoch - 1ms/step\n",
      "Epoch 1249/5000\n",
      "31/31 - 0s - loss: 9.6814 - mae: 1.7744 - val_loss: 1.8455 - val_mae: 1.3181 - 38ms/epoch - 1ms/step\n",
      "Epoch 1250/5000\n",
      "31/31 - 0s - loss: 2.2149 - mae: 1.2442 - val_loss: 82.6985 - val_mae: 9.0880 - 36ms/epoch - 1ms/step\n",
      "Epoch 1251/5000\n",
      "31/31 - 0s - loss: 9.4728 - mae: 1.5385 - val_loss: 8.0381 - val_mae: 2.8160 - 37ms/epoch - 1ms/step\n",
      "Epoch 1252/5000\n",
      "31/31 - 0s - loss: 18.5931 - mae: 2.0260 - val_loss: 1.3913 - val_mae: 1.1365 - 39ms/epoch - 1ms/step\n",
      "Epoch 1253/5000\n",
      "31/31 - 0s - loss: 1.4955 - mae: 0.8923 - val_loss: 1.9615 - val_mae: 1.3635 - 37ms/epoch - 1ms/step\n",
      "Epoch 1254/5000\n",
      "31/31 - 0s - loss: 1.4724 - mae: 0.8921 - val_loss: 3.7537 - val_mae: 1.9047 - 37ms/epoch - 1ms/step\n",
      "Epoch 1255/5000\n",
      "31/31 - 0s - loss: 12.8391 - mae: 1.9596 - val_loss: 0.1570 - val_mae: 0.3580 - 37ms/epoch - 1ms/step\n",
      "Epoch 1256/5000\n",
      "31/31 - 0s - loss: 4.7145 - mae: 1.3720 - val_loss: 160.8034 - val_mae: 12.6770 - 36ms/epoch - 1ms/step\n",
      "Epoch 1257/5000\n",
      "31/31 - 0s - loss: 8.6470 - mae: 1.5274 - val_loss: 0.6669 - val_mae: 0.7437 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1258/5000\n",
      "31/31 - 0s - loss: 9.5314 - mae: 1.6662 - val_loss: 28.7160 - val_mae: 5.3453 - 38ms/epoch - 1ms/step\n",
      "Epoch 1259/5000\n",
      "31/31 - 0s - loss: 5.8914 - mae: 1.8392 - val_loss: 0.3749 - val_mae: 0.5091 - 38ms/epoch - 1ms/step\n",
      "Epoch 1260/5000\n",
      "31/31 - 0s - loss: 4.0604 - mae: 1.3294 - val_loss: 271.9180 - val_mae: 16.4872 - 37ms/epoch - 1ms/step\n",
      "Epoch 1261/5000\n",
      "31/31 - 0s - loss: 8.8040 - mae: 1.5829 - val_loss: 1.8571 - val_mae: 1.3207 - 36ms/epoch - 1ms/step\n",
      "Epoch 1262/5000\n",
      "31/31 - 0s - loss: 4.0258 - mae: 1.5653 - val_loss: 20.9649 - val_mae: 4.5649 - 37ms/epoch - 1ms/step\n",
      "Epoch 1263/5000\n",
      "31/31 - 0s - loss: 1.1424 - mae: 0.7581 - val_loss: 0.8067 - val_mae: 0.8294 - 37ms/epoch - 1ms/step\n",
      "Epoch 1264/5000\n",
      "31/31 - 0s - loss: 16.7213 - mae: 2.2174 - val_loss: 3.5624 - val_mae: 1.8545 - 38ms/epoch - 1ms/step\n",
      "Epoch 1265/5000\n",
      "31/31 - 0s - loss: 1.8937 - mae: 1.1848 - val_loss: 0.1150 - val_mae: 0.2947 - 37ms/epoch - 1ms/step\n",
      "Epoch 1266/5000\n",
      "31/31 - 0s - loss: 24.3761 - mae: 1.8565 - val_loss: 0.4878 - val_mae: 0.6077 - 37ms/epoch - 1ms/step\n",
      "Epoch 1267/5000\n",
      "31/31 - 0s - loss: 2.6126 - mae: 1.4027 - val_loss: 0.3763 - val_mae: 0.5196 - 37ms/epoch - 1ms/step\n",
      "Epoch 1268/5000\n",
      "31/31 - 0s - loss: 1.8800 - mae: 1.1787 - val_loss: 6.4571 - val_mae: 2.5163 - 38ms/epoch - 1ms/step\n",
      "Epoch 1269/5000\n",
      "31/31 - 0s - loss: 9.3037 - mae: 1.9830 - val_loss: 4.6113 - val_mae: 2.1215 - 38ms/epoch - 1ms/step\n",
      "Epoch 1270/5000\n",
      "31/31 - 0s - loss: 3.0579 - mae: 1.3493 - val_loss: 29.6132 - val_mae: 5.4305 - 39ms/epoch - 1ms/step\n",
      "Epoch 1271/5000\n",
      "31/31 - 0s - loss: 6.9356 - mae: 1.4513 - val_loss: 0.1162 - val_mae: 0.2978 - 39ms/epoch - 1ms/step\n",
      "Epoch 1272/5000\n",
      "31/31 - 0s - loss: 17.4002 - mae: 1.7664 - val_loss: 0.4304 - val_mae: 0.5656 - 37ms/epoch - 1ms/step\n",
      "Epoch 1273/5000\n",
      "31/31 - 0s - loss: 1.2011 - mae: 0.9132 - val_loss: 0.1519 - val_mae: 0.2896 - 50ms/epoch - 2ms/step\n",
      "Epoch 1274/5000\n",
      "31/31 - 0s - loss: 13.7751 - mae: 2.2109 - val_loss: 0.1790 - val_mae: 0.3803 - 37ms/epoch - 1ms/step\n",
      "Epoch 1275/5000\n",
      "31/31 - 0s - loss: 1.1121 - mae: 0.7207 - val_loss: 0.9680 - val_mae: 0.9262 - 38ms/epoch - 1ms/step\n",
      "Epoch 1276/5000\n",
      "31/31 - 0s - loss: 6.2069 - mae: 1.3709 - val_loss: 187.0936 - val_mae: 13.6747 - 40ms/epoch - 1ms/step\n",
      "Epoch 1277/5000\n",
      "31/31 - 0s - loss: 17.4848 - mae: 1.8014 - val_loss: 3.9462 - val_mae: 1.9566 - 38ms/epoch - 1ms/step\n",
      "Epoch 1278/5000\n",
      "31/31 - 0s - loss: 1.8233 - mae: 1.0071 - val_loss: 0.1413 - val_mae: 0.3336 - 38ms/epoch - 1ms/step\n",
      "Epoch 1279/5000\n",
      "31/31 - 0s - loss: 17.0581 - mae: 2.2153 - val_loss: 0.3322 - val_mae: 0.4734 - 39ms/epoch - 1ms/step\n",
      "Epoch 1280/5000\n",
      "31/31 - 0s - loss: 1.4651 - mae: 1.0278 - val_loss: 0.6524 - val_mae: 0.7387 - 37ms/epoch - 1ms/step\n",
      "Epoch 1281/5000\n",
      "31/31 - 0s - loss: 10.5473 - mae: 1.7988 - val_loss: 0.4550 - val_mae: 0.5850 - 38ms/epoch - 1ms/step\n",
      "Epoch 1282/5000\n",
      "31/31 - 0s - loss: 1.5379 - mae: 0.9685 - val_loss: 0.4062 - val_mae: 0.5387 - 39ms/epoch - 1ms/step\n",
      "Epoch 1283/5000\n",
      "31/31 - 0s - loss: 16.5193 - mae: 2.1503 - val_loss: 1.2106 - val_mae: 1.0470 - 36ms/epoch - 1ms/step\n",
      "Epoch 1284/5000\n",
      "31/31 - 0s - loss: 2.9769 - mae: 1.4194 - val_loss: 3.4922 - val_mae: 1.8400 - 36ms/epoch - 1ms/step\n",
      "Epoch 1285/5000\n",
      "31/31 - 0s - loss: 3.8482 - mae: 1.3636 - val_loss: 0.4200 - val_mae: 0.5564 - 37ms/epoch - 1ms/step\n",
      "Epoch 1286/5000\n",
      "31/31 - 0s - loss: 16.6716 - mae: 1.9567 - val_loss: 0.1416 - val_mae: 0.2992 - 38ms/epoch - 1ms/step\n",
      "Epoch 1287/5000\n",
      "31/31 - 0s - loss: 1.4586 - mae: 1.0084 - val_loss: 1.1454 - val_mae: 1.0186 - 36ms/epoch - 1ms/step\n",
      "Epoch 1288/5000\n",
      "31/31 - 0s - loss: 13.7969 - mae: 2.1948 - val_loss: 0.2249 - val_mae: 0.4191 - 36ms/epoch - 1ms/step\n",
      "Epoch 1289/5000\n",
      "31/31 - 0s - loss: 1.1336 - mae: 0.8449 - val_loss: 0.1133 - val_mae: 0.2959 - 36ms/epoch - 1ms/step\n",
      "Epoch 1290/5000\n",
      "31/31 - 0s - loss: 13.1151 - mae: 2.0470 - val_loss: 1.1604 - val_mae: 1.0243 - 34ms/epoch - 1ms/step\n",
      "Epoch 1291/5000\n",
      "31/31 - 0s - loss: 1.2395 - mae: 0.8909 - val_loss: 93.7916 - val_mae: 9.6799 - 37ms/epoch - 1ms/step\n",
      "Epoch 1292/5000\n",
      "31/31 - 0s - loss: 11.3891 - mae: 1.9076 - val_loss: 0.2036 - val_mae: 0.4030 - 37ms/epoch - 1ms/step\n",
      "Epoch 1293/5000\n",
      "31/31 - 0s - loss: 6.1209 - mae: 1.6783 - val_loss: 3.1609 - val_mae: 1.7446 - 37ms/epoch - 1ms/step\n",
      "Epoch 1294/5000\n",
      "31/31 - 0s - loss: 1.4834 - mae: 1.0040 - val_loss: 7.2858 - val_mae: 2.6796 - 35ms/epoch - 1ms/step\n",
      "Epoch 1295/5000\n",
      "31/31 - 0s - loss: 12.1891 - mae: 2.3250 - val_loss: 7.5473 - val_mae: 2.7270 - 36ms/epoch - 1ms/step\n",
      "Epoch 1296/5000\n",
      "31/31 - 0s - loss: 2.5260 - mae: 1.1047 - val_loss: 31.1118 - val_mae: 5.5689 - 37ms/epoch - 1ms/step\n",
      "Epoch 1297/5000\n",
      "31/31 - 0s - loss: 5.0680 - mae: 1.5857 - val_loss: 0.5741 - val_mae: 0.6811 - 35ms/epoch - 1ms/step\n",
      "Epoch 1298/5000\n",
      "31/31 - 0s - loss: 11.0465 - mae: 1.9270 - val_loss: 4.5665 - val_mae: 2.1127 - 36ms/epoch - 1ms/step\n",
      "Epoch 1299/5000\n",
      "31/31 - 0s - loss: 0.9314 - mae: 0.8288 - val_loss: 2.8657 - val_mae: 1.6596 - 36ms/epoch - 1ms/step\n",
      "Epoch 1300/5000\n",
      "31/31 - 0s - loss: 15.2440 - mae: 2.2132 - val_loss: 1.8375 - val_mae: 1.3149 - 39ms/epoch - 1ms/step\n",
      "Epoch 1301/5000\n",
      "31/31 - 0s - loss: 1.3724 - mae: 0.7243 - val_loss: 0.2198 - val_mae: 0.3552 - 39ms/epoch - 1ms/step\n",
      "Epoch 1302/5000\n",
      "31/31 - 0s - loss: 11.8088 - mae: 2.1325 - val_loss: 4.7755 - val_mae: 2.1606 - 37ms/epoch - 1ms/step\n",
      "Epoch 1303/5000\n",
      "31/31 - 0s - loss: 1.4301 - mae: 1.0300 - val_loss: 0.1175 - val_mae: 0.3020 - 39ms/epoch - 1ms/step\n",
      "Epoch 1304/5000\n",
      "31/31 - 0s - loss: 6.2944 - mae: 1.5094 - val_loss: 0.1323 - val_mae: 0.3009 - 37ms/epoch - 1ms/step\n",
      "Epoch 1305/5000\n",
      "31/31 - 0s - loss: 12.3290 - mae: 2.0626 - val_loss: 1.6759 - val_mae: 1.2472 - 38ms/epoch - 1ms/step\n",
      "Epoch 1306/5000\n",
      "31/31 - 0s - loss: 1.1931 - mae: 0.8920 - val_loss: 0.1354 - val_mae: 0.2902 - 38ms/epoch - 1ms/step\n",
      "Epoch 1307/5000\n",
      "31/31 - 0s - loss: 19.2883 - mae: 1.6390 - val_loss: 0.1293 - val_mae: 0.2857 - 37ms/epoch - 1ms/step\n",
      "Epoch 1308/5000\n",
      "31/31 - 0s - loss: 1.7850 - mae: 1.0907 - val_loss: 0.3815 - val_mae: 0.5177 - 41ms/epoch - 1ms/step\n",
      "Epoch 1309/5000\n",
      "31/31 - 0s - loss: 1.1495 - mae: 0.8748 - val_loss: 226.1449 - val_mae: 15.0333 - 38ms/epoch - 1ms/step\n",
      "Epoch 1310/5000\n",
      "31/31 - 0s - loss: 17.1238 - mae: 1.8083 - val_loss: 0.4040 - val_mae: 0.5465 - 38ms/epoch - 1ms/step\n",
      "Epoch 1311/5000\n",
      "31/31 - 0s - loss: 1.5570 - mae: 0.8832 - val_loss: 0.1194 - val_mae: 0.2997 - 37ms/epoch - 1ms/step\n",
      "Epoch 1312/5000\n",
      "31/31 - 0s - loss: 11.6539 - mae: 1.9853 - val_loss: 0.2964 - val_mae: 0.4680 - 38ms/epoch - 1ms/step\n",
      "Epoch 1313/5000\n",
      "31/31 - 0s - loss: 2.5323 - mae: 1.2683 - val_loss: 214.8203 - val_mae: 14.6533 - 38ms/epoch - 1ms/step\n",
      "Epoch 1314/5000\n",
      "31/31 - 0s - loss: 13.6023 - mae: 1.9917 - val_loss: 0.5864 - val_mae: 0.6874 - 38ms/epoch - 1ms/step\n",
      "Epoch 1315/5000\n",
      "31/31 - 0s - loss: 5.5632 - mae: 1.5997 - val_loss: 14.4281 - val_mae: 3.7816 - 38ms/epoch - 1ms/step\n",
      "Epoch 1316/5000\n",
      "31/31 - 0s - loss: 3.5242 - mae: 1.4229 - val_loss: 2.6004 - val_mae: 1.5779 - 37ms/epoch - 1ms/step\n",
      "Epoch 1317/5000\n",
      "31/31 - 0s - loss: 10.3936 - mae: 2.1292 - val_loss: 2.7668 - val_mae: 1.6297 - 36ms/epoch - 1ms/step\n",
      "Epoch 1318/5000\n",
      "31/31 - 0s - loss: 3.1332 - mae: 1.3128 - val_loss: 116.5939 - val_mae: 10.7939 - 37ms/epoch - 1ms/step\n",
      "Epoch 1319/5000\n",
      "31/31 - 0s - loss: 14.1589 - mae: 1.9404 - val_loss: 0.1847 - val_mae: 0.3241 - 37ms/epoch - 1ms/step\n",
      "Epoch 1320/5000\n",
      "31/31 - 0s - loss: 11.8549 - mae: 2.0166 - val_loss: 0.3440 - val_mae: 0.4938 - 38ms/epoch - 1ms/step\n",
      "Epoch 1321/5000\n",
      "31/31 - 0s - loss: 0.3264 - mae: 0.4786 - val_loss: 2.1235 - val_mae: 1.4170 - 38ms/epoch - 1ms/step\n",
      "Epoch 1322/5000\n",
      "31/31 - 0s - loss: 15.9137 - mae: 2.1449 - val_loss: 0.1517 - val_mae: 0.2909 - 37ms/epoch - 1ms/step\n",
      "Epoch 1323/5000\n",
      "31/31 - 0s - loss: 1.2484 - mae: 0.9031 - val_loss: 0.1169 - val_mae: 0.2949 - 37ms/epoch - 1ms/step\n",
      "Epoch 1324/5000\n",
      "31/31 - 0s - loss: 6.0176 - mae: 1.4784 - val_loss: 1.6073 - val_mae: 1.2242 - 38ms/epoch - 1ms/step\n",
      "Epoch 1325/5000\n",
      "31/31 - 0s - loss: 0.9192 - mae: 0.7646 - val_loss: 240.0207 - val_mae: 15.4882 - 37ms/epoch - 1ms/step\n",
      "Epoch 1326/5000\n",
      "31/31 - 0s - loss: 17.4477 - mae: 1.8091 - val_loss: 0.1716 - val_mae: 0.3068 - 39ms/epoch - 1ms/step\n",
      "Epoch 1327/5000\n",
      "31/31 - 0s - loss: 1.3433 - mae: 0.8521 - val_loss: 3.5909 - val_mae: 1.8621 - 39ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1328/5000\n",
      "31/31 - 0s - loss: 14.9218 - mae: 2.1213 - val_loss: 4.4648 - val_mae: 2.0865 - 37ms/epoch - 1ms/step\n",
      "Epoch 1329/5000\n",
      "31/31 - 0s - loss: 7.8609 - mae: 1.5942 - val_loss: 1.2607 - val_mae: 1.0676 - 37ms/epoch - 1ms/step\n",
      "Epoch 1330/5000\n",
      "31/31 - 0s - loss: 2.9717 - mae: 1.2659 - val_loss: 3.0240 - val_mae: 1.7065 - 38ms/epoch - 1ms/step\n",
      "Epoch 1331/5000\n",
      "31/31 - 0s - loss: 33.9355 - mae: 2.5136 - val_loss: 0.3870 - val_mae: 0.5177 - 37ms/epoch - 1ms/step\n",
      "Epoch 1332/5000\n",
      "31/31 - 0s - loss: 1.7932 - mae: 1.0836 - val_loss: 0.2712 - val_mae: 0.3934 - 38ms/epoch - 1ms/step\n",
      "Epoch 1333/5000\n",
      "31/31 - 0s - loss: 1.9051 - mae: 1.0425 - val_loss: 0.8531 - val_mae: 0.8620 - 37ms/epoch - 1ms/step\n",
      "Epoch 1334/5000\n",
      "31/31 - 0s - loss: 22.5301 - mae: 2.1884 - val_loss: 2.0235 - val_mae: 1.3833 - 36ms/epoch - 1ms/step\n",
      "Epoch 1335/5000\n",
      "31/31 - 0s - loss: 2.4397 - mae: 1.1190 - val_loss: 0.3316 - val_mae: 0.4725 - 38ms/epoch - 1ms/step\n",
      "Epoch 1336/5000\n",
      "31/31 - 0s - loss: 18.1213 - mae: 1.9796 - val_loss: 64.1015 - val_mae: 8.0001 - 38ms/epoch - 1ms/step\n",
      "Epoch 1337/5000\n",
      "31/31 - 0s - loss: 3.1337 - mae: 1.0836 - val_loss: 0.1968 - val_mae: 0.3304 - 37ms/epoch - 1ms/step\n",
      "Epoch 1338/5000\n",
      "31/31 - 0s - loss: 1.3109 - mae: 0.9415 - val_loss: 0.3291 - val_mae: 0.4853 - 37ms/epoch - 1ms/step\n",
      "Epoch 1339/5000\n",
      "31/31 - 0s - loss: 19.8583 - mae: 1.9898 - val_loss: 1.7769 - val_mae: 1.2912 - 38ms/epoch - 1ms/step\n",
      "Epoch 1340/5000\n",
      "31/31 - 0s - loss: 1.1816 - mae: 0.8591 - val_loss: 2.7874 - val_mae: 1.6352 - 37ms/epoch - 1ms/step\n",
      "Epoch 1341/5000\n",
      "31/31 - 0s - loss: 8.4775 - mae: 1.8189 - val_loss: 6.3124 - val_mae: 2.4906 - 38ms/epoch - 1ms/step\n",
      "Epoch 1342/5000\n",
      "31/31 - 0s - loss: 6.3009 - mae: 1.6737 - val_loss: 2.8796 - val_mae: 1.6668 - 38ms/epoch - 1ms/step\n",
      "Epoch 1343/5000\n",
      "31/31 - 0s - loss: 1.9521 - mae: 0.9773 - val_loss: 0.8226 - val_mae: 0.8400 - 36ms/epoch - 1ms/step\n",
      "Epoch 1344/5000\n",
      "31/31 - 0s - loss: 16.2977 - mae: 1.7202 - val_loss: 5.8147 - val_mae: 2.3884 - 36ms/epoch - 1ms/step\n",
      "Epoch 1345/5000\n",
      "31/31 - 0s - loss: 2.5752 - mae: 1.3074 - val_loss: 1.0876 - val_mae: 0.9867 - 38ms/epoch - 1ms/step\n",
      "Epoch 1346/5000\n",
      "31/31 - 0s - loss: 8.0041 - mae: 1.7825 - val_loss: 77.5432 - val_mae: 8.7998 - 40ms/epoch - 1ms/step\n",
      "Epoch 1347/5000\n",
      "31/31 - 0s - loss: 5.0962 - mae: 1.5456 - val_loss: 0.2958 - val_mae: 0.4657 - 39ms/epoch - 1ms/step\n",
      "Epoch 1348/5000\n",
      "31/31 - 0s - loss: 13.8130 - mae: 1.9091 - val_loss: 0.5628 - val_mae: 0.6651 - 37ms/epoch - 1ms/step\n",
      "Epoch 1349/5000\n",
      "31/31 - 0s - loss: 2.5702 - mae: 1.3402 - val_loss: 0.1412 - val_mae: 0.3362 - 37ms/epoch - 1ms/step\n",
      "Epoch 1350/5000\n",
      "31/31 - 0s - loss: 5.4559 - mae: 1.6907 - val_loss: 0.9397 - val_mae: 0.9123 - 39ms/epoch - 1ms/step\n",
      "Epoch 1351/5000\n",
      "31/31 - 0s - loss: 5.0963 - mae: 1.3779 - val_loss: 4.2808 - val_mae: 2.0417 - 37ms/epoch - 1ms/step\n",
      "Epoch 1352/5000\n",
      "31/31 - 0s - loss: 2.9663 - mae: 1.2692 - val_loss: 0.1108 - val_mae: 0.2926 - 37ms/epoch - 1ms/step\n",
      "Epoch 1353/5000\n",
      "31/31 - 0s - loss: 12.8713 - mae: 1.7910 - val_loss: 0.7865 - val_mae: 0.8171 - 37ms/epoch - 1ms/step\n",
      "Epoch 1354/5000\n",
      "31/31 - 0s - loss: 1.1412 - mae: 0.6927 - val_loss: 0.6300 - val_mae: 0.7210 - 38ms/epoch - 1ms/step\n",
      "Epoch 1355/5000\n",
      "31/31 - 0s - loss: 18.2639 - mae: 2.1311 - val_loss: 0.1332 - val_mae: 0.2991 - 36ms/epoch - 1ms/step\n",
      "Epoch 1356/5000\n",
      "31/31 - 0s - loss: 1.2612 - mae: 0.9278 - val_loss: 0.5292 - val_mae: 0.6467 - 37ms/epoch - 1ms/step\n",
      "Epoch 1357/5000\n",
      "31/31 - 0s - loss: 12.6640 - mae: 2.1182 - val_loss: 0.1730 - val_mae: 0.3174 - 38ms/epoch - 1ms/step\n",
      "Epoch 1358/5000\n",
      "31/31 - 0s - loss: 1.0826 - mae: 0.8404 - val_loss: 1.0993 - val_mae: 0.9937 - 39ms/epoch - 1ms/step\n",
      "Epoch 1359/5000\n",
      "31/31 - 0s - loss: 9.6448 - mae: 1.8917 - val_loss: 0.1125 - val_mae: 0.2903 - 37ms/epoch - 1ms/step\n",
      "Epoch 1360/5000\n",
      "31/31 - 0s - loss: 2.5067 - mae: 1.2028 - val_loss: 0.9496 - val_mae: 0.9138 - 38ms/epoch - 1ms/step\n",
      "Epoch 1361/5000\n",
      "31/31 - 0s - loss: 12.3841 - mae: 1.8916 - val_loss: 32.0294 - val_mae: 5.6503 - 37ms/epoch - 1ms/step\n",
      "Epoch 1362/5000\n",
      "31/31 - 0s - loss: 4.2595 - mae: 1.5908 - val_loss: 0.1563 - val_mae: 0.3595 - 37ms/epoch - 1ms/step\n",
      "Epoch 1363/5000\n",
      "31/31 - 0s - loss: 15.3299 - mae: 2.0818 - val_loss: 1.3343 - val_mae: 1.1056 - 39ms/epoch - 1ms/step\n",
      "Epoch 1364/5000\n",
      "31/31 - 0s - loss: 1.1962 - mae: 0.8367 - val_loss: 0.9673 - val_mae: 0.9255 - 36ms/epoch - 1ms/step\n",
      "Epoch 1365/5000\n",
      "31/31 - 0s - loss: 7.9547 - mae: 1.5992 - val_loss: 0.1157 - val_mae: 0.2949 - 36ms/epoch - 1ms/step\n",
      "Epoch 1366/5000\n",
      "31/31 - 0s - loss: 1.6866 - mae: 0.9261 - val_loss: 2.9930 - val_mae: 1.6989 - 39ms/epoch - 1ms/step\n",
      "Epoch 1367/5000\n",
      "31/31 - 0s - loss: 10.3845 - mae: 1.8960 - val_loss: 2.2441 - val_mae: 1.4605 - 37ms/epoch - 1ms/step\n",
      "Epoch 1368/5000\n",
      "31/31 - 0s - loss: 8.2157 - mae: 1.5229 - val_loss: 0.2522 - val_mae: 0.3812 - 38ms/epoch - 1ms/step\n",
      "Epoch 1369/5000\n",
      "31/31 - 0s - loss: 0.7603 - mae: 0.6653 - val_loss: 21.9761 - val_mae: 4.6746 - 38ms/epoch - 1ms/step\n",
      "Epoch 1370/5000\n",
      "31/31 - 0s - loss: 18.4994 - mae: 2.1295 - val_loss: 0.8316 - val_mae: 0.8500 - 37ms/epoch - 1ms/step\n",
      "Epoch 1371/5000\n",
      "31/31 - 0s - loss: 0.8227 - mae: 0.7963 - val_loss: 2.2217 - val_mae: 1.4504 - 37ms/epoch - 1ms/step\n",
      "Epoch 1372/5000\n",
      "31/31 - 0s - loss: 16.3595 - mae: 2.2171 - val_loss: 0.3171 - val_mae: 0.4532 - 37ms/epoch - 1ms/step\n",
      "Epoch 1373/5000\n",
      "31/31 - 0s - loss: 1.2702 - mae: 0.9500 - val_loss: 0.4373 - val_mae: 0.5830 - 35ms/epoch - 1ms/step\n",
      "Epoch 1374/5000\n",
      "31/31 - 0s - loss: 11.4937 - mae: 2.2716 - val_loss: 0.1964 - val_mae: 0.3969 - 34ms/epoch - 1ms/step\n",
      "Epoch 1375/5000\n",
      "31/31 - 0s - loss: 20.8760 - mae: 2.2205 - val_loss: 0.5747 - val_mae: 0.6836 - 38ms/epoch - 1ms/step\n",
      "Epoch 1376/5000\n",
      "31/31 - 0s - loss: 0.5854 - mae: 0.5788 - val_loss: 0.3486 - val_mae: 0.4885 - 36ms/epoch - 1ms/step\n",
      "Epoch 1377/5000\n",
      "31/31 - 0s - loss: 0.6566 - mae: 0.6004 - val_loss: 1.1454 - val_mae: 1.0185 - 40ms/epoch - 1ms/step\n",
      "Epoch 1378/5000\n",
      "31/31 - 0s - loss: 11.8575 - mae: 2.0285 - val_loss: 0.3993 - val_mae: 0.5394 - 44ms/epoch - 1ms/step\n",
      "Epoch 1379/5000\n",
      "31/31 - 0s - loss: 1.1466 - mae: 0.8591 - val_loss: 0.1045 - val_mae: 0.2765 - 44ms/epoch - 1ms/step\n",
      "Epoch 1380/5000\n",
      "31/31 - 0s - loss: 20.1945 - mae: 2.1237 - val_loss: 0.5736 - val_mae: 0.6832 - 40ms/epoch - 1ms/step\n",
      "Epoch 1381/5000\n",
      "31/31 - 0s - loss: 1.4047 - mae: 0.9065 - val_loss: 3.6888 - val_mae: 1.8946 - 43ms/epoch - 1ms/step\n",
      "Epoch 1382/5000\n",
      "31/31 - 0s - loss: 19.7762 - mae: 2.0393 - val_loss: 0.2170 - val_mae: 0.3514 - 45ms/epoch - 1ms/step\n",
      "Epoch 1383/5000\n",
      "31/31 - 0s - loss: 1.9921 - mae: 1.0073 - val_loss: 3.2077 - val_mae: 1.7622 - 43ms/epoch - 1ms/step\n",
      "Epoch 1384/5000\n",
      "31/31 - 0s - loss: 16.9745 - mae: 2.0444 - val_loss: 1.7328 - val_mae: 1.2726 - 42ms/epoch - 1ms/step\n",
      "Epoch 1385/5000\n",
      "31/31 - 0s - loss: 0.8841 - mae: 0.7960 - val_loss: 0.1117 - val_mae: 0.2938 - 46ms/epoch - 1ms/step\n",
      "Epoch 1386/5000\n",
      "31/31 - 0s - loss: 14.4361 - mae: 2.0352 - val_loss: 0.1395 - val_mae: 0.3358 - 42ms/epoch - 1ms/step\n",
      "Epoch 1387/5000\n",
      "31/31 - 0s - loss: 3.5765 - mae: 1.3951 - val_loss: 1.0830 - val_mae: 0.9911 - 47ms/epoch - 2ms/step\n",
      "Epoch 1388/5000\n",
      "31/31 - 0s - loss: 2.7663 - mae: 1.3256 - val_loss: 49.3149 - val_mae: 7.0150 - 44ms/epoch - 1ms/step\n",
      "Epoch 1389/5000\n",
      "31/31 - 0s - loss: 8.6178 - mae: 1.4950 - val_loss: 0.1249 - val_mae: 0.3094 - 45ms/epoch - 1ms/step\n",
      "Epoch 1390/5000\n",
      "31/31 - 0s - loss: 9.6578 - mae: 1.8314 - val_loss: 27.2175 - val_mae: 5.2050 - 43ms/epoch - 1ms/step\n",
      "Epoch 1391/5000\n",
      "31/31 - 0s - loss: 4.3837 - mae: 1.6867 - val_loss: 0.6351 - val_mae: 0.7205 - 41ms/epoch - 1ms/step\n",
      "Epoch 1392/5000\n",
      "31/31 - 0s - loss: 14.7586 - mae: 1.6149 - val_loss: 17.1092 - val_mae: 4.1223 - 42ms/epoch - 1ms/step\n",
      "Epoch 1393/5000\n",
      "31/31 - 0s - loss: 2.2900 - mae: 1.2407 - val_loss: 0.5043 - val_mae: 0.6270 - 45ms/epoch - 1ms/step\n",
      "Epoch 1394/5000\n",
      "31/31 - 0s - loss: 1.2423 - mae: 0.9014 - val_loss: 1.9134 - val_mae: 1.3405 - 54ms/epoch - 2ms/step\n",
      "Epoch 1395/5000\n",
      "31/31 - 0s - loss: 19.1913 - mae: 2.4868 - val_loss: 1.6433 - val_mae: 1.2399 - 49ms/epoch - 2ms/step\n",
      "Epoch 1396/5000\n",
      "31/31 - 0s - loss: 0.7368 - mae: 0.6590 - val_loss: 1.3731 - val_mae: 1.1232 - 42ms/epoch - 1ms/step\n",
      "Epoch 1397/5000\n",
      "31/31 - 0s - loss: 13.0796 - mae: 2.1161 - val_loss: 0.4502 - val_mae: 0.5836 - 45ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1398/5000\n",
      "31/31 - 0s - loss: 1.0977 - mae: 0.7301 - val_loss: 0.1115 - val_mae: 0.2934 - 43ms/epoch - 1ms/step\n",
      "Epoch 1399/5000\n",
      "31/31 - 0s - loss: 18.7381 - mae: 2.0644 - val_loss: 0.7455 - val_mae: 0.7964 - 44ms/epoch - 1ms/step\n",
      "Epoch 1400/5000\n",
      "31/31 - 0s - loss: 3.0199 - mae: 1.4194 - val_loss: 2.9386 - val_mae: 1.6807 - 46ms/epoch - 1ms/step\n",
      "Epoch 1401/5000\n",
      "31/31 - 0s - loss: 11.9815 - mae: 1.9699 - val_loss: 0.1110 - val_mae: 0.2838 - 45ms/epoch - 1ms/step\n",
      "Epoch 1402/5000\n",
      "31/31 - 0s - loss: 1.7103 - mae: 0.9684 - val_loss: 2.2050 - val_mae: 1.4467 - 45ms/epoch - 1ms/step\n",
      "Epoch 1403/5000\n",
      "31/31 - 0s - loss: 7.1736 - mae: 1.8130 - val_loss: 0.3415 - val_mae: 0.4833 - 47ms/epoch - 2ms/step\n",
      "Epoch 1404/5000\n",
      "31/31 - 0s - loss: 5.0421 - mae: 1.1313 - val_loss: 11.0625 - val_mae: 3.3112 - 45ms/epoch - 1ms/step\n",
      "Epoch 1405/5000\n",
      "31/31 - 0s - loss: 3.6433 - mae: 1.3706 - val_loss: 0.6123 - val_mae: 0.7043 - 41ms/epoch - 1ms/step\n",
      "Epoch 1406/5000\n",
      "31/31 - 0s - loss: 7.8172 - mae: 1.5623 - val_loss: 0.1170 - val_mae: 0.3040 - 39ms/epoch - 1ms/step\n",
      "Epoch 1407/5000\n",
      "31/31 - 0s - loss: 2.7657 - mae: 1.2273 - val_loss: 0.1143 - val_mae: 0.2924 - 41ms/epoch - 1ms/step\n",
      "Epoch 1408/5000\n",
      "31/31 - 0s - loss: 0.9338 - mae: 0.7174 - val_loss: 66.9536 - val_mae: 8.1744 - 40ms/epoch - 1ms/step\n",
      "Epoch 1409/5000\n",
      "31/31 - 0s - loss: 24.0024 - mae: 2.4203 - val_loss: 3.5125 - val_mae: 1.8429 - 38ms/epoch - 1ms/step\n",
      "Epoch 1410/5000\n",
      "31/31 - 0s - loss: 1.0820 - mae: 0.8365 - val_loss: 0.2133 - val_mae: 0.4109 - 39ms/epoch - 1ms/step\n",
      "Epoch 1411/5000\n",
      "31/31 - 0s - loss: 26.6158 - mae: 2.3728 - val_loss: 0.2687 - val_mae: 0.3942 - 39ms/epoch - 1ms/step\n",
      "Epoch 1412/5000\n",
      "31/31 - 0s - loss: 1.5706 - mae: 1.0356 - val_loss: 2.0262 - val_mae: 1.3846 - 38ms/epoch - 1ms/step\n",
      "Epoch 1413/5000\n",
      "31/31 - 0s - loss: 8.4987 - mae: 1.7123 - val_loss: 0.7462 - val_mae: 0.7945 - 39ms/epoch - 1ms/step\n",
      "Epoch 1414/5000\n",
      "31/31 - 0s - loss: 1.2562 - mae: 0.9383 - val_loss: 5.9073 - val_mae: 2.4075 - 35ms/epoch - 1ms/step\n",
      "Epoch 1415/5000\n",
      "31/31 - 0s - loss: 10.6860 - mae: 1.9586 - val_loss: 0.1529 - val_mae: 0.3541 - 38ms/epoch - 1ms/step\n",
      "Epoch 1416/5000\n",
      "31/31 - 0s - loss: 11.8254 - mae: 1.8836 - val_loss: 0.1489 - val_mae: 0.3414 - 38ms/epoch - 1ms/step\n",
      "Epoch 1417/5000\n",
      "31/31 - 0s - loss: 1.5068 - mae: 0.9385 - val_loss: 1.2618 - val_mae: 1.0713 - 35ms/epoch - 1ms/step\n",
      "Epoch 1418/5000\n",
      "31/31 - 0s - loss: 12.4907 - mae: 2.3580 - val_loss: 2.9886 - val_mae: 1.6953 - 37ms/epoch - 1ms/step\n",
      "Epoch 1419/5000\n",
      "31/31 - 0s - loss: 2.6565 - mae: 1.2774 - val_loss: 234.3179 - val_mae: 15.3042 - 38ms/epoch - 1ms/step\n",
      "Epoch 1420/5000\n",
      "31/31 - 0s - loss: 9.2874 - mae: 1.5063 - val_loss: 0.1323 - val_mae: 0.2864 - 37ms/epoch - 1ms/step\n",
      "Epoch 1421/5000\n",
      "31/31 - 0s - loss: 5.9198 - mae: 1.7813 - val_loss: 0.2240 - val_mae: 0.4191 - 36ms/epoch - 1ms/step\n",
      "Epoch 1422/5000\n",
      "31/31 - 0s - loss: 0.9380 - mae: 0.7878 - val_loss: 0.9750 - val_mae: 0.9284 - 39ms/epoch - 1ms/step\n",
      "Epoch 1423/5000\n",
      "31/31 - 0s - loss: 23.9855 - mae: 2.6028 - val_loss: 0.1094 - val_mae: 0.2810 - 38ms/epoch - 1ms/step\n",
      "Epoch 1424/5000\n",
      "31/31 - 0s - loss: 2.1295 - mae: 1.1956 - val_loss: 0.1229 - val_mae: 0.3008 - 38ms/epoch - 1ms/step\n",
      "Epoch 1425/5000\n",
      "31/31 - 0s - loss: 12.6309 - mae: 1.9788 - val_loss: 1.9813 - val_mae: 1.3679 - 37ms/epoch - 1ms/step\n",
      "Epoch 1426/5000\n",
      "31/31 - 0s - loss: 2.7911 - mae: 1.4716 - val_loss: 0.6698 - val_mae: 0.7483 - 37ms/epoch - 1ms/step\n",
      "Epoch 1427/5000\n",
      "31/31 - 0s - loss: 10.9843 - mae: 1.6675 - val_loss: 0.3517 - val_mae: 0.4998 - 37ms/epoch - 1ms/step\n",
      "Epoch 1428/5000\n",
      "31/31 - 0s - loss: 1.6696 - mae: 0.9760 - val_loss: 0.1257 - val_mae: 0.2902 - 37ms/epoch - 1ms/step\n",
      "Epoch 1429/5000\n",
      "31/31 - 0s - loss: 17.0026 - mae: 2.0414 - val_loss: 0.3217 - val_mae: 0.4591 - 37ms/epoch - 1ms/step\n",
      "Epoch 1430/5000\n",
      "31/31 - 0s - loss: 1.3689 - mae: 0.8437 - val_loss: 0.1696 - val_mae: 0.3094 - 34ms/epoch - 1ms/step\n",
      "Epoch 1431/5000\n",
      "31/31 - 0s - loss: 9.0518 - mae: 1.7509 - val_loss: 0.5719 - val_mae: 0.6793 - 37ms/epoch - 1ms/step\n",
      "Epoch 1432/5000\n",
      "31/31 - 0s - loss: 1.5188 - mae: 1.0870 - val_loss: 1.2254 - val_mae: 1.0566 - 37ms/epoch - 1ms/step\n",
      "Epoch 1433/5000\n",
      "31/31 - 0s - loss: 12.7662 - mae: 2.1044 - val_loss: 2.8509 - val_mae: 1.6586 - 37ms/epoch - 1ms/step\n",
      "Epoch 1434/5000\n",
      "31/31 - 0s - loss: 2.3789 - mae: 1.0626 - val_loss: 0.6909 - val_mae: 0.7611 - 39ms/epoch - 1ms/step\n",
      "Epoch 1435/5000\n",
      "31/31 - 0s - loss: 7.6571 - mae: 1.3361 - val_loss: 23.9969 - val_mae: 4.8854 - 38ms/epoch - 1ms/step\n",
      "Epoch 1436/5000\n",
      "31/31 - 0s - loss: 4.6864 - mae: 1.7142 - val_loss: 2.6533 - val_mae: 1.5937 - 38ms/epoch - 1ms/step\n",
      "Epoch 1437/5000\n",
      "31/31 - 0s - loss: 7.5766 - mae: 2.1172 - val_loss: 6.7167 - val_mae: 2.5703 - 38ms/epoch - 1ms/step\n",
      "Epoch 1438/5000\n",
      "31/31 - 0s - loss: 8.0352 - mae: 1.8187 - val_loss: 25.3697 - val_mae: 5.0263 - 36ms/epoch - 1ms/step\n",
      "Epoch 1439/5000\n",
      "31/31 - 0s - loss: 3.3829 - mae: 1.1615 - val_loss: 0.3386 - val_mae: 0.4857 - 37ms/epoch - 1ms/step\n",
      "Epoch 1440/5000\n",
      "31/31 - 0s - loss: 7.0118 - mae: 1.5581 - val_loss: 2.6113 - val_mae: 1.5825 - 37ms/epoch - 1ms/step\n",
      "Epoch 1441/5000\n",
      "31/31 - 0s - loss: 35.6195 - mae: 2.2576 - val_loss: 0.5883 - val_mae: 0.6907 - 37ms/epoch - 1ms/step\n",
      "Epoch 1442/5000\n",
      "31/31 - 0s - loss: 1.8353 - mae: 0.9879 - val_loss: 0.7201 - val_mae: 0.7778 - 37ms/epoch - 1ms/step\n",
      "Epoch 1443/5000\n",
      "31/31 - 0s - loss: 9.7768 - mae: 1.8933 - val_loss: 25.0419 - val_mae: 4.9918 - 36ms/epoch - 1ms/step\n",
      "Epoch 1444/5000\n",
      "31/31 - 0s - loss: 3.0690 - mae: 1.3862 - val_loss: 1.5330 - val_mae: 1.1910 - 37ms/epoch - 1ms/step\n",
      "Epoch 1445/5000\n",
      "31/31 - 0s - loss: 12.5101 - mae: 1.8061 - val_loss: 129.4034 - val_mae: 11.3703 - 38ms/epoch - 1ms/step\n",
      "Epoch 1446/5000\n",
      "31/31 - 0s - loss: 6.2446 - mae: 1.3854 - val_loss: 0.1221 - val_mae: 0.2978 - 38ms/epoch - 1ms/step\n",
      "Epoch 1447/5000\n",
      "31/31 - 0s - loss: 0.9199 - mae: 0.7410 - val_loss: 3.7330 - val_mae: 1.9022 - 36ms/epoch - 1ms/step\n",
      "Epoch 1448/5000\n",
      "31/31 - 0s - loss: 14.7543 - mae: 2.1159 - val_loss: 0.1227 - val_mae: 0.2987 - 36ms/epoch - 1ms/step\n",
      "Epoch 1449/5000\n",
      "31/31 - 0s - loss: 2.2338 - mae: 1.1123 - val_loss: 55.4370 - val_mae: 7.4378 - 37ms/epoch - 1ms/step\n",
      "Epoch 1450/5000\n",
      "31/31 - 0s - loss: 18.4028 - mae: 2.0131 - val_loss: 4.8019 - val_mae: 2.1660 - 38ms/epoch - 1ms/step\n",
      "Epoch 1451/5000\n",
      "31/31 - 0s - loss: 1.0754 - mae: 0.8389 - val_loss: 1.7678 - val_mae: 1.2894 - 38ms/epoch - 1ms/step\n",
      "Epoch 1452/5000\n",
      "31/31 - 0s - loss: 35.9616 - mae: 2.3442 - val_loss: 0.4929 - val_mae: 0.6214 - 37ms/epoch - 1ms/step\n",
      "Epoch 1453/5000\n",
      "31/31 - 0s - loss: 1.7265 - mae: 0.9919 - val_loss: 1.6773 - val_mae: 1.2497 - 37ms/epoch - 1ms/step\n",
      "Epoch 1454/5000\n",
      "31/31 - 0s - loss: 1.3148 - mae: 0.9092 - val_loss: 0.3424 - val_mae: 0.4922 - 37ms/epoch - 1ms/step\n",
      "Epoch 1455/5000\n",
      "31/31 - 0s - loss: 21.9993 - mae: 2.3350 - val_loss: 4.6617 - val_mae: 2.1333 - 38ms/epoch - 1ms/step\n",
      "Epoch 1456/5000\n",
      "31/31 - 0s - loss: 2.3641 - mae: 1.2741 - val_loss: 1.1096 - val_mae: 1.0025 - 38ms/epoch - 1ms/step\n",
      "Epoch 1457/5000\n",
      "31/31 - 0s - loss: 11.7578 - mae: 1.6783 - val_loss: 0.1347 - val_mae: 0.2881 - 38ms/epoch - 1ms/step\n",
      "Epoch 1458/5000\n",
      "31/31 - 0s - loss: 1.1123 - mae: 0.8412 - val_loss: 1.2316 - val_mae: 1.0577 - 38ms/epoch - 1ms/step\n",
      "Epoch 1459/5000\n",
      "31/31 - 0s - loss: 14.7998 - mae: 2.1555 - val_loss: 0.1952 - val_mae: 0.3966 - 38ms/epoch - 1ms/step\n",
      "Epoch 1460/5000\n",
      "31/31 - 0s - loss: 1.0704 - mae: 0.8387 - val_loss: 0.7864 - val_mae: 0.8178 - 37ms/epoch - 1ms/step\n",
      "Epoch 1461/5000\n",
      "31/31 - 0s - loss: 8.3828 - mae: 1.9600 - val_loss: 10.8018 - val_mae: 3.2681 - 37ms/epoch - 1ms/step\n",
      "Epoch 1462/5000\n",
      "31/31 - 0s - loss: 10.6858 - mae: 1.8448 - val_loss: 1.2625 - val_mae: 1.0766 - 37ms/epoch - 1ms/step\n",
      "Epoch 1463/5000\n",
      "31/31 - 0s - loss: 1.8111 - mae: 1.0488 - val_loss: 0.6718 - val_mae: 0.7520 - 36ms/epoch - 1ms/step\n",
      "Epoch 1464/5000\n",
      "31/31 - 0s - loss: 9.7637 - mae: 1.9730 - val_loss: 0.1142 - val_mae: 0.2959 - 38ms/epoch - 1ms/step\n",
      "Epoch 1465/5000\n",
      "31/31 - 0s - loss: 0.3962 - mae: 0.5122 - val_loss: 0.9787 - val_mae: 0.9304 - 36ms/epoch - 1ms/step\n",
      "Epoch 1466/5000\n",
      "31/31 - 0s - loss: 7.0477 - mae: 1.6389 - val_loss: 0.1471 - val_mae: 0.3458 - 38ms/epoch - 1ms/step\n",
      "Epoch 1467/5000\n",
      "31/31 - 0s - loss: 1.3286 - mae: 0.9587 - val_loss: 0.1134 - val_mae: 0.2932 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1468/5000\n",
      "31/31 - 0s - loss: 22.8225 - mae: 2.1505 - val_loss: 8.8375 - val_mae: 2.9549 - 40ms/epoch - 1ms/step\n",
      "Epoch 1469/5000\n",
      "31/31 - 0s - loss: 1.8328 - mae: 0.9745 - val_loss: 1.4733 - val_mae: 1.1677 - 39ms/epoch - 1ms/step\n",
      "Epoch 1470/5000\n",
      "31/31 - 0s - loss: 18.1991 - mae: 2.0595 - val_loss: 0.2720 - val_mae: 0.4019 - 39ms/epoch - 1ms/step\n",
      "Epoch 1471/5000\n",
      "31/31 - 0s - loss: 1.0514 - mae: 0.7386 - val_loss: 0.5160 - val_mae: 0.6355 - 37ms/epoch - 1ms/step\n",
      "Epoch 1472/5000\n",
      "31/31 - 0s - loss: 11.4561 - mae: 1.9683 - val_loss: 3.4459 - val_mae: 1.8254 - 38ms/epoch - 1ms/step\n",
      "Epoch 1473/5000\n",
      "31/31 - 0s - loss: 3.3050 - mae: 1.4312 - val_loss: 1.7924 - val_mae: 1.2984 - 37ms/epoch - 1ms/step\n",
      "Epoch 1474/5000\n",
      "31/31 - 0s - loss: 10.1072 - mae: 1.9559 - val_loss: 0.7516 - val_mae: 0.7990 - 36ms/epoch - 1ms/step\n",
      "Epoch 1475/5000\n",
      "31/31 - 0s - loss: 1.3077 - mae: 0.9353 - val_loss: 0.8253 - val_mae: 0.8463 - 40ms/epoch - 1ms/step\n",
      "Epoch 1476/5000\n",
      "31/31 - 0s - loss: 15.3907 - mae: 2.1132 - val_loss: 0.1923 - val_mae: 0.3331 - 37ms/epoch - 1ms/step\n",
      "Epoch 1477/5000\n",
      "31/31 - 0s - loss: 2.5936 - mae: 1.2954 - val_loss: 0.1584 - val_mae: 0.3065 - 38ms/epoch - 1ms/step\n",
      "Epoch 1478/5000\n",
      "31/31 - 0s - loss: 12.4156 - mae: 2.2275 - val_loss: 5.8348 - val_mae: 2.3940 - 38ms/epoch - 1ms/step\n",
      "Epoch 1479/5000\n",
      "31/31 - 0s - loss: 1.2017 - mae: 0.8855 - val_loss: 2.5537 - val_mae: 1.5622 - 40ms/epoch - 1ms/step\n",
      "Epoch 1480/5000\n",
      "31/31 - 0s - loss: 9.2063 - mae: 1.9706 - val_loss: 0.8677 - val_mae: 0.8672 - 38ms/epoch - 1ms/step\n",
      "Epoch 1481/5000\n",
      "31/31 - 0s - loss: 6.0979 - mae: 1.5792 - val_loss: 0.3101 - val_mae: 0.4409 - 38ms/epoch - 1ms/step\n",
      "Epoch 1482/5000\n",
      "31/31 - 0s - loss: 1.2047 - mae: 0.8600 - val_loss: 6.4848 - val_mae: 2.5260 - 39ms/epoch - 1ms/step\n",
      "Epoch 1483/5000\n",
      "31/31 - 0s - loss: 18.4294 - mae: 1.8642 - val_loss: 0.2327 - val_mae: 0.4255 - 39ms/epoch - 1ms/step\n",
      "Epoch 1484/5000\n",
      "31/31 - 0s - loss: 1.5534 - mae: 1.0923 - val_loss: 0.1204 - val_mae: 0.3046 - 37ms/epoch - 1ms/step\n",
      "Epoch 1485/5000\n",
      "31/31 - 0s - loss: 20.9808 - mae: 1.9447 - val_loss: 1.2800 - val_mae: 1.0786 - 38ms/epoch - 1ms/step\n",
      "Epoch 1486/5000\n",
      "31/31 - 0s - loss: 2.0956 - mae: 1.0945 - val_loss: 6.7255 - val_mae: 2.5722 - 38ms/epoch - 1ms/step\n",
      "Epoch 1487/5000\n",
      "31/31 - 0s - loss: 14.3080 - mae: 2.0101 - val_loss: 0.1611 - val_mae: 0.3608 - 38ms/epoch - 1ms/step\n",
      "Epoch 1488/5000\n",
      "31/31 - 0s - loss: 2.0993 - mae: 1.0835 - val_loss: 0.7247 - val_mae: 0.7843 - 35ms/epoch - 1ms/step\n",
      "Epoch 1489/5000\n",
      "31/31 - 0s - loss: 6.8185 - mae: 1.9650 - val_loss: 0.2516 - val_mae: 0.4386 - 37ms/epoch - 1ms/step\n",
      "Epoch 1490/5000\n",
      "31/31 - 0s - loss: 10.5638 - mae: 1.7506 - val_loss: 3.6652 - val_mae: 1.8814 - 38ms/epoch - 1ms/step\n",
      "Epoch 1491/5000\n",
      "31/31 - 0s - loss: 2.3819 - mae: 1.2075 - val_loss: 0.1489 - val_mae: 0.2936 - 36ms/epoch - 1ms/step\n",
      "Epoch 1492/5000\n",
      "31/31 - 0s - loss: 10.1587 - mae: 2.1835 - val_loss: 3.2648 - val_mae: 1.7774 - 37ms/epoch - 1ms/step\n",
      "Epoch 1493/5000\n",
      "31/31 - 0s - loss: 1.3199 - mae: 0.9331 - val_loss: 0.7669 - val_mae: 0.8007 - 38ms/epoch - 1ms/step\n",
      "Epoch 1494/5000\n",
      "31/31 - 0s - loss: 11.5771 - mae: 2.2013 - val_loss: 0.8803 - val_mae: 0.8784 - 39ms/epoch - 1ms/step\n",
      "Epoch 1495/5000\n",
      "31/31 - 0s - loss: 14.1921 - mae: 2.2699 - val_loss: 6.2948 - val_mae: 2.4867 - 39ms/epoch - 1ms/step\n",
      "Epoch 1496/5000\n",
      "31/31 - 0s - loss: 1.5333 - mae: 1.0043 - val_loss: 2.2094 - val_mae: 1.4478 - 38ms/epoch - 1ms/step\n",
      "Epoch 1497/5000\n",
      "31/31 - 0s - loss: 7.0165 - mae: 1.9152 - val_loss: 0.6782 - val_mae: 0.7550 - 37ms/epoch - 1ms/step\n",
      "Epoch 1498/5000\n",
      "31/31 - 0s - loss: 1.7625 - mae: 0.8536 - val_loss: 169.1907 - val_mae: 13.0040 - 37ms/epoch - 1ms/step\n",
      "Epoch 1499/5000\n",
      "31/31 - 0s - loss: 17.9327 - mae: 1.9789 - val_loss: 0.9302 - val_mae: 0.9019 - 36ms/epoch - 1ms/step\n",
      "Epoch 1500/5000\n",
      "31/31 - 0s - loss: 0.9771 - mae: 0.8409 - val_loss: 0.1433 - val_mae: 0.3404 - 37ms/epoch - 1ms/step\n",
      "Epoch 1501/5000\n",
      "31/31 - 0s - loss: 7.5703 - mae: 1.8203 - val_loss: 0.1127 - val_mae: 0.2951 - 37ms/epoch - 1ms/step\n",
      "Epoch 1502/5000\n",
      "31/31 - 0s - loss: 17.2820 - mae: 1.8269 - val_loss: 0.1208 - val_mae: 0.3054 - 38ms/epoch - 1ms/step\n",
      "Epoch 1503/5000\n",
      "31/31 - 0s - loss: 0.9482 - mae: 0.8625 - val_loss: 0.9071 - val_mae: 0.8919 - 37ms/epoch - 1ms/step\n",
      "Epoch 1504/5000\n",
      "31/31 - 0s - loss: 7.4354 - mae: 2.0744 - val_loss: 1.2034 - val_mae: 1.0462 - 35ms/epoch - 1ms/step\n",
      "Epoch 1505/5000\n",
      "31/31 - 0s - loss: 1.1638 - mae: 0.8984 - val_loss: 2.3919 - val_mae: 1.5117 - 38ms/epoch - 1ms/step\n",
      "Epoch 1506/5000\n",
      "31/31 - 0s - loss: 26.5733 - mae: 2.3037 - val_loss: 0.1752 - val_mae: 0.3775 - 37ms/epoch - 1ms/step\n",
      "Epoch 1507/5000\n",
      "31/31 - 0s - loss: 1.2206 - mae: 0.8633 - val_loss: 2.3200 - val_mae: 1.4874 - 38ms/epoch - 1ms/step\n",
      "Epoch 1508/5000\n",
      "31/31 - 0s - loss: 16.0314 - mae: 1.8518 - val_loss: 0.7491 - val_mae: 0.7988 - 38ms/epoch - 1ms/step\n",
      "Epoch 1509/5000\n",
      "31/31 - 0s - loss: 2.4148 - mae: 1.2608 - val_loss: 0.5766 - val_mae: 0.6772 - 38ms/epoch - 1ms/step\n",
      "Epoch 1510/5000\n",
      "31/31 - 0s - loss: 23.5157 - mae: 2.0499 - val_loss: 0.2882 - val_mae: 0.4612 - 37ms/epoch - 1ms/step\n",
      "Epoch 1511/5000\n",
      "31/31 - 0s - loss: 0.8091 - mae: 0.6953 - val_loss: 2.2849 - val_mae: 1.4762 - 38ms/epoch - 1ms/step\n",
      "Epoch 1512/5000\n",
      "31/31 - 0s - loss: 9.0557 - mae: 1.9992 - val_loss: 6.5753 - val_mae: 2.5434 - 37ms/epoch - 1ms/step\n",
      "Epoch 1513/5000\n",
      "31/31 - 0s - loss: 3.0769 - mae: 1.3866 - val_loss: 14.6395 - val_mae: 3.8118 - 36ms/epoch - 1ms/step\n",
      "Epoch 1514/5000\n",
      "31/31 - 0s - loss: 11.9282 - mae: 1.8779 - val_loss: 0.6132 - val_mae: 0.7096 - 39ms/epoch - 1ms/step\n",
      "Epoch 1515/5000\n",
      "31/31 - 0s - loss: 5.1246 - mae: 1.5015 - val_loss: 0.1710 - val_mae: 0.3739 - 37ms/epoch - 1ms/step\n",
      "Epoch 1516/5000\n",
      "31/31 - 0s - loss: 0.6103 - mae: 0.6193 - val_loss: 0.1511 - val_mae: 0.3407 - 36ms/epoch - 1ms/step\n",
      "Epoch 1517/5000\n",
      "31/31 - 0s - loss: 27.9711 - mae: 2.2449 - val_loss: 0.1845 - val_mae: 0.3871 - 38ms/epoch - 1ms/step\n",
      "Epoch 1518/5000\n",
      "31/31 - 0s - loss: 1.3401 - mae: 0.9105 - val_loss: 7.1194 - val_mae: 2.6474 - 36ms/epoch - 1ms/step\n",
      "Epoch 1519/5000\n",
      "31/31 - 0s - loss: 14.5390 - mae: 2.0812 - val_loss: 0.1763 - val_mae: 0.3804 - 37ms/epoch - 1ms/step\n",
      "Epoch 1520/5000\n",
      "31/31 - 0s - loss: 1.5235 - mae: 0.9468 - val_loss: 0.3461 - val_mae: 0.4921 - 40ms/epoch - 1ms/step\n",
      "Epoch 1521/5000\n",
      "31/31 - 0s - loss: 7.8959 - mae: 1.5361 - val_loss: 9.8675 - val_mae: 3.1243 - 36ms/epoch - 1ms/step\n",
      "Epoch 1522/5000\n",
      "31/31 - 0s - loss: 18.6832 - mae: 2.0873 - val_loss: 0.4403 - val_mae: 0.5831 - 37ms/epoch - 1ms/step\n",
      "Epoch 1523/5000\n",
      "31/31 - 0s - loss: 1.3348 - mae: 0.8741 - val_loss: 0.1151 - val_mae: 0.2935 - 35ms/epoch - 1ms/step\n",
      "Epoch 1524/5000\n",
      "31/31 - 0s - loss: 9.2224 - mae: 1.4269 - val_loss: 168.1691 - val_mae: 12.9635 - 37ms/epoch - 1ms/step\n",
      "Epoch 1525/5000\n",
      "31/31 - 0s - loss: 7.9867 - mae: 1.4047 - val_loss: 0.2298 - val_mae: 0.4228 - 38ms/epoch - 1ms/step\n",
      "Epoch 1526/5000\n",
      "31/31 - 0s - loss: 1.4541 - mae: 0.9461 - val_loss: 59.8936 - val_mae: 7.7323 - 35ms/epoch - 1ms/step\n",
      "Epoch 1527/5000\n",
      "31/31 - 0s - loss: 13.7261 - mae: 2.0245 - val_loss: 0.6452 - val_mae: 0.7327 - 38ms/epoch - 1ms/step\n",
      "Epoch 1528/5000\n",
      "31/31 - 0s - loss: 7.6917 - mae: 1.7329 - val_loss: 1.6368 - val_mae: 1.2388 - 39ms/epoch - 1ms/step\n",
      "Epoch 1529/5000\n",
      "31/31 - 0s - loss: 2.6630 - mae: 1.2725 - val_loss: 0.9230 - val_mae: 0.9029 - 37ms/epoch - 1ms/step\n",
      "Epoch 1530/5000\n",
      "31/31 - 0s - loss: 16.4511 - mae: 2.0503 - val_loss: 0.3847 - val_mae: 0.5156 - 37ms/epoch - 1ms/step\n",
      "Epoch 1531/5000\n",
      "31/31 - 0s - loss: 2.6115 - mae: 1.1018 - val_loss: 0.4943 - val_mae: 0.6204 - 36ms/epoch - 1ms/step\n",
      "Epoch 1532/5000\n",
      "31/31 - 0s - loss: 7.2558 - mae: 1.7903 - val_loss: 0.8715 - val_mae: 0.8709 - 36ms/epoch - 1ms/step\n",
      "Epoch 1533/5000\n",
      "31/31 - 0s - loss: 0.8685 - mae: 0.7773 - val_loss: 1.9134 - val_mae: 1.3415 - 35ms/epoch - 1ms/step\n",
      "Epoch 1534/5000\n",
      "31/31 - 0s - loss: 14.4949 - mae: 2.4174 - val_loss: 4.3123 - val_mae: 2.0512 - 36ms/epoch - 1ms/step\n",
      "Epoch 1535/5000\n",
      "31/31 - 0s - loss: 5.7769 - mae: 1.7734 - val_loss: 12.7213 - val_mae: 3.5514 - 50ms/epoch - 2ms/step\n",
      "Epoch 1536/5000\n",
      "31/31 - 0s - loss: 1.2026 - mae: 0.7761 - val_loss: 0.1189 - val_mae: 0.3022 - 38ms/epoch - 1ms/step\n",
      "Epoch 1537/5000\n",
      "31/31 - 0s - loss: 9.0941 - mae: 1.7827 - val_loss: 0.4881 - val_mae: 0.6186 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1538/5000\n",
      "31/31 - 0s - loss: 12.9276 - mae: 2.1982 - val_loss: 1.0207 - val_mae: 0.9507 - 37ms/epoch - 1ms/step\n",
      "Epoch 1539/5000\n",
      "31/31 - 0s - loss: 2.4840 - mae: 1.3399 - val_loss: 0.5546 - val_mae: 0.6662 - 38ms/epoch - 1ms/step\n",
      "Epoch 1540/5000\n",
      "31/31 - 0s - loss: 20.6782 - mae: 2.2114 - val_loss: 0.1786 - val_mae: 0.3200 - 37ms/epoch - 1ms/step\n",
      "Epoch 1541/5000\n",
      "31/31 - 0s - loss: 1.4964 - mae: 0.9281 - val_loss: 0.7066 - val_mae: 0.7763 - 37ms/epoch - 1ms/step\n",
      "Epoch 1542/5000\n",
      "31/31 - 0s - loss: 6.3707 - mae: 1.9857 - val_loss: 0.3694 - val_mae: 0.5063 - 39ms/epoch - 1ms/step\n",
      "Epoch 1543/5000\n",
      "31/31 - 0s - loss: 8.0617 - mae: 1.5146 - val_loss: 43.1542 - val_mae: 6.5616 - 37ms/epoch - 1ms/step\n",
      "Epoch 1544/5000\n",
      "31/31 - 0s - loss: 4.6075 - mae: 1.3353 - val_loss: 0.1060 - val_mae: 0.2846 - 38ms/epoch - 1ms/step\n",
      "Epoch 1545/5000\n",
      "31/31 - 0s - loss: 8.9151 - mae: 1.7838 - val_loss: 17.4186 - val_mae: 4.1619 - 37ms/epoch - 1ms/step\n",
      "Epoch 1546/5000\n",
      "31/31 - 0s - loss: 1.9771 - mae: 1.0955 - val_loss: 5.5703 - val_mae: 2.3384 - 37ms/epoch - 1ms/step\n",
      "Epoch 1547/5000\n",
      "31/31 - 0s - loss: 10.1503 - mae: 2.3802 - val_loss: 5.4334 - val_mae: 2.3057 - 36ms/epoch - 1ms/step\n",
      "Epoch 1548/5000\n",
      "31/31 - 0s - loss: 1.0994 - mae: 0.7778 - val_loss: 0.8364 - val_mae: 0.8528 - 39ms/epoch - 1ms/step\n",
      "Epoch 1549/5000\n",
      "31/31 - 0s - loss: 17.3072 - mae: 2.0259 - val_loss: 15.3434 - val_mae: 3.9048 - 38ms/epoch - 1ms/step\n",
      "Epoch 1550/5000\n",
      "31/31 - 0s - loss: 2.2343 - mae: 0.9678 - val_loss: 1.3786 - val_mae: 1.1267 - 36ms/epoch - 1ms/step\n",
      "Epoch 1551/5000\n",
      "31/31 - 0s - loss: 8.7996 - mae: 1.9862 - val_loss: 0.3070 - val_mae: 0.4453 - 36ms/epoch - 1ms/step\n",
      "Epoch 1552/5000\n",
      "31/31 - 0s - loss: 8.3910 - mae: 1.7362 - val_loss: 2.3543 - val_mae: 1.4979 - 38ms/epoch - 1ms/step\n",
      "Epoch 1553/5000\n",
      "31/31 - 0s - loss: 1.5621 - mae: 0.9630 - val_loss: 0.1240 - val_mae: 0.2915 - 36ms/epoch - 1ms/step\n",
      "Epoch 1554/5000\n",
      "31/31 - 0s - loss: 17.8032 - mae: 2.0862 - val_loss: 1.0883 - val_mae: 0.9908 - 37ms/epoch - 1ms/step\n",
      "Epoch 1555/5000\n",
      "31/31 - 0s - loss: 1.8464 - mae: 1.0768 - val_loss: 0.2256 - val_mae: 0.3591 - 36ms/epoch - 1ms/step\n",
      "Epoch 1556/5000\n",
      "31/31 - 0s - loss: 7.9188 - mae: 1.5964 - val_loss: 0.1723 - val_mae: 0.3111 - 38ms/epoch - 1ms/step\n",
      "Epoch 1557/5000\n",
      "31/31 - 0s - loss: 0.6689 - mae: 0.6551 - val_loss: 1.7025 - val_mae: 1.2640 - 37ms/epoch - 1ms/step\n",
      "Epoch 1558/5000\n",
      "31/31 - 0s - loss: 13.4834 - mae: 1.9480 - val_loss: 0.3856 - val_mae: 0.5282 - 35ms/epoch - 1ms/step\n",
      "Epoch 1559/5000\n",
      "31/31 - 0s - loss: 1.4637 - mae: 0.8542 - val_loss: 15.5590 - val_mae: 3.9275 - 37ms/epoch - 1ms/step\n",
      "Epoch 1560/5000\n",
      "31/31 - 0s - loss: 11.0097 - mae: 1.9058 - val_loss: 3.9583 - val_mae: 1.9624 - 36ms/epoch - 1ms/step\n",
      "Epoch 1561/5000\n",
      "31/31 - 0s - loss: 17.7901 - mae: 2.3704 - val_loss: 0.2697 - val_mae: 0.4509 - 37ms/epoch - 1ms/step\n",
      "Epoch 1562/5000\n",
      "31/31 - 0s - loss: 0.8223 - mae: 0.6910 - val_loss: 0.1757 - val_mae: 0.3145 - 36ms/epoch - 1ms/step\n",
      "Epoch 1563/5000\n",
      "31/31 - 0s - loss: 1.4965 - mae: 0.9612 - val_loss: 0.3008 - val_mae: 0.4514 - 37ms/epoch - 1ms/step\n",
      "Epoch 1564/5000\n",
      "31/31 - 0s - loss: 22.5214 - mae: 2.2561 - val_loss: 2.2596 - val_mae: 1.4676 - 36ms/epoch - 1ms/step\n",
      "Epoch 1565/5000\n",
      "31/31 - 0s - loss: 0.7982 - mae: 0.6886 - val_loss: 3.7566 - val_mae: 1.9105 - 38ms/epoch - 1ms/step\n",
      "Epoch 1566/5000\n",
      "31/31 - 0s - loss: 13.1999 - mae: 1.9662 - val_loss: 1.7751 - val_mae: 1.2937 - 38ms/epoch - 1ms/step\n",
      "Epoch 1567/5000\n",
      "31/31 - 0s - loss: 1.4401 - mae: 0.9056 - val_loss: 4.6580 - val_mae: 2.1338 - 38ms/epoch - 1ms/step\n",
      "Epoch 1568/5000\n",
      "31/31 - 0s - loss: 15.1265 - mae: 2.2772 - val_loss: 0.1425 - val_mae: 0.3369 - 36ms/epoch - 1ms/step\n",
      "Epoch 1569/5000\n",
      "31/31 - 0s - loss: 2.0281 - mae: 1.2848 - val_loss: 107.0325 - val_mae: 10.3406 - 36ms/epoch - 1ms/step\n",
      "Epoch 1570/5000\n",
      "31/31 - 0s - loss: 11.6933 - mae: 1.7171 - val_loss: 0.3680 - val_mae: 0.5111 - 37ms/epoch - 1ms/step\n",
      "Epoch 1571/5000\n",
      "31/31 - 0s - loss: 18.8911 - mae: 1.9986 - val_loss: 13.1434 - val_mae: 3.6108 - 36ms/epoch - 1ms/step\n",
      "Epoch 1572/5000\n",
      "31/31 - 0s - loss: 1.0252 - mae: 0.8004 - val_loss: 0.8213 - val_mae: 0.8459 - 37ms/epoch - 1ms/step\n",
      "Epoch 1573/5000\n",
      "31/31 - 0s - loss: 3.2899 - mae: 1.3040 - val_loss: 0.1870 - val_mae: 0.3820 - 37ms/epoch - 1ms/step\n",
      "Epoch 1574/5000\n",
      "31/31 - 0s - loss: 14.5262 - mae: 1.7792 - val_loss: 0.2870 - val_mae: 0.4605 - 38ms/epoch - 1ms/step\n",
      "Epoch 1575/5000\n",
      "31/31 - 0s - loss: 0.6397 - mae: 0.6995 - val_loss: 2.3217 - val_mae: 1.4863 - 36ms/epoch - 1ms/step\n",
      "Epoch 1576/5000\n",
      "31/31 - 0s - loss: 6.1729 - mae: 1.6648 - val_loss: 0.6875 - val_mae: 0.7622 - 39ms/epoch - 1ms/step\n",
      "Epoch 1577/5000\n",
      "31/31 - 0s - loss: 18.3524 - mae: 2.1509 - val_loss: 0.2878 - val_mae: 0.4267 - 36ms/epoch - 1ms/step\n",
      "Epoch 1578/5000\n",
      "31/31 - 0s - loss: 1.0849 - mae: 0.8053 - val_loss: 0.1831 - val_mae: 0.3193 - 37ms/epoch - 1ms/step\n",
      "Epoch 1579/5000\n",
      "31/31 - 0s - loss: 9.8214 - mae: 1.5915 - val_loss: 0.5715 - val_mae: 0.6728 - 37ms/epoch - 1ms/step\n",
      "Epoch 1580/5000\n",
      "31/31 - 0s - loss: 1.7038 - mae: 1.0032 - val_loss: 0.1312 - val_mae: 0.3244 - 38ms/epoch - 1ms/step\n",
      "Epoch 1581/5000\n",
      "31/31 - 0s - loss: 7.6684 - mae: 1.4916 - val_loss: 0.3791 - val_mae: 0.5140 - 37ms/epoch - 1ms/step\n",
      "Epoch 1582/5000\n",
      "31/31 - 0s - loss: 1.5485 - mae: 0.8570 - val_loss: 0.1404 - val_mae: 0.2909 - 38ms/epoch - 1ms/step\n",
      "Epoch 1583/5000\n",
      "31/31 - 0s - loss: 9.4056 - mae: 1.8066 - val_loss: 2.5155 - val_mae: 1.5517 - 38ms/epoch - 1ms/step\n",
      "Epoch 1584/5000\n",
      "31/31 - 0s - loss: 23.0204 - mae: 2.1512 - val_loss: 0.2378 - val_mae: 0.4286 - 36ms/epoch - 1ms/step\n",
      "Epoch 1585/5000\n",
      "31/31 - 0s - loss: 0.9979 - mae: 0.7950 - val_loss: 0.1111 - val_mae: 0.2896 - 37ms/epoch - 1ms/step\n",
      "Epoch 1586/5000\n",
      "31/31 - 0s - loss: 0.9686 - mae: 0.7493 - val_loss: 1.3961 - val_mae: 1.1363 - 38ms/epoch - 1ms/step\n",
      "Epoch 1587/5000\n",
      "31/31 - 0s - loss: 11.9662 - mae: 2.2370 - val_loss: 10.7810 - val_mae: 3.2667 - 37ms/epoch - 1ms/step\n",
      "Epoch 1588/5000\n",
      "31/31 - 0s - loss: 6.2296 - mae: 1.8898 - val_loss: 25.9515 - val_mae: 5.0823 - 37ms/epoch - 1ms/step\n",
      "Epoch 1589/5000\n",
      "31/31 - 0s - loss: 1.9843 - mae: 0.9242 - val_loss: 5.4414 - val_mae: 2.3089 - 37ms/epoch - 1ms/step\n",
      "Epoch 1590/5000\n",
      "31/31 - 0s - loss: 17.8007 - mae: 1.9815 - val_loss: 0.1121 - val_mae: 0.2923 - 35ms/epoch - 1ms/step\n",
      "Epoch 1591/5000\n",
      "31/31 - 0s - loss: 1.8486 - mae: 1.1415 - val_loss: 0.1110 - val_mae: 0.2918 - 37ms/epoch - 1ms/step\n",
      "Epoch 1592/5000\n",
      "31/31 - 0s - loss: 7.0178 - mae: 2.0067 - val_loss: 2.9128 - val_mae: 1.6725 - 39ms/epoch - 1ms/step\n",
      "Epoch 1593/5000\n",
      "31/31 - 0s - loss: 3.0262 - mae: 1.3150 - val_loss: 0.4190 - val_mae: 0.5581 - 39ms/epoch - 1ms/step\n",
      "Epoch 1594/5000\n",
      "31/31 - 0s - loss: 19.6818 - mae: 1.8424 - val_loss: 0.3408 - val_mae: 0.4717 - 37ms/epoch - 1ms/step\n",
      "Epoch 1595/5000\n",
      "31/31 - 0s - loss: 2.2941 - mae: 1.1967 - val_loss: 0.4389 - val_mae: 0.5729 - 36ms/epoch - 1ms/step\n",
      "Epoch 1596/5000\n",
      "31/31 - 0s - loss: 13.7843 - mae: 1.8901 - val_loss: 0.1442 - val_mae: 0.3407 - 37ms/epoch - 1ms/step\n",
      "Epoch 1597/5000\n",
      "31/31 - 0s - loss: 0.9100 - mae: 0.7430 - val_loss: 4.6680 - val_mae: 2.1342 - 37ms/epoch - 1ms/step\n",
      "Epoch 1598/5000\n",
      "31/31 - 0s - loss: 3.1712 - mae: 1.3147 - val_loss: 0.4112 - val_mae: 0.5519 - 38ms/epoch - 1ms/step\n",
      "Epoch 1599/5000\n",
      "31/31 - 0s - loss: 20.3974 - mae: 2.1240 - val_loss: 0.1450 - val_mae: 0.3411 - 39ms/epoch - 1ms/step\n",
      "Epoch 1600/5000\n",
      "31/31 - 0s - loss: 0.8507 - mae: 0.7677 - val_loss: 0.2434 - val_mae: 0.3703 - 37ms/epoch - 1ms/step\n",
      "Epoch 1601/5000\n",
      "31/31 - 0s - loss: 11.9540 - mae: 2.0541 - val_loss: 1.7455 - val_mae: 1.2742 - 39ms/epoch - 1ms/step\n",
      "Epoch 1602/5000\n",
      "31/31 - 0s - loss: 1.5092 - mae: 1.0719 - val_loss: 1.9609 - val_mae: 1.3607 - 37ms/epoch - 1ms/step\n",
      "Epoch 1603/5000\n",
      "31/31 - 0s - loss: 17.7845 - mae: 2.1441 - val_loss: 0.2990 - val_mae: 0.4389 - 37ms/epoch - 1ms/step\n",
      "Epoch 1604/5000\n",
      "31/31 - 0s - loss: 1.4321 - mae: 0.9842 - val_loss: 1.2585 - val_mae: 1.0701 - 37ms/epoch - 1ms/step\n",
      "Epoch 1605/5000\n",
      "31/31 - 0s - loss: 9.8545 - mae: 1.7417 - val_loss: 10.3081 - val_mae: 3.1913 - 38ms/epoch - 1ms/step\n",
      "Epoch 1606/5000\n",
      "31/31 - 0s - loss: 3.5822 - mae: 1.5058 - val_loss: 0.5721 - val_mae: 0.6773 - 38ms/epoch - 1ms/step\n",
      "Epoch 1607/5000\n",
      "31/31 - 0s - loss: 18.0063 - mae: 2.2490 - val_loss: 0.3627 - val_mae: 0.5043 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1608/5000\n",
      "31/31 - 0s - loss: 1.1837 - mae: 0.9223 - val_loss: 0.5497 - val_mae: 0.6583 - 36ms/epoch - 1ms/step\n",
      "Epoch 1609/5000\n",
      "31/31 - 0s - loss: 6.7663 - mae: 1.7965 - val_loss: 8.2071 - val_mae: 2.8457 - 37ms/epoch - 1ms/step\n",
      "Epoch 1610/5000\n",
      "31/31 - 0s - loss: 1.7954 - mae: 0.9161 - val_loss: 1.2929 - val_mae: 1.0827 - 39ms/epoch - 1ms/step\n",
      "Epoch 1611/5000\n",
      "31/31 - 0s - loss: 8.3851 - mae: 1.8092 - val_loss: 3.6734 - val_mae: 1.8880 - 38ms/epoch - 1ms/step\n",
      "Epoch 1612/5000\n",
      "31/31 - 0s - loss: 7.6016 - mae: 1.3989 - val_loss: 0.7581 - val_mae: 0.8007 - 36ms/epoch - 1ms/step\n",
      "Epoch 1613/5000\n",
      "31/31 - 0s - loss: 1.7073 - mae: 0.9979 - val_loss: 0.1226 - val_mae: 0.2950 - 37ms/epoch - 1ms/step\n",
      "Epoch 1614/5000\n",
      "31/31 - 0s - loss: 13.8266 - mae: 1.9512 - val_loss: 0.4786 - val_mae: 0.6048 - 37ms/epoch - 1ms/step\n",
      "Epoch 1615/5000\n",
      "31/31 - 0s - loss: 0.5260 - mae: 0.5875 - val_loss: 6.8075 - val_mae: 2.5890 - 37ms/epoch - 1ms/step\n",
      "Epoch 1616/5000\n",
      "31/31 - 0s - loss: 31.3237 - mae: 2.3311 - val_loss: 0.1184 - val_mae: 0.2953 - 37ms/epoch - 1ms/step\n",
      "Epoch 1617/5000\n",
      "31/31 - 0s - loss: 1.5593 - mae: 0.9795 - val_loss: 0.1120 - val_mae: 0.2933 - 37ms/epoch - 1ms/step\n",
      "Epoch 1618/5000\n",
      "31/31 - 0s - loss: 5.7546 - mae: 1.6016 - val_loss: 0.4183 - val_mae: 0.5573 - 38ms/epoch - 1ms/step\n",
      "Epoch 1619/5000\n",
      "31/31 - 0s - loss: 2.1891 - mae: 0.9919 - val_loss: 139.4431 - val_mae: 11.8035 - 38ms/epoch - 1ms/step\n",
      "Epoch 1620/5000\n",
      "31/31 - 0s - loss: 12.4143 - mae: 2.0784 - val_loss: 1.6975 - val_mae: 1.2629 - 37ms/epoch - 1ms/step\n",
      "Epoch 1621/5000\n",
      "31/31 - 0s - loss: 12.1400 - mae: 2.0899 - val_loss: 0.2799 - val_mae: 0.4079 - 38ms/epoch - 1ms/step\n",
      "Epoch 1622/5000\n",
      "31/31 - 0s - loss: 0.9578 - mae: 0.7660 - val_loss: 0.7362 - val_mae: 0.7945 - 39ms/epoch - 1ms/step\n",
      "Epoch 1623/5000\n",
      "31/31 - 0s - loss: 13.1217 - mae: 1.9386 - val_loss: 0.3685 - val_mae: 0.5002 - 37ms/epoch - 1ms/step\n",
      "Epoch 1624/5000\n",
      "31/31 - 0s - loss: 1.0562 - mae: 0.8963 - val_loss: 0.2930 - val_mae: 0.4649 - 37ms/epoch - 1ms/step\n",
      "Epoch 1625/5000\n",
      "31/31 - 0s - loss: 9.6253 - mae: 2.1139 - val_loss: 0.1718 - val_mae: 0.3744 - 37ms/epoch - 1ms/step\n",
      "Epoch 1626/5000\n",
      "31/31 - 0s - loss: 2.1793 - mae: 1.1751 - val_loss: 31.0138 - val_mae: 5.5597 - 37ms/epoch - 1ms/step\n",
      "Epoch 1627/5000\n",
      "31/31 - 0s - loss: 9.7309 - mae: 1.9293 - val_loss: 1.2009 - val_mae: 1.0464 - 38ms/epoch - 1ms/step\n",
      "Epoch 1628/5000\n",
      "31/31 - 0s - loss: 7.3004 - mae: 1.4425 - val_loss: 45.0094 - val_mae: 6.7011 - 37ms/epoch - 1ms/step\n",
      "Epoch 1629/5000\n",
      "31/31 - 0s - loss: 3.0393 - mae: 1.0818 - val_loss: 2.2764 - val_mae: 1.4723 - 37ms/epoch - 1ms/step\n",
      "Epoch 1630/5000\n",
      "31/31 - 0s - loss: 7.9666 - mae: 1.5770 - val_loss: 1.5471 - val_mae: 1.1968 - 39ms/epoch - 1ms/step\n",
      "Epoch 1631/5000\n",
      "31/31 - 0s - loss: 1.2249 - mae: 0.9572 - val_loss: 0.1358 - val_mae: 0.2894 - 37ms/epoch - 1ms/step\n",
      "Epoch 1632/5000\n",
      "31/31 - 0s - loss: 11.5201 - mae: 2.1112 - val_loss: 0.7732 - val_mae: 0.8170 - 38ms/epoch - 1ms/step\n",
      "Epoch 1633/5000\n",
      "31/31 - 0s - loss: 1.5289 - mae: 1.0323 - val_loss: 2.7961 - val_mae: 1.6374 - 37ms/epoch - 1ms/step\n",
      "Epoch 1634/5000\n",
      "31/31 - 0s - loss: 9.4399 - mae: 1.7699 - val_loss: 0.1070 - val_mae: 0.2857 - 39ms/epoch - 1ms/step\n",
      "Epoch 1635/5000\n",
      "31/31 - 0s - loss: 10.2494 - mae: 1.8793 - val_loss: 0.2219 - val_mae: 0.4182 - 37ms/epoch - 1ms/step\n",
      "Epoch 1636/5000\n",
      "31/31 - 0s - loss: 1.4889 - mae: 0.8815 - val_loss: 0.1980 - val_mae: 0.3349 - 37ms/epoch - 1ms/step\n",
      "Epoch 1637/5000\n",
      "31/31 - 0s - loss: 28.3298 - mae: 2.3509 - val_loss: 0.2490 - val_mae: 0.4367 - 37ms/epoch - 1ms/step\n",
      "Epoch 1638/5000\n",
      "31/31 - 0s - loss: 1.7276 - mae: 1.1564 - val_loss: 3.3561 - val_mae: 1.8025 - 38ms/epoch - 1ms/step\n",
      "Epoch 1639/5000\n",
      "31/31 - 0s - loss: 0.7851 - mae: 0.7780 - val_loss: 2.5042 - val_mae: 1.5464 - 38ms/epoch - 1ms/step\n",
      "Epoch 1640/5000\n",
      "31/31 - 0s - loss: 12.8787 - mae: 2.3300 - val_loss: 0.6997 - val_mae: 0.7629 - 37ms/epoch - 1ms/step\n",
      "Epoch 1641/5000\n",
      "31/31 - 0s - loss: 3.3689 - mae: 1.4500 - val_loss: 35.2901 - val_mae: 5.9330 - 37ms/epoch - 1ms/step\n",
      "Epoch 1642/5000\n",
      "31/31 - 0s - loss: 20.0241 - mae: 1.9478 - val_loss: 3.0045 - val_mae: 1.7008 - 37ms/epoch - 1ms/step\n",
      "Epoch 1643/5000\n",
      "31/31 - 0s - loss: 6.2930 - mae: 1.7343 - val_loss: 0.1344 - val_mae: 0.2926 - 38ms/epoch - 1ms/step\n",
      "Epoch 1644/5000\n",
      "31/31 - 0s - loss: 1.0062 - mae: 0.7978 - val_loss: 1.0120 - val_mae: 0.9503 - 37ms/epoch - 1ms/step\n",
      "Epoch 1645/5000\n",
      "31/31 - 0s - loss: 28.9798 - mae: 2.2240 - val_loss: 16.0536 - val_mae: 3.9927 - 38ms/epoch - 1ms/step\n",
      "Epoch 1646/5000\n",
      "31/31 - 0s - loss: 2.7406 - mae: 1.3107 - val_loss: 8.7231 - val_mae: 2.9355 - 36ms/epoch - 1ms/step\n",
      "Epoch 1647/5000\n",
      "31/31 - 0s - loss: 1.0986 - mae: 0.7486 - val_loss: 0.2399 - val_mae: 0.4305 - 38ms/epoch - 1ms/step\n",
      "Epoch 1648/5000\n",
      "31/31 - 0s - loss: 21.8579 - mae: 2.0620 - val_loss: 4.4653 - val_mae: 2.0880 - 37ms/epoch - 1ms/step\n",
      "Epoch 1649/5000\n",
      "31/31 - 0s - loss: 2.5803 - mae: 0.9718 - val_loss: 3.0548 - val_mae: 1.7177 - 40ms/epoch - 1ms/step\n",
      "Epoch 1650/5000\n",
      "31/31 - 0s - loss: 12.6058 - mae: 2.0338 - val_loss: 0.4386 - val_mae: 0.5755 - 38ms/epoch - 1ms/step\n",
      "Epoch 1651/5000\n",
      "31/31 - 0s - loss: 2.0753 - mae: 1.0399 - val_loss: 1.5173 - val_mae: 1.1877 - 38ms/epoch - 1ms/step\n",
      "Epoch 1652/5000\n",
      "31/31 - 0s - loss: 9.2370 - mae: 1.6744 - val_loss: 0.5532 - val_mae: 0.6687 - 36ms/epoch - 1ms/step\n",
      "Epoch 1653/5000\n",
      "31/31 - 0s - loss: 1.1837 - mae: 0.9098 - val_loss: 4.4175 - val_mae: 2.0767 - 38ms/epoch - 1ms/step\n",
      "Epoch 1654/5000\n",
      "31/31 - 0s - loss: 8.7051 - mae: 2.0554 - val_loss: 1.2883 - val_mae: 1.0888 - 37ms/epoch - 1ms/step\n",
      "Epoch 1655/5000\n",
      "31/31 - 0s - loss: 1.0195 - mae: 0.8175 - val_loss: 0.6948 - val_mae: 0.7628 - 35ms/epoch - 1ms/step\n",
      "Epoch 1656/5000\n",
      "31/31 - 0s - loss: 31.1754 - mae: 2.3079 - val_loss: 0.2029 - val_mae: 0.3396 - 38ms/epoch - 1ms/step\n",
      "Epoch 1657/5000\n",
      "31/31 - 0s - loss: 1.6954 - mae: 1.0199 - val_loss: 0.4264 - val_mae: 0.5625 - 38ms/epoch - 1ms/step\n",
      "Epoch 1658/5000\n",
      "31/31 - 0s - loss: 12.5447 - mae: 1.7012 - val_loss: 0.5342 - val_mae: 0.6487 - 38ms/epoch - 1ms/step\n",
      "Epoch 1659/5000\n",
      "31/31 - 0s - loss: 1.7527 - mae: 0.9093 - val_loss: 9.3693 - val_mae: 3.0419 - 38ms/epoch - 1ms/step\n",
      "Epoch 1660/5000\n",
      "31/31 - 0s - loss: 13.4466 - mae: 2.1289 - val_loss: 0.7752 - val_mae: 0.8181 - 38ms/epoch - 1ms/step\n",
      "Epoch 1661/5000\n",
      "31/31 - 0s - loss: 2.0427 - mae: 1.0894 - val_loss: 1.0129 - val_mae: 0.9496 - 37ms/epoch - 1ms/step\n",
      "Epoch 1662/5000\n",
      "31/31 - 0s - loss: 5.9752 - mae: 1.6701 - val_loss: 0.1046 - val_mae: 0.2819 - 37ms/epoch - 1ms/step\n",
      "Epoch 1663/5000\n",
      "31/31 - 0s - loss: 5.8020 - mae: 1.5983 - val_loss: 0.7875 - val_mae: 0.8186 - 39ms/epoch - 1ms/step\n",
      "Epoch 1664/5000\n",
      "31/31 - 0s - loss: 2.5568 - mae: 1.3714 - val_loss: 137.5758 - val_mae: 11.7231 - 37ms/epoch - 1ms/step\n",
      "Epoch 1665/5000\n",
      "31/31 - 0s - loss: 13.5653 - mae: 1.9627 - val_loss: 7.3739 - val_mae: 2.6956 - 37ms/epoch - 1ms/step\n",
      "Epoch 1666/5000\n",
      "31/31 - 0s - loss: 1.3449 - mae: 0.9577 - val_loss: 3.9961 - val_mae: 1.9698 - 38ms/epoch - 1ms/step\n",
      "Epoch 1667/5000\n",
      "31/31 - 0s - loss: 20.4487 - mae: 2.0384 - val_loss: 4.4201 - val_mae: 2.0766 - 38ms/epoch - 1ms/step\n",
      "Epoch 1668/5000\n",
      "31/31 - 0s - loss: 2.1506 - mae: 1.2090 - val_loss: 0.8371 - val_mae: 0.8557 - 36ms/epoch - 1ms/step\n",
      "Epoch 1669/5000\n",
      "31/31 - 0s - loss: 23.9825 - mae: 2.0549 - val_loss: 0.1199 - val_mae: 0.2902 - 36ms/epoch - 1ms/step\n",
      "Epoch 1670/5000\n",
      "31/31 - 0s - loss: 1.4599 - mae: 1.0236 - val_loss: 1.0530 - val_mae: 0.9705 - 38ms/epoch - 1ms/step\n",
      "Epoch 1671/5000\n",
      "31/31 - 0s - loss: 8.2381 - mae: 1.7551 - val_loss: 0.3396 - val_mae: 0.4825 - 38ms/epoch - 1ms/step\n",
      "Epoch 1672/5000\n",
      "31/31 - 0s - loss: 5.9208 - mae: 1.3258 - val_loss: 17.4158 - val_mae: 4.1595 - 38ms/epoch - 1ms/step\n",
      "Epoch 1673/5000\n",
      "31/31 - 0s - loss: 5.1649 - mae: 1.0820 - val_loss: 0.1601 - val_mae: 0.3620 - 35ms/epoch - 1ms/step\n",
      "Epoch 1674/5000\n",
      "31/31 - 0s - loss: 21.4221 - mae: 2.0315 - val_loss: 0.2687 - val_mae: 0.4501 - 36ms/epoch - 1ms/step\n",
      "Epoch 1675/5000\n",
      "31/31 - 0s - loss: 1.1655 - mae: 0.8471 - val_loss: 6.5265 - val_mae: 2.5343 - 36ms/epoch - 1ms/step\n",
      "Epoch 1676/5000\n",
      "31/31 - 0s - loss: 1.9351 - mae: 0.9783 - val_loss: 170.4666 - val_mae: 13.0514 - 37ms/epoch - 1ms/step\n",
      "Epoch 1677/5000\n",
      "31/31 - 0s - loss: 13.4252 - mae: 1.8419 - val_loss: 4.6282 - val_mae: 2.1269 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1678/5000\n",
      "31/31 - 0s - loss: 1.3509 - mae: 0.9583 - val_loss: 1.2495 - val_mae: 1.0638 - 36ms/epoch - 1ms/step\n",
      "Epoch 1679/5000\n",
      "31/31 - 0s - loss: 23.2963 - mae: 2.1668 - val_loss: 0.3681 - val_mae: 0.5157 - 38ms/epoch - 1ms/step\n",
      "Epoch 1680/5000\n",
      "31/31 - 0s - loss: 2.2114 - mae: 1.1713 - val_loss: 0.0985 - val_mae: 0.2704 - 36ms/epoch - 1ms/step\n",
      "Epoch 1681/5000\n",
      "31/31 - 0s - loss: 13.2648 - mae: 1.9967 - val_loss: 0.1309 - val_mae: 0.2899 - 34ms/epoch - 1ms/step\n",
      "Epoch 1682/5000\n",
      "31/31 - 0s - loss: 5.8241 - mae: 1.4102 - val_loss: 86.4000 - val_mae: 9.2900 - 35ms/epoch - 1ms/step\n",
      "Epoch 1683/5000\n",
      "31/31 - 0s - loss: 6.7700 - mae: 1.5260 - val_loss: 2.3584 - val_mae: 1.5006 - 36ms/epoch - 1ms/step\n",
      "Epoch 1684/5000\n",
      "31/31 - 0s - loss: 9.8851 - mae: 1.9809 - val_loss: 0.2507 - val_mae: 0.3817 - 37ms/epoch - 1ms/step\n",
      "Epoch 1685/5000\n",
      "31/31 - 0s - loss: 0.9469 - mae: 0.7284 - val_loss: 0.1892 - val_mae: 0.3903 - 38ms/epoch - 1ms/step\n",
      "Epoch 1686/5000\n",
      "31/31 - 0s - loss: 10.2841 - mae: 1.9605 - val_loss: 0.5802 - val_mae: 0.6902 - 37ms/epoch - 1ms/step\n",
      "Epoch 1687/5000\n",
      "31/31 - 0s - loss: 1.1320 - mae: 0.8547 - val_loss: 13.5696 - val_mae: 3.6702 - 42ms/epoch - 1ms/step\n",
      "Epoch 1688/5000\n",
      "31/31 - 0s - loss: 5.7597 - mae: 1.6748 - val_loss: 7.8591 - val_mae: 2.7844 - 36ms/epoch - 1ms/step\n",
      "Epoch 1689/5000\n",
      "31/31 - 0s - loss: 10.4622 - mae: 2.2978 - val_loss: 3.4045 - val_mae: 1.8182 - 35ms/epoch - 1ms/step\n",
      "Epoch 1690/5000\n",
      "31/31 - 0s - loss: 11.0714 - mae: 1.9694 - val_loss: 0.3568 - val_mae: 0.4999 - 36ms/epoch - 1ms/step\n",
      "Epoch 1691/5000\n",
      "31/31 - 0s - loss: 1.9648 - mae: 1.1162 - val_loss: 0.1879 - val_mae: 0.3899 - 36ms/epoch - 1ms/step\n",
      "Epoch 1692/5000\n",
      "31/31 - 0s - loss: 13.8706 - mae: 1.8199 - val_loss: 0.4980 - val_mae: 0.6232 - 36ms/epoch - 1ms/step\n",
      "Epoch 1693/5000\n",
      "31/31 - 0s - loss: 0.7515 - mae: 0.6220 - val_loss: 0.1314 - val_mae: 0.3260 - 37ms/epoch - 1ms/step\n",
      "Epoch 1694/5000\n",
      "31/31 - 0s - loss: 8.7563 - mae: 1.6092 - val_loss: 1.8043 - val_mae: 1.2953 - 35ms/epoch - 1ms/step\n",
      "Epoch 1695/5000\n",
      "31/31 - 0s - loss: 2.5047 - mae: 1.1940 - val_loss: 21.3867 - val_mae: 4.6112 - 36ms/epoch - 1ms/step\n",
      "Epoch 1696/5000\n",
      "31/31 - 0s - loss: 5.1137 - mae: 1.6693 - val_loss: 0.1209 - val_mae: 0.2969 - 36ms/epoch - 1ms/step\n",
      "Epoch 1697/5000\n",
      "31/31 - 0s - loss: 7.1933 - mae: 1.8657 - val_loss: 0.2294 - val_mae: 0.3679 - 37ms/epoch - 1ms/step\n",
      "Epoch 1698/5000\n",
      "31/31 - 0s - loss: 28.3307 - mae: 2.7314 - val_loss: 7.4390 - val_mae: 2.7088 - 36ms/epoch - 1ms/step\n",
      "Epoch 1699/5000\n",
      "31/31 - 0s - loss: 3.8175 - mae: 1.4173 - val_loss: 3.2977 - val_mae: 1.7848 - 36ms/epoch - 1ms/step\n",
      "Epoch 1700/5000\n",
      "31/31 - 0s - loss: 11.1640 - mae: 2.0899 - val_loss: 10.8778 - val_mae: 3.2794 - 37ms/epoch - 1ms/step\n",
      "Epoch 1701/5000\n",
      "31/31 - 0s - loss: 1.1828 - mae: 0.7330 - val_loss: 0.3039 - val_mae: 0.4407 - 34ms/epoch - 1ms/step\n",
      "Epoch 1702/5000\n",
      "31/31 - 0s - loss: 9.1901 - mae: 2.2207 - val_loss: 0.2948 - val_mae: 0.4272 - 35ms/epoch - 1ms/step\n",
      "Epoch 1703/5000\n",
      "31/31 - 0s - loss: 1.0110 - mae: 0.8315 - val_loss: 0.9694 - val_mae: 0.9279 - 36ms/epoch - 1ms/step\n",
      "Epoch 1704/5000\n",
      "31/31 - 0s - loss: 20.2555 - mae: 2.1978 - val_loss: 0.4382 - val_mae: 0.5599 - 36ms/epoch - 1ms/step\n",
      "Epoch 1705/5000\n",
      "31/31 - 0s - loss: 1.9364 - mae: 1.1329 - val_loss: 0.3028 - val_mae: 0.4346 - 34ms/epoch - 1ms/step\n",
      "Epoch 1706/5000\n",
      "31/31 - 0s - loss: 9.9232 - mae: 1.8611 - val_loss: 0.4930 - val_mae: 0.6224 - 35ms/epoch - 1ms/step\n",
      "Epoch 1707/5000\n",
      "31/31 - 0s - loss: 1.3965 - mae: 0.8877 - val_loss: 1.1961 - val_mae: 1.0446 - 36ms/epoch - 1ms/step\n",
      "Epoch 1708/5000\n",
      "31/31 - 0s - loss: 9.7983 - mae: 1.8859 - val_loss: 18.1603 - val_mae: 4.2502 - 34ms/epoch - 1ms/step\n",
      "Epoch 1709/5000\n",
      "31/31 - 0s - loss: 1.6513 - mae: 0.9330 - val_loss: 0.6436 - val_mae: 0.7311 - 35ms/epoch - 1ms/step\n",
      "Epoch 1710/5000\n",
      "31/31 - 0s - loss: 22.0401 - mae: 2.1154 - val_loss: 6.9880 - val_mae: 2.6228 - 34ms/epoch - 1ms/step\n",
      "Epoch 1711/5000\n",
      "31/31 - 0s - loss: 2.7725 - mae: 1.2780 - val_loss: 0.3754 - val_mae: 0.5115 - 37ms/epoch - 1ms/step\n",
      "Epoch 1712/5000\n",
      "31/31 - 0s - loss: 4.4809 - mae: 1.4659 - val_loss: 1.5036 - val_mae: 1.1798 - 37ms/epoch - 1ms/step\n",
      "Epoch 1713/5000\n",
      "31/31 - 0s - loss: 3.0278 - mae: 1.0304 - val_loss: 32.0152 - val_mae: 5.6508 - 38ms/epoch - 1ms/step\n",
      "Epoch 1714/5000\n",
      "31/31 - 0s - loss: 14.4976 - mae: 1.7076 - val_loss: 1.2737 - val_mae: 1.0786 - 34ms/epoch - 1ms/step\n",
      "Epoch 1715/5000\n",
      "31/31 - 0s - loss: 0.8981 - mae: 0.7737 - val_loss: 0.7270 - val_mae: 0.7853 - 35ms/epoch - 1ms/step\n",
      "Epoch 1716/5000\n",
      "31/31 - 0s - loss: 18.2368 - mae: 1.9229 - val_loss: 1.9149 - val_mae: 1.3442 - 36ms/epoch - 1ms/step\n",
      "Epoch 1717/5000\n",
      "31/31 - 0s - loss: 1.5403 - mae: 1.0019 - val_loss: 0.6238 - val_mae: 0.7145 - 36ms/epoch - 1ms/step\n",
      "Epoch 1718/5000\n",
      "31/31 - 0s - loss: 9.6233 - mae: 2.2484 - val_loss: 12.3750 - val_mae: 3.5022 - 37ms/epoch - 1ms/step\n",
      "Epoch 1719/5000\n",
      "31/31 - 0s - loss: 6.3649 - mae: 1.9755 - val_loss: 5.1738 - val_mae: 2.2493 - 34ms/epoch - 1ms/step\n",
      "Epoch 1720/5000\n",
      "31/31 - 0s - loss: 1.4300 - mae: 0.9526 - val_loss: 1.8340 - val_mae: 1.3104 - 36ms/epoch - 1ms/step\n",
      "Epoch 1721/5000\n",
      "31/31 - 0s - loss: 39.5879 - mae: 2.1641 - val_loss: 0.2181 - val_mae: 0.4139 - 36ms/epoch - 1ms/step\n",
      "Epoch 1722/5000\n",
      "31/31 - 0s - loss: 0.7011 - mae: 0.6377 - val_loss: 11.9654 - val_mae: 3.4430 - 37ms/epoch - 1ms/step\n",
      "Epoch 1723/5000\n",
      "31/31 - 0s - loss: 1.8880 - mae: 1.0502 - val_loss: 0.2728 - val_mae: 0.4520 - 38ms/epoch - 1ms/step\n",
      "Epoch 1724/5000\n",
      "31/31 - 0s - loss: 12.3352 - mae: 1.8048 - val_loss: 2.4115 - val_mae: 1.5181 - 35ms/epoch - 1ms/step\n",
      "Epoch 1725/5000\n",
      "31/31 - 0s - loss: 1.0759 - mae: 0.9153 - val_loss: 0.1230 - val_mae: 0.3081 - 36ms/epoch - 1ms/step\n",
      "Epoch 1726/5000\n",
      "31/31 - 0s - loss: 16.0093 - mae: 1.9369 - val_loss: 1.0255 - val_mae: 0.9592 - 35ms/epoch - 1ms/step\n",
      "Epoch 1727/5000\n",
      "31/31 - 0s - loss: 2.3289 - mae: 1.0518 - val_loss: 0.7181 - val_mae: 0.7817 - 34ms/epoch - 1ms/step\n",
      "Epoch 1728/5000\n",
      "31/31 - 0s - loss: 6.8876 - mae: 1.6308 - val_loss: 0.3988 - val_mae: 0.5428 - 35ms/epoch - 1ms/step\n",
      "Epoch 1729/5000\n",
      "31/31 - 0s - loss: 1.1249 - mae: 0.7394 - val_loss: 14.3316 - val_mae: 3.7735 - 35ms/epoch - 1ms/step\n",
      "Epoch 1730/5000\n",
      "31/31 - 0s - loss: 17.0952 - mae: 1.8343 - val_loss: 0.1177 - val_mae: 0.3041 - 35ms/epoch - 1ms/step\n",
      "Epoch 1731/5000\n",
      "31/31 - 0s - loss: 0.6232 - mae: 0.6232 - val_loss: 0.7928 - val_mae: 0.8271 - 35ms/epoch - 1ms/step\n",
      "Epoch 1732/5000\n",
      "31/31 - 0s - loss: 24.2822 - mae: 2.4641 - val_loss: 0.7236 - val_mae: 0.7816 - 39ms/epoch - 1ms/step\n",
      "Epoch 1733/5000\n",
      "31/31 - 0s - loss: 1.2558 - mae: 0.8467 - val_loss: 0.4972 - val_mae: 0.6226 - 39ms/epoch - 1ms/step\n",
      "Epoch 1734/5000\n",
      "31/31 - 0s - loss: 16.7854 - mae: 2.1020 - val_loss: 0.6413 - val_mae: 0.7235 - 36ms/epoch - 1ms/step\n",
      "Epoch 1735/5000\n",
      "31/31 - 0s - loss: 0.8744 - mae: 0.7516 - val_loss: 0.4149 - val_mae: 0.5483 - 36ms/epoch - 1ms/step\n",
      "Epoch 1736/5000\n",
      "31/31 - 0s - loss: 18.4583 - mae: 1.9849 - val_loss: 0.1073 - val_mae: 0.2820 - 35ms/epoch - 1ms/step\n",
      "Epoch 1737/5000\n",
      "31/31 - 0s - loss: 1.5056 - mae: 0.8882 - val_loss: 0.4329 - val_mae: 0.5724 - 36ms/epoch - 1ms/step\n",
      "Epoch 1738/5000\n",
      "31/31 - 0s - loss: 12.1678 - mae: 1.9919 - val_loss: 0.2758 - val_mae: 0.4119 - 37ms/epoch - 1ms/step\n",
      "Epoch 1739/5000\n",
      "31/31 - 0s - loss: 0.7373 - mae: 0.6217 - val_loss: 0.7839 - val_mae: 0.8221 - 37ms/epoch - 1ms/step\n",
      "Epoch 1740/5000\n",
      "31/31 - 0s - loss: 22.9530 - mae: 2.0249 - val_loss: 6.9418 - val_mae: 2.6108 - 36ms/epoch - 1ms/step\n",
      "Epoch 1741/5000\n",
      "31/31 - 0s - loss: 1.8394 - mae: 1.0923 - val_loss: 1.8406 - val_mae: 1.3141 - 36ms/epoch - 1ms/step\n",
      "Epoch 1742/5000\n",
      "31/31 - 0s - loss: 2.2674 - mae: 1.1173 - val_loss: 0.7787 - val_mae: 0.8102 - 36ms/epoch - 1ms/step\n",
      "Epoch 1743/5000\n",
      "31/31 - 0s - loss: 8.0610 - mae: 1.7019 - val_loss: 0.9451 - val_mae: 0.9147 - 37ms/epoch - 1ms/step\n",
      "Epoch 1744/5000\n",
      "31/31 - 0s - loss: 15.4577 - mae: 1.9256 - val_loss: 0.1104 - val_mae: 0.2895 - 36ms/epoch - 1ms/step\n",
      "Epoch 1745/5000\n",
      "31/31 - 0s - loss: 0.6985 - mae: 0.6122 - val_loss: 0.1555 - val_mae: 0.2921 - 36ms/epoch - 1ms/step\n",
      "Epoch 1746/5000\n",
      "31/31 - 0s - loss: 13.1402 - mae: 2.0774 - val_loss: 0.4157 - val_mae: 0.5571 - 35ms/epoch - 1ms/step\n",
      "Epoch 1747/5000\n",
      "31/31 - 0s - loss: 0.9048 - mae: 0.7788 - val_loss: 5.4591 - val_mae: 2.3121 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1748/5000\n",
      "31/31 - 0s - loss: 7.9982 - mae: 1.7776 - val_loss: 1.7360 - val_mae: 1.2772 - 37ms/epoch - 1ms/step\n",
      "Epoch 1749/5000\n",
      "31/31 - 0s - loss: 1.9558 - mae: 1.1144 - val_loss: 0.9124 - val_mae: 0.8937 - 35ms/epoch - 1ms/step\n",
      "Epoch 1750/5000\n",
      "31/31 - 0s - loss: 8.2451 - mae: 1.7928 - val_loss: 1.1293 - val_mae: 1.0037 - 37ms/epoch - 1ms/step\n",
      "Epoch 1751/5000\n",
      "31/31 - 0s - loss: 1.2503 - mae: 0.9674 - val_loss: 12.4107 - val_mae: 3.5055 - 37ms/epoch - 1ms/step\n",
      "Epoch 1752/5000\n",
      "31/31 - 0s - loss: 28.3780 - mae: 2.4847 - val_loss: 1.9527 - val_mae: 1.3572 - 37ms/epoch - 1ms/step\n",
      "Epoch 1753/5000\n",
      "31/31 - 0s - loss: 1.3765 - mae: 1.0180 - val_loss: 0.3284 - val_mae: 0.4850 - 37ms/epoch - 1ms/step\n",
      "Epoch 1754/5000\n",
      "31/31 - 0s - loss: 10.5713 - mae: 1.8510 - val_loss: 0.2402 - val_mae: 0.4307 - 37ms/epoch - 1ms/step\n",
      "Epoch 1755/5000\n",
      "31/31 - 0s - loss: 0.4928 - mae: 0.5484 - val_loss: 0.6645 - val_mae: 0.7420 - 35ms/epoch - 1ms/step\n",
      "Epoch 1756/5000\n",
      "31/31 - 0s - loss: 20.5480 - mae: 1.8648 - val_loss: 0.1372 - val_mae: 0.3364 - 37ms/epoch - 1ms/step\n",
      "Epoch 1757/5000\n",
      "31/31 - 0s - loss: 2.0786 - mae: 1.0737 - val_loss: 1.1909 - val_mae: 1.0397 - 36ms/epoch - 1ms/step\n",
      "Epoch 1758/5000\n",
      "31/31 - 0s - loss: 14.0638 - mae: 2.0326 - val_loss: 5.2361 - val_mae: 2.2653 - 36ms/epoch - 1ms/step\n",
      "Epoch 1759/5000\n",
      "31/31 - 0s - loss: 1.0781 - mae: 0.8295 - val_loss: 0.8714 - val_mae: 0.8735 - 35ms/epoch - 1ms/step\n",
      "Epoch 1760/5000\n",
      "31/31 - 0s - loss: 8.8404 - mae: 1.9759 - val_loss: 0.2246 - val_mae: 0.4197 - 37ms/epoch - 1ms/step\n",
      "Epoch 1761/5000\n",
      "31/31 - 0s - loss: 6.8478 - mae: 1.8258 - val_loss: 0.2376 - val_mae: 0.4293 - 37ms/epoch - 1ms/step\n",
      "Epoch 1762/5000\n",
      "31/31 - 0s - loss: 1.6216 - mae: 0.9522 - val_loss: 2.8417 - val_mae: 1.6539 - 35ms/epoch - 1ms/step\n",
      "Epoch 1763/5000\n",
      "31/31 - 0s - loss: 10.8988 - mae: 1.7503 - val_loss: 0.7559 - val_mae: 0.8048 - 36ms/epoch - 1ms/step\n",
      "Epoch 1764/5000\n",
      "31/31 - 0s - loss: 0.8369 - mae: 0.7175 - val_loss: 0.1453 - val_mae: 0.2933 - 38ms/epoch - 1ms/step\n",
      "Epoch 1765/5000\n",
      "31/31 - 0s - loss: 14.5143 - mae: 2.0553 - val_loss: 6.1438 - val_mae: 2.4580 - 35ms/epoch - 1ms/step\n",
      "Epoch 1766/5000\n",
      "31/31 - 0s - loss: 1.9110 - mae: 1.0298 - val_loss: 1.2574 - val_mae: 1.0738 - 34ms/epoch - 1ms/step\n",
      "Epoch 1767/5000\n",
      "31/31 - 0s - loss: 19.0515 - mae: 2.1836 - val_loss: 0.2224 - val_mae: 0.3495 - 36ms/epoch - 1ms/step\n",
      "Epoch 1768/5000\n",
      "31/31 - 0s - loss: 1.4535 - mae: 1.0573 - val_loss: 0.1069 - val_mae: 0.2861 - 37ms/epoch - 1ms/step\n",
      "Epoch 1769/5000\n",
      "31/31 - 0s - loss: 10.2714 - mae: 1.8469 - val_loss: 0.4912 - val_mae: 0.6211 - 34ms/epoch - 1ms/step\n",
      "Epoch 1770/5000\n",
      "31/31 - 0s - loss: 2.5264 - mae: 1.2890 - val_loss: 0.8260 - val_mae: 0.8466 - 36ms/epoch - 1ms/step\n",
      "Epoch 1771/5000\n",
      "31/31 - 0s - loss: 7.7176 - mae: 1.6974 - val_loss: 0.1728 - val_mae: 0.3756 - 37ms/epoch - 1ms/step\n",
      "Epoch 1772/5000\n",
      "31/31 - 0s - loss: 7.0589 - mae: 1.8112 - val_loss: 1.0755 - val_mae: 0.9803 - 37ms/epoch - 1ms/step\n",
      "Epoch 1773/5000\n",
      "31/31 - 0s - loss: 2.5193 - mae: 1.1602 - val_loss: 86.4640 - val_mae: 9.2915 - 36ms/epoch - 1ms/step\n",
      "Epoch 1774/5000\n",
      "31/31 - 0s - loss: 8.7384 - mae: 1.9818 - val_loss: 2.3012 - val_mae: 1.4816 - 35ms/epoch - 1ms/step\n",
      "Epoch 1775/5000\n",
      "31/31 - 0s - loss: 20.4632 - mae: 2.0568 - val_loss: 1.8253 - val_mae: 1.3116 - 37ms/epoch - 1ms/step\n",
      "Epoch 1776/5000\n",
      "31/31 - 0s - loss: 0.8320 - mae: 0.7398 - val_loss: 0.8070 - val_mae: 0.8349 - 38ms/epoch - 1ms/step\n",
      "Epoch 1777/5000\n",
      "31/31 - 0s - loss: 3.2609 - mae: 1.3548 - val_loss: 251.2406 - val_mae: 15.8474 - 38ms/epoch - 1ms/step\n",
      "Epoch 1778/5000\n",
      "31/31 - 0s - loss: 13.0723 - mae: 1.6359 - val_loss: 0.3348 - val_mae: 0.4870 - 36ms/epoch - 1ms/step\n",
      "Epoch 1779/5000\n",
      "31/31 - 0s - loss: 5.7477 - mae: 1.1941 - val_loss: 67.3684 - val_mae: 8.2018 - 39ms/epoch - 1ms/step\n",
      "Epoch 1780/5000\n",
      "31/31 - 0s - loss: 4.2100 - mae: 1.3573 - val_loss: 1.7056 - val_mae: 1.2631 - 40ms/epoch - 1ms/step\n",
      "Epoch 1781/5000\n",
      "31/31 - 0s - loss: 22.1747 - mae: 2.3423 - val_loss: 0.3053 - val_mae: 0.4439 - 36ms/epoch - 1ms/step\n",
      "Epoch 1782/5000\n",
      "31/31 - 0s - loss: 1.1378 - mae: 0.8648 - val_loss: 0.1417 - val_mae: 0.3413 - 37ms/epoch - 1ms/step\n",
      "Epoch 1783/5000\n",
      "31/31 - 0s - loss: 0.7890 - mae: 0.6878 - val_loss: 0.1794 - val_mae: 0.3820 - 40ms/epoch - 1ms/step\n",
      "Epoch 1784/5000\n",
      "31/31 - 0s - loss: 17.7661 - mae: 1.9751 - val_loss: 0.1326 - val_mae: 0.3258 - 37ms/epoch - 1ms/step\n",
      "Epoch 1785/5000\n",
      "31/31 - 0s - loss: 1.1880 - mae: 0.8009 - val_loss: 0.1268 - val_mae: 0.3129 - 36ms/epoch - 1ms/step\n",
      "Epoch 1786/5000\n",
      "31/31 - 0s - loss: 9.2970 - mae: 1.6199 - val_loss: 6.5003 - val_mae: 2.5265 - 36ms/epoch - 1ms/step\n",
      "Epoch 1787/5000\n",
      "31/31 - 0s - loss: 1.6801 - mae: 1.0063 - val_loss: 0.2073 - val_mae: 0.4056 - 38ms/epoch - 1ms/step\n",
      "Epoch 1788/5000\n",
      "31/31 - 0s - loss: 13.6232 - mae: 1.8731 - val_loss: 0.2109 - val_mae: 0.3405 - 38ms/epoch - 1ms/step\n",
      "Epoch 1789/5000\n",
      "31/31 - 0s - loss: 1.8104 - mae: 0.9420 - val_loss: 1.3065 - val_mae: 1.0970 - 37ms/epoch - 1ms/step\n",
      "Epoch 1790/5000\n",
      "31/31 - 0s - loss: 12.9563 - mae: 1.9147 - val_loss: 0.2571 - val_mae: 0.3877 - 48ms/epoch - 2ms/step\n",
      "Epoch 1791/5000\n",
      "31/31 - 0s - loss: 1.6083 - mae: 1.0957 - val_loss: 0.6773 - val_mae: 0.7553 - 38ms/epoch - 1ms/step\n",
      "Epoch 1792/5000\n",
      "31/31 - 0s - loss: 7.3186 - mae: 1.6669 - val_loss: 2.0102 - val_mae: 1.3774 - 39ms/epoch - 1ms/step\n",
      "Epoch 1793/5000\n",
      "31/31 - 0s - loss: 13.2574 - mae: 2.4071 - val_loss: 0.9513 - val_mae: 0.9140 - 40ms/epoch - 1ms/step\n",
      "Epoch 1794/5000\n",
      "31/31 - 0s - loss: 0.7685 - mae: 0.6395 - val_loss: 0.1169 - val_mae: 0.2993 - 51ms/epoch - 2ms/step\n",
      "Epoch 1795/5000\n",
      "31/31 - 0s - loss: 7.9942 - mae: 1.7396 - val_loss: 0.1354 - val_mae: 0.3254 - 42ms/epoch - 1ms/step\n",
      "Epoch 1796/5000\n",
      "31/31 - 0s - loss: 0.4981 - mae: 0.5655 - val_loss: 0.3629 - val_mae: 0.5035 - 41ms/epoch - 1ms/step\n",
      "Epoch 1797/5000\n",
      "31/31 - 0s - loss: 16.6495 - mae: 1.8484 - val_loss: 2.8385 - val_mae: 1.6478 - 44ms/epoch - 1ms/step\n",
      "Epoch 1798/5000\n",
      "31/31 - 0s - loss: 1.7627 - mae: 1.0750 - val_loss: 0.7324 - val_mae: 0.7900 - 41ms/epoch - 1ms/step\n",
      "Epoch 1799/5000\n",
      "31/31 - 0s - loss: 19.9190 - mae: 2.0414 - val_loss: 0.1217 - val_mae: 0.2986 - 40ms/epoch - 1ms/step\n",
      "Epoch 1800/5000\n",
      "31/31 - 0s - loss: 2.7810 - mae: 1.1697 - val_loss: 0.1036 - val_mae: 0.2797 - 41ms/epoch - 1ms/step\n",
      "Epoch 1801/5000\n",
      "31/31 - 0s - loss: 6.9504 - mae: 1.6527 - val_loss: 27.2054 - val_mae: 5.2051 - 46ms/epoch - 1ms/step\n",
      "Epoch 1802/5000\n",
      "31/31 - 0s - loss: 1.2637 - mae: 0.7108 - val_loss: 1.8193 - val_mae: 1.3092 - 42ms/epoch - 1ms/step\n",
      "Epoch 1803/5000\n",
      "31/31 - 0s - loss: 12.2155 - mae: 1.8027 - val_loss: 0.2798 - val_mae: 0.4562 - 50ms/epoch - 2ms/step\n",
      "Epoch 1804/5000\n",
      "31/31 - 0s - loss: 2.1521 - mae: 1.0433 - val_loss: 2.7095 - val_mae: 1.6116 - 41ms/epoch - 1ms/step\n",
      "Epoch 1805/5000\n",
      "31/31 - 0s - loss: 6.8249 - mae: 1.8247 - val_loss: 0.5165 - val_mae: 0.6389 - 41ms/epoch - 1ms/step\n",
      "Epoch 1806/5000\n",
      "31/31 - 0s - loss: 4.3955 - mae: 1.3884 - val_loss: 0.7487 - val_mae: 0.8015 - 45ms/epoch - 1ms/step\n",
      "Epoch 1807/5000\n",
      "31/31 - 0s - loss: 17.4193 - mae: 1.9092 - val_loss: 1.1364 - val_mae: 1.0132 - 44ms/epoch - 1ms/step\n",
      "Epoch 1808/5000\n",
      "31/31 - 0s - loss: 1.5100 - mae: 0.9873 - val_loss: 0.1294 - val_mae: 0.2958 - 45ms/epoch - 1ms/step\n",
      "Epoch 1809/5000\n",
      "31/31 - 0s - loss: 8.0157 - mae: 1.7572 - val_loss: 0.1070 - val_mae: 0.2862 - 57ms/epoch - 2ms/step\n",
      "Epoch 1810/5000\n",
      "31/31 - 0s - loss: 3.4944 - mae: 1.3729 - val_loss: 0.1531 - val_mae: 0.3563 - 47ms/epoch - 2ms/step\n",
      "Epoch 1811/5000\n",
      "31/31 - 0s - loss: 12.1776 - mae: 1.8883 - val_loss: 2.2553 - val_mae: 1.4674 - 42ms/epoch - 1ms/step\n",
      "Epoch 1812/5000\n",
      "31/31 - 0s - loss: 1.0515 - mae: 0.8271 - val_loss: 0.7151 - val_mae: 0.7785 - 43ms/epoch - 1ms/step\n",
      "Epoch 1813/5000\n",
      "31/31 - 0s - loss: 9.8640 - mae: 1.8921 - val_loss: 3.3683 - val_mae: 1.8069 - 50ms/epoch - 2ms/step\n",
      "Epoch 1814/5000\n",
      "31/31 - 0s - loss: 1.4461 - mae: 0.9847 - val_loss: 1.0379 - val_mae: 0.9650 - 47ms/epoch - 2ms/step\n",
      "Epoch 1815/5000\n",
      "31/31 - 0s - loss: 11.8036 - mae: 1.9917 - val_loss: 0.3426 - val_mae: 0.4903 - 45ms/epoch - 1ms/step\n",
      "Epoch 1816/5000\n",
      "31/31 - 0s - loss: 1.7044 - mae: 1.1850 - val_loss: 29.8554 - val_mae: 5.4522 - 45ms/epoch - 1ms/step\n",
      "Epoch 1817/5000\n",
      "31/31 - 0s - loss: 7.2063 - mae: 1.7776 - val_loss: 0.3685 - val_mae: 0.5058 - 45ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1818/5000\n",
      "31/31 - 0s - loss: 17.8962 - mae: 2.1757 - val_loss: 0.4592 - val_mae: 0.5965 - 40ms/epoch - 1ms/step\n",
      "Epoch 1819/5000\n",
      "31/31 - 0s - loss: 0.6434 - mae: 0.5789 - val_loss: 0.7512 - val_mae: 0.8014 - 39ms/epoch - 1ms/step\n",
      "Epoch 1820/5000\n",
      "31/31 - 0s - loss: 0.8470 - mae: 0.7532 - val_loss: 2.7988 - val_mae: 1.6403 - 38ms/epoch - 1ms/step\n",
      "Epoch 1821/5000\n",
      "31/31 - 0s - loss: 18.4657 - mae: 2.0707 - val_loss: 1.5985 - val_mae: 1.2221 - 39ms/epoch - 1ms/step\n",
      "Epoch 1822/5000\n",
      "31/31 - 0s - loss: 0.7799 - mae: 0.7376 - val_loss: 1.3133 - val_mae: 1.0978 - 39ms/epoch - 1ms/step\n",
      "Epoch 1823/5000\n",
      "31/31 - 0s - loss: 26.2239 - mae: 2.1385 - val_loss: 0.4359 - val_mae: 0.5745 - 39ms/epoch - 1ms/step\n",
      "Epoch 1824/5000\n",
      "31/31 - 0s - loss: 1.4656 - mae: 1.0016 - val_loss: 2.0798 - val_mae: 1.4042 - 38ms/epoch - 1ms/step\n",
      "Epoch 1825/5000\n",
      "31/31 - 0s - loss: 3.9888 - mae: 1.5303 - val_loss: 0.5228 - val_mae: 0.6436 - 36ms/epoch - 1ms/step\n",
      "Epoch 1826/5000\n",
      "31/31 - 0s - loss: 11.8739 - mae: 1.9178 - val_loss: 0.4404 - val_mae: 0.5748 - 39ms/epoch - 1ms/step\n",
      "Epoch 1827/5000\n",
      "31/31 - 0s - loss: 1.6687 - mae: 0.8953 - val_loss: 4.9739 - val_mae: 2.2057 - 37ms/epoch - 1ms/step\n",
      "Epoch 1828/5000\n",
      "31/31 - 0s - loss: 11.9716 - mae: 1.9369 - val_loss: 1.0363 - val_mae: 0.9610 - 37ms/epoch - 1ms/step\n",
      "Epoch 1829/5000\n",
      "31/31 - 0s - loss: 2.5742 - mae: 1.1143 - val_loss: 2.1203 - val_mae: 1.4190 - 37ms/epoch - 1ms/step\n",
      "Epoch 1830/5000\n",
      "31/31 - 0s - loss: 21.4615 - mae: 2.2592 - val_loss: 0.6598 - val_mae: 0.7438 - 38ms/epoch - 1ms/step\n",
      "Epoch 1831/5000\n",
      "31/31 - 0s - loss: 1.4209 - mae: 0.7117 - val_loss: 0.3557 - val_mae: 0.5010 - 38ms/epoch - 1ms/step\n",
      "Epoch 1832/5000\n",
      "31/31 - 0s - loss: 19.7359 - mae: 2.1090 - val_loss: 0.4871 - val_mae: 0.6071 - 39ms/epoch - 1ms/step\n",
      "Epoch 1833/5000\n",
      "31/31 - 0s - loss: 1.0551 - mae: 0.7847 - val_loss: 0.1233 - val_mae: 0.3017 - 38ms/epoch - 1ms/step\n",
      "Epoch 1834/5000\n",
      "31/31 - 0s - loss: 1.1778 - mae: 0.9630 - val_loss: 2.8610 - val_mae: 1.6569 - 37ms/epoch - 1ms/step\n",
      "Epoch 1835/5000\n",
      "31/31 - 0s - loss: 14.1532 - mae: 2.2229 - val_loss: 0.4439 - val_mae: 0.5764 - 37ms/epoch - 1ms/step\n",
      "Epoch 1836/5000\n",
      "31/31 - 0s - loss: 2.3843 - mae: 1.2980 - val_loss: 6.6226 - val_mae: 2.5532 - 38ms/epoch - 1ms/step\n",
      "Epoch 1837/5000\n",
      "31/31 - 0s - loss: 8.4681 - mae: 1.9461 - val_loss: 0.7743 - val_mae: 0.8149 - 37ms/epoch - 1ms/step\n",
      "Epoch 1838/5000\n",
      "31/31 - 0s - loss: 0.9996 - mae: 0.8738 - val_loss: 4.2994 - val_mae: 2.0479 - 38ms/epoch - 1ms/step\n",
      "Epoch 1839/5000\n",
      "31/31 - 0s - loss: 17.5874 - mae: 2.2071 - val_loss: 4.6791 - val_mae: 2.1362 - 38ms/epoch - 1ms/step\n",
      "Epoch 1840/5000\n",
      "31/31 - 0s - loss: 1.5704 - mae: 0.9983 - val_loss: 2.9061 - val_mae: 1.6744 - 35ms/epoch - 1ms/step\n",
      "Epoch 1841/5000\n",
      "31/31 - 0s - loss: 15.6832 - mae: 1.8462 - val_loss: 0.4697 - val_mae: 0.5982 - 37ms/epoch - 1ms/step\n",
      "Epoch 1842/5000\n",
      "31/31 - 0s - loss: 1.1406 - mae: 0.9029 - val_loss: 0.3858 - val_mae: 0.5300 - 38ms/epoch - 1ms/step\n",
      "Epoch 1843/5000\n",
      "31/31 - 0s - loss: 4.0567 - mae: 1.3862 - val_loss: 0.3745 - val_mae: 0.5190 - 36ms/epoch - 1ms/step\n",
      "Epoch 1844/5000\n",
      "31/31 - 0s - loss: 7.7549 - mae: 1.5247 - val_loss: 0.2619 - val_mae: 0.4464 - 37ms/epoch - 1ms/step\n",
      "Epoch 1845/5000\n",
      "31/31 - 0s - loss: 1.2394 - mae: 0.9165 - val_loss: 0.4193 - val_mae: 0.5537 - 36ms/epoch - 1ms/step\n",
      "Epoch 1846/5000\n",
      "31/31 - 0s - loss: 15.8550 - mae: 1.7737 - val_loss: 0.6743 - val_mae: 0.7364 - 38ms/epoch - 1ms/step\n",
      "Epoch 1847/5000\n",
      "31/31 - 0s - loss: 2.7819 - mae: 1.3386 - val_loss: 6.9958 - val_mae: 2.6236 - 36ms/epoch - 1ms/step\n",
      "Epoch 1848/5000\n",
      "31/31 - 0s - loss: 1.3585 - mae: 0.8549 - val_loss: 180.3010 - val_mae: 13.4243 - 36ms/epoch - 1ms/step\n",
      "Epoch 1849/5000\n",
      "31/31 - 0s - loss: 8.5390 - mae: 1.8179 - val_loss: 0.3068 - val_mae: 0.4734 - 36ms/epoch - 1ms/step\n",
      "Epoch 1850/5000\n",
      "31/31 - 0s - loss: 8.6713 - mae: 2.1549 - val_loss: 0.1320 - val_mae: 0.3040 - 37ms/epoch - 1ms/step\n",
      "Epoch 1851/5000\n",
      "31/31 - 0s - loss: 2.3463 - mae: 1.2160 - val_loss: 3.0400 - val_mae: 1.7151 - 37ms/epoch - 1ms/step\n",
      "Epoch 1852/5000\n",
      "31/31 - 0s - loss: 23.4516 - mae: 2.5391 - val_loss: 0.1171 - val_mae: 0.2831 - 37ms/epoch - 1ms/step\n",
      "Epoch 1853/5000\n",
      "31/31 - 0s - loss: 1.6623 - mae: 1.1352 - val_loss: 0.4612 - val_mae: 0.5949 - 36ms/epoch - 1ms/step\n",
      "Epoch 1854/5000\n",
      "31/31 - 0s - loss: 21.5054 - mae: 2.3485 - val_loss: 0.6622 - val_mae: 0.7382 - 39ms/epoch - 1ms/step\n",
      "Epoch 1855/5000\n",
      "31/31 - 0s - loss: 2.4608 - mae: 1.2097 - val_loss: 1.8817 - val_mae: 1.3301 - 37ms/epoch - 1ms/step\n",
      "Epoch 1856/5000\n",
      "31/31 - 0s - loss: 7.3312 - mae: 2.2300 - val_loss: 1.0085 - val_mae: 0.9505 - 39ms/epoch - 1ms/step\n",
      "Epoch 1857/5000\n",
      "31/31 - 0s - loss: 1.3267 - mae: 0.9359 - val_loss: 0.2612 - val_mae: 0.4443 - 35ms/epoch - 1ms/step\n",
      "Epoch 1858/5000\n",
      "31/31 - 0s - loss: 16.3246 - mae: 2.2631 - val_loss: 1.0495 - val_mae: 0.9594 - 38ms/epoch - 1ms/step\n",
      "Epoch 1859/5000\n",
      "31/31 - 0s - loss: 2.4992 - mae: 1.2251 - val_loss: 0.1411 - val_mae: 0.3342 - 37ms/epoch - 1ms/step\n",
      "Epoch 1860/5000\n",
      "31/31 - 0s - loss: 22.6097 - mae: 2.0252 - val_loss: 0.7493 - val_mae: 0.7931 - 39ms/epoch - 1ms/step\n",
      "Epoch 1861/5000\n",
      "31/31 - 0s - loss: 1.5822 - mae: 1.0332 - val_loss: 0.1814 - val_mae: 0.3187 - 38ms/epoch - 1ms/step\n",
      "Epoch 1862/5000\n",
      "31/31 - 0s - loss: 1.7236 - mae: 1.0594 - val_loss: 28.1663 - val_mae: 5.2952 - 38ms/epoch - 1ms/step\n",
      "Epoch 1863/5000\n",
      "31/31 - 0s - loss: 7.9574 - mae: 1.5192 - val_loss: 3.2893 - val_mae: 1.7826 - 37ms/epoch - 1ms/step\n",
      "Epoch 1864/5000\n",
      "31/31 - 0s - loss: 12.8874 - mae: 1.9667 - val_loss: 1.0930 - val_mae: 0.9915 - 36ms/epoch - 1ms/step\n",
      "Epoch 1865/5000\n",
      "31/31 - 0s - loss: 1.1032 - mae: 0.8076 - val_loss: 0.1474 - val_mae: 0.3429 - 37ms/epoch - 1ms/step\n",
      "Epoch 1866/5000\n",
      "31/31 - 0s - loss: 6.6045 - mae: 1.6559 - val_loss: 0.8098 - val_mae: 0.8404 - 38ms/epoch - 1ms/step\n",
      "Epoch 1867/5000\n",
      "31/31 - 0s - loss: 3.4845 - mae: 1.1574 - val_loss: 63.4755 - val_mae: 7.9615 - 37ms/epoch - 1ms/step\n",
      "Epoch 1868/5000\n",
      "31/31 - 0s - loss: 4.6094 - mae: 1.2260 - val_loss: 0.4468 - val_mae: 0.5792 - 37ms/epoch - 1ms/step\n",
      "Epoch 1869/5000\n",
      "31/31 - 0s - loss: 4.8994 - mae: 1.5297 - val_loss: 0.9923 - val_mae: 0.9415 - 38ms/epoch - 1ms/step\n",
      "Epoch 1870/5000\n",
      "31/31 - 0s - loss: 12.2947 - mae: 1.9938 - val_loss: 3.5502 - val_mae: 1.8544 - 37ms/epoch - 1ms/step\n",
      "Epoch 1871/5000\n",
      "31/31 - 0s - loss: 1.5844 - mae: 0.9383 - val_loss: 0.2338 - val_mae: 0.3625 - 37ms/epoch - 1ms/step\n",
      "Epoch 1872/5000\n",
      "31/31 - 0s - loss: 17.3509 - mae: 2.1789 - val_loss: 0.8090 - val_mae: 0.8426 - 37ms/epoch - 1ms/step\n",
      "Epoch 1873/5000\n",
      "31/31 - 0s - loss: 2.6483 - mae: 1.2607 - val_loss: 7.4795 - val_mae: 2.7146 - 37ms/epoch - 1ms/step\n",
      "Epoch 1874/5000\n",
      "31/31 - 0s - loss: 11.6722 - mae: 1.9128 - val_loss: 1.2139 - val_mae: 1.0511 - 36ms/epoch - 1ms/step\n",
      "Epoch 1875/5000\n",
      "31/31 - 0s - loss: 2.8492 - mae: 1.2686 - val_loss: 0.1498 - val_mae: 0.2938 - 36ms/epoch - 1ms/step\n",
      "Epoch 1876/5000\n",
      "31/31 - 0s - loss: 0.7602 - mae: 0.6344 - val_loss: 23.7388 - val_mae: 4.8593 - 37ms/epoch - 1ms/step\n",
      "Epoch 1877/5000\n",
      "31/31 - 0s - loss: 25.3808 - mae: 2.1834 - val_loss: 0.4784 - val_mae: 0.6101 - 37ms/epoch - 1ms/step\n",
      "Epoch 1878/5000\n",
      "31/31 - 0s - loss: 1.5577 - mae: 0.8672 - val_loss: 0.1708 - val_mae: 0.3745 - 38ms/epoch - 1ms/step\n",
      "Epoch 1879/5000\n",
      "31/31 - 0s - loss: 23.9316 - mae: 1.8395 - val_loss: 1.4332 - val_mae: 1.1549 - 36ms/epoch - 1ms/step\n",
      "Epoch 1880/5000\n",
      "31/31 - 0s - loss: 3.6402 - mae: 1.5469 - val_loss: 0.2156 - val_mae: 0.4126 - 35ms/epoch - 1ms/step\n",
      "Epoch 1881/5000\n",
      "31/31 - 0s - loss: 7.9181 - mae: 1.7862 - val_loss: 1.1117 - val_mae: 1.0002 - 37ms/epoch - 1ms/step\n",
      "Epoch 1882/5000\n",
      "31/31 - 0s - loss: 2.0471 - mae: 1.0391 - val_loss: 2.1991 - val_mae: 1.4467 - 36ms/epoch - 1ms/step\n",
      "Epoch 1883/5000\n",
      "31/31 - 0s - loss: 4.2638 - mae: 1.5938 - val_loss: 0.1622 - val_mae: 0.2997 - 39ms/epoch - 1ms/step\n",
      "Epoch 1884/5000\n",
      "31/31 - 0s - loss: 14.2888 - mae: 1.7851 - val_loss: 3.4577 - val_mae: 1.8302 - 37ms/epoch - 1ms/step\n",
      "Epoch 1885/5000\n",
      "31/31 - 0s - loss: 1.1553 - mae: 0.7979 - val_loss: 14.7174 - val_mae: 3.8231 - 38ms/epoch - 1ms/step\n",
      "Epoch 1886/5000\n",
      "31/31 - 0s - loss: 6.4208 - mae: 1.7987 - val_loss: 0.5479 - val_mae: 0.6621 - 37ms/epoch - 1ms/step\n",
      "Epoch 1887/5000\n",
      "31/31 - 0s - loss: 43.5103 - mae: 2.5993 - val_loss: 0.1567 - val_mae: 0.3596 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888/5000\n",
      "31/31 - 0s - loss: 2.4880 - mae: 1.2637 - val_loss: 11.7126 - val_mae: 3.4078 - 37ms/epoch - 1ms/step\n",
      "Epoch 1889/5000\n",
      "31/31 - 0s - loss: 1.7862 - mae: 1.0677 - val_loss: 16.3020 - val_mae: 4.0224 - 38ms/epoch - 1ms/step\n",
      "Epoch 1890/5000\n",
      "31/31 - 0s - loss: 1.6525 - mae: 0.9076 - val_loss: 0.8607 - val_mae: 0.8702 - 38ms/epoch - 1ms/step\n",
      "Epoch 1891/5000\n",
      "31/31 - 0s - loss: 25.3069 - mae: 2.4156 - val_loss: 5.3894 - val_mae: 2.2998 - 35ms/epoch - 1ms/step\n",
      "Epoch 1892/5000\n",
      "31/31 - 0s - loss: 1.8066 - mae: 1.0113 - val_loss: 0.2610 - val_mae: 0.4443 - 38ms/epoch - 1ms/step\n",
      "Epoch 1893/5000\n",
      "31/31 - 0s - loss: 6.6294 - mae: 1.7316 - val_loss: 2.6595 - val_mae: 1.5976 - 37ms/epoch - 1ms/step\n",
      "Epoch 1894/5000\n",
      "31/31 - 0s - loss: 2.1086 - mae: 1.1862 - val_loss: 1.0528 - val_mae: 0.9723 - 37ms/epoch - 1ms/step\n",
      "Epoch 1895/5000\n",
      "31/31 - 0s - loss: 12.6986 - mae: 2.0064 - val_loss: 0.4438 - val_mae: 0.5793 - 37ms/epoch - 1ms/step\n",
      "Epoch 1896/5000\n",
      "31/31 - 0s - loss: 1.4193 - mae: 1.0561 - val_loss: 0.1192 - val_mae: 0.3007 - 36ms/epoch - 1ms/step\n",
      "Epoch 1897/5000\n",
      "31/31 - 0s - loss: 5.4595 - mae: 1.5738 - val_loss: 1.1764 - val_mae: 1.0320 - 35ms/epoch - 1ms/step\n",
      "Epoch 1898/5000\n",
      "31/31 - 0s - loss: 3.5826 - mae: 1.4605 - val_loss: 1.5201 - val_mae: 1.1904 - 37ms/epoch - 1ms/step\n",
      "Epoch 1899/5000\n",
      "31/31 - 0s - loss: 24.2667 - mae: 2.1219 - val_loss: 10.7388 - val_mae: 3.2617 - 38ms/epoch - 1ms/step\n",
      "Epoch 1900/5000\n",
      "31/31 - 0s - loss: 1.6226 - mae: 1.0019 - val_loss: 4.2099 - val_mae: 2.0232 - 37ms/epoch - 1ms/step\n",
      "Epoch 1901/5000\n",
      "31/31 - 0s - loss: 9.6384 - mae: 1.5946 - val_loss: 32.9881 - val_mae: 5.7340 - 37ms/epoch - 1ms/step\n",
      "Epoch 1902/5000\n",
      "31/31 - 0s - loss: 5.8759 - mae: 1.3671 - val_loss: 3.9874 - val_mae: 1.9704 - 35ms/epoch - 1ms/step\n",
      "Epoch 1903/5000\n",
      "31/31 - 0s - loss: 21.8059 - mae: 2.1673 - val_loss: 0.2102 - val_mae: 0.3437 - 36ms/epoch - 1ms/step\n",
      "Epoch 1904/5000\n",
      "31/31 - 0s - loss: 1.0609 - mae: 0.7592 - val_loss: 0.3392 - val_mae: 0.4894 - 36ms/epoch - 1ms/step\n",
      "Epoch 1905/5000\n",
      "31/31 - 0s - loss: 10.4654 - mae: 1.6556 - val_loss: 11.2343 - val_mae: 3.3350 - 36ms/epoch - 1ms/step\n",
      "Epoch 1906/5000\n",
      "31/31 - 0s - loss: 2.5419 - mae: 1.1360 - val_loss: 3.3202 - val_mae: 1.7926 - 37ms/epoch - 1ms/step\n",
      "Epoch 1907/5000\n",
      "31/31 - 0s - loss: 20.6792 - mae: 2.1109 - val_loss: 0.4622 - val_mae: 0.5882 - 36ms/epoch - 1ms/step\n",
      "Epoch 1908/5000\n",
      "31/31 - 0s - loss: 1.0090 - mae: 0.7922 - val_loss: 0.1915 - val_mae: 0.3313 - 36ms/epoch - 1ms/step\n",
      "Epoch 1909/5000\n",
      "31/31 - 0s - loss: 1.8962 - mae: 1.0604 - val_loss: 5.2003 - val_mae: 2.2590 - 35ms/epoch - 1ms/step\n",
      "Epoch 1910/5000\n",
      "31/31 - 0s - loss: 11.6509 - mae: 1.9327 - val_loss: 0.3483 - val_mae: 0.4931 - 37ms/epoch - 1ms/step\n",
      "Epoch 1911/5000\n",
      "31/31 - 0s - loss: 2.5573 - mae: 1.3033 - val_loss: 0.4246 - val_mae: 0.5612 - 36ms/epoch - 1ms/step\n",
      "Epoch 1912/5000\n",
      "31/31 - 0s - loss: 24.2451 - mae: 2.2399 - val_loss: 0.5747 - val_mae: 0.6768 - 37ms/epoch - 1ms/step\n",
      "Epoch 1913/5000\n",
      "31/31 - 0s - loss: 1.8668 - mae: 1.0480 - val_loss: 0.9894 - val_mae: 0.9397 - 36ms/epoch - 1ms/step\n",
      "Epoch 1914/5000\n",
      "31/31 - 0s - loss: 0.9161 - mae: 0.7421 - val_loss: 0.9066 - val_mae: 0.8829 - 37ms/epoch - 1ms/step\n",
      "Epoch 1915/5000\n",
      "31/31 - 0s - loss: 27.8771 - mae: 2.5133 - val_loss: 12.3847 - val_mae: 3.5044 - 36ms/epoch - 1ms/step\n",
      "Epoch 1916/5000\n",
      "31/31 - 0s - loss: 1.3695 - mae: 0.8910 - val_loss: 0.1960 - val_mae: 0.3968 - 36ms/epoch - 1ms/step\n",
      "Epoch 1917/5000\n",
      "31/31 - 0s - loss: 12.1954 - mae: 2.1865 - val_loss: 1.4339 - val_mae: 1.1508 - 37ms/epoch - 1ms/step\n",
      "Epoch 1918/5000\n",
      "31/31 - 0s - loss: 3.0268 - mae: 1.2412 - val_loss: 0.2297 - val_mae: 0.3571 - 35ms/epoch - 1ms/step\n",
      "Epoch 1919/5000\n",
      "31/31 - 0s - loss: 6.1570 - mae: 1.8245 - val_loss: 2.4008 - val_mae: 1.5122 - 34ms/epoch - 1ms/step\n",
      "Epoch 1920/5000\n",
      "31/31 - 0s - loss: 22.9988 - mae: 2.5713 - val_loss: 0.1217 - val_mae: 0.3044 - 34ms/epoch - 1ms/step\n",
      "Epoch 1921/5000\n",
      "31/31 - 0s - loss: 1.4103 - mae: 0.8516 - val_loss: 0.1063 - val_mae: 0.2833 - 34ms/epoch - 1ms/step\n",
      "Epoch 1922/5000\n",
      "31/31 - 0s - loss: 1.3116 - mae: 0.8762 - val_loss: 0.9534 - val_mae: 0.9206 - 35ms/epoch - 1ms/step\n",
      "Epoch 1923/5000\n",
      "31/31 - 0s - loss: 16.9725 - mae: 2.0307 - val_loss: 1.8102 - val_mae: 1.3019 - 35ms/epoch - 1ms/step\n",
      "Epoch 1924/5000\n",
      "31/31 - 0s - loss: 1.3809 - mae: 0.7790 - val_loss: 1.0271 - val_mae: 0.9596 - 34ms/epoch - 1ms/step\n",
      "Epoch 1925/5000\n",
      "31/31 - 0s - loss: 13.9912 - mae: 2.2679 - val_loss: 0.6315 - val_mae: 0.7281 - 36ms/epoch - 1ms/step\n",
      "Epoch 1926/5000\n",
      "31/31 - 0s - loss: 1.3834 - mae: 0.9792 - val_loss: 0.1042 - val_mae: 0.2791 - 35ms/epoch - 1ms/step\n",
      "Epoch 1927/5000\n",
      "31/31 - 0s - loss: 26.7860 - mae: 2.7437 - val_loss: 1.2365 - val_mae: 1.0624 - 34ms/epoch - 1ms/step\n",
      "Epoch 1928/5000\n",
      "31/31 - 0s - loss: 3.0417 - mae: 1.4106 - val_loss: 20.9553 - val_mae: 4.5648 - 36ms/epoch - 1ms/step\n",
      "Epoch 1929/5000\n",
      "31/31 - 0s - loss: 2.3171 - mae: 0.8757 - val_loss: 1.9662 - val_mae: 1.3639 - 35ms/epoch - 1ms/step\n",
      "Epoch 1930/5000\n",
      "31/31 - 0s - loss: 15.3932 - mae: 1.8436 - val_loss: 2.7442 - val_mae: 1.6229 - 35ms/epoch - 1ms/step\n",
      "Epoch 1931/5000\n",
      "31/31 - 0s - loss: 2.4588 - mae: 1.3387 - val_loss: 4.9167 - val_mae: 2.1934 - 35ms/epoch - 1ms/step\n",
      "Epoch 1932/5000\n",
      "31/31 - 0s - loss: 17.9556 - mae: 2.1605 - val_loss: 1.4419 - val_mae: 1.1568 - 35ms/epoch - 1ms/step\n",
      "Epoch 1933/5000\n",
      "31/31 - 0s - loss: 2.2864 - mae: 1.1403 - val_loss: 3.8656 - val_mae: 1.9385 - 36ms/epoch - 1ms/step\n",
      "Epoch 1934/5000\n",
      "31/31 - 0s - loss: 1.4443 - mae: 0.9368 - val_loss: 1.6517 - val_mae: 1.2425 - 35ms/epoch - 1ms/step\n",
      "Epoch 1935/5000\n",
      "31/31 - 0s - loss: 29.0637 - mae: 2.2820 - val_loss: 0.8183 - val_mae: 0.8449 - 35ms/epoch - 1ms/step\n",
      "Epoch 1936/5000\n",
      "31/31 - 0s - loss: 1.7423 - mae: 1.0159 - val_loss: 0.2777 - val_mae: 0.4135 - 34ms/epoch - 1ms/step\n",
      "Epoch 1937/5000\n",
      "31/31 - 0s - loss: 15.9846 - mae: 1.8854 - val_loss: 0.4692 - val_mae: 0.6045 - 36ms/epoch - 1ms/step\n",
      "Epoch 1938/5000\n",
      "31/31 - 0s - loss: 1.1558 - mae: 0.7956 - val_loss: 0.5150 - val_mae: 0.6410 - 36ms/epoch - 1ms/step\n",
      "Epoch 1939/5000\n",
      "31/31 - 0s - loss: 31.4526 - mae: 2.2039 - val_loss: 1.3560 - val_mae: 1.1222 - 34ms/epoch - 1ms/step\n",
      "Epoch 1940/5000\n",
      "31/31 - 0s - loss: 2.0105 - mae: 0.8565 - val_loss: 0.5105 - val_mae: 0.6367 - 34ms/epoch - 1ms/step\n",
      "Epoch 1941/5000\n",
      "31/31 - 0s - loss: 4.3190 - mae: 1.3289 - val_loss: 42.2121 - val_mae: 6.4891 - 37ms/epoch - 1ms/step\n",
      "Epoch 1942/5000\n",
      "31/31 - 0s - loss: 9.1428 - mae: 1.4487 - val_loss: 4.2652 - val_mae: 2.0386 - 35ms/epoch - 1ms/step\n",
      "Epoch 1943/5000\n",
      "31/31 - 0s - loss: 0.8330 - mae: 0.7540 - val_loss: 1.9901 - val_mae: 1.3703 - 36ms/epoch - 1ms/step\n",
      "Epoch 1944/5000\n",
      "31/31 - 0s - loss: 28.5986 - mae: 2.4772 - val_loss: 3.0052 - val_mae: 1.7024 - 34ms/epoch - 1ms/step\n",
      "Epoch 1945/5000\n",
      "31/31 - 0s - loss: 2.6381 - mae: 1.2329 - val_loss: 0.1891 - val_mae: 0.3906 - 47ms/epoch - 2ms/step\n",
      "Epoch 1946/5000\n",
      "31/31 - 0s - loss: 12.1517 - mae: 1.9949 - val_loss: 0.3708 - val_mae: 0.5076 - 37ms/epoch - 1ms/step\n",
      "Epoch 1947/5000\n",
      "31/31 - 0s - loss: 1.3728 - mae: 0.9547 - val_loss: 0.7934 - val_mae: 0.8291 - 38ms/epoch - 1ms/step\n",
      "Epoch 1948/5000\n",
      "31/31 - 0s - loss: 12.2125 - mae: 1.8099 - val_loss: 4.2599 - val_mae: 2.0382 - 38ms/epoch - 1ms/step\n",
      "Epoch 1949/5000\n",
      "31/31 - 0s - loss: 1.5063 - mae: 1.0011 - val_loss: 0.4103 - val_mae: 0.5507 - 36ms/epoch - 1ms/step\n",
      "Epoch 1950/5000\n",
      "31/31 - 0s - loss: 8.7158 - mae: 1.7247 - val_loss: 0.1799 - val_mae: 0.3121 - 36ms/epoch - 1ms/step\n",
      "Epoch 1951/5000\n",
      "31/31 - 0s - loss: 2.8295 - mae: 1.3451 - val_loss: 0.3261 - val_mae: 0.4675 - 37ms/epoch - 1ms/step\n",
      "Epoch 1952/5000\n",
      "31/31 - 0s - loss: 7.0062 - mae: 1.7804 - val_loss: 0.8748 - val_mae: 0.8727 - 37ms/epoch - 1ms/step\n",
      "Epoch 1953/5000\n",
      "31/31 - 0s - loss: 18.4958 - mae: 2.2705 - val_loss: 0.9481 - val_mae: 0.9148 - 37ms/epoch - 1ms/step\n",
      "Epoch 1954/5000\n",
      "31/31 - 0s - loss: 2.0358 - mae: 1.0993 - val_loss: 0.7879 - val_mae: 0.8250 - 35ms/epoch - 1ms/step\n",
      "Epoch 1955/5000\n",
      "31/31 - 0s - loss: 5.8484 - mae: 1.2103 - val_loss: 406.7958 - val_mae: 20.1668 - 35ms/epoch - 1ms/step\n",
      "Epoch 1956/5000\n",
      "31/31 - 0s - loss: 14.6542 - mae: 1.6480 - val_loss: 0.1178 - val_mae: 0.3001 - 38ms/epoch - 1ms/step\n",
      "Epoch 1957/5000\n",
      "31/31 - 0s - loss: 5.2490 - mae: 1.7060 - val_loss: 2.1550 - val_mae: 1.4309 - 40ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1958/5000\n",
      "31/31 - 0s - loss: 22.0711 - mae: 2.2421 - val_loss: 2.1364 - val_mae: 1.4205 - 36ms/epoch - 1ms/step\n",
      "Epoch 1959/5000\n",
      "31/31 - 0s - loss: 1.7220 - mae: 1.1294 - val_loss: 0.5194 - val_mae: 0.6383 - 36ms/epoch - 1ms/step\n",
      "Epoch 1960/5000\n",
      "31/31 - 0s - loss: 5.1031 - mae: 1.6667 - val_loss: 8.5613 - val_mae: 2.9073 - 37ms/epoch - 1ms/step\n",
      "Epoch 1961/5000\n",
      "31/31 - 0s - loss: 1.1490 - mae: 0.7957 - val_loss: 1.1977 - val_mae: 1.0417 - 35ms/epoch - 1ms/step\n",
      "Epoch 1962/5000\n",
      "31/31 - 0s - loss: 7.0613 - mae: 1.8310 - val_loss: 0.1325 - val_mae: 0.2873 - 37ms/epoch - 1ms/step\n",
      "Epoch 1963/5000\n",
      "31/31 - 0s - loss: 11.8990 - mae: 2.0369 - val_loss: 0.1175 - val_mae: 0.3082 - 37ms/epoch - 1ms/step\n",
      "Epoch 1964/5000\n",
      "31/31 - 0s - loss: 0.9704 - mae: 0.7670 - val_loss: 2.8764 - val_mae: 1.6671 - 37ms/epoch - 1ms/step\n",
      "Epoch 1965/5000\n",
      "31/31 - 0s - loss: 17.6328 - mae: 2.2912 - val_loss: 0.1202 - val_mae: 0.2831 - 36ms/epoch - 1ms/step\n",
      "Epoch 1966/5000\n",
      "31/31 - 0s - loss: 1.2237 - mae: 0.9415 - val_loss: 1.7496 - val_mae: 1.2812 - 36ms/epoch - 1ms/step\n",
      "Epoch 1967/5000\n",
      "31/31 - 0s - loss: 12.1558 - mae: 2.0287 - val_loss: 0.1156 - val_mae: 0.2924 - 37ms/epoch - 1ms/step\n",
      "Epoch 1968/5000\n",
      "31/31 - 0s - loss: 0.6912 - mae: 0.6489 - val_loss: 0.7298 - val_mae: 0.7864 - 38ms/epoch - 1ms/step\n",
      "Epoch 1969/5000\n",
      "31/31 - 0s - loss: 18.0653 - mae: 2.1240 - val_loss: 0.3378 - val_mae: 0.4882 - 37ms/epoch - 1ms/step\n",
      "Epoch 1970/5000\n",
      "31/31 - 0s - loss: 1.0611 - mae: 0.7923 - val_loss: 0.2875 - val_mae: 0.4281 - 35ms/epoch - 1ms/step\n",
      "Epoch 1971/5000\n",
      "31/31 - 0s - loss: 5.5275 - mae: 1.4143 - val_loss: 0.3666 - val_mae: 0.5108 - 38ms/epoch - 1ms/step\n",
      "Epoch 1972/5000\n",
      "31/31 - 0s - loss: 0.5977 - mae: 0.6058 - val_loss: 7.3329 - val_mae: 2.6866 - 35ms/epoch - 1ms/step\n",
      "Epoch 1973/5000\n",
      "31/31 - 0s - loss: 14.6309 - mae: 1.8371 - val_loss: 4.3416 - val_mae: 2.0573 - 40ms/epoch - 1ms/step\n",
      "Epoch 1974/5000\n",
      "31/31 - 0s - loss: 13.0836 - mae: 1.9286 - val_loss: 75.6506 - val_mae: 8.6906 - 47ms/epoch - 2ms/step\n",
      "Epoch 1975/5000\n",
      "31/31 - 0s - loss: 4.2716 - mae: 1.3541 - val_loss: 0.1093 - val_mae: 0.2895 - 45ms/epoch - 1ms/step\n",
      "Epoch 1976/5000\n",
      "31/31 - 0s - loss: 5.0034 - mae: 1.5994 - val_loss: 0.1254 - val_mae: 0.3007 - 37ms/epoch - 1ms/step\n",
      "Epoch 1977/5000\n",
      "31/31 - 0s - loss: 1.1875 - mae: 0.8516 - val_loss: 0.2450 - val_mae: 0.4340 - 38ms/epoch - 1ms/step\n",
      "Epoch 1978/5000\n",
      "31/31 - 0s - loss: 23.4077 - mae: 2.1542 - val_loss: 3.9920 - val_mae: 1.9687 - 47ms/epoch - 2ms/step\n",
      "Epoch 1979/5000\n",
      "31/31 - 0s - loss: 2.0058 - mae: 1.0156 - val_loss: 0.8569 - val_mae: 0.8664 - 40ms/epoch - 1ms/step\n",
      "Epoch 1980/5000\n",
      "31/31 - 0s - loss: 10.8496 - mae: 1.9995 - val_loss: 0.1050 - val_mae: 0.2831 - 38ms/epoch - 1ms/step\n",
      "Epoch 1981/5000\n",
      "31/31 - 0s - loss: 0.5837 - mae: 0.6012 - val_loss: 3.5368 - val_mae: 1.8535 - 38ms/epoch - 1ms/step\n",
      "Epoch 1982/5000\n",
      "31/31 - 0s - loss: 11.5978 - mae: 2.2059 - val_loss: 0.1979 - val_mae: 0.3311 - 39ms/epoch - 1ms/step\n",
      "Epoch 1983/5000\n",
      "31/31 - 0s - loss: 10.5710 - mae: 1.9123 - val_loss: 0.1442 - val_mae: 0.2892 - 38ms/epoch - 1ms/step\n",
      "Epoch 1984/5000\n",
      "31/31 - 0s - loss: 0.7999 - mae: 0.6825 - val_loss: 3.7828 - val_mae: 1.9176 - 35ms/epoch - 1ms/step\n",
      "Epoch 1985/5000\n",
      "31/31 - 0s - loss: 22.6172 - mae: 2.3446 - val_loss: 0.1200 - val_mae: 0.2880 - 37ms/epoch - 1ms/step\n",
      "Epoch 1986/5000\n",
      "31/31 - 0s - loss: 1.4641 - mae: 0.9748 - val_loss: 0.2645 - val_mae: 0.4461 - 37ms/epoch - 1ms/step\n",
      "Epoch 1987/5000\n",
      "31/31 - 0s - loss: 11.3346 - mae: 1.9272 - val_loss: 0.4625 - val_mae: 0.5974 - 38ms/epoch - 1ms/step\n",
      "Epoch 1988/5000\n",
      "31/31 - 0s - loss: 1.0263 - mae: 0.8117 - val_loss: 8.1759 - val_mae: 2.8418 - 37ms/epoch - 1ms/step\n",
      "Epoch 1989/5000\n",
      "31/31 - 0s - loss: 9.5735 - mae: 1.9387 - val_loss: 0.1040 - val_mae: 0.2811 - 37ms/epoch - 1ms/step\n",
      "Epoch 1990/5000\n",
      "31/31 - 0s - loss: 13.4010 - mae: 1.8927 - val_loss: 1.0120 - val_mae: 0.9450 - 39ms/epoch - 1ms/step\n",
      "Epoch 1991/5000\n",
      "31/31 - 0s - loss: 2.2437 - mae: 1.0889 - val_loss: 0.2199 - val_mae: 0.4162 - 37ms/epoch - 1ms/step\n",
      "Epoch 1992/5000\n",
      "31/31 - 0s - loss: 3.7199 - mae: 1.3074 - val_loss: 0.1257 - val_mae: 0.3095 - 38ms/epoch - 1ms/step\n",
      "Epoch 1993/5000\n",
      "31/31 - 0s - loss: 0.9307 - mae: 0.7194 - val_loss: 0.2888 - val_mae: 0.4618 - 36ms/epoch - 1ms/step\n",
      "Epoch 1994/5000\n",
      "31/31 - 0s - loss: 11.5348 - mae: 1.9771 - val_loss: 2.8407 - val_mae: 1.6546 - 36ms/epoch - 1ms/step\n",
      "Epoch 1995/5000\n",
      "31/31 - 0s - loss: 1.0871 - mae: 0.7813 - val_loss: 0.8832 - val_mae: 0.8831 - 37ms/epoch - 1ms/step\n",
      "Epoch 1996/5000\n",
      "31/31 - 0s - loss: 12.2418 - mae: 2.0298 - val_loss: 3.9757 - val_mae: 1.9685 - 38ms/epoch - 1ms/step\n",
      "Epoch 1997/5000\n",
      "31/31 - 0s - loss: 7.6657 - mae: 1.8318 - val_loss: 0.7576 - val_mae: 0.8034 - 49ms/epoch - 2ms/step\n",
      "Epoch 1998/5000\n",
      "31/31 - 0s - loss: 1.0339 - mae: 0.8570 - val_loss: 0.2390 - val_mae: 0.4299 - 37ms/epoch - 1ms/step\n",
      "Epoch 1999/5000\n",
      "31/31 - 0s - loss: 19.5641 - mae: 1.9042 - val_loss: 14.0107 - val_mae: 3.7289 - 38ms/epoch - 1ms/step\n",
      "Epoch 2000/5000\n",
      "31/31 - 0s - loss: 3.0359 - mae: 1.4318 - val_loss: 9.8392 - val_mae: 3.1203 - 37ms/epoch - 1ms/step\n",
      "Epoch 2001/5000\n",
      "31/31 - 0s - loss: 2.4582 - mae: 1.1532 - val_loss: 1.8577 - val_mae: 1.3237 - 39ms/epoch - 1ms/step\n",
      "Epoch 2002/5000\n",
      "31/31 - 0s - loss: 6.7392 - mae: 1.9287 - val_loss: 0.1219 - val_mae: 0.2838 - 38ms/epoch - 1ms/step\n",
      "Epoch 2003/5000\n",
      "31/31 - 0s - loss: 0.9194 - mae: 0.6911 - val_loss: 6.7806 - val_mae: 2.5853 - 37ms/epoch - 1ms/step\n",
      "Epoch 2004/5000\n",
      "31/31 - 0s - loss: 24.6215 - mae: 2.1955 - val_loss: 0.1438 - val_mae: 0.2909 - 38ms/epoch - 1ms/step\n",
      "Epoch 2005/5000\n",
      "31/31 - 0s - loss: 2.1004 - mae: 1.0734 - val_loss: 2.3066 - val_mae: 1.4851 - 37ms/epoch - 1ms/step\n",
      "Epoch 2006/5000\n",
      "31/31 - 0s - loss: 14.8818 - mae: 1.9045 - val_loss: 0.1410 - val_mae: 0.2902 - 38ms/epoch - 1ms/step\n",
      "Epoch 2007/5000\n",
      "31/31 - 0s - loss: 0.9877 - mae: 0.8607 - val_loss: 4.1050 - val_mae: 1.9980 - 36ms/epoch - 1ms/step\n",
      "Epoch 2008/5000\n",
      "31/31 - 0s - loss: 13.6912 - mae: 2.1732 - val_loss: 0.1382 - val_mae: 0.2772 - 37ms/epoch - 1ms/step\n",
      "Epoch 2009/5000\n",
      "31/31 - 0s - loss: 1.0689 - mae: 0.7354 - val_loss: 0.2135 - val_mae: 0.4111 - 37ms/epoch - 1ms/step\n",
      "Epoch 2010/5000\n",
      "31/31 - 0s - loss: 5.3326 - mae: 1.6639 - val_loss: 0.6342 - val_mae: 0.7273 - 37ms/epoch - 1ms/step\n",
      "Epoch 2011/5000\n",
      "31/31 - 0s - loss: 0.9537 - mae: 0.7476 - val_loss: 49.5879 - val_mae: 7.0353 - 37ms/epoch - 1ms/step\n",
      "Epoch 2012/5000\n",
      "31/31 - 0s - loss: 5.7721 - mae: 1.4751 - val_loss: 0.4209 - val_mae: 0.5619 - 38ms/epoch - 1ms/step\n",
      "Epoch 2013/5000\n",
      "31/31 - 0s - loss: 22.7395 - mae: 2.2362 - val_loss: 2.4373 - val_mae: 1.5286 - 38ms/epoch - 1ms/step\n",
      "Epoch 2014/5000\n",
      "31/31 - 0s - loss: 1.8962 - mae: 0.8525 - val_loss: 0.2513 - val_mae: 0.4375 - 35ms/epoch - 1ms/step\n",
      "Epoch 2015/5000\n",
      "31/31 - 0s - loss: 34.0823 - mae: 2.5014 - val_loss: 0.2010 - val_mae: 0.3316 - 36ms/epoch - 1ms/step\n",
      "Epoch 2016/5000\n",
      "31/31 - 0s - loss: 2.0738 - mae: 1.2323 - val_loss: 0.2847 - val_mae: 0.4570 - 39ms/epoch - 1ms/step\n",
      "Epoch 2017/5000\n",
      "31/31 - 0s - loss: 1.8092 - mae: 1.0101 - val_loss: 0.4690 - val_mae: 0.6014 - 38ms/epoch - 1ms/step\n",
      "Epoch 2018/5000\n",
      "31/31 - 0s - loss: 22.8004 - mae: 2.3061 - val_loss: 1.2805 - val_mae: 1.0828 - 36ms/epoch - 1ms/step\n",
      "Epoch 2019/5000\n",
      "31/31 - 0s - loss: 1.6927 - mae: 1.0881 - val_loss: 5.2055 - val_mae: 2.2563 - 36ms/epoch - 1ms/step\n",
      "Epoch 2020/5000\n",
      "31/31 - 0s - loss: 3.9799 - mae: 1.4096 - val_loss: 0.1446 - val_mae: 0.3407 - 37ms/epoch - 1ms/step\n",
      "Epoch 2021/5000\n",
      "31/31 - 0s - loss: 20.7999 - mae: 1.9355 - val_loss: 3.3720 - val_mae: 1.8043 - 35ms/epoch - 1ms/step\n",
      "Epoch 2022/5000\n",
      "31/31 - 0s - loss: 2.4058 - mae: 1.3268 - val_loss: 2.5069 - val_mae: 1.5485 - 37ms/epoch - 1ms/step\n",
      "Epoch 2023/5000\n",
      "31/31 - 0s - loss: 13.1773 - mae: 2.1464 - val_loss: 0.8371 - val_mae: 0.8522 - 39ms/epoch - 1ms/step\n",
      "Epoch 2024/5000\n",
      "31/31 - 0s - loss: 0.6045 - mae: 0.6617 - val_loss: 3.5435 - val_mae: 1.8541 - 36ms/epoch - 1ms/step\n",
      "Epoch 2025/5000\n",
      "31/31 - 0s - loss: 10.4383 - mae: 2.1338 - val_loss: 1.3122 - val_mae: 1.0945 - 35ms/epoch - 1ms/step\n",
      "Epoch 2026/5000\n",
      "31/31 - 0s - loss: 1.3445 - mae: 0.8774 - val_loss: 0.4301 - val_mae: 0.5658 - 37ms/epoch - 1ms/step\n",
      "Epoch 2027/5000\n",
      "31/31 - 0s - loss: 24.4458 - mae: 2.0744 - val_loss: 2.4717 - val_mae: 1.5362 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2028/5000\n",
      "31/31 - 0s - loss: 1.9766 - mae: 1.1589 - val_loss: 2.8689 - val_mae: 1.6611 - 39ms/epoch - 1ms/step\n",
      "Epoch 2029/5000\n",
      "31/31 - 0s - loss: 5.1549 - mae: 1.7722 - val_loss: 0.2253 - val_mae: 0.3550 - 37ms/epoch - 1ms/step\n",
      "Epoch 2030/5000\n",
      "31/31 - 0s - loss: 17.5445 - mae: 1.6678 - val_loss: 80.6728 - val_mae: 8.9752 - 38ms/epoch - 1ms/step\n",
      "Epoch 2031/5000\n",
      "31/31 - 0s - loss: 5.6524 - mae: 1.1652 - val_loss: 2.3905 - val_mae: 1.5098 - 37ms/epoch - 1ms/step\n",
      "Epoch 2032/5000\n",
      "31/31 - 0s - loss: 0.9303 - mae: 0.8105 - val_loss: 0.3823 - val_mae: 0.5276 - 37ms/epoch - 1ms/step\n",
      "Epoch 2033/5000\n",
      "31/31 - 0s - loss: 11.3101 - mae: 2.0100 - val_loss: 0.1485 - val_mae: 0.3488 - 39ms/epoch - 1ms/step\n",
      "Epoch 2034/5000\n",
      "31/31 - 0s - loss: 8.1571 - mae: 1.7556 - val_loss: 128.1224 - val_mae: 11.3148 - 35ms/epoch - 1ms/step\n",
      "Epoch 2035/5000\n",
      "31/31 - 0s - loss: 4.4002 - mae: 1.0032 - val_loss: 0.1728 - val_mae: 0.3761 - 36ms/epoch - 1ms/step\n",
      "Epoch 2036/5000\n",
      "31/31 - 0s - loss: 18.3077 - mae: 1.8655 - val_loss: 0.1430 - val_mae: 0.2791 - 36ms/epoch - 1ms/step\n",
      "Epoch 2037/5000\n",
      "31/31 - 0s - loss: 2.8345 - mae: 1.3815 - val_loss: 1.3502 - val_mae: 1.1145 - 35ms/epoch - 1ms/step\n",
      "Epoch 2038/5000\n",
      "31/31 - 0s - loss: 1.2272 - mae: 0.9672 - val_loss: 6.9182 - val_mae: 2.6106 - 37ms/epoch - 1ms/step\n",
      "Epoch 2039/5000\n",
      "31/31 - 0s - loss: 18.0948 - mae: 2.3006 - val_loss: 2.5850 - val_mae: 1.5715 - 36ms/epoch - 1ms/step\n",
      "Epoch 2040/5000\n",
      "31/31 - 0s - loss: 2.0826 - mae: 1.1848 - val_loss: 0.2406 - val_mae: 0.4311 - 37ms/epoch - 1ms/step\n",
      "Epoch 2041/5000\n",
      "31/31 - 0s - loss: 8.9667 - mae: 2.0977 - val_loss: 0.2292 - val_mae: 0.3544 - 36ms/epoch - 1ms/step\n",
      "Epoch 2042/5000\n",
      "31/31 - 0s - loss: 3.7596 - mae: 1.3849 - val_loss: 108.7917 - val_mae: 10.4261 - 36ms/epoch - 1ms/step\n",
      "Epoch 2043/5000\n",
      "31/31 - 0s - loss: 6.8037 - mae: 1.3713 - val_loss: 0.1198 - val_mae: 0.2862 - 36ms/epoch - 1ms/step\n",
      "Epoch 2044/5000\n",
      "31/31 - 0s - loss: 14.3615 - mae: 2.0544 - val_loss: 0.3786 - val_mae: 0.5185 - 37ms/epoch - 1ms/step\n",
      "Epoch 2045/5000\n",
      "31/31 - 0s - loss: 0.5280 - mae: 0.5287 - val_loss: 0.6137 - val_mae: 0.7123 - 36ms/epoch - 1ms/step\n",
      "Epoch 2046/5000\n",
      "31/31 - 0s - loss: 6.4604 - mae: 1.1352 - val_loss: 129.4587 - val_mae: 11.3729 - 37ms/epoch - 1ms/step\n",
      "Epoch 2047/5000\n",
      "31/31 - 0s - loss: 6.1860 - mae: 1.4870 - val_loss: 0.5461 - val_mae: 0.6608 - 37ms/epoch - 1ms/step\n",
      "Epoch 2048/5000\n",
      "31/31 - 0s - loss: 1.0046 - mae: 0.8201 - val_loss: 1.9996 - val_mae: 1.3795 - 37ms/epoch - 1ms/step\n",
      "Epoch 2049/5000\n",
      "31/31 - 0s - loss: 12.0045 - mae: 1.8707 - val_loss: 0.2121 - val_mae: 0.4103 - 37ms/epoch - 1ms/step\n",
      "Epoch 2050/5000\n",
      "31/31 - 0s - loss: 0.5413 - mae: 0.5588 - val_loss: 0.2596 - val_mae: 0.4433 - 36ms/epoch - 1ms/step\n",
      "Epoch 2051/5000\n",
      "31/31 - 0s - loss: 11.7127 - mae: 1.7755 - val_loss: 1.0849 - val_mae: 0.9883 - 38ms/epoch - 1ms/step\n",
      "Epoch 2052/5000\n",
      "31/31 - 0s - loss: 1.3251 - mae: 0.8499 - val_loss: 1.0967 - val_mae: 0.9929 - 36ms/epoch - 1ms/step\n",
      "Epoch 2053/5000\n",
      "31/31 - 0s - loss: 8.9678 - mae: 1.7437 - val_loss: 0.8051 - val_mae: 0.8353 - 34ms/epoch - 1ms/step\n",
      "Epoch 2054/5000\n",
      "31/31 - 0s - loss: 8.0512 - mae: 1.5860 - val_loss: 22.1571 - val_mae: 4.6946 - 38ms/epoch - 1ms/step\n",
      "Epoch 2055/5000\n",
      "31/31 - 0s - loss: 2.3057 - mae: 1.1471 - val_loss: 0.1923 - val_mae: 0.3288 - 37ms/epoch - 1ms/step\n",
      "Epoch 2056/5000\n",
      "31/31 - 0s - loss: 10.2885 - mae: 1.8489 - val_loss: 0.1283 - val_mae: 0.2879 - 37ms/epoch - 1ms/step\n",
      "Epoch 2057/5000\n",
      "31/31 - 0s - loss: 1.7119 - mae: 0.8416 - val_loss: 0.2070 - val_mae: 0.4046 - 35ms/epoch - 1ms/step\n",
      "Epoch 2058/5000\n",
      "31/31 - 0s - loss: 11.3534 - mae: 1.7944 - val_loss: 1.1873 - val_mae: 1.0394 - 38ms/epoch - 1ms/step\n",
      "Epoch 2059/5000\n",
      "31/31 - 0s - loss: 22.2407 - mae: 2.1537 - val_loss: 0.2052 - val_mae: 0.3435 - 37ms/epoch - 1ms/step\n",
      "Epoch 2060/5000\n",
      "31/31 - 0s - loss: 1.0386 - mae: 0.8505 - val_loss: 0.1148 - val_mae: 0.2856 - 38ms/epoch - 1ms/step\n",
      "Epoch 2061/5000\n",
      "31/31 - 0s - loss: 0.9608 - mae: 0.6391 - val_loss: 1.2618 - val_mae: 1.0761 - 37ms/epoch - 1ms/step\n",
      "Epoch 2062/5000\n",
      "31/31 - 0s - loss: 14.3596 - mae: 2.1302 - val_loss: 2.8491 - val_mae: 1.6522 - 37ms/epoch - 1ms/step\n",
      "Epoch 2063/5000\n",
      "31/31 - 0s - loss: 3.9058 - mae: 1.7555 - val_loss: 1.3841 - val_mae: 1.1294 - 36ms/epoch - 1ms/step\n",
      "Epoch 2064/5000\n",
      "31/31 - 0s - loss: 26.7502 - mae: 2.3975 - val_loss: 0.7217 - val_mae: 0.7861 - 35ms/epoch - 1ms/step\n",
      "Epoch 2065/5000\n",
      "31/31 - 0s - loss: 3.6769 - mae: 1.6228 - val_loss: 2.0835 - val_mae: 1.4065 - 38ms/epoch - 1ms/step\n",
      "Epoch 2066/5000\n",
      "31/31 - 0s - loss: 8.9278 - mae: 1.9983 - val_loss: 3.9846 - val_mae: 1.9708 - 36ms/epoch - 1ms/step\n",
      "Epoch 2067/5000\n",
      "31/31 - 0s - loss: 0.8615 - mae: 0.7281 - val_loss: 0.1841 - val_mae: 0.3210 - 36ms/epoch - 1ms/step\n",
      "Epoch 2068/5000\n",
      "31/31 - 0s - loss: 23.6066 - mae: 2.0991 - val_loss: 1.2331 - val_mae: 1.0623 - 38ms/epoch - 1ms/step\n",
      "Epoch 2069/5000\n",
      "31/31 - 0s - loss: 2.8005 - mae: 1.2604 - val_loss: 2.4697 - val_mae: 1.5387 - 38ms/epoch - 1ms/step\n",
      "Epoch 2070/5000\n",
      "31/31 - 0s - loss: 1.1608 - mae: 0.8536 - val_loss: 142.1748 - val_mae: 11.9202 - 37ms/epoch - 1ms/step\n",
      "Epoch 2071/5000\n",
      "31/31 - 0s - loss: 8.2822 - mae: 1.9578 - val_loss: 0.7733 - val_mae: 0.8167 - 37ms/epoch - 1ms/step\n",
      "Epoch 2072/5000\n",
      "31/31 - 0s - loss: 12.0824 - mae: 1.9352 - val_loss: 0.1986 - val_mae: 0.3368 - 36ms/epoch - 1ms/step\n",
      "Epoch 2073/5000\n",
      "31/31 - 0s - loss: 0.7959 - mae: 0.7791 - val_loss: 0.5584 - val_mae: 0.6734 - 37ms/epoch - 1ms/step\n",
      "Epoch 2074/5000\n",
      "31/31 - 0s - loss: 11.7070 - mae: 1.8134 - val_loss: 0.2907 - val_mae: 0.4368 - 36ms/epoch - 1ms/step\n",
      "Epoch 2075/5000\n",
      "31/31 - 0s - loss: 1.0072 - mae: 0.8101 - val_loss: 0.9454 - val_mae: 0.9149 - 36ms/epoch - 1ms/step\n",
      "Epoch 2076/5000\n",
      "31/31 - 0s - loss: 12.9562 - mae: 1.7384 - val_loss: 5.6042 - val_mae: 2.3475 - 37ms/epoch - 1ms/step\n",
      "Epoch 2077/5000\n",
      "31/31 - 0s - loss: 3.0605 - mae: 1.4639 - val_loss: 0.5655 - val_mae: 0.6776 - 37ms/epoch - 1ms/step\n",
      "Epoch 2078/5000\n",
      "31/31 - 0s - loss: 11.5745 - mae: 1.8655 - val_loss: 0.2771 - val_mae: 0.4556 - 37ms/epoch - 1ms/step\n",
      "Epoch 2079/5000\n",
      "31/31 - 0s - loss: 1.5868 - mae: 0.8992 - val_loss: 3.4612 - val_mae: 1.8313 - 36ms/epoch - 1ms/step\n",
      "Epoch 2080/5000\n",
      "31/31 - 0s - loss: 32.9067 - mae: 2.5731 - val_loss: 0.8273 - val_mae: 0.8506 - 36ms/epoch - 1ms/step\n",
      "Epoch 2081/5000\n",
      "31/31 - 0s - loss: 1.4747 - mae: 1.0047 - val_loss: 2.9318 - val_mae: 1.6817 - 36ms/epoch - 1ms/step\n",
      "Epoch 2082/5000\n",
      "31/31 - 0s - loss: 1.1455 - mae: 0.7883 - val_loss: 0.4363 - val_mae: 0.5725 - 38ms/epoch - 1ms/step\n",
      "Epoch 2083/5000\n",
      "31/31 - 0s - loss: 24.5836 - mae: 1.9363 - val_loss: 0.1046 - val_mae: 0.2838 - 39ms/epoch - 1ms/step\n",
      "Epoch 2084/5000\n",
      "31/31 - 0s - loss: 2.8572 - mae: 1.1666 - val_loss: 47.4712 - val_mae: 6.8829 - 38ms/epoch - 1ms/step\n",
      "Epoch 2085/5000\n",
      "31/31 - 0s - loss: 3.4806 - mae: 1.0051 - val_loss: 0.7076 - val_mae: 0.7724 - 35ms/epoch - 1ms/step\n",
      "Epoch 2086/5000\n",
      "31/31 - 0s - loss: 13.0654 - mae: 2.1443 - val_loss: 0.5844 - val_mae: 0.6891 - 37ms/epoch - 1ms/step\n",
      "Epoch 2087/5000\n",
      "31/31 - 0s - loss: 0.6653 - mae: 0.6884 - val_loss: 3.3917 - val_mae: 1.8142 - 37ms/epoch - 1ms/step\n",
      "Epoch 2088/5000\n",
      "31/31 - 0s - loss: 16.1947 - mae: 2.0147 - val_loss: 0.2648 - val_mae: 0.3999 - 36ms/epoch - 1ms/step\n",
      "Epoch 2089/5000\n",
      "31/31 - 0s - loss: 0.9707 - mae: 0.6897 - val_loss: 0.8543 - val_mae: 0.8637 - 38ms/epoch - 1ms/step\n",
      "Epoch 2090/5000\n",
      "31/31 - 0s - loss: 13.1652 - mae: 1.9349 - val_loss: 1.0640 - val_mae: 0.9780 - 38ms/epoch - 1ms/step\n",
      "Epoch 2091/5000\n",
      "31/31 - 0s - loss: 2.4345 - mae: 0.9990 - val_loss: 0.5772 - val_mae: 0.6886 - 35ms/epoch - 1ms/step\n",
      "Epoch 2092/5000\n",
      "31/31 - 0s - loss: 7.5774 - mae: 1.6086 - val_loss: 0.5669 - val_mae: 0.6757 - 38ms/epoch - 1ms/step\n",
      "Epoch 2093/5000\n",
      "31/31 - 0s - loss: 11.0860 - mae: 1.7708 - val_loss: 0.3014 - val_mae: 0.4392 - 38ms/epoch - 1ms/step\n",
      "Epoch 2094/5000\n",
      "31/31 - 0s - loss: 2.2003 - mae: 1.1678 - val_loss: 2.1347 - val_mae: 1.4236 - 38ms/epoch - 1ms/step\n",
      "Epoch 2095/5000\n",
      "31/31 - 0s - loss: 16.9022 - mae: 2.0222 - val_loss: 2.0996 - val_mae: 1.4130 - 37ms/epoch - 1ms/step\n",
      "Epoch 2096/5000\n",
      "31/31 - 0s - loss: 1.2520 - mae: 0.9230 - val_loss: 5.1016 - val_mae: 2.2349 - 35ms/epoch - 1ms/step\n",
      "Epoch 2097/5000\n",
      "31/31 - 0s - loss: 2.5032 - mae: 1.2267 - val_loss: 0.5855 - val_mae: 0.6920 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2098/5000\n",
      "31/31 - 0s - loss: 18.6127 - mae: 1.8274 - val_loss: 1.2628 - val_mae: 1.0747 - 37ms/epoch - 1ms/step\n",
      "Epoch 2099/5000\n",
      "31/31 - 0s - loss: 2.5273 - mae: 1.1806 - val_loss: 1.9006 - val_mae: 1.3405 - 35ms/epoch - 1ms/step\n",
      "Epoch 2100/5000\n",
      "31/31 - 0s - loss: 10.7134 - mae: 1.6679 - val_loss: 22.0405 - val_mae: 4.6815 - 37ms/epoch - 1ms/step\n",
      "Epoch 2101/5000\n",
      "31/31 - 0s - loss: 3.0860 - mae: 1.3215 - val_loss: 0.3428 - val_mae: 0.4939 - 37ms/epoch - 1ms/step\n",
      "Epoch 2102/5000\n",
      "31/31 - 0s - loss: 19.7897 - mae: 2.3082 - val_loss: 0.1190 - val_mae: 0.3028 - 37ms/epoch - 1ms/step\n",
      "Epoch 2103/5000\n",
      "31/31 - 0s - loss: 0.9779 - mae: 0.7324 - val_loss: 0.1088 - val_mae: 0.2846 - 36ms/epoch - 1ms/step\n",
      "Epoch 2104/5000\n",
      "31/31 - 0s - loss: 10.2329 - mae: 1.8344 - val_loss: 31.3746 - val_mae: 5.5908 - 37ms/epoch - 1ms/step\n",
      "Epoch 2105/5000\n",
      "31/31 - 0s - loss: 2.1618 - mae: 1.0676 - val_loss: 1.3254 - val_mae: 1.1047 - 36ms/epoch - 1ms/step\n",
      "Epoch 2106/5000\n",
      "31/31 - 0s - loss: 12.1263 - mae: 2.0944 - val_loss: 1.6286 - val_mae: 1.2350 - 36ms/epoch - 1ms/step\n",
      "Epoch 2107/5000\n",
      "31/31 - 0s - loss: 1.7973 - mae: 1.0682 - val_loss: 0.6574 - val_mae: 0.7401 - 36ms/epoch - 1ms/step\n",
      "Epoch 2108/5000\n",
      "31/31 - 0s - loss: 18.1374 - mae: 2.2277 - val_loss: 0.7898 - val_mae: 0.8198 - 38ms/epoch - 1ms/step\n",
      "Epoch 2109/5000\n",
      "31/31 - 0s - loss: 1.1451 - mae: 0.8092 - val_loss: 0.2940 - val_mae: 0.4658 - 37ms/epoch - 1ms/step\n",
      "Epoch 2110/5000\n",
      "31/31 - 0s - loss: 1.3308 - mae: 0.8706 - val_loss: 40.8780 - val_mae: 6.3860 - 36ms/epoch - 1ms/step\n",
      "Epoch 2111/5000\n",
      "31/31 - 0s - loss: 14.4460 - mae: 1.9423 - val_loss: 1.0335 - val_mae: 0.9645 - 37ms/epoch - 1ms/step\n",
      "Epoch 2112/5000\n",
      "31/31 - 0s - loss: 10.4545 - mae: 1.8063 - val_loss: 0.2898 - val_mae: 0.4271 - 35ms/epoch - 1ms/step\n",
      "Epoch 2113/5000\n",
      "31/31 - 0s - loss: 1.9050 - mae: 1.1318 - val_loss: 0.1174 - val_mae: 0.3010 - 37ms/epoch - 1ms/step\n",
      "Epoch 2114/5000\n",
      "31/31 - 0s - loss: 10.2745 - mae: 2.0005 - val_loss: 1.0707 - val_mae: 0.9771 - 38ms/epoch - 1ms/step\n",
      "Epoch 2115/5000\n",
      "31/31 - 0s - loss: 2.4675 - mae: 1.2934 - val_loss: 0.2091 - val_mae: 0.3432 - 35ms/epoch - 1ms/step\n",
      "Epoch 2116/5000\n",
      "31/31 - 0s - loss: 13.4038 - mae: 2.0037 - val_loss: 0.3966 - val_mae: 0.5353 - 37ms/epoch - 1ms/step\n",
      "Epoch 2117/5000\n",
      "31/31 - 0s - loss: 1.5714 - mae: 1.0474 - val_loss: 0.7263 - val_mae: 0.7883 - 36ms/epoch - 1ms/step\n",
      "Epoch 2118/5000\n",
      "31/31 - 0s - loss: 26.7361 - mae: 1.9876 - val_loss: 1.3672 - val_mae: 1.1193 - 37ms/epoch - 1ms/step\n",
      "Epoch 2119/5000\n",
      "31/31 - 0s - loss: 1.9779 - mae: 1.0449 - val_loss: 0.3625 - val_mae: 0.5021 - 35ms/epoch - 1ms/step\n",
      "Epoch 2120/5000\n",
      "31/31 - 0s - loss: 13.3991 - mae: 1.9102 - val_loss: 0.9149 - val_mae: 0.8915 - 35ms/epoch - 1ms/step\n",
      "Epoch 2121/5000\n",
      "31/31 - 0s - loss: 1.9102 - mae: 1.0095 - val_loss: 0.4584 - val_mae: 0.5853 - 36ms/epoch - 1ms/step\n",
      "Epoch 2122/5000\n",
      "31/31 - 0s - loss: 7.5700 - mae: 1.8728 - val_loss: 0.4843 - val_mae: 0.6098 - 35ms/epoch - 1ms/step\n",
      "Epoch 2123/5000\n",
      "31/31 - 0s - loss: 3.2709 - mae: 1.1474 - val_loss: 39.8271 - val_mae: 6.3027 - 35ms/epoch - 1ms/step\n",
      "Epoch 2124/5000\n",
      "31/31 - 0s - loss: 14.9023 - mae: 2.0195 - val_loss: 0.9807 - val_mae: 0.9345 - 36ms/epoch - 1ms/step\n",
      "Epoch 2125/5000\n",
      "31/31 - 0s - loss: 1.0890 - mae: 0.8924 - val_loss: 3.6885 - val_mae: 1.8940 - 34ms/epoch - 1ms/step\n",
      "Epoch 2126/5000\n",
      "31/31 - 0s - loss: 23.0060 - mae: 2.0845 - val_loss: 0.1799 - val_mae: 0.3191 - 35ms/epoch - 1ms/step\n",
      "Epoch 2127/5000\n",
      "31/31 - 0s - loss: 2.4782 - mae: 1.2523 - val_loss: 0.1228 - val_mae: 0.3155 - 36ms/epoch - 1ms/step\n",
      "Epoch 2128/5000\n",
      "31/31 - 0s - loss: 17.9375 - mae: 2.0865 - val_loss: 0.1120 - val_mae: 0.2936 - 36ms/epoch - 1ms/step\n",
      "Epoch 2129/5000\n",
      "31/31 - 0s - loss: 0.6478 - mae: 0.6522 - val_loss: 3.6851 - val_mae: 1.8896 - 34ms/epoch - 1ms/step\n",
      "Epoch 2130/5000\n",
      "31/31 - 0s - loss: 0.7244 - mae: 0.6706 - val_loss: 0.6055 - val_mae: 0.7082 - 37ms/epoch - 1ms/step\n",
      "Epoch 2131/5000\n",
      "31/31 - 0s - loss: 22.0944 - mae: 2.4936 - val_loss: 0.9623 - val_mae: 0.9266 - 35ms/epoch - 1ms/step\n",
      "Epoch 2132/5000\n",
      "31/31 - 0s - loss: 1.2376 - mae: 0.8861 - val_loss: 0.1207 - val_mae: 0.2880 - 35ms/epoch - 1ms/step\n",
      "Epoch 2133/5000\n",
      "31/31 - 0s - loss: 8.9617 - mae: 1.7205 - val_loss: 0.1103 - val_mae: 0.2870 - 34ms/epoch - 1ms/step\n",
      "Epoch 2134/5000\n",
      "31/31 - 0s - loss: 14.6626 - mae: 2.1229 - val_loss: 0.9794 - val_mae: 0.9319 - 35ms/epoch - 1ms/step\n",
      "Epoch 2135/5000\n",
      "31/31 - 0s - loss: 2.0884 - mae: 1.0789 - val_loss: 0.5726 - val_mae: 0.6789 - 36ms/epoch - 1ms/step\n",
      "Epoch 2136/5000\n",
      "31/31 - 0s - loss: 0.8264 - mae: 0.7724 - val_loss: 0.1407 - val_mae: 0.3399 - 34ms/epoch - 1ms/step\n",
      "Epoch 2137/5000\n",
      "31/31 - 0s - loss: 11.1322 - mae: 1.5544 - val_loss: 0.1132 - val_mae: 0.2879 - 35ms/epoch - 1ms/step\n",
      "Epoch 2138/5000\n",
      "31/31 - 0s - loss: 1.2654 - mae: 0.7944 - val_loss: 0.2435 - val_mae: 0.4326 - 46ms/epoch - 1ms/step\n",
      "Epoch 2139/5000\n",
      "31/31 - 0s - loss: 15.9252 - mae: 1.8346 - val_loss: 1.3694 - val_mae: 1.1212 - 36ms/epoch - 1ms/step\n",
      "Epoch 2140/5000\n",
      "31/31 - 0s - loss: 1.0277 - mae: 0.8348 - val_loss: 0.7495 - val_mae: 0.8018 - 36ms/epoch - 1ms/step\n",
      "Epoch 2141/5000\n",
      "31/31 - 0s - loss: 13.4089 - mae: 2.0224 - val_loss: 1.6351 - val_mae: 1.2377 - 36ms/epoch - 1ms/step\n",
      "Epoch 2142/5000\n",
      "31/31 - 0s - loss: 2.0481 - mae: 1.0490 - val_loss: 0.1628 - val_mae: 0.3028 - 37ms/epoch - 1ms/step\n",
      "Epoch 2143/5000\n",
      "31/31 - 0s - loss: 7.4564 - mae: 1.6696 - val_loss: 3.2886 - val_mae: 1.7818 - 37ms/epoch - 1ms/step\n",
      "Epoch 2144/5000\n",
      "31/31 - 0s - loss: 2.9510 - mae: 1.3182 - val_loss: 67.6200 - val_mae: 8.2153 - 37ms/epoch - 1ms/step\n",
      "Epoch 2145/5000\n",
      "31/31 - 0s - loss: 16.2194 - mae: 1.7203 - val_loss: 0.1160 - val_mae: 0.2925 - 40ms/epoch - 1ms/step\n",
      "Epoch 2146/5000\n",
      "31/31 - 0s - loss: 7.6779 - mae: 1.5409 - val_loss: 0.1863 - val_mae: 0.3879 - 35ms/epoch - 1ms/step\n",
      "Epoch 2147/5000\n",
      "31/31 - 0s - loss: 1.0522 - mae: 0.8437 - val_loss: 11.1010 - val_mae: 3.3171 - 36ms/epoch - 1ms/step\n",
      "Epoch 2148/5000\n",
      "31/31 - 0s - loss: 21.2770 - mae: 2.0724 - val_loss: 5.2829 - val_mae: 2.2755 - 35ms/epoch - 1ms/step\n",
      "Epoch 2149/5000\n",
      "31/31 - 0s - loss: 15.5611 - mae: 2.2413 - val_loss: 6.4971 - val_mae: 2.5284 - 36ms/epoch - 1ms/step\n",
      "Epoch 2150/5000\n",
      "31/31 - 0s - loss: 0.5823 - mae: 0.6142 - val_loss: 0.2552 - val_mae: 0.3830 - 37ms/epoch - 1ms/step\n",
      "Epoch 2151/5000\n",
      "31/31 - 0s - loss: 11.3970 - mae: 1.6274 - val_loss: 33.2641 - val_mae: 5.7596 - 38ms/epoch - 1ms/step\n",
      "Epoch 2152/5000\n",
      "31/31 - 0s - loss: 2.1025 - mae: 0.8388 - val_loss: 0.2919 - val_mae: 0.4299 - 37ms/epoch - 1ms/step\n",
      "Epoch 2153/5000\n",
      "31/31 - 0s - loss: 0.8182 - mae: 0.7427 - val_loss: 0.1678 - val_mae: 0.3063 - 38ms/epoch - 1ms/step\n",
      "Epoch 2154/5000\n",
      "31/31 - 0s - loss: 19.0740 - mae: 2.1736 - val_loss: 0.1458 - val_mae: 0.2869 - 38ms/epoch - 1ms/step\n",
      "Epoch 2155/5000\n",
      "31/31 - 0s - loss: 2.0984 - mae: 1.0599 - val_loss: 3.7416 - val_mae: 1.9071 - 36ms/epoch - 1ms/step\n",
      "Epoch 2156/5000\n",
      "31/31 - 0s - loss: 15.0957 - mae: 2.0806 - val_loss: 0.6233 - val_mae: 0.7123 - 35ms/epoch - 1ms/step\n",
      "Epoch 2157/5000\n",
      "31/31 - 0s - loss: 2.1011 - mae: 1.1978 - val_loss: 5.0250 - val_mae: 2.2187 - 37ms/epoch - 1ms/step\n",
      "Epoch 2158/5000\n",
      "31/31 - 0s - loss: 17.8910 - mae: 1.9087 - val_loss: 0.3313 - val_mae: 0.4738 - 38ms/epoch - 1ms/step\n",
      "Epoch 2159/5000\n",
      "31/31 - 0s - loss: 1.3214 - mae: 0.8531 - val_loss: 0.1231 - val_mae: 0.2933 - 36ms/epoch - 1ms/step\n",
      "Epoch 2160/5000\n",
      "31/31 - 0s - loss: 18.9099 - mae: 2.2733 - val_loss: 0.6233 - val_mae: 0.7137 - 37ms/epoch - 1ms/step\n",
      "Epoch 2161/5000\n",
      "31/31 - 0s - loss: 1.2073 - mae: 0.8184 - val_loss: 5.2792 - val_mae: 2.2750 - 37ms/epoch - 1ms/step\n",
      "Epoch 2162/5000\n",
      "31/31 - 0s - loss: 6.3056 - mae: 1.6060 - val_loss: 123.0554 - val_mae: 11.0873 - 38ms/epoch - 1ms/step\n",
      "Epoch 2163/5000\n",
      "31/31 - 0s - loss: 5.1602 - mae: 1.1484 - val_loss: 0.5851 - val_mae: 0.6913 - 37ms/epoch - 1ms/step\n",
      "Epoch 2164/5000\n",
      "31/31 - 0s - loss: 12.1923 - mae: 1.9120 - val_loss: 0.5850 - val_mae: 0.6879 - 36ms/epoch - 1ms/step\n",
      "Epoch 2165/5000\n",
      "31/31 - 0s - loss: 0.5945 - mae: 0.5956 - val_loss: 0.2186 - val_mae: 0.3486 - 38ms/epoch - 1ms/step\n",
      "Epoch 2166/5000\n",
      "31/31 - 0s - loss: 14.1159 - mae: 1.9059 - val_loss: 1.6051 - val_mae: 1.2208 - 37ms/epoch - 1ms/step\n",
      "Epoch 2167/5000\n",
      "31/31 - 0s - loss: 0.8814 - mae: 0.8175 - val_loss: 5.5414 - val_mae: 2.3321 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2168/5000\n",
      "31/31 - 0s - loss: 20.7411 - mae: 1.8919 - val_loss: 0.6655 - val_mae: 0.7488 - 38ms/epoch - 1ms/step\n",
      "Epoch 2169/5000\n",
      "31/31 - 0s - loss: 1.7013 - mae: 1.1280 - val_loss: 0.2714 - val_mae: 0.4039 - 37ms/epoch - 1ms/step\n",
      "Epoch 2170/5000\n",
      "31/31 - 0s - loss: 7.9632 - mae: 1.4090 - val_loss: 166.2468 - val_mae: 12.8888 - 37ms/epoch - 1ms/step\n",
      "Epoch 2171/5000\n",
      "31/31 - 0s - loss: 7.6849 - mae: 1.1892 - val_loss: 0.1371 - val_mae: 0.3364 - 38ms/epoch - 1ms/step\n",
      "Epoch 2172/5000\n",
      "31/31 - 0s - loss: 14.8745 - mae: 2.0094 - val_loss: 0.5610 - val_mae: 0.6811 - 37ms/epoch - 1ms/step\n",
      "Epoch 2173/5000\n",
      "31/31 - 0s - loss: 0.9951 - mae: 0.7250 - val_loss: 3.1362 - val_mae: 1.7407 - 37ms/epoch - 1ms/step\n",
      "Epoch 2174/5000\n",
      "31/31 - 0s - loss: 21.6928 - mae: 2.2918 - val_loss: 0.3119 - val_mae: 0.4506 - 37ms/epoch - 1ms/step\n",
      "Epoch 2175/5000\n",
      "31/31 - 0s - loss: 1.4987 - mae: 0.8097 - val_loss: 0.6131 - val_mae: 0.7101 - 39ms/epoch - 1ms/step\n",
      "Epoch 2176/5000\n",
      "31/31 - 0s - loss: 0.7429 - mae: 0.7462 - val_loss: 1.9724 - val_mae: 1.3645 - 38ms/epoch - 1ms/step\n",
      "Epoch 2177/5000\n",
      "31/31 - 0s - loss: 10.9940 - mae: 2.0160 - val_loss: 1.3764 - val_mae: 1.1268 - 37ms/epoch - 1ms/step\n",
      "Epoch 2178/5000\n",
      "31/31 - 0s - loss: 10.3066 - mae: 2.0180 - val_loss: 0.4168 - val_mae: 0.5612 - 37ms/epoch - 1ms/step\n",
      "Epoch 2179/5000\n",
      "31/31 - 0s - loss: 1.1033 - mae: 0.7713 - val_loss: 0.5993 - val_mae: 0.7041 - 35ms/epoch - 1ms/step\n",
      "Epoch 2180/5000\n",
      "31/31 - 0s - loss: 20.7755 - mae: 2.2485 - val_loss: 0.2194 - val_mae: 0.3508 - 37ms/epoch - 1ms/step\n",
      "Epoch 2181/5000\n",
      "31/31 - 0s - loss: 0.6658 - mae: 0.7307 - val_loss: 3.1837 - val_mae: 1.7531 - 37ms/epoch - 1ms/step\n",
      "Epoch 2182/5000\n",
      "31/31 - 0s - loss: 5.4986 - mae: 1.7104 - val_loss: 0.8325 - val_mae: 0.8525 - 36ms/epoch - 1ms/step\n",
      "Epoch 2183/5000\n",
      "31/31 - 0s - loss: 2.0655 - mae: 1.1099 - val_loss: 0.6920 - val_mae: 0.7628 - 37ms/epoch - 1ms/step\n",
      "Epoch 2184/5000\n",
      "31/31 - 0s - loss: 18.2139 - mae: 2.2246 - val_loss: 1.1457 - val_mae: 1.0149 - 36ms/epoch - 1ms/step\n",
      "Epoch 2185/5000\n",
      "31/31 - 0s - loss: 1.0890 - mae: 0.8511 - val_loss: 0.1122 - val_mae: 0.2836 - 36ms/epoch - 1ms/step\n",
      "Epoch 2186/5000\n",
      "31/31 - 0s - loss: 7.8975 - mae: 1.7667 - val_loss: 0.1240 - val_mae: 0.2879 - 35ms/epoch - 1ms/step\n",
      "Epoch 2187/5000\n",
      "31/31 - 0s - loss: 1.0852 - mae: 0.8162 - val_loss: 1.4854 - val_mae: 1.1771 - 37ms/epoch - 1ms/step\n",
      "Epoch 2188/5000\n",
      "31/31 - 0s - loss: 8.5708 - mae: 1.8950 - val_loss: 0.3786 - val_mae: 0.5216 - 37ms/epoch - 1ms/step\n",
      "Epoch 2189/5000\n",
      "31/31 - 0s - loss: 2.0925 - mae: 0.9816 - val_loss: 1.1994 - val_mae: 1.0441 - 37ms/epoch - 1ms/step\n",
      "Epoch 2190/5000\n",
      "31/31 - 0s - loss: 14.2610 - mae: 2.2303 - val_loss: 4.2508 - val_mae: 2.0327 - 35ms/epoch - 1ms/step\n",
      "Epoch 2191/5000\n",
      "31/31 - 0s - loss: 2.9738 - mae: 1.4589 - val_loss: 83.9591 - val_mae: 9.1571 - 36ms/epoch - 1ms/step\n",
      "Epoch 2192/5000\n",
      "31/31 - 0s - loss: 8.3938 - mae: 1.6040 - val_loss: 0.2298 - val_mae: 0.3593 - 36ms/epoch - 1ms/step\n",
      "Epoch 2193/5000\n",
      "31/31 - 0s - loss: 9.4280 - mae: 1.7942 - val_loss: 1.2833 - val_mae: 1.0862 - 38ms/epoch - 1ms/step\n",
      "Epoch 2194/5000\n",
      "31/31 - 0s - loss: 0.7161 - mae: 0.7180 - val_loss: 0.5336 - val_mae: 0.6523 - 36ms/epoch - 1ms/step\n",
      "Epoch 2195/5000\n",
      "31/31 - 0s - loss: 7.5817 - mae: 1.5903 - val_loss: 1.1165 - val_mae: 1.0028 - 36ms/epoch - 1ms/step\n",
      "Epoch 2196/5000\n",
      "31/31 - 0s - loss: 1.0833 - mae: 0.8759 - val_loss: 0.1338 - val_mae: 0.2856 - 40ms/epoch - 1ms/step\n",
      "Epoch 2197/5000\n",
      "31/31 - 0s - loss: 23.6176 - mae: 2.1699 - val_loss: 0.1108 - val_mae: 0.2884 - 37ms/epoch - 1ms/step\n",
      "Epoch 2198/5000\n",
      "31/31 - 0s - loss: 0.8996 - mae: 0.7025 - val_loss: 1.3929 - val_mae: 1.1351 - 38ms/epoch - 1ms/step\n",
      "Epoch 2199/5000\n",
      "31/31 - 0s - loss: 5.9288 - mae: 1.8235 - val_loss: 0.7767 - val_mae: 0.8174 - 39ms/epoch - 1ms/step\n",
      "Epoch 2200/5000\n",
      "31/31 - 0s - loss: 7.7060 - mae: 1.7626 - val_loss: 0.1223 - val_mae: 0.2982 - 35ms/epoch - 1ms/step\n",
      "Epoch 2201/5000\n",
      "31/31 - 0s - loss: 11.4256 - mae: 1.9845 - val_loss: 0.4973 - val_mae: 0.6269 - 36ms/epoch - 1ms/step\n",
      "Epoch 2202/5000\n",
      "31/31 - 0s - loss: 0.5540 - mae: 0.6276 - val_loss: 3.6986 - val_mae: 1.8959 - 39ms/epoch - 1ms/step\n",
      "Epoch 2203/5000\n",
      "31/31 - 0s - loss: 4.3923 - mae: 1.2120 - val_loss: 74.2790 - val_mae: 8.6125 - 39ms/epoch - 1ms/step\n",
      "Epoch 2204/5000\n",
      "31/31 - 0s - loss: 8.0009 - mae: 1.5784 - val_loss: 0.1737 - val_mae: 0.3115 - 42ms/epoch - 1ms/step\n",
      "Epoch 2205/5000\n",
      "31/31 - 0s - loss: 16.0992 - mae: 2.1414 - val_loss: 0.1993 - val_mae: 0.3996 - 38ms/epoch - 1ms/step\n",
      "Epoch 2206/5000\n",
      "31/31 - 0s - loss: 1.0367 - mae: 0.8661 - val_loss: 0.1096 - val_mae: 0.2846 - 42ms/epoch - 1ms/step\n",
      "Epoch 2207/5000\n",
      "31/31 - 0s - loss: 21.4431 - mae: 1.9794 - val_loss: 0.4549 - val_mae: 0.5877 - 42ms/epoch - 1ms/step\n",
      "Epoch 2208/5000\n",
      "31/31 - 0s - loss: 0.8233 - mae: 0.7403 - val_loss: 0.1135 - val_mae: 0.2905 - 44ms/epoch - 1ms/step\n",
      "Epoch 2209/5000\n",
      "31/31 - 0s - loss: 0.6182 - mae: 0.6759 - val_loss: 0.1092 - val_mae: 0.2835 - 45ms/epoch - 1ms/step\n",
      "Epoch 2210/5000\n",
      "31/31 - 0s - loss: 17.2222 - mae: 2.2985 - val_loss: 0.6937 - val_mae: 0.7633 - 42ms/epoch - 1ms/step\n",
      "Epoch 2211/5000\n",
      "31/31 - 0s - loss: 2.5920 - mae: 0.9961 - val_loss: 7.1396 - val_mae: 2.6499 - 49ms/epoch - 2ms/step\n",
      "Epoch 2212/5000\n",
      "31/31 - 0s - loss: 2.5235 - mae: 1.2118 - val_loss: 0.6770 - val_mae: 0.7556 - 47ms/epoch - 2ms/step\n",
      "Epoch 2213/5000\n",
      "31/31 - 0s - loss: 15.5489 - mae: 1.9247 - val_loss: 0.1459 - val_mae: 0.3426 - 42ms/epoch - 1ms/step\n",
      "Epoch 2214/5000\n",
      "31/31 - 0s - loss: 0.4797 - mae: 0.5651 - val_loss: 0.9054 - val_mae: 0.8956 - 61ms/epoch - 2ms/step\n",
      "Epoch 2215/5000\n",
      "31/31 - 0s - loss: 13.2664 - mae: 2.0549 - val_loss: 0.4620 - val_mae: 0.5990 - 43ms/epoch - 1ms/step\n",
      "Epoch 2216/5000\n",
      "31/31 - 0s - loss: 1.3375 - mae: 0.8476 - val_loss: 3.9035 - val_mae: 1.9495 - 42ms/epoch - 1ms/step\n",
      "Epoch 2217/5000\n",
      "31/31 - 0s - loss: 17.8763 - mae: 2.1481 - val_loss: 1.6265 - val_mae: 1.2335 - 42ms/epoch - 1ms/step\n",
      "Epoch 2218/5000\n",
      "31/31 - 0s - loss: 1.1660 - mae: 0.8639 - val_loss: 0.1637 - val_mae: 0.2994 - 51ms/epoch - 2ms/step\n",
      "Epoch 2219/5000\n",
      "31/31 - 0s - loss: 22.9784 - mae: 2.3238 - val_loss: 1.1443 - val_mae: 1.0181 - 45ms/epoch - 1ms/step\n",
      "Epoch 2220/5000\n",
      "31/31 - 0s - loss: 2.7638 - mae: 1.2992 - val_loss: 0.1100 - val_mae: 0.2911 - 46ms/epoch - 1ms/step\n",
      "Epoch 2221/5000\n",
      "31/31 - 0s - loss: 18.0295 - mae: 2.2380 - val_loss: 0.2963 - val_mae: 0.4657 - 44ms/epoch - 1ms/step\n",
      "Epoch 2222/5000\n",
      "31/31 - 0s - loss: 1.2293 - mae: 0.8505 - val_loss: 0.1239 - val_mae: 0.3166 - 45ms/epoch - 1ms/step\n",
      "Epoch 2223/5000\n",
      "31/31 - 0s - loss: 7.3464 - mae: 1.9266 - val_loss: 0.3320 - val_mae: 0.4773 - 46ms/epoch - 1ms/step\n",
      "Epoch 2224/5000\n",
      "31/31 - 0s - loss: 1.6462 - mae: 1.1459 - val_loss: 1.8948 - val_mae: 1.3390 - 44ms/epoch - 1ms/step\n",
      "Epoch 2225/5000\n",
      "31/31 - 0s - loss: 14.2272 - mae: 1.9935 - val_loss: 3.8502 - val_mae: 1.9361 - 52ms/epoch - 2ms/step\n",
      "Epoch 2226/5000\n",
      "31/31 - 0s - loss: 1.2197 - mae: 0.9652 - val_loss: 0.2858 - val_mae: 0.4599 - 44ms/epoch - 1ms/step\n",
      "Epoch 2227/5000\n",
      "31/31 - 0s - loss: 18.9793 - mae: 2.0028 - val_loss: 2.3285 - val_mae: 1.4926 - 50ms/epoch - 2ms/step\n",
      "Epoch 2228/5000\n",
      "31/31 - 0s - loss: 1.4995 - mae: 0.9794 - val_loss: 4.9486 - val_mae: 2.2013 - 45ms/epoch - 1ms/step\n",
      "Epoch 2229/5000\n",
      "31/31 - 0s - loss: 9.4256 - mae: 1.9909 - val_loss: 0.5469 - val_mae: 0.6606 - 46ms/epoch - 1ms/step\n",
      "Epoch 2230/5000\n",
      "31/31 - 0s - loss: 1.8122 - mae: 1.1180 - val_loss: 2.2786 - val_mae: 1.4739 - 40ms/epoch - 1ms/step\n",
      "Epoch 2231/5000\n",
      "31/31 - 0s - loss: 18.2526 - mae: 2.3307 - val_loss: 0.4841 - val_mae: 0.6122 - 40ms/epoch - 1ms/step\n",
      "Epoch 2232/5000\n",
      "31/31 - 0s - loss: 1.7854 - mae: 1.0209 - val_loss: 4.8705 - val_mae: 2.1831 - 40ms/epoch - 1ms/step\n",
      "Epoch 2233/5000\n",
      "31/31 - 0s - loss: 6.3624 - mae: 1.7599 - val_loss: 0.1251 - val_mae: 0.2827 - 40ms/epoch - 1ms/step\n",
      "Epoch 2234/5000\n",
      "31/31 - 0s - loss: 11.3153 - mae: 1.6109 - val_loss: 0.5927 - val_mae: 0.6941 - 38ms/epoch - 1ms/step\n",
      "Epoch 2235/5000\n",
      "31/31 - 0s - loss: 1.1792 - mae: 0.8537 - val_loss: 2.9141 - val_mae: 1.6754 - 39ms/epoch - 1ms/step\n",
      "Epoch 2236/5000\n",
      "31/31 - 0s - loss: 16.9429 - mae: 2.0270 - val_loss: 0.2156 - val_mae: 0.3410 - 39ms/epoch - 1ms/step\n",
      "Epoch 2237/5000\n",
      "31/31 - 0s - loss: 0.7084 - mae: 0.6458 - val_loss: 1.9361 - val_mae: 1.3542 - 39ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2238/5000\n",
      "31/31 - 0s - loss: 0.7389 - mae: 0.7144 - val_loss: 1.6649 - val_mae: 1.2468 - 39ms/epoch - 1ms/step\n",
      "Epoch 2239/5000\n",
      "31/31 - 0s - loss: 16.5981 - mae: 2.3102 - val_loss: 7.2701 - val_mae: 2.6757 - 38ms/epoch - 1ms/step\n",
      "Epoch 2240/5000\n",
      "31/31 - 0s - loss: 1.4083 - mae: 0.9375 - val_loss: 21.0761 - val_mae: 4.5806 - 38ms/epoch - 1ms/step\n",
      "Epoch 2241/5000\n",
      "31/31 - 0s - loss: 8.6484 - mae: 2.1729 - val_loss: 1.1432 - val_mae: 1.0127 - 36ms/epoch - 1ms/step\n",
      "Epoch 2242/5000\n",
      "31/31 - 0s - loss: 17.4881 - mae: 2.0981 - val_loss: 0.1171 - val_mae: 0.2817 - 36ms/epoch - 1ms/step\n",
      "Epoch 2243/5000\n",
      "31/31 - 0s - loss: 2.7788 - mae: 1.4247 - val_loss: 0.9818 - val_mae: 0.9361 - 37ms/epoch - 1ms/step\n",
      "Epoch 2244/5000\n",
      "31/31 - 0s - loss: 13.1720 - mae: 2.0638 - val_loss: 0.7582 - val_mae: 0.8105 - 37ms/epoch - 1ms/step\n",
      "Epoch 2245/5000\n",
      "31/31 - 0s - loss: 0.3546 - mae: 0.4782 - val_loss: 0.5125 - val_mae: 0.6353 - 36ms/epoch - 1ms/step\n",
      "Epoch 2246/5000\n",
      "31/31 - 0s - loss: 7.2445 - mae: 1.6572 - val_loss: 1.0580 - val_mae: 0.9735 - 37ms/epoch - 1ms/step\n",
      "Epoch 2247/5000\n",
      "31/31 - 0s - loss: 9.8663 - mae: 1.6080 - val_loss: 0.8138 - val_mae: 0.8488 - 37ms/epoch - 1ms/step\n",
      "Epoch 2248/5000\n",
      "31/31 - 0s - loss: 2.1885 - mae: 0.8847 - val_loss: 0.1163 - val_mae: 0.2995 - 37ms/epoch - 1ms/step\n",
      "Epoch 2249/5000\n",
      "31/31 - 0s - loss: 14.4180 - mae: 2.0245 - val_loss: 0.1126 - val_mae: 0.2925 - 37ms/epoch - 1ms/step\n",
      "Epoch 2250/5000\n",
      "31/31 - 0s - loss: 0.8386 - mae: 0.6881 - val_loss: 0.1131 - val_mae: 0.2903 - 36ms/epoch - 1ms/step\n",
      "Epoch 2251/5000\n",
      "31/31 - 0s - loss: 1.2299 - mae: 0.6640 - val_loss: 34.5424 - val_mae: 5.8673 - 35ms/epoch - 1ms/step\n",
      "Epoch 2252/5000\n",
      "31/31 - 0s - loss: 7.7455 - mae: 1.9798 - val_loss: 1.3918 - val_mae: 1.1334 - 36ms/epoch - 1ms/step\n",
      "Epoch 2253/5000\n",
      "31/31 - 0s - loss: 13.8037 - mae: 1.8638 - val_loss: 0.1195 - val_mae: 0.2856 - 37ms/epoch - 1ms/step\n",
      "Epoch 2254/5000\n",
      "31/31 - 0s - loss: 0.5011 - mae: 0.5564 - val_loss: 0.7709 - val_mae: 0.8149 - 36ms/epoch - 1ms/step\n",
      "Epoch 2255/5000\n",
      "31/31 - 0s - loss: 7.1996 - mae: 1.8594 - val_loss: 0.2016 - val_mae: 0.4001 - 35ms/epoch - 1ms/step\n",
      "Epoch 2256/5000\n",
      "31/31 - 0s - loss: 6.1700 - mae: 1.7832 - val_loss: 0.7060 - val_mae: 0.7738 - 36ms/epoch - 1ms/step\n",
      "Epoch 2257/5000\n",
      "31/31 - 0s - loss: 3.2961 - mae: 1.2574 - val_loss: 0.4547 - val_mae: 0.5884 - 37ms/epoch - 1ms/step\n",
      "Epoch 2258/5000\n",
      "31/31 - 0s - loss: 13.8110 - mae: 1.7552 - val_loss: 0.2301 - val_mae: 0.3603 - 37ms/epoch - 1ms/step\n",
      "Epoch 2259/5000\n",
      "31/31 - 0s - loss: 2.2383 - mae: 1.2322 - val_loss: 0.3668 - val_mae: 0.5152 - 37ms/epoch - 1ms/step\n",
      "Epoch 2260/5000\n",
      "31/31 - 0s - loss: 6.3397 - mae: 1.7264 - val_loss: 12.0928 - val_mae: 3.4622 - 36ms/epoch - 1ms/step\n",
      "Epoch 2261/5000\n",
      "31/31 - 0s - loss: 13.5310 - mae: 2.3715 - val_loss: 0.6689 - val_mae: 0.7530 - 36ms/epoch - 1ms/step\n",
      "Epoch 2262/5000\n",
      "31/31 - 0s - loss: 0.7786 - mae: 0.6653 - val_loss: 0.1401 - val_mae: 0.2826 - 36ms/epoch - 1ms/step\n",
      "Epoch 2263/5000\n",
      "31/31 - 0s - loss: 19.7385 - mae: 2.1212 - val_loss: 0.3387 - val_mae: 0.4845 - 35ms/epoch - 1ms/step\n",
      "Epoch 2264/5000\n",
      "31/31 - 0s - loss: 1.4107 - mae: 0.6990 - val_loss: 0.7222 - val_mae: 0.7843 - 36ms/epoch - 1ms/step\n",
      "Epoch 2265/5000\n",
      "31/31 - 0s - loss: 11.9620 - mae: 2.0538 - val_loss: 0.3051 - val_mae: 0.4505 - 37ms/epoch - 1ms/step\n",
      "Epoch 2266/5000\n",
      "31/31 - 0s - loss: 1.0778 - mae: 0.7410 - val_loss: 0.9913 - val_mae: 0.9433 - 35ms/epoch - 1ms/step\n",
      "Epoch 2267/5000\n",
      "31/31 - 0s - loss: 19.3536 - mae: 2.1994 - val_loss: 0.1927 - val_mae: 0.3261 - 38ms/epoch - 1ms/step\n",
      "Epoch 2268/5000\n",
      "31/31 - 0s - loss: 2.6440 - mae: 1.2194 - val_loss: 1.6502 - val_mae: 1.2399 - 38ms/epoch - 1ms/step\n",
      "Epoch 2269/5000\n",
      "31/31 - 0s - loss: 10.1041 - mae: 2.0686 - val_loss: 0.1110 - val_mae: 0.2877 - 35ms/epoch - 1ms/step\n",
      "Epoch 2270/5000\n",
      "31/31 - 0s - loss: 0.8913 - mae: 0.7849 - val_loss: 0.1262 - val_mae: 0.3156 - 35ms/epoch - 1ms/step\n",
      "Epoch 2271/5000\n",
      "31/31 - 0s - loss: 17.1687 - mae: 1.9865 - val_loss: 0.2293 - val_mae: 0.4227 - 36ms/epoch - 1ms/step\n",
      "Epoch 2272/5000\n",
      "31/31 - 0s - loss: 0.7060 - mae: 0.5884 - val_loss: 0.3403 - val_mae: 0.4841 - 36ms/epoch - 1ms/step\n",
      "Epoch 2273/5000\n",
      "31/31 - 0s - loss: 7.9799 - mae: 1.7098 - val_loss: 0.1653 - val_mae: 0.3673 - 35ms/epoch - 1ms/step\n",
      "Epoch 2274/5000\n",
      "31/31 - 0s - loss: 1.0067 - mae: 0.8081 - val_loss: 2.0906 - val_mae: 1.4054 - 37ms/epoch - 1ms/step\n",
      "Epoch 2275/5000\n",
      "31/31 - 0s - loss: 10.1443 - mae: 1.8840 - val_loss: 4.6644 - val_mae: 2.1344 - 36ms/epoch - 1ms/step\n",
      "Epoch 2276/5000\n",
      "31/31 - 0s - loss: 3.4885 - mae: 1.2612 - val_loss: 45.4161 - val_mae: 6.7304 - 34ms/epoch - 1ms/step\n",
      "Epoch 2277/5000\n",
      "31/31 - 0s - loss: 12.9013 - mae: 1.4883 - val_loss: 0.1460 - val_mae: 0.2826 - 36ms/epoch - 1ms/step\n",
      "Epoch 2278/5000\n",
      "31/31 - 0s - loss: 8.1180 - mae: 1.6457 - val_loss: 16.7609 - val_mae: 4.0819 - 36ms/epoch - 1ms/step\n",
      "Epoch 2279/5000\n",
      "31/31 - 0s - loss: 2.7460 - mae: 1.2119 - val_loss: 2.9500 - val_mae: 1.6873 - 37ms/epoch - 1ms/step\n",
      "Epoch 2280/5000\n",
      "31/31 - 0s - loss: 18.2250 - mae: 2.2355 - val_loss: 0.1377 - val_mae: 0.3276 - 36ms/epoch - 1ms/step\n",
      "Epoch 2281/5000\n",
      "31/31 - 0s - loss: 1.5169 - mae: 1.0151 - val_loss: 1.0426 - val_mae: 0.9660 - 36ms/epoch - 1ms/step\n",
      "Epoch 2282/5000\n",
      "31/31 - 0s - loss: 14.4263 - mae: 2.0666 - val_loss: 0.1596 - val_mae: 0.2958 - 35ms/epoch - 1ms/step\n",
      "Epoch 2283/5000\n",
      "31/31 - 0s - loss: 0.5684 - mae: 0.5441 - val_loss: 0.1275 - val_mae: 0.3217 - 39ms/epoch - 1ms/step\n",
      "Epoch 2284/5000\n",
      "31/31 - 0s - loss: 17.5828 - mae: 1.9559 - val_loss: 2.1017 - val_mae: 1.4177 - 37ms/epoch - 1ms/step\n",
      "Epoch 2285/5000\n",
      "31/31 - 0s - loss: 2.4583 - mae: 1.0160 - val_loss: 2.6139 - val_mae: 1.5843 - 35ms/epoch - 1ms/step\n",
      "Epoch 2286/5000\n",
      "31/31 - 0s - loss: 12.0911 - mae: 1.6072 - val_loss: 0.3567 - val_mae: 0.4992 - 50ms/epoch - 2ms/step\n",
      "Epoch 2287/5000\n",
      "31/31 - 0s - loss: 1.3113 - mae: 0.8881 - val_loss: 0.6747 - val_mae: 0.7549 - 38ms/epoch - 1ms/step\n",
      "Epoch 2288/5000\n",
      "31/31 - 0s - loss: 15.3868 - mae: 2.0784 - val_loss: 0.1123 - val_mae: 0.2887 - 38ms/epoch - 1ms/step\n",
      "Epoch 2289/5000\n",
      "31/31 - 0s - loss: 1.0544 - mae: 0.7904 - val_loss: 2.2420 - val_mae: 1.4609 - 36ms/epoch - 1ms/step\n",
      "Epoch 2290/5000\n",
      "31/31 - 0s - loss: 13.0537 - mae: 2.0290 - val_loss: 0.1517 - val_mae: 0.2990 - 36ms/epoch - 1ms/step\n",
      "Epoch 2291/5000\n",
      "31/31 - 0s - loss: 1.4112 - mae: 0.9957 - val_loss: 0.4922 - val_mae: 0.6217 - 36ms/epoch - 1ms/step\n",
      "Epoch 2292/5000\n",
      "31/31 - 0s - loss: 7.7239 - mae: 1.9511 - val_loss: 0.3404 - val_mae: 0.4856 - 37ms/epoch - 1ms/step\n",
      "Epoch 2293/5000\n",
      "31/31 - 0s - loss: 1.2111 - mae: 0.7199 - val_loss: 270.2836 - val_mae: 16.4365 - 37ms/epoch - 1ms/step\n",
      "Epoch 2294/5000\n",
      "31/31 - 0s - loss: 21.9581 - mae: 2.1048 - val_loss: 8.6663 - val_mae: 2.9259 - 37ms/epoch - 1ms/step\n",
      "Epoch 2295/5000\n",
      "31/31 - 0s - loss: 2.2059 - mae: 1.1989 - val_loss: 1.6354 - val_mae: 1.2355 - 37ms/epoch - 1ms/step\n",
      "Epoch 2296/5000\n",
      "31/31 - 0s - loss: 10.7109 - mae: 1.8513 - val_loss: 1.0172 - val_mae: 0.9542 - 34ms/epoch - 1ms/step\n",
      "Epoch 2297/5000\n",
      "31/31 - 0s - loss: 32.7921 - mae: 1.8534 - val_loss: 27.4712 - val_mae: 5.2315 - 36ms/epoch - 1ms/step\n",
      "Epoch 2298/5000\n",
      "31/31 - 0s - loss: 1.7038 - mae: 0.8921 - val_loss: 0.1260 - val_mae: 0.3166 - 37ms/epoch - 1ms/step\n",
      "Epoch 2299/5000\n",
      "31/31 - 0s - loss: 1.8458 - mae: 0.9660 - val_loss: 0.2992 - val_mae: 0.4678 - 37ms/epoch - 1ms/step\n",
      "Epoch 2300/5000\n",
      "31/31 - 0s - loss: 15.1069 - mae: 2.0599 - val_loss: 0.1880 - val_mae: 0.3262 - 36ms/epoch - 1ms/step\n",
      "Epoch 2301/5000\n",
      "31/31 - 0s - loss: 0.5993 - mae: 0.6063 - val_loss: 4.4278 - val_mae: 2.0789 - 35ms/epoch - 1ms/step\n",
      "Epoch 2302/5000\n",
      "31/31 - 0s - loss: 23.4269 - mae: 2.1292 - val_loss: 0.1529 - val_mae: 0.3516 - 37ms/epoch - 1ms/step\n",
      "Epoch 2303/5000\n",
      "31/31 - 0s - loss: 1.6935 - mae: 1.0104 - val_loss: 7.8052 - val_mae: 2.7749 - 37ms/epoch - 1ms/step\n",
      "Epoch 2304/5000\n",
      "31/31 - 0s - loss: 15.6357 - mae: 2.2174 - val_loss: 0.1632 - val_mae: 0.2991 - 36ms/epoch - 1ms/step\n",
      "Epoch 2305/5000\n",
      "31/31 - 0s - loss: 0.8678 - mae: 0.6836 - val_loss: 0.2734 - val_mae: 0.4525 - 35ms/epoch - 1ms/step\n",
      "Epoch 2306/5000\n",
      "31/31 - 0s - loss: 14.1494 - mae: 1.8651 - val_loss: 0.1242 - val_mae: 0.3002 - 36ms/epoch - 1ms/step\n",
      "Epoch 2307/5000\n",
      "31/31 - 0s - loss: 1.5155 - mae: 0.9129 - val_loss: 0.1276 - val_mae: 0.2884 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2308/5000\n",
      "31/31 - 0s - loss: 0.7149 - mae: 0.7096 - val_loss: 3.2789 - val_mae: 1.7794 - 36ms/epoch - 1ms/step\n",
      "Epoch 2309/5000\n",
      "31/31 - 0s - loss: 15.3446 - mae: 1.9162 - val_loss: 1.0940 - val_mae: 0.9892 - 37ms/epoch - 1ms/step\n",
      "Epoch 2310/5000\n",
      "31/31 - 0s - loss: 17.5162 - mae: 2.1411 - val_loss: 7.1217 - val_mae: 2.6457 - 37ms/epoch - 1ms/step\n",
      "Epoch 2311/5000\n",
      "31/31 - 0s - loss: 2.2938 - mae: 1.2537 - val_loss: 0.1225 - val_mae: 0.3016 - 37ms/epoch - 1ms/step\n",
      "Epoch 2312/5000\n",
      "31/31 - 0s - loss: 1.7038 - mae: 0.9306 - val_loss: 1.0339 - val_mae: 0.9644 - 36ms/epoch - 1ms/step\n",
      "Epoch 2313/5000\n",
      "31/31 - 0s - loss: 14.2245 - mae: 1.8777 - val_loss: 2.2936 - val_mae: 1.4802 - 35ms/epoch - 1ms/step\n",
      "Epoch 2314/5000\n",
      "31/31 - 0s - loss: 1.2845 - mae: 0.8517 - val_loss: 0.7185 - val_mae: 0.7814 - 37ms/epoch - 1ms/step\n",
      "Epoch 2315/5000\n",
      "31/31 - 0s - loss: 20.4123 - mae: 2.1463 - val_loss: 0.4413 - val_mae: 0.5754 - 37ms/epoch - 1ms/step\n",
      "Epoch 2316/5000\n",
      "31/31 - 0s - loss: 1.2814 - mae: 0.9141 - val_loss: 1.1163 - val_mae: 1.0021 - 35ms/epoch - 1ms/step\n",
      "Epoch 2317/5000\n",
      "31/31 - 0s - loss: 6.7473 - mae: 1.5815 - val_loss: 1.0642 - val_mae: 0.9772 - 36ms/epoch - 1ms/step\n",
      "Epoch 2318/5000\n",
      "31/31 - 0s - loss: 12.6652 - mae: 1.8516 - val_loss: 0.4287 - val_mae: 0.5593 - 36ms/epoch - 1ms/step\n",
      "Epoch 2319/5000\n",
      "31/31 - 0s - loss: 0.9853 - mae: 0.8455 - val_loss: 0.3486 - val_mae: 0.4871 - 35ms/epoch - 1ms/step\n",
      "Epoch 2320/5000\n",
      "31/31 - 0s - loss: 13.8270 - mae: 1.8891 - val_loss: 0.1863 - val_mae: 0.3219 - 37ms/epoch - 1ms/step\n",
      "Epoch 2321/5000\n",
      "31/31 - 0s - loss: 0.7487 - mae: 0.5803 - val_loss: 0.1146 - val_mae: 0.2897 - 38ms/epoch - 1ms/step\n",
      "Epoch 2322/5000\n",
      "31/31 - 0s - loss: 6.6898 - mae: 1.7070 - val_loss: 0.7087 - val_mae: 0.7758 - 38ms/epoch - 1ms/step\n",
      "Epoch 2323/5000\n",
      "31/31 - 0s - loss: 1.2670 - mae: 0.9319 - val_loss: 6.7060 - val_mae: 2.5682 - 36ms/epoch - 1ms/step\n",
      "Epoch 2324/5000\n",
      "31/31 - 0s - loss: 5.5280 - mae: 1.6048 - val_loss: 0.1122 - val_mae: 0.2861 - 35ms/epoch - 1ms/step\n",
      "Epoch 2325/5000\n",
      "31/31 - 0s - loss: 32.5027 - mae: 1.8244 - val_loss: 14.1755 - val_mae: 3.7490 - 34ms/epoch - 1ms/step\n",
      "Epoch 2326/5000\n",
      "31/31 - 0s - loss: 1.8351 - mae: 0.9398 - val_loss: 1.0454 - val_mae: 0.9666 - 35ms/epoch - 1ms/step\n",
      "Epoch 2327/5000\n",
      "31/31 - 0s - loss: 5.6662 - mae: 1.8441 - val_loss: 0.4423 - val_mae: 0.5790 - 36ms/epoch - 1ms/step\n",
      "Epoch 2328/5000\n",
      "31/31 - 0s - loss: 0.5848 - mae: 0.6402 - val_loss: 0.2766 - val_mae: 0.4541 - 36ms/epoch - 1ms/step\n",
      "Epoch 2329/5000\n",
      "31/31 - 0s - loss: 12.6818 - mae: 1.9945 - val_loss: 0.2987 - val_mae: 0.4679 - 35ms/epoch - 1ms/step\n",
      "Epoch 2330/5000\n",
      "31/31 - 0s - loss: 1.2435 - mae: 0.8837 - val_loss: 0.7539 - val_mae: 0.8059 - 34ms/epoch - 1ms/step\n",
      "Epoch 2331/5000\n",
      "31/31 - 0s - loss: 8.2597 - mae: 1.8935 - val_loss: 0.3028 - val_mae: 0.4405 - 36ms/epoch - 1ms/step\n",
      "Epoch 2332/5000\n",
      "31/31 - 0s - loss: 10.9571 - mae: 2.0018 - val_loss: 0.6834 - val_mae: 0.7655 - 37ms/epoch - 1ms/step\n",
      "Epoch 2333/5000\n",
      "31/31 - 0s - loss: 0.7665 - mae: 0.6400 - val_loss: 2.8513 - val_mae: 1.6570 - 38ms/epoch - 1ms/step\n",
      "Epoch 2334/5000\n",
      "31/31 - 0s - loss: 13.1864 - mae: 1.9239 - val_loss: 0.1405 - val_mae: 0.2845 - 36ms/epoch - 1ms/step\n",
      "Epoch 2335/5000\n",
      "31/31 - 0s - loss: 2.1532 - mae: 1.0901 - val_loss: 0.9125 - val_mae: 0.8965 - 36ms/epoch - 1ms/step\n",
      "Epoch 2336/5000\n",
      "31/31 - 0s - loss: 8.0928 - mae: 1.8485 - val_loss: 0.1114 - val_mae: 0.2885 - 35ms/epoch - 1ms/step\n",
      "Epoch 2337/5000\n",
      "31/31 - 0s - loss: 0.5859 - mae: 0.5262 - val_loss: 0.2774 - val_mae: 0.4548 - 37ms/epoch - 1ms/step\n",
      "Epoch 2338/5000\n",
      "31/31 - 0s - loss: 15.7781 - mae: 2.1349 - val_loss: 1.0496 - val_mae: 0.9679 - 36ms/epoch - 1ms/step\n",
      "Epoch 2339/5000\n",
      "31/31 - 0s - loss: 5.2764 - mae: 1.8140 - val_loss: 407.0286 - val_mae: 20.1714 - 37ms/epoch - 1ms/step\n",
      "Epoch 2340/5000\n",
      "31/31 - 0s - loss: 18.3952 - mae: 2.1430 - val_loss: 0.1535 - val_mae: 0.2913 - 36ms/epoch - 1ms/step\n",
      "Epoch 2341/5000\n",
      "31/31 - 0s - loss: 1.1086 - mae: 0.8780 - val_loss: 0.3004 - val_mae: 0.4405 - 36ms/epoch - 1ms/step\n",
      "Epoch 2342/5000\n",
      "31/31 - 0s - loss: 19.6672 - mae: 2.1734 - val_loss: 0.5627 - val_mae: 0.6763 - 35ms/epoch - 1ms/step\n",
      "Epoch 2343/5000\n",
      "31/31 - 0s - loss: 0.8253 - mae: 0.6140 - val_loss: 2.6026 - val_mae: 1.5806 - 36ms/epoch - 1ms/step\n",
      "Epoch 2344/5000\n",
      "31/31 - 0s - loss: 2.8726 - mae: 0.8845 - val_loss: 978.7275 - val_mae: 31.2825 - 35ms/epoch - 1ms/step\n",
      "Epoch 2345/5000\n",
      "31/31 - 0s - loss: 36.7394 - mae: 2.3608 - val_loss: 0.1277 - val_mae: 0.2881 - 38ms/epoch - 1ms/step\n",
      "Epoch 2346/5000\n",
      "31/31 - 0s - loss: 2.0268 - mae: 1.2604 - val_loss: 23.2033 - val_mae: 4.8073 - 35ms/epoch - 1ms/step\n",
      "Epoch 2347/5000\n",
      "31/31 - 0s - loss: 2.0204 - mae: 0.9598 - val_loss: 1.1817 - val_mae: 1.0355 - 36ms/epoch - 1ms/step\n",
      "Epoch 2348/5000\n",
      "31/31 - 0s - loss: 13.1884 - mae: 1.8514 - val_loss: 0.1974 - val_mae: 0.3307 - 38ms/epoch - 1ms/step\n",
      "Epoch 2349/5000\n",
      "31/31 - 0s - loss: 1.3196 - mae: 0.9327 - val_loss: 9.4547 - val_mae: 3.0568 - 35ms/epoch - 1ms/step\n",
      "Epoch 2350/5000\n",
      "31/31 - 0s - loss: 10.0315 - mae: 2.0892 - val_loss: 11.1679 - val_mae: 3.3264 - 34ms/epoch - 1ms/step\n",
      "Epoch 2351/5000\n",
      "31/31 - 0s - loss: 29.0237 - mae: 2.3640 - val_loss: 20.2119 - val_mae: 4.4833 - 37ms/epoch - 1ms/step\n",
      "Epoch 2352/5000\n",
      "31/31 - 0s - loss: 1.6176 - mae: 0.9238 - val_loss: 1.7609 - val_mae: 1.2856 - 38ms/epoch - 1ms/step\n",
      "Epoch 2353/5000\n",
      "31/31 - 0s - loss: 0.6089 - mae: 0.6233 - val_loss: 0.1748 - val_mae: 0.3108 - 36ms/epoch - 1ms/step\n",
      "Epoch 2354/5000\n",
      "31/31 - 0s - loss: 20.1807 - mae: 1.9932 - val_loss: 0.3440 - val_mae: 0.4853 - 35ms/epoch - 1ms/step\n",
      "Epoch 2355/5000\n",
      "31/31 - 0s - loss: 3.6299 - mae: 1.4560 - val_loss: 0.1117 - val_mae: 0.2834 - 36ms/epoch - 1ms/step\n",
      "Epoch 2356/5000\n",
      "31/31 - 0s - loss: 16.6198 - mae: 1.9253 - val_loss: 0.5882 - val_mae: 0.6978 - 37ms/epoch - 1ms/step\n",
      "Epoch 2357/5000\n",
      "31/31 - 0s - loss: 1.1623 - mae: 0.9118 - val_loss: 0.1195 - val_mae: 0.3056 - 36ms/epoch - 1ms/step\n",
      "Epoch 2358/5000\n",
      "31/31 - 0s - loss: 12.6313 - mae: 1.8693 - val_loss: 0.1230 - val_mae: 0.2835 - 36ms/epoch - 1ms/step\n",
      "Epoch 2359/5000\n",
      "31/31 - 0s - loss: 0.7335 - mae: 0.7012 - val_loss: 1.5227 - val_mae: 1.1903 - 38ms/epoch - 1ms/step\n",
      "Epoch 2360/5000\n",
      "31/31 - 0s - loss: 12.0033 - mae: 2.0622 - val_loss: 0.7129 - val_mae: 0.7760 - 37ms/epoch - 1ms/step\n",
      "Epoch 2361/5000\n",
      "31/31 - 0s - loss: 1.5512 - mae: 0.9628 - val_loss: 4.6346 - val_mae: 2.1293 - 36ms/epoch - 1ms/step\n",
      "Epoch 2362/5000\n",
      "31/31 - 0s - loss: 15.9504 - mae: 2.1803 - val_loss: 0.2830 - val_mae: 0.4583 - 34ms/epoch - 1ms/step\n",
      "Epoch 2363/5000\n",
      "31/31 - 0s - loss: 2.8565 - mae: 1.3549 - val_loss: 116.5060 - val_mae: 10.7898 - 36ms/epoch - 1ms/step\n",
      "Epoch 2364/5000\n",
      "31/31 - 0s - loss: 7.4938 - mae: 1.8049 - val_loss: 0.4525 - val_mae: 0.5891 - 36ms/epoch - 1ms/step\n",
      "Epoch 2365/5000\n",
      "31/31 - 0s - loss: 7.8134 - mae: 1.8007 - val_loss: 0.4554 - val_mae: 0.5898 - 37ms/epoch - 1ms/step\n",
      "Epoch 2366/5000\n",
      "31/31 - 0s - loss: 0.8598 - mae: 0.7324 - val_loss: 0.1270 - val_mae: 0.3191 - 35ms/epoch - 1ms/step\n",
      "Epoch 2367/5000\n",
      "31/31 - 0s - loss: 14.5486 - mae: 1.8581 - val_loss: 0.5179 - val_mae: 0.6360 - 35ms/epoch - 1ms/step\n",
      "Epoch 2368/5000\n",
      "31/31 - 0s - loss: 0.7963 - mae: 0.6952 - val_loss: 0.4647 - val_mae: 0.6021 - 36ms/epoch - 1ms/step\n",
      "Epoch 2369/5000\n",
      "31/31 - 0s - loss: 14.1045 - mae: 2.1049 - val_loss: 0.1087 - val_mae: 0.2844 - 36ms/epoch - 1ms/step\n",
      "Epoch 2370/5000\n",
      "31/31 - 0s - loss: 0.4216 - mae: 0.4790 - val_loss: 3.3653 - val_mae: 1.8077 - 36ms/epoch - 1ms/step\n",
      "Epoch 2371/5000\n",
      "31/31 - 0s - loss: 18.8649 - mae: 2.0061 - val_loss: 1.8775 - val_mae: 1.3316 - 35ms/epoch - 1ms/step\n",
      "Epoch 2372/5000\n",
      "31/31 - 0s - loss: 1.2277 - mae: 0.9611 - val_loss: 1.4389 - val_mae: 1.1538 - 36ms/epoch - 1ms/step\n",
      "Epoch 2373/5000\n",
      "31/31 - 0s - loss: 13.1310 - mae: 2.0450 - val_loss: 2.2053 - val_mae: 1.4446 - 36ms/epoch - 1ms/step\n",
      "Epoch 2374/5000\n",
      "31/31 - 0s - loss: 2.5103 - mae: 1.3009 - val_loss: 0.4325 - val_mae: 0.5655 - 36ms/epoch - 1ms/step\n",
      "Epoch 2375/5000\n",
      "31/31 - 0s - loss: 18.1894 - mae: 2.6410 - val_loss: 0.1101 - val_mae: 0.2802 - 36ms/epoch - 1ms/step\n",
      "Epoch 2376/5000\n",
      "31/31 - 0s - loss: 1.7479 - mae: 1.1248 - val_loss: 0.1138 - val_mae: 0.2889 - 36ms/epoch - 1ms/step\n",
      "Epoch 2377/5000\n",
      "31/31 - 0s - loss: 10.4304 - mae: 1.9556 - val_loss: 10.0093 - val_mae: 3.1466 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2378/5000\n",
      "31/31 - 0s - loss: 2.8454 - mae: 1.2328 - val_loss: 8.8283 - val_mae: 2.9531 - 36ms/epoch - 1ms/step\n",
      "Epoch 2379/5000\n",
      "31/31 - 0s - loss: 10.9587 - mae: 2.4216 - val_loss: 0.7811 - val_mae: 0.8152 - 38ms/epoch - 1ms/step\n",
      "Epoch 2380/5000\n",
      "31/31 - 0s - loss: 2.6647 - mae: 1.3986 - val_loss: 1.5348 - val_mae: 1.1953 - 36ms/epoch - 1ms/step\n",
      "Epoch 2381/5000\n",
      "31/31 - 0s - loss: 19.6598 - mae: 2.2434 - val_loss: 1.2264 - val_mae: 1.0588 - 34ms/epoch - 1ms/step\n",
      "Epoch 2382/5000\n",
      "31/31 - 0s - loss: 1.2191 - mae: 0.9628 - val_loss: 0.1215 - val_mae: 0.3079 - 36ms/epoch - 1ms/step\n",
      "Epoch 2383/5000\n",
      "31/31 - 0s - loss: 10.4475 - mae: 2.0536 - val_loss: 0.2644 - val_mae: 0.4050 - 38ms/epoch - 1ms/step\n",
      "Epoch 2384/5000\n",
      "31/31 - 0s - loss: 0.7701 - mae: 0.6891 - val_loss: 1.2596 - val_mae: 1.0722 - 37ms/epoch - 1ms/step\n",
      "Epoch 2385/5000\n",
      "31/31 - 0s - loss: 12.8131 - mae: 1.9861 - val_loss: 0.1946 - val_mae: 0.3964 - 37ms/epoch - 1ms/step\n",
      "Epoch 2386/5000\n",
      "31/31 - 0s - loss: 1.0956 - mae: 0.7359 - val_loss: 0.1437 - val_mae: 0.2808 - 36ms/epoch - 1ms/step\n",
      "Epoch 2387/5000\n",
      "31/31 - 0s - loss: 25.5049 - mae: 2.3085 - val_loss: 1.2944 - val_mae: 1.0917 - 49ms/epoch - 2ms/step\n",
      "Epoch 2388/5000\n",
      "31/31 - 0s - loss: 1.4777 - mae: 0.8587 - val_loss: 0.6524 - val_mae: 0.7403 - 38ms/epoch - 1ms/step\n",
      "Epoch 2389/5000\n",
      "31/31 - 0s - loss: 14.0303 - mae: 1.8616 - val_loss: 0.2826 - val_mae: 0.4254 - 37ms/epoch - 1ms/step\n",
      "Epoch 2390/5000\n",
      "31/31 - 0s - loss: 0.8275 - mae: 0.8192 - val_loss: 0.1144 - val_mae: 0.2830 - 36ms/epoch - 1ms/step\n",
      "Epoch 2391/5000\n",
      "31/31 - 0s - loss: 9.8236 - mae: 1.5971 - val_loss: 1.8249 - val_mae: 1.3131 - 36ms/epoch - 1ms/step\n",
      "Epoch 2392/5000\n",
      "31/31 - 0s - loss: 0.8931 - mae: 0.8540 - val_loss: 4.8875 - val_mae: 2.1877 - 36ms/epoch - 1ms/step\n",
      "Epoch 2393/5000\n",
      "31/31 - 0s - loss: 9.4486 - mae: 2.3730 - val_loss: 0.9316 - val_mae: 0.9074 - 37ms/epoch - 1ms/step\n",
      "Epoch 2394/5000\n",
      "31/31 - 0s - loss: 3.1898 - mae: 1.4989 - val_loss: 9.0144 - val_mae: 2.9872 - 36ms/epoch - 1ms/step\n",
      "Epoch 2395/5000\n",
      "31/31 - 0s - loss: 15.1541 - mae: 1.8924 - val_loss: 0.2294 - val_mae: 0.4229 - 36ms/epoch - 1ms/step\n",
      "Epoch 2396/5000\n",
      "31/31 - 0s - loss: 1.2222 - mae: 0.7597 - val_loss: 0.2303 - val_mae: 0.4238 - 37ms/epoch - 1ms/step\n",
      "Epoch 2397/5000\n",
      "31/31 - 0s - loss: 8.3513 - mae: 1.9088 - val_loss: 0.8187 - val_mae: 0.8463 - 37ms/epoch - 1ms/step\n",
      "Epoch 2398/5000\n",
      "31/31 - 0s - loss: 4.6474 - mae: 1.2471 - val_loss: 594.9446 - val_mae: 24.3892 - 37ms/epoch - 1ms/step\n",
      "Epoch 2399/5000\n",
      "31/31 - 0s - loss: 23.1902 - mae: 2.1050 - val_loss: 0.2610 - val_mae: 0.4452 - 37ms/epoch - 1ms/step\n",
      "Epoch 2400/5000\n",
      "31/31 - 0s - loss: 1.6836 - mae: 1.0683 - val_loss: 0.1611 - val_mae: 0.3654 - 35ms/epoch - 1ms/step\n",
      "Epoch 2401/5000\n",
      "31/31 - 0s - loss: 13.2167 - mae: 1.8863 - val_loss: 0.1268 - val_mae: 0.2927 - 36ms/epoch - 1ms/step\n",
      "Epoch 2402/5000\n",
      "31/31 - 0s - loss: 2.7163 - mae: 1.1211 - val_loss: 0.1225 - val_mae: 0.2946 - 36ms/epoch - 1ms/step\n",
      "Epoch 2403/5000\n",
      "31/31 - 0s - loss: 14.4908 - mae: 2.1752 - val_loss: 2.9885 - val_mae: 1.6958 - 37ms/epoch - 1ms/step\n",
      "Epoch 2404/5000\n",
      "31/31 - 0s - loss: 2.0308 - mae: 1.2359 - val_loss: 0.2282 - val_mae: 0.3558 - 34ms/epoch - 1ms/step\n",
      "Epoch 2405/5000\n",
      "31/31 - 0s - loss: 21.7464 - mae: 2.1328 - val_loss: 0.1064 - val_mae: 0.2841 - 36ms/epoch - 1ms/step\n",
      "Epoch 2406/5000\n",
      "31/31 - 0s - loss: 1.1980 - mae: 0.8943 - val_loss: 0.1288 - val_mae: 0.2762 - 37ms/epoch - 1ms/step\n",
      "Epoch 2407/5000\n",
      "31/31 - 0s - loss: 6.0084 - mae: 1.5143 - val_loss: 0.1053 - val_mae: 0.2836 - 35ms/epoch - 1ms/step\n",
      "Epoch 2408/5000\n",
      "31/31 - 0s - loss: 12.1551 - mae: 1.8270 - val_loss: 0.1394 - val_mae: 0.3373 - 37ms/epoch - 1ms/step\n",
      "Epoch 2409/5000\n",
      "31/31 - 0s - loss: 1.0185 - mae: 0.7574 - val_loss: 0.2953 - val_mae: 0.4334 - 37ms/epoch - 1ms/step\n",
      "Epoch 2410/5000\n",
      "31/31 - 0s - loss: 9.2120 - mae: 2.1125 - val_loss: 3.3003 - val_mae: 1.7893 - 36ms/epoch - 1ms/step\n",
      "Epoch 2411/5000\n",
      "31/31 - 0s - loss: 1.3645 - mae: 0.9287 - val_loss: 0.4687 - val_mae: 0.5991 - 36ms/epoch - 1ms/step\n",
      "Epoch 2412/5000\n",
      "31/31 - 0s - loss: 16.1343 - mae: 1.9671 - val_loss: 0.8467 - val_mae: 0.8639 - 35ms/epoch - 1ms/step\n",
      "Epoch 2413/5000\n",
      "31/31 - 0s - loss: 1.5528 - mae: 0.9916 - val_loss: 1.9661 - val_mae: 1.3632 - 36ms/epoch - 1ms/step\n",
      "Epoch 2414/5000\n",
      "31/31 - 0s - loss: 4.8081 - mae: 1.5388 - val_loss: 0.1214 - val_mae: 0.2857 - 36ms/epoch - 1ms/step\n",
      "Epoch 2415/5000\n",
      "31/31 - 0s - loss: 8.0097 - mae: 1.9915 - val_loss: 14.3895 - val_mae: 3.7785 - 37ms/epoch - 1ms/step\n",
      "Epoch 2416/5000\n",
      "31/31 - 0s - loss: 4.0695 - mae: 1.4957 - val_loss: 61.3196 - val_mae: 7.8248 - 36ms/epoch - 1ms/step\n",
      "Epoch 2417/5000\n",
      "31/31 - 0s - loss: 12.0465 - mae: 2.0078 - val_loss: 0.1556 - val_mae: 0.2929 - 35ms/epoch - 1ms/step\n",
      "Epoch 2418/5000\n",
      "31/31 - 0s - loss: 8.4268 - mae: 1.3403 - val_loss: 228.4118 - val_mae: 15.1097 - 36ms/epoch - 1ms/step\n",
      "Epoch 2419/5000\n",
      "31/31 - 0s - loss: 10.1089 - mae: 1.6908 - val_loss: 0.1336 - val_mae: 0.2938 - 37ms/epoch - 1ms/step\n",
      "Epoch 2420/5000\n",
      "31/31 - 0s - loss: 0.7476 - mae: 0.7400 - val_loss: 1.9055 - val_mae: 1.3427 - 37ms/epoch - 1ms/step\n",
      "Epoch 2421/5000\n",
      "31/31 - 0s - loss: 13.2483 - mae: 2.0912 - val_loss: 0.3839 - val_mae: 0.5185 - 36ms/epoch - 1ms/step\n",
      "Epoch 2422/5000\n",
      "31/31 - 0s - loss: 1.4155 - mae: 0.9267 - val_loss: 0.1421 - val_mae: 0.3382 - 36ms/epoch - 1ms/step\n",
      "Epoch 2423/5000\n",
      "31/31 - 0s - loss: 17.0562 - mae: 2.1404 - val_loss: 1.1424 - val_mae: 1.0148 - 35ms/epoch - 1ms/step\n",
      "Epoch 2424/5000\n",
      "31/31 - 0s - loss: 1.0372 - mae: 0.7883 - val_loss: 0.5438 - val_mae: 0.6578 - 38ms/epoch - 1ms/step\n",
      "Epoch 2425/5000\n",
      "31/31 - 0s - loss: 14.0115 - mae: 2.0940 - val_loss: 0.6725 - val_mae: 0.7534 - 35ms/epoch - 1ms/step\n",
      "Epoch 2426/5000\n",
      "31/31 - 0s - loss: 1.7613 - mae: 0.9974 - val_loss: 0.1172 - val_mae: 0.2834 - 36ms/epoch - 1ms/step\n",
      "Epoch 2427/5000\n",
      "31/31 - 0s - loss: 10.8571 - mae: 1.7512 - val_loss: 0.5544 - val_mae: 0.6733 - 38ms/epoch - 1ms/step\n",
      "Epoch 2428/5000\n",
      "31/31 - 0s - loss: 0.4879 - mae: 0.5356 - val_loss: 6.1604 - val_mae: 2.4616 - 38ms/epoch - 1ms/step\n",
      "Epoch 2429/5000\n",
      "31/31 - 0s - loss: 13.5906 - mae: 1.8599 - val_loss: 0.1241 - val_mae: 0.3072 - 35ms/epoch - 1ms/step\n",
      "Epoch 2430/5000\n",
      "31/31 - 0s - loss: 0.8300 - mae: 0.6228 - val_loss: 0.1639 - val_mae: 0.3015 - 36ms/epoch - 1ms/step\n",
      "Epoch 2431/5000\n",
      "31/31 - 0s - loss: 10.7974 - mae: 1.8292 - val_loss: 1.9953 - val_mae: 1.3737 - 37ms/epoch - 1ms/step\n",
      "Epoch 2432/5000\n",
      "31/31 - 0s - loss: 8.0670 - mae: 1.9088 - val_loss: 30.5621 - val_mae: 5.5181 - 36ms/epoch - 1ms/step\n",
      "Epoch 2433/5000\n",
      "31/31 - 0s - loss: 1.8179 - mae: 0.8851 - val_loss: 0.3698 - val_mae: 0.5152 - 34ms/epoch - 1ms/step\n",
      "Epoch 2434/5000\n",
      "31/31 - 0s - loss: 8.8859 - mae: 1.9895 - val_loss: 0.4458 - val_mae: 0.5826 - 36ms/epoch - 1ms/step\n",
      "Epoch 2435/5000\n",
      "31/31 - 0s - loss: 0.4140 - mae: 0.5033 - val_loss: 0.4698 - val_mae: 0.6051 - 36ms/epoch - 1ms/step\n",
      "Epoch 2436/5000\n",
      "31/31 - 0s - loss: 12.8491 - mae: 1.7861 - val_loss: 0.3695 - val_mae: 0.5114 - 36ms/epoch - 1ms/step\n",
      "Epoch 2437/5000\n",
      "31/31 - 0s - loss: 0.8977 - mae: 0.7663 - val_loss: 0.6293 - val_mae: 0.7225 - 35ms/epoch - 1ms/step\n",
      "Epoch 2438/5000\n",
      "31/31 - 0s - loss: 20.1941 - mae: 2.0012 - val_loss: 0.4316 - val_mae: 0.5745 - 36ms/epoch - 1ms/step\n",
      "Epoch 2439/5000\n",
      "31/31 - 0s - loss: 1.2570 - mae: 0.9056 - val_loss: 0.2031 - val_mae: 0.3361 - 36ms/epoch - 1ms/step\n",
      "Epoch 2440/5000\n",
      "31/31 - 0s - loss: 0.8124 - mae: 0.7648 - val_loss: 2.9479 - val_mae: 1.6862 - 37ms/epoch - 1ms/step\n",
      "Epoch 2441/5000\n",
      "31/31 - 0s - loss: 18.6721 - mae: 2.0803 - val_loss: 0.5444 - val_mae: 0.6638 - 37ms/epoch - 1ms/step\n",
      "Epoch 2442/5000\n",
      "31/31 - 0s - loss: 0.7356 - mae: 0.6848 - val_loss: 0.3760 - val_mae: 0.5189 - 36ms/epoch - 1ms/step\n",
      "Epoch 2443/5000\n",
      "31/31 - 0s - loss: 15.5995 - mae: 2.2063 - val_loss: 0.2983 - val_mae: 0.4657 - 36ms/epoch - 1ms/step\n",
      "Epoch 2444/5000\n",
      "31/31 - 0s - loss: 2.4572 - mae: 1.1616 - val_loss: 0.1215 - val_mae: 0.2875 - 36ms/epoch - 1ms/step\n",
      "Epoch 2445/5000\n",
      "31/31 - 0s - loss: 13.3869 - mae: 1.9805 - val_loss: 0.6855 - val_mae: 0.7610 - 36ms/epoch - 1ms/step\n",
      "Epoch 2446/5000\n",
      "31/31 - 0s - loss: 1.1210 - mae: 0.8555 - val_loss: 1.7482 - val_mae: 1.2814 - 36ms/epoch - 1ms/step\n",
      "Epoch 2447/5000\n",
      "31/31 - 0s - loss: 8.8620 - mae: 2.1811 - val_loss: 9.2735 - val_mae: 3.0285 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2448/5000\n",
      "31/31 - 0s - loss: 2.2661 - mae: 1.0175 - val_loss: 3.9948 - val_mae: 1.9693 - 36ms/epoch - 1ms/step\n",
      "Epoch 2449/5000\n",
      "31/31 - 0s - loss: 13.7091 - mae: 1.9362 - val_loss: 3.7177 - val_mae: 1.9021 - 38ms/epoch - 1ms/step\n",
      "Epoch 2450/5000\n",
      "31/31 - 0s - loss: 9.9112 - mae: 2.0455 - val_loss: 0.5399 - val_mae: 0.6572 - 37ms/epoch - 1ms/step\n",
      "Epoch 2451/5000\n",
      "31/31 - 0s - loss: 0.7979 - mae: 0.6952 - val_loss: 0.2132 - val_mae: 0.4111 - 36ms/epoch - 1ms/step\n",
      "Epoch 2452/5000\n",
      "31/31 - 0s - loss: 18.7470 - mae: 1.9824 - val_loss: 4.2094 - val_mae: 2.0261 - 37ms/epoch - 1ms/step\n",
      "Epoch 2453/5000\n",
      "31/31 - 0s - loss: 1.1405 - mae: 0.8915 - val_loss: 2.3712 - val_mae: 1.5045 - 36ms/epoch - 1ms/step\n",
      "Epoch 2454/5000\n",
      "31/31 - 0s - loss: 13.6656 - mae: 2.2509 - val_loss: 2.4431 - val_mae: 1.5284 - 35ms/epoch - 1ms/step\n",
      "Epoch 2455/5000\n",
      "31/31 - 0s - loss: 1.5754 - mae: 0.9752 - val_loss: 0.1410 - val_mae: 0.3404 - 34ms/epoch - 1ms/step\n",
      "Epoch 2456/5000\n",
      "31/31 - 0s - loss: 13.4086 - mae: 2.0576 - val_loss: 0.9517 - val_mae: 0.9169 - 36ms/epoch - 1ms/step\n",
      "Epoch 2457/5000\n",
      "31/31 - 0s - loss: 1.7690 - mae: 1.1156 - val_loss: 3.5583 - val_mae: 1.8598 - 36ms/epoch - 1ms/step\n",
      "Epoch 2458/5000\n",
      "31/31 - 0s - loss: 13.0227 - mae: 1.9666 - val_loss: 0.2030 - val_mae: 0.3379 - 36ms/epoch - 1ms/step\n",
      "Epoch 2459/5000\n",
      "31/31 - 0s - loss: 0.7401 - mae: 0.6874 - val_loss: 0.6274 - val_mae: 0.7220 - 36ms/epoch - 1ms/step\n",
      "Epoch 2460/5000\n",
      "31/31 - 0s - loss: 29.2668 - mae: 2.4005 - val_loss: 6.6868 - val_mae: 2.5660 - 33ms/epoch - 1ms/step\n",
      "Epoch 2461/5000\n",
      "31/31 - 0s - loss: 1.5403 - mae: 1.0361 - val_loss: 2.5050 - val_mae: 1.5488 - 35ms/epoch - 1ms/step\n",
      "Epoch 2462/5000\n",
      "31/31 - 0s - loss: 5.4277 - mae: 1.5673 - val_loss: 0.1998 - val_mae: 0.3339 - 38ms/epoch - 1ms/step\n",
      "Epoch 2463/5000\n",
      "31/31 - 0s - loss: 21.5297 - mae: 2.2277 - val_loss: 0.1148 - val_mae: 0.2989 - 36ms/epoch - 1ms/step\n",
      "Epoch 2464/5000\n",
      "31/31 - 0s - loss: 1.3778 - mae: 0.9440 - val_loss: 0.1074 - val_mae: 0.2856 - 36ms/epoch - 1ms/step\n",
      "Epoch 2465/5000\n",
      "31/31 - 0s - loss: 8.1228 - mae: 1.6228 - val_loss: 1.1815 - val_mae: 1.0351 - 35ms/epoch - 1ms/step\n",
      "Epoch 2466/5000\n",
      "31/31 - 0s - loss: 2.3094 - mae: 1.2075 - val_loss: 0.1460 - val_mae: 0.3487 - 35ms/epoch - 1ms/step\n",
      "Epoch 2467/5000\n",
      "31/31 - 0s - loss: 26.1625 - mae: 2.4113 - val_loss: 0.1123 - val_mae: 0.2824 - 36ms/epoch - 1ms/step\n",
      "Epoch 2468/5000\n",
      "31/31 - 0s - loss: 1.1360 - mae: 0.8727 - val_loss: 0.3765 - val_mae: 0.5222 - 36ms/epoch - 1ms/step\n",
      "Epoch 2469/5000\n",
      "31/31 - 0s - loss: 15.2008 - mae: 2.1732 - val_loss: 0.8230 - val_mae: 0.8507 - 38ms/epoch - 1ms/step\n",
      "Epoch 2470/5000\n",
      "31/31 - 0s - loss: 0.7389 - mae: 0.5866 - val_loss: 0.7081 - val_mae: 0.7774 - 37ms/epoch - 1ms/step\n",
      "Epoch 2471/5000\n",
      "31/31 - 0s - loss: 9.1862 - mae: 1.8784 - val_loss: 0.1019 - val_mae: 0.2810 - 36ms/epoch - 1ms/step\n",
      "Epoch 2472/5000\n",
      "31/31 - 0s - loss: 1.9849 - mae: 1.1936 - val_loss: 0.2153 - val_mae: 0.3437 - 35ms/epoch - 1ms/step\n",
      "Epoch 2473/5000\n",
      "31/31 - 0s - loss: 12.7697 - mae: 1.9725 - val_loss: 0.1202 - val_mae: 0.2949 - 36ms/epoch - 1ms/step\n",
      "Epoch 2474/5000\n",
      "31/31 - 0s - loss: 0.6787 - mae: 0.6407 - val_loss: 0.1150 - val_mae: 0.2985 - 36ms/epoch - 1ms/step\n",
      "Epoch 2475/5000\n",
      "31/31 - 0s - loss: 19.4092 - mae: 2.0002 - val_loss: 0.5593 - val_mae: 0.6698 - 36ms/epoch - 1ms/step\n",
      "Epoch 2476/5000\n",
      "31/31 - 0s - loss: 0.8510 - mae: 0.6891 - val_loss: 2.5348 - val_mae: 1.5584 - 36ms/epoch - 1ms/step\n",
      "Epoch 2477/5000\n",
      "31/31 - 0s - loss: 2.1921 - mae: 0.9223 - val_loss: 3.8244 - val_mae: 1.9293 - 36ms/epoch - 1ms/step\n",
      "Epoch 2478/5000\n",
      "31/31 - 0s - loss: 6.3408 - mae: 1.5403 - val_loss: 1.0211 - val_mae: 0.9574 - 36ms/epoch - 1ms/step\n",
      "Epoch 2479/5000\n",
      "31/31 - 0s - loss: 10.1301 - mae: 1.6284 - val_loss: 0.5695 - val_mae: 0.6842 - 37ms/epoch - 1ms/step\n",
      "Epoch 2480/5000\n",
      "31/31 - 0s - loss: 1.9793 - mae: 1.1077 - val_loss: 0.1292 - val_mae: 0.3241 - 36ms/epoch - 1ms/step\n",
      "Epoch 2481/5000\n",
      "31/31 - 0s - loss: 13.5716 - mae: 2.1766 - val_loss: 0.1145 - val_mae: 0.2907 - 37ms/epoch - 1ms/step\n",
      "Epoch 2482/5000\n",
      "31/31 - 0s - loss: 1.5401 - mae: 0.9029 - val_loss: 2.4893 - val_mae: 1.5432 - 35ms/epoch - 1ms/step\n",
      "Epoch 2483/5000\n",
      "31/31 - 0s - loss: 4.9224 - mae: 1.7153 - val_loss: 0.1107 - val_mae: 0.2914 - 36ms/epoch - 1ms/step\n",
      "Epoch 2484/5000\n",
      "31/31 - 0s - loss: 16.3816 - mae: 2.3525 - val_loss: 0.2308 - val_mae: 0.3562 - 36ms/epoch - 1ms/step\n",
      "Epoch 2485/5000\n",
      "31/31 - 0s - loss: 0.9801 - mae: 0.6220 - val_loss: 0.2206 - val_mae: 0.3489 - 36ms/epoch - 1ms/step\n",
      "Epoch 2486/5000\n",
      "31/31 - 0s - loss: 0.5513 - mae: 0.6315 - val_loss: 2.3790 - val_mae: 1.5085 - 42ms/epoch - 1ms/step\n",
      "Epoch 2487/5000\n",
      "31/31 - 0s - loss: 24.6237 - mae: 2.7487 - val_loss: 0.4289 - val_mae: 0.5728 - 36ms/epoch - 1ms/step\n",
      "Epoch 2488/5000\n",
      "31/31 - 0s - loss: 2.3020 - mae: 1.0688 - val_loss: 15.6452 - val_mae: 3.9425 - 36ms/epoch - 1ms/step\n",
      "Epoch 2489/5000\n",
      "31/31 - 0s - loss: 17.7878 - mae: 2.1932 - val_loss: 0.1940 - val_mae: 0.3317 - 36ms/epoch - 1ms/step\n",
      "Epoch 2490/5000\n",
      "31/31 - 0s - loss: 1.7417 - mae: 1.0331 - val_loss: 1.8402 - val_mae: 1.3183 - 36ms/epoch - 1ms/step\n",
      "Epoch 2491/5000\n",
      "31/31 - 0s - loss: 13.5609 - mae: 1.8799 - val_loss: 51.1864 - val_mae: 7.1465 - 38ms/epoch - 1ms/step\n",
      "Epoch 2492/5000\n",
      "31/31 - 0s - loss: 3.6825 - mae: 1.2395 - val_loss: 0.8762 - val_mae: 0.8776 - 36ms/epoch - 1ms/step\n",
      "Epoch 2493/5000\n",
      "31/31 - 0s - loss: 12.0010 - mae: 1.7787 - val_loss: 0.4871 - val_mae: 0.6235 - 36ms/epoch - 1ms/step\n",
      "Epoch 2494/5000\n",
      "31/31 - 0s - loss: 1.5612 - mae: 1.0229 - val_loss: 0.1873 - val_mae: 0.3900 - 36ms/epoch - 1ms/step\n",
      "Epoch 2495/5000\n",
      "31/31 - 0s - loss: 7.1414 - mae: 1.5520 - val_loss: 0.3137 - val_mae: 0.4751 - 34ms/epoch - 1ms/step\n",
      "Epoch 2496/5000\n",
      "31/31 - 0s - loss: 1.4783 - mae: 0.9545 - val_loss: 63.8096 - val_mae: 7.9808 - 36ms/epoch - 1ms/step\n",
      "Epoch 2497/5000\n",
      "31/31 - 0s - loss: 13.0268 - mae: 2.2533 - val_loss: 0.1151 - val_mae: 0.2976 - 50ms/epoch - 2ms/step\n",
      "Epoch 2498/5000\n",
      "31/31 - 0s - loss: 7.5257 - mae: 2.0278 - val_loss: 6.7351 - val_mae: 2.5728 - 39ms/epoch - 1ms/step\n",
      "Epoch 2499/5000\n",
      "31/31 - 0s - loss: 5.2878 - mae: 1.7848 - val_loss: 0.1350 - val_mae: 0.2846 - 36ms/epoch - 1ms/step\n",
      "Epoch 2500/5000\n",
      "31/31 - 0s - loss: 8.2407 - mae: 1.6089 - val_loss: 178.3262 - val_mae: 13.3497 - 35ms/epoch - 1ms/step\n",
      "Epoch 2501/5000\n",
      "31/31 - 0s - loss: 7.7444 - mae: 1.2065 - val_loss: 0.1660 - val_mae: 0.3014 - 36ms/epoch - 1ms/step\n",
      "Epoch 2502/5000\n",
      "31/31 - 0s - loss: 12.6812 - mae: 1.9413 - val_loss: 0.1485 - val_mae: 0.2836 - 37ms/epoch - 1ms/step\n",
      "Epoch 2503/5000\n",
      "31/31 - 0s - loss: 0.6138 - mae: 0.6186 - val_loss: 1.8380 - val_mae: 1.3173 - 38ms/epoch - 1ms/step\n",
      "Epoch 2504/5000\n",
      "31/31 - 0s - loss: 1.7292 - mae: 1.0335 - val_loss: 849.3197 - val_mae: 29.1413 - 36ms/epoch - 1ms/step\n",
      "Epoch 2505/5000\n",
      "31/31 - 0s - loss: 29.3381 - mae: 2.1671 - val_loss: 0.3568 - val_mae: 0.4995 - 36ms/epoch - 1ms/step\n",
      "Epoch 2506/5000\n",
      "31/31 - 0s - loss: 2.2530 - mae: 1.1289 - val_loss: 2.1746 - val_mae: 1.4365 - 37ms/epoch - 1ms/step\n",
      "Epoch 2507/5000\n",
      "31/31 - 0s - loss: 4.4804 - mae: 1.4579 - val_loss: 6.1836 - val_mae: 2.4661 - 35ms/epoch - 1ms/step\n",
      "Epoch 2508/5000\n",
      "31/31 - 0s - loss: 1.1748 - mae: 0.8377 - val_loss: 0.1518 - val_mae: 0.2874 - 35ms/epoch - 1ms/step\n",
      "Epoch 2509/5000\n",
      "31/31 - 0s - loss: 22.6317 - mae: 2.0104 - val_loss: 0.1534 - val_mae: 0.2944 - 34ms/epoch - 1ms/step\n",
      "Epoch 2510/5000\n",
      "31/31 - 0s - loss: 1.1891 - mae: 0.8195 - val_loss: 0.7716 - val_mae: 0.8146 - 36ms/epoch - 1ms/step\n",
      "Epoch 2511/5000\n",
      "31/31 - 0s - loss: 15.5484 - mae: 2.0823 - val_loss: 0.1109 - val_mae: 0.2880 - 35ms/epoch - 1ms/step\n",
      "Epoch 2512/5000\n",
      "31/31 - 0s - loss: 0.7374 - mae: 0.6438 - val_loss: 2.1602 - val_mae: 1.4318 - 35ms/epoch - 1ms/step\n",
      "Epoch 2513/5000\n",
      "31/31 - 0s - loss: 13.1909 - mae: 1.8644 - val_loss: 0.3210 - val_mae: 0.4657 - 36ms/epoch - 1ms/step\n",
      "Epoch 2514/5000\n",
      "31/31 - 0s - loss: 1.3780 - mae: 0.9238 - val_loss: 1.7586 - val_mae: 1.2852 - 36ms/epoch - 1ms/step\n",
      "Epoch 2515/5000\n",
      "31/31 - 0s - loss: 12.0045 - mae: 1.8776 - val_loss: 1.7045 - val_mae: 1.2630 - 36ms/epoch - 1ms/step\n",
      "Epoch 2516/5000\n",
      "31/31 - 0s - loss: 1.0149 - mae: 0.8631 - val_loss: 0.1711 - val_mae: 0.3085 - 35ms/epoch - 1ms/step\n",
      "Epoch 2517/5000\n",
      "31/31 - 0s - loss: 11.4892 - mae: 2.0654 - val_loss: 0.1093 - val_mae: 0.2987 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2518/5000\n",
      "31/31 - 0s - loss: 3.1054 - mae: 1.2779 - val_loss: 2.8817 - val_mae: 1.6649 - 36ms/epoch - 1ms/step\n",
      "Epoch 2519/5000\n",
      "31/31 - 0s - loss: 11.4742 - mae: 2.0993 - val_loss: 0.2997 - val_mae: 0.4668 - 35ms/epoch - 1ms/step\n",
      "Epoch 2520/5000\n",
      "31/31 - 0s - loss: 1.2111 - mae: 0.8929 - val_loss: 1.4634 - val_mae: 1.1636 - 36ms/epoch - 1ms/step\n",
      "Epoch 2521/5000\n",
      "31/31 - 0s - loss: 15.9806 - mae: 2.1936 - val_loss: 6.6612 - val_mae: 2.5603 - 37ms/epoch - 1ms/step\n",
      "Epoch 2522/5000\n",
      "31/31 - 0s - loss: 2.8006 - mae: 1.3522 - val_loss: 0.6466 - val_mae: 0.7313 - 37ms/epoch - 1ms/step\n",
      "Epoch 2523/5000\n",
      "31/31 - 0s - loss: 16.4459 - mae: 2.3296 - val_loss: 41.0888 - val_mae: 6.4019 - 38ms/epoch - 1ms/step\n",
      "Epoch 2524/5000\n",
      "31/31 - 0s - loss: 2.5624 - mae: 1.1214 - val_loss: 0.5195 - val_mae: 0.6445 - 36ms/epoch - 1ms/step\n",
      "Epoch 2525/5000\n",
      "31/31 - 0s - loss: 28.6222 - mae: 2.3352 - val_loss: 0.7629 - val_mae: 0.8111 - 36ms/epoch - 1ms/step\n",
      "Epoch 2526/5000\n",
      "31/31 - 0s - loss: 2.2113 - mae: 0.9245 - val_loss: 0.7375 - val_mae: 0.7916 - 36ms/epoch - 1ms/step\n",
      "Epoch 2527/5000\n",
      "31/31 - 0s - loss: 1.3399 - mae: 0.8664 - val_loss: 6.0810 - val_mae: 2.4423 - 37ms/epoch - 1ms/step\n",
      "Epoch 2528/5000\n",
      "31/31 - 0s - loss: 6.5426 - mae: 1.7817 - val_loss: 2.0229 - val_mae: 1.3844 - 37ms/epoch - 1ms/step\n",
      "Epoch 2529/5000\n",
      "31/31 - 0s - loss: 8.5999 - mae: 1.6791 - val_loss: 8.8178 - val_mae: 2.9533 - 37ms/epoch - 1ms/step\n",
      "Epoch 2530/5000\n",
      "31/31 - 0s - loss: 1.4662 - mae: 0.9726 - val_loss: 5.0224 - val_mae: 2.2145 - 37ms/epoch - 1ms/step\n",
      "Epoch 2531/5000\n",
      "31/31 - 0s - loss: 10.0609 - mae: 2.0087 - val_loss: 0.1710 - val_mae: 0.3746 - 36ms/epoch - 1ms/step\n",
      "Epoch 2532/5000\n",
      "31/31 - 0s - loss: 7.7879 - mae: 1.7518 - val_loss: 38.3184 - val_mae: 6.1824 - 36ms/epoch - 1ms/step\n",
      "Epoch 2533/5000\n",
      "31/31 - 0s - loss: 2.0933 - mae: 1.0887 - val_loss: 4.6980 - val_mae: 2.1438 - 37ms/epoch - 1ms/step\n",
      "Epoch 2534/5000\n",
      "31/31 - 0s - loss: 7.2185 - mae: 1.6203 - val_loss: 0.7322 - val_mae: 0.7906 - 36ms/epoch - 1ms/step\n",
      "Epoch 2535/5000\n",
      "31/31 - 0s - loss: 1.0975 - mae: 0.7174 - val_loss: 1.0762 - val_mae: 0.9870 - 36ms/epoch - 1ms/step\n",
      "Epoch 2536/5000\n",
      "31/31 - 0s - loss: 9.7412 - mae: 2.0392 - val_loss: 0.8457 - val_mae: 0.8587 - 37ms/epoch - 1ms/step\n",
      "Epoch 2537/5000\n",
      "31/31 - 0s - loss: 12.9796 - mae: 1.7570 - val_loss: 48.9998 - val_mae: 6.9915 - 35ms/epoch - 1ms/step\n",
      "Epoch 2538/5000\n",
      "31/31 - 0s - loss: 3.8716 - mae: 1.2144 - val_loss: 0.3665 - val_mae: 0.5077 - 35ms/epoch - 1ms/step\n",
      "Epoch 2539/5000\n",
      "31/31 - 0s - loss: 0.7544 - mae: 0.6266 - val_loss: 0.1314 - val_mae: 0.2908 - 35ms/epoch - 1ms/step\n",
      "Epoch 2540/5000\n",
      "31/31 - 0s - loss: 20.1642 - mae: 2.3901 - val_loss: 0.1603 - val_mae: 0.2997 - 36ms/epoch - 1ms/step\n",
      "Epoch 2541/5000\n",
      "31/31 - 0s - loss: 2.2593 - mae: 1.1259 - val_loss: 1.2789 - val_mae: 1.0800 - 37ms/epoch - 1ms/step\n",
      "Epoch 2542/5000\n",
      "31/31 - 0s - loss: 6.0794 - mae: 1.8497 - val_loss: 1.5023 - val_mae: 1.1803 - 37ms/epoch - 1ms/step\n",
      "Epoch 2543/5000\n",
      "31/31 - 0s - loss: 17.0664 - mae: 2.1255 - val_loss: 2.1011 - val_mae: 1.4136 - 37ms/epoch - 1ms/step\n",
      "Epoch 2544/5000\n",
      "31/31 - 0s - loss: 1.4024 - mae: 0.8530 - val_loss: 0.5275 - val_mae: 0.6489 - 36ms/epoch - 1ms/step\n",
      "Epoch 2545/5000\n",
      "31/31 - 0s - loss: 1.4364 - mae: 0.8246 - val_loss: 51.9196 - val_mae: 7.1995 - 36ms/epoch - 1ms/step\n",
      "Epoch 2546/5000\n",
      "31/31 - 0s - loss: 18.2470 - mae: 2.0809 - val_loss: 2.3684 - val_mae: 1.5045 - 35ms/epoch - 1ms/step\n",
      "Epoch 2547/5000\n",
      "31/31 - 0s - loss: 1.3137 - mae: 0.8918 - val_loss: 0.2967 - val_mae: 0.4397 - 36ms/epoch - 1ms/step\n",
      "Epoch 2548/5000\n",
      "31/31 - 0s - loss: 10.9106 - mae: 1.9401 - val_loss: 0.2447 - val_mae: 0.4335 - 36ms/epoch - 1ms/step\n",
      "Epoch 2549/5000\n",
      "31/31 - 0s - loss: 16.8778 - mae: 2.2575 - val_loss: 2.3715 - val_mae: 1.5066 - 36ms/epoch - 1ms/step\n",
      "Epoch 2550/5000\n",
      "31/31 - 0s - loss: 2.0086 - mae: 1.0124 - val_loss: 0.1564 - val_mae: 0.2928 - 37ms/epoch - 1ms/step\n",
      "Epoch 2551/5000\n",
      "31/31 - 0s - loss: 14.5728 - mae: 1.9788 - val_loss: 0.1106 - val_mae: 0.2904 - 38ms/epoch - 1ms/step\n",
      "Epoch 2552/5000\n",
      "31/31 - 0s - loss: 1.0296 - mae: 0.7480 - val_loss: 1.9033 - val_mae: 1.3429 - 37ms/epoch - 1ms/step\n",
      "Epoch 2553/5000\n",
      "31/31 - 0s - loss: 20.0464 - mae: 2.2019 - val_loss: 0.4454 - val_mae: 0.5801 - 36ms/epoch - 1ms/step\n",
      "Epoch 2554/5000\n",
      "31/31 - 0s - loss: 1.0521 - mae: 0.6986 - val_loss: 0.5674 - val_mae: 0.6784 - 35ms/epoch - 1ms/step\n",
      "Epoch 2555/5000\n",
      "31/31 - 0s - loss: 1.7771 - mae: 0.9760 - val_loss: 126.6403 - val_mae: 11.2476 - 37ms/epoch - 1ms/step\n",
      "Epoch 2556/5000\n",
      "31/31 - 0s - loss: 18.0581 - mae: 2.1082 - val_loss: 1.2500 - val_mae: 1.0737 - 36ms/epoch - 1ms/step\n",
      "Epoch 2557/5000\n",
      "31/31 - 0s - loss: 1.5197 - mae: 0.9402 - val_loss: 0.9245 - val_mae: 0.9009 - 38ms/epoch - 1ms/step\n",
      "Epoch 2558/5000\n",
      "31/31 - 0s - loss: 10.3559 - mae: 2.0633 - val_loss: 1.8645 - val_mae: 1.3254 - 36ms/epoch - 1ms/step\n",
      "Epoch 2559/5000\n",
      "31/31 - 0s - loss: 11.9958 - mae: 2.0207 - val_loss: 2.0525 - val_mae: 1.3983 - 38ms/epoch - 1ms/step\n",
      "Epoch 2560/5000\n",
      "31/31 - 0s - loss: 1.4123 - mae: 0.9891 - val_loss: 0.9749 - val_mae: 0.9350 - 38ms/epoch - 1ms/step\n",
      "Epoch 2561/5000\n",
      "31/31 - 0s - loss: 14.8819 - mae: 1.9487 - val_loss: 0.1380 - val_mae: 0.2855 - 38ms/epoch - 1ms/step\n",
      "Epoch 2562/5000\n",
      "31/31 - 0s - loss: 0.6646 - mae: 0.6013 - val_loss: 0.1976 - val_mae: 0.3988 - 38ms/epoch - 1ms/step\n",
      "Epoch 2563/5000\n",
      "31/31 - 0s - loss: 21.5479 - mae: 1.9253 - val_loss: 41.1705 - val_mae: 6.4084 - 38ms/epoch - 1ms/step\n",
      "Epoch 2564/5000\n",
      "31/31 - 0s - loss: 2.9258 - mae: 1.3075 - val_loss: 0.1354 - val_mae: 0.2827 - 36ms/epoch - 1ms/step\n",
      "Epoch 2565/5000\n",
      "31/31 - 0s - loss: 1.4291 - mae: 0.8863 - val_loss: 6.4812 - val_mae: 2.5261 - 37ms/epoch - 1ms/step\n",
      "Epoch 2566/5000\n",
      "31/31 - 0s - loss: 17.1413 - mae: 2.1302 - val_loss: 0.1398 - val_mae: 0.2820 - 36ms/epoch - 1ms/step\n",
      "Epoch 2567/5000\n",
      "31/31 - 0s - loss: 1.1809 - mae: 0.7873 - val_loss: 0.3570 - val_mae: 0.5040 - 37ms/epoch - 1ms/step\n",
      "Epoch 2568/5000\n",
      "31/31 - 0s - loss: 22.7482 - mae: 2.3467 - val_loss: 2.4067 - val_mae: 1.5152 - 34ms/epoch - 1ms/step\n",
      "Epoch 2569/5000\n",
      "31/31 - 0s - loss: 2.2338 - mae: 1.0980 - val_loss: 9.9006 - val_mae: 3.1296 - 37ms/epoch - 1ms/step\n",
      "Epoch 2570/5000\n",
      "31/31 - 0s - loss: 8.7372 - mae: 1.8548 - val_loss: 0.2332 - val_mae: 0.4258 - 36ms/epoch - 1ms/step\n",
      "Epoch 2571/5000\n",
      "31/31 - 0s - loss: 11.2503 - mae: 1.7243 - val_loss: 0.1487 - val_mae: 0.3537 - 36ms/epoch - 1ms/step\n",
      "Epoch 2572/5000\n",
      "31/31 - 0s - loss: 3.1748 - mae: 1.4832 - val_loss: 3.4750 - val_mae: 1.8367 - 36ms/epoch - 1ms/step\n",
      "Epoch 2573/5000\n",
      "31/31 - 0s - loss: 1.7345 - mae: 0.9466 - val_loss: 5.3607 - val_mae: 2.2903 - 35ms/epoch - 1ms/step\n",
      "Epoch 2574/5000\n",
      "31/31 - 0s - loss: 24.2020 - mae: 2.0950 - val_loss: 2.0052 - val_mae: 1.3781 - 38ms/epoch - 1ms/step\n",
      "Epoch 2575/5000\n",
      "31/31 - 0s - loss: 3.3338 - mae: 1.3135 - val_loss: 10.7902 - val_mae: 3.2665 - 37ms/epoch - 1ms/step\n",
      "Epoch 2576/5000\n",
      "31/31 - 0s - loss: 6.7570 - mae: 1.5045 - val_loss: 0.1102 - val_mae: 0.2877 - 36ms/epoch - 1ms/step\n",
      "Epoch 2577/5000\n",
      "31/31 - 0s - loss: 8.7789 - mae: 1.6520 - val_loss: 26.3971 - val_mae: 5.1263 - 34ms/epoch - 1ms/step\n",
      "Epoch 2578/5000\n",
      "31/31 - 0s - loss: 3.3556 - mae: 1.0272 - val_loss: 5.5126 - val_mae: 2.3244 - 36ms/epoch - 1ms/step\n",
      "Epoch 2579/5000\n",
      "31/31 - 0s - loss: 2.2465 - mae: 1.1416 - val_loss: 5.4976 - val_mae: 2.3238 - 35ms/epoch - 1ms/step\n",
      "Epoch 2580/5000\n",
      "31/31 - 0s - loss: 4.2988 - mae: 1.4299 - val_loss: 0.1048 - val_mae: 0.2796 - 37ms/epoch - 1ms/step\n",
      "Epoch 2581/5000\n",
      "31/31 - 0s - loss: 12.7047 - mae: 1.7971 - val_loss: 0.7337 - val_mae: 0.7873 - 36ms/epoch - 1ms/step\n",
      "Epoch 2582/5000\n",
      "31/31 - 0s - loss: 2.3320 - mae: 1.2017 - val_loss: 18.1863 - val_mae: 4.2529 - 37ms/epoch - 1ms/step\n",
      "Epoch 2583/5000\n",
      "31/31 - 0s - loss: 5.4799 - mae: 1.7313 - val_loss: 0.1814 - val_mae: 0.3180 - 36ms/epoch - 1ms/step\n",
      "Epoch 2584/5000\n",
      "31/31 - 0s - loss: 12.3463 - mae: 2.0409 - val_loss: 2.0809 - val_mae: 1.4005 - 36ms/epoch - 1ms/step\n",
      "Epoch 2585/5000\n",
      "31/31 - 0s - loss: 2.3768 - mae: 1.2038 - val_loss: 1.4733 - val_mae: 1.1682 - 36ms/epoch - 1ms/step\n",
      "Epoch 2586/5000\n",
      "31/31 - 0s - loss: 16.8908 - mae: 2.0934 - val_loss: 0.1964 - val_mae: 0.3356 - 36ms/epoch - 1ms/step\n",
      "Epoch 2587/5000\n",
      "31/31 - 0s - loss: 1.1553 - mae: 0.8759 - val_loss: 2.4301 - val_mae: 1.5250 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2588/5000\n",
      "31/31 - 0s - loss: 11.4512 - mae: 1.8768 - val_loss: 0.1660 - val_mae: 0.3668 - 37ms/epoch - 1ms/step\n",
      "Epoch 2589/5000\n",
      "31/31 - 0s - loss: 3.0650 - mae: 1.4344 - val_loss: 0.3963 - val_mae: 0.5306 - 35ms/epoch - 1ms/step\n",
      "Epoch 2590/5000\n",
      "31/31 - 0s - loss: 16.0853 - mae: 2.2788 - val_loss: 0.3106 - val_mae: 0.4529 - 35ms/epoch - 1ms/step\n",
      "Epoch 2591/5000\n",
      "31/31 - 0s - loss: 1.6693 - mae: 0.8749 - val_loss: 0.4011 - val_mae: 0.5448 - 36ms/epoch - 1ms/step\n",
      "Epoch 2592/5000\n",
      "31/31 - 0s - loss: 9.4905 - mae: 2.0060 - val_loss: 0.1451 - val_mae: 0.2874 - 37ms/epoch - 1ms/step\n",
      "Epoch 2593/5000\n",
      "31/31 - 0s - loss: 0.5841 - mae: 0.5523 - val_loss: 0.7168 - val_mae: 0.7823 - 36ms/epoch - 1ms/step\n",
      "Epoch 2594/5000\n",
      "31/31 - 0s - loss: 14.5503 - mae: 1.8439 - val_loss: 10.8187 - val_mae: 3.2735 - 35ms/epoch - 1ms/step\n",
      "Epoch 2595/5000\n",
      "31/31 - 0s - loss: 3.4082 - mae: 1.4777 - val_loss: 6.6780 - val_mae: 2.5649 - 36ms/epoch - 1ms/step\n",
      "Epoch 2596/5000\n",
      "31/31 - 0s - loss: 10.1396 - mae: 1.7581 - val_loss: 1.5490 - val_mae: 1.2012 - 37ms/epoch - 1ms/step\n",
      "Epoch 2597/5000\n",
      "31/31 - 0s - loss: 0.7262 - mae: 0.6818 - val_loss: 0.1106 - val_mae: 0.2854 - 36ms/epoch - 1ms/step\n",
      "Epoch 2598/5000\n",
      "31/31 - 0s - loss: 33.7370 - mae: 2.3569 - val_loss: 5.7769 - val_mae: 2.3796 - 35ms/epoch - 1ms/step\n",
      "Epoch 2599/5000\n",
      "31/31 - 0s - loss: 1.9007 - mae: 1.0277 - val_loss: 1.9393 - val_mae: 1.3551 - 36ms/epoch - 1ms/step\n",
      "Epoch 2600/5000\n",
      "31/31 - 0s - loss: 6.1553 - mae: 1.4610 - val_loss: 5.6497 - val_mae: 2.3533 - 49ms/epoch - 2ms/step\n",
      "Epoch 2601/5000\n",
      "31/31 - 0s - loss: 10.1648 - mae: 1.7363 - val_loss: 27.3718 - val_mae: 5.2217 - 37ms/epoch - 1ms/step\n",
      "Epoch 2602/5000\n",
      "31/31 - 0s - loss: 2.8318 - mae: 1.1362 - val_loss: 0.5851 - val_mae: 0.6923 - 35ms/epoch - 1ms/step\n",
      "Epoch 2603/5000\n",
      "31/31 - 0s - loss: 5.2100 - mae: 1.2780 - val_loss: 5.2609 - val_mae: 2.2669 - 35ms/epoch - 1ms/step\n",
      "Epoch 2604/5000\n",
      "31/31 - 0s - loss: 6.7703 - mae: 1.7856 - val_loss: 0.8461 - val_mae: 0.8626 - 36ms/epoch - 1ms/step\n",
      "Epoch 2605/5000\n",
      "31/31 - 0s - loss: 17.6507 - mae: 2.1824 - val_loss: 0.1948 - val_mae: 0.3254 - 38ms/epoch - 1ms/step\n",
      "Epoch 2606/5000\n",
      "31/31 - 0s - loss: 2.2487 - mae: 1.1509 - val_loss: 0.9398 - val_mae: 0.9125 - 36ms/epoch - 1ms/step\n",
      "Epoch 2607/5000\n",
      "31/31 - 0s - loss: 21.9778 - mae: 2.2299 - val_loss: 3.3187 - val_mae: 1.7930 - 35ms/epoch - 1ms/step\n",
      "Epoch 2608/5000\n",
      "31/31 - 0s - loss: 0.9144 - mae: 0.7238 - val_loss: 0.1092 - val_mae: 0.2838 - 34ms/epoch - 1ms/step\n",
      "Epoch 2609/5000\n",
      "31/31 - 0s - loss: 0.7976 - mae: 0.7030 - val_loss: 0.3161 - val_mae: 0.4574 - 35ms/epoch - 1ms/step\n",
      "Epoch 2610/5000\n",
      "31/31 - 0s - loss: 17.8411 - mae: 2.2970 - val_loss: 0.9962 - val_mae: 0.9389 - 36ms/epoch - 1ms/step\n",
      "Epoch 2611/5000\n",
      "31/31 - 0s - loss: 10.0567 - mae: 2.1944 - val_loss: 0.1124 - val_mae: 0.2877 - 37ms/epoch - 1ms/step\n",
      "Epoch 2612/5000\n",
      "31/31 - 0s - loss: 0.4331 - mae: 0.5779 - val_loss: 1.1517 - val_mae: 1.0210 - 38ms/epoch - 1ms/step\n",
      "Epoch 2613/5000\n",
      "31/31 - 0s - loss: 10.9398 - mae: 1.9545 - val_loss: 5.2768 - val_mae: 2.2729 - 36ms/epoch - 1ms/step\n",
      "Epoch 2614/5000\n",
      "31/31 - 0s - loss: 2.0993 - mae: 1.1616 - val_loss: 7.5844 - val_mae: 2.7329 - 36ms/epoch - 1ms/step\n",
      "Epoch 2615/5000\n",
      "31/31 - 0s - loss: 5.7061 - mae: 1.7328 - val_loss: 0.3734 - val_mae: 0.5154 - 35ms/epoch - 1ms/step\n",
      "Epoch 2616/5000\n",
      "31/31 - 0s - loss: 7.3591 - mae: 1.5663 - val_loss: 2.8734 - val_mae: 1.6627 - 35ms/epoch - 1ms/step\n",
      "Epoch 2617/5000\n",
      "31/31 - 0s - loss: 1.2820 - mae: 0.9957 - val_loss: 0.1175 - val_mae: 0.2936 - 36ms/epoch - 1ms/step\n",
      "Epoch 2618/5000\n",
      "31/31 - 0s - loss: 29.8230 - mae: 2.0498 - val_loss: 4.8623 - val_mae: 2.1791 - 36ms/epoch - 1ms/step\n",
      "Epoch 2619/5000\n",
      "31/31 - 0s - loss: 1.5995 - mae: 1.0580 - val_loss: 0.7292 - val_mae: 0.7864 - 36ms/epoch - 1ms/step\n",
      "Epoch 2620/5000\n",
      "31/31 - 0s - loss: 9.2150 - mae: 1.9992 - val_loss: 16.6720 - val_mae: 4.0695 - 37ms/epoch - 1ms/step\n",
      "Epoch 2621/5000\n",
      "31/31 - 0s - loss: 11.5115 - mae: 2.2728 - val_loss: 0.5476 - val_mae: 0.6699 - 38ms/epoch - 1ms/step\n",
      "Epoch 2622/5000\n",
      "31/31 - 0s - loss: 0.9866 - mae: 0.7594 - val_loss: 2.9672 - val_mae: 1.6908 - 42ms/epoch - 1ms/step\n",
      "Epoch 2623/5000\n",
      "31/31 - 0s - loss: 6.8338 - mae: 2.1152 - val_loss: 0.7170 - val_mae: 0.7790 - 40ms/epoch - 1ms/step\n",
      "Epoch 2624/5000\n",
      "31/31 - 0s - loss: 20.1759 - mae: 2.2089 - val_loss: 0.2559 - val_mae: 0.4419 - 39ms/epoch - 1ms/step\n",
      "Epoch 2625/5000\n",
      "31/31 - 0s - loss: 1.3305 - mae: 0.9460 - val_loss: 7.4873 - val_mae: 2.7180 - 41ms/epoch - 1ms/step\n",
      "Epoch 2626/5000\n",
      "31/31 - 0s - loss: 12.2339 - mae: 1.9008 - val_loss: 1.0413 - val_mae: 0.9652 - 39ms/epoch - 1ms/step\n",
      "Epoch 2627/5000\n",
      "31/31 - 0s - loss: 2.5171 - mae: 1.1791 - val_loss: 0.7088 - val_mae: 0.7743 - 42ms/epoch - 1ms/step\n",
      "Epoch 2628/5000\n",
      "31/31 - 0s - loss: 17.7717 - mae: 2.3790 - val_loss: 4.4053 - val_mae: 2.0742 - 40ms/epoch - 1ms/step\n",
      "Epoch 2629/5000\n",
      "31/31 - 0s - loss: 1.5046 - mae: 0.9642 - val_loss: 2.7688 - val_mae: 1.6330 - 46ms/epoch - 1ms/step\n",
      "Epoch 2630/5000\n",
      "31/31 - 0s - loss: 2.4466 - mae: 1.1206 - val_loss: 0.1073 - val_mae: 0.2856 - 45ms/epoch - 1ms/step\n",
      "Epoch 2631/5000\n",
      "31/31 - 0s - loss: 43.8711 - mae: 2.2672 - val_loss: 2.5211 - val_mae: 1.5551 - 43ms/epoch - 1ms/step\n",
      "Epoch 2632/5000\n",
      "31/31 - 0s - loss: 2.0754 - mae: 1.1592 - val_loss: 14.4839 - val_mae: 3.7923 - 44ms/epoch - 1ms/step\n",
      "Epoch 2633/5000\n",
      "31/31 - 0s - loss: 5.3518 - mae: 1.2233 - val_loss: 0.4566 - val_mae: 0.5934 - 47ms/epoch - 2ms/step\n",
      "Epoch 2634/5000\n",
      "31/31 - 0s - loss: 32.4751 - mae: 2.1500 - val_loss: 0.2297 - val_mae: 0.3599 - 42ms/epoch - 1ms/step\n",
      "Epoch 2635/5000\n",
      "31/31 - 0s - loss: 1.4837 - mae: 0.9997 - val_loss: 0.3959 - val_mae: 0.5321 - 42ms/epoch - 1ms/step\n",
      "Epoch 2636/5000\n",
      "31/31 - 0s - loss: 1.6619 - mae: 1.0777 - val_loss: 0.2073 - val_mae: 0.3363 - 44ms/epoch - 1ms/step\n",
      "Epoch 2637/5000\n",
      "31/31 - 0s - loss: 13.1779 - mae: 2.0426 - val_loss: 0.3184 - val_mae: 0.4753 - 42ms/epoch - 1ms/step\n",
      "Epoch 2638/5000\n",
      "31/31 - 0s - loss: 1.5299 - mae: 0.8954 - val_loss: 0.3043 - val_mae: 0.4710 - 45ms/epoch - 1ms/step\n",
      "Epoch 2639/5000\n",
      "31/31 - 0s - loss: 15.5639 - mae: 2.2837 - val_loss: 6.8284 - val_mae: 2.5941 - 42ms/epoch - 1ms/step\n",
      "Epoch 2640/5000\n",
      "31/31 - 0s - loss: 7.9469 - mae: 1.8717 - val_loss: 31.7711 - val_mae: 5.6264 - 55ms/epoch - 2ms/step\n",
      "Epoch 2641/5000\n",
      "31/31 - 0s - loss: 1.9610 - mae: 0.7974 - val_loss: 0.1140 - val_mae: 0.2897 - 44ms/epoch - 1ms/step\n",
      "Epoch 2642/5000\n",
      "31/31 - 0s - loss: 22.7288 - mae: 2.2051 - val_loss: 1.4107 - val_mae: 1.1405 - 46ms/epoch - 1ms/step\n",
      "Epoch 2643/5000\n",
      "31/31 - 0s - loss: 1.4865 - mae: 0.9871 - val_loss: 0.1724 - val_mae: 0.3760 - 47ms/epoch - 2ms/step\n",
      "Epoch 2644/5000\n",
      "31/31 - 0s - loss: 0.9412 - mae: 0.7572 - val_loss: 0.1767 - val_mae: 0.3132 - 48ms/epoch - 2ms/step\n",
      "Epoch 2645/5000\n",
      "31/31 - 0s - loss: 28.6058 - mae: 2.1735 - val_loss: 0.1342 - val_mae: 0.3349 - 42ms/epoch - 1ms/step\n",
      "Epoch 2646/5000\n",
      "31/31 - 0s - loss: 1.3593 - mae: 0.9108 - val_loss: 0.2220 - val_mae: 0.3499 - 46ms/epoch - 1ms/step\n",
      "Epoch 2647/5000\n",
      "31/31 - 0s - loss: 10.3458 - mae: 1.9327 - val_loss: 3.3765 - val_mae: 1.8094 - 45ms/epoch - 1ms/step\n",
      "Epoch 2648/5000\n",
      "31/31 - 0s - loss: 2.8793 - mae: 1.3889 - val_loss: 0.1218 - val_mae: 0.2858 - 42ms/epoch - 1ms/step\n",
      "Epoch 2649/5000\n",
      "31/31 - 0s - loss: 20.1024 - mae: 2.1006 - val_loss: 0.1671 - val_mae: 0.2998 - 38ms/epoch - 1ms/step\n",
      "Epoch 2650/5000\n",
      "31/31 - 0s - loss: 1.4302 - mae: 0.8564 - val_loss: 5.4095 - val_mae: 2.3036 - 38ms/epoch - 1ms/step\n",
      "Epoch 2651/5000\n",
      "31/31 - 0s - loss: 12.5810 - mae: 1.9555 - val_loss: 0.3211 - val_mae: 0.4779 - 39ms/epoch - 1ms/step\n",
      "Epoch 2652/5000\n",
      "31/31 - 0s - loss: 2.4677 - mae: 1.1245 - val_loss: 0.2649 - val_mae: 0.4041 - 39ms/epoch - 1ms/step\n",
      "Epoch 2653/5000\n",
      "31/31 - 0s - loss: 10.6895 - mae: 1.9170 - val_loss: 0.1196 - val_mae: 0.2812 - 39ms/epoch - 1ms/step\n",
      "Epoch 2654/5000\n",
      "31/31 - 0s - loss: 1.4765 - mae: 0.9214 - val_loss: 0.6022 - val_mae: 0.7059 - 38ms/epoch - 1ms/step\n",
      "Epoch 2655/5000\n",
      "31/31 - 0s - loss: 25.0742 - mae: 2.1861 - val_loss: 0.3999 - val_mae: 0.5394 - 39ms/epoch - 1ms/step\n",
      "Epoch 2656/5000\n",
      "31/31 - 0s - loss: 1.4629 - mae: 0.9839 - val_loss: 0.1079 - val_mae: 0.2878 - 37ms/epoch - 1ms/step\n",
      "Epoch 2657/5000\n",
      "31/31 - 0s - loss: 2.6140 - mae: 1.3763 - val_loss: 1.1126 - val_mae: 1.0027 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2658/5000\n",
      "31/31 - 0s - loss: 26.1164 - mae: 2.1720 - val_loss: 0.3781 - val_mae: 0.5278 - 37ms/epoch - 1ms/step\n",
      "Epoch 2659/5000\n",
      "31/31 - 0s - loss: 1.2515 - mae: 0.8224 - val_loss: 0.3063 - val_mae: 0.4526 - 36ms/epoch - 1ms/step\n",
      "Epoch 2660/5000\n",
      "31/31 - 0s - loss: 1.3906 - mae: 1.0046 - val_loss: 6.2644 - val_mae: 2.4803 - 37ms/epoch - 1ms/step\n",
      "Epoch 2661/5000\n",
      "31/31 - 0s - loss: 6.7266 - mae: 2.0273 - val_loss: 2.0643 - val_mae: 1.4007 - 36ms/epoch - 1ms/step\n",
      "Epoch 2662/5000\n",
      "31/31 - 0s - loss: 11.9717 - mae: 2.0276 - val_loss: 8.2673 - val_mae: 2.8576 - 38ms/epoch - 1ms/step\n",
      "Epoch 2663/5000\n",
      "31/31 - 0s - loss: 2.2052 - mae: 1.1361 - val_loss: 0.3530 - val_mae: 0.4999 - 35ms/epoch - 1ms/step\n",
      "Epoch 2664/5000\n",
      "31/31 - 0s - loss: 12.0415 - mae: 2.1000 - val_loss: 0.1182 - val_mae: 0.2873 - 35ms/epoch - 1ms/step\n",
      "Epoch 2665/5000\n",
      "31/31 - 0s - loss: 1.8658 - mae: 0.9238 - val_loss: 2.4228 - val_mae: 1.5211 - 37ms/epoch - 1ms/step\n",
      "Epoch 2666/5000\n",
      "31/31 - 0s - loss: 20.9305 - mae: 2.4255 - val_loss: 0.5565 - val_mae: 0.6752 - 36ms/epoch - 1ms/step\n",
      "Epoch 2667/5000\n",
      "31/31 - 0s - loss: 1.5224 - mae: 1.0024 - val_loss: 0.7315 - val_mae: 0.7891 - 36ms/epoch - 1ms/step\n",
      "Epoch 2668/5000\n",
      "31/31 - 0s - loss: 18.9929 - mae: 2.0197 - val_loss: 0.1612 - val_mae: 0.2985 - 37ms/epoch - 1ms/step\n",
      "Epoch 2669/5000\n",
      "31/31 - 0s - loss: 1.2412 - mae: 0.8839 - val_loss: 0.2178 - val_mae: 0.4143 - 36ms/epoch - 1ms/step\n",
      "Epoch 2670/5000\n",
      "31/31 - 0s - loss: 7.2924 - mae: 1.8766 - val_loss: 4.0404 - val_mae: 1.9843 - 37ms/epoch - 1ms/step\n",
      "Epoch 2671/5000\n",
      "31/31 - 0s - loss: 1.4781 - mae: 0.8435 - val_loss: 0.2818 - val_mae: 0.4576 - 37ms/epoch - 1ms/step\n",
      "Epoch 2672/5000\n",
      "31/31 - 0s - loss: 21.4911 - mae: 2.1073 - val_loss: 0.1187 - val_mae: 0.2832 - 37ms/epoch - 1ms/step\n",
      "Epoch 2673/5000\n",
      "31/31 - 0s - loss: 0.9173 - mae: 0.8421 - val_loss: 2.0834 - val_mae: 1.4076 - 38ms/epoch - 1ms/step\n",
      "Epoch 2674/5000\n",
      "31/31 - 0s - loss: 6.5292 - mae: 1.7019 - val_loss: 14.0294 - val_mae: 3.7324 - 36ms/epoch - 1ms/step\n",
      "Epoch 2675/5000\n",
      "31/31 - 0s - loss: 19.6592 - mae: 2.2747 - val_loss: 0.2440 - val_mae: 0.3798 - 38ms/epoch - 1ms/step\n",
      "Epoch 2676/5000\n",
      "31/31 - 0s - loss: 1.7663 - mae: 0.9943 - val_loss: 0.3752 - val_mae: 0.5175 - 37ms/epoch - 1ms/step\n",
      "Epoch 2677/5000\n",
      "31/31 - 0s - loss: 0.7711 - mae: 0.7423 - val_loss: 0.2854 - val_mae: 0.4594 - 37ms/epoch - 1ms/step\n",
      "Epoch 2678/5000\n",
      "31/31 - 0s - loss: 21.5848 - mae: 2.1215 - val_loss: 0.2393 - val_mae: 0.3664 - 36ms/epoch - 1ms/step\n",
      "Epoch 2679/5000\n",
      "31/31 - 0s - loss: 0.5248 - mae: 0.5974 - val_loss: 0.2645 - val_mae: 0.3968 - 35ms/epoch - 1ms/step\n",
      "Epoch 2680/5000\n",
      "31/31 - 0s - loss: 14.2626 - mae: 2.0287 - val_loss: 0.1364 - val_mae: 0.2856 - 36ms/epoch - 1ms/step\n",
      "Epoch 2681/5000\n",
      "31/31 - 0s - loss: 0.7387 - mae: 0.7410 - val_loss: 0.1116 - val_mae: 0.2820 - 37ms/epoch - 1ms/step\n",
      "Epoch 2682/5000\n",
      "31/31 - 0s - loss: 20.3253 - mae: 2.0855 - val_loss: 0.4247 - val_mae: 0.5615 - 36ms/epoch - 1ms/step\n",
      "Epoch 2683/5000\n",
      "31/31 - 0s - loss: 1.2746 - mae: 0.9244 - val_loss: 0.2177 - val_mae: 0.3509 - 35ms/epoch - 1ms/step\n",
      "Epoch 2684/5000\n",
      "31/31 - 0s - loss: 6.6290 - mae: 1.7723 - val_loss: 4.9286 - val_mae: 2.1941 - 36ms/epoch - 1ms/step\n",
      "Epoch 2685/5000\n",
      "31/31 - 0s - loss: 2.6420 - mae: 1.0175 - val_loss: 169.0791 - val_mae: 12.9996 - 37ms/epoch - 1ms/step\n",
      "Epoch 2686/5000\n",
      "31/31 - 0s - loss: 16.2614 - mae: 1.9930 - val_loss: 0.1125 - val_mae: 0.2882 - 36ms/epoch - 1ms/step\n",
      "Epoch 2687/5000\n",
      "31/31 - 0s - loss: 0.8213 - mae: 0.6900 - val_loss: 48.1868 - val_mae: 6.9352 - 36ms/epoch - 1ms/step\n",
      "Epoch 2688/5000\n",
      "31/31 - 0s - loss: 21.9087 - mae: 2.1724 - val_loss: 2.3182 - val_mae: 1.4881 - 36ms/epoch - 1ms/step\n",
      "Epoch 2689/5000\n",
      "31/31 - 0s - loss: 0.8774 - mae: 0.7947 - val_loss: 0.2612 - val_mae: 0.4451 - 36ms/epoch - 1ms/step\n",
      "Epoch 2690/5000\n",
      "31/31 - 0s - loss: 15.8227 - mae: 1.9200 - val_loss: 1.8507 - val_mae: 1.3201 - 36ms/epoch - 1ms/step\n",
      "Epoch 2691/5000\n",
      "31/31 - 0s - loss: 0.8067 - mae: 0.7255 - val_loss: 0.1501 - val_mae: 0.2874 - 36ms/epoch - 1ms/step\n",
      "Epoch 2692/5000\n",
      "31/31 - 0s - loss: 10.4591 - mae: 1.9803 - val_loss: 0.6485 - val_mae: 0.7404 - 36ms/epoch - 1ms/step\n",
      "Epoch 2693/5000\n",
      "31/31 - 0s - loss: 3.3309 - mae: 1.3702 - val_loss: 2.9849 - val_mae: 1.6985 - 36ms/epoch - 1ms/step\n",
      "Epoch 2694/5000\n",
      "31/31 - 0s - loss: 14.0800 - mae: 1.8615 - val_loss: 1.2342 - val_mae: 1.0607 - 35ms/epoch - 1ms/step\n",
      "Epoch 2695/5000\n",
      "31/31 - 0s - loss: 2.0729 - mae: 1.2069 - val_loss: 0.3634 - val_mae: 0.5069 - 36ms/epoch - 1ms/step\n",
      "Epoch 2696/5000\n",
      "31/31 - 0s - loss: 12.6180 - mae: 2.0641 - val_loss: 0.4508 - val_mae: 0.5850 - 35ms/epoch - 1ms/step\n",
      "Epoch 2697/5000\n",
      "31/31 - 0s - loss: 0.8910 - mae: 0.7352 - val_loss: 2.6307 - val_mae: 1.5873 - 34ms/epoch - 1ms/step\n",
      "Epoch 2698/5000\n",
      "31/31 - 0s - loss: 24.5735 - mae: 2.2434 - val_loss: 0.2734 - val_mae: 0.4514 - 35ms/epoch - 1ms/step\n",
      "Epoch 2699/5000\n",
      "31/31 - 0s - loss: 1.7048 - mae: 0.8242 - val_loss: 0.1614 - val_mae: 0.2972 - 36ms/epoch - 1ms/step\n",
      "Epoch 2700/5000\n",
      "31/31 - 0s - loss: 7.3590 - mae: 1.8276 - val_loss: 0.1745 - val_mae: 0.3118 - 36ms/epoch - 1ms/step\n",
      "Epoch 2701/5000\n",
      "31/31 - 0s - loss: 0.5238 - mae: 0.5887 - val_loss: 0.3739 - val_mae: 0.5180 - 35ms/epoch - 1ms/step\n",
      "Epoch 2702/5000\n",
      "31/31 - 0s - loss: 15.5170 - mae: 1.9836 - val_loss: 0.5959 - val_mae: 0.6968 - 38ms/epoch - 1ms/step\n",
      "Epoch 2703/5000\n",
      "31/31 - 0s - loss: 2.1789 - mae: 1.1790 - val_loss: 5.7452 - val_mae: 2.3743 - 36ms/epoch - 1ms/step\n",
      "Epoch 2704/5000\n",
      "31/31 - 0s - loss: 14.1420 - mae: 2.1453 - val_loss: 0.2889 - val_mae: 0.4622 - 36ms/epoch - 1ms/step\n",
      "Epoch 2705/5000\n",
      "31/31 - 0s - loss: 2.0947 - mae: 1.2368 - val_loss: 182.1654 - val_mae: 13.4924 - 36ms/epoch - 1ms/step\n",
      "Epoch 2706/5000\n",
      "31/31 - 0s - loss: 10.2671 - mae: 2.0527 - val_loss: 3.9955 - val_mae: 1.9704 - 48ms/epoch - 2ms/step\n",
      "Epoch 2707/5000\n",
      "31/31 - 0s - loss: 12.1899 - mae: 2.2491 - val_loss: 0.1042 - val_mae: 0.2735 - 39ms/epoch - 1ms/step\n",
      "Epoch 2708/5000\n",
      "31/31 - 0s - loss: 1.2619 - mae: 0.9317 - val_loss: 0.7050 - val_mae: 0.7710 - 37ms/epoch - 1ms/step\n",
      "Epoch 2709/5000\n",
      "31/31 - 0s - loss: 14.8404 - mae: 1.5776 - val_loss: 0.3354 - val_mae: 0.4818 - 36ms/epoch - 1ms/step\n",
      "Epoch 2710/5000\n",
      "31/31 - 0s - loss: 1.1653 - mae: 0.8198 - val_loss: 0.1753 - val_mae: 0.3785 - 37ms/epoch - 1ms/step\n",
      "Epoch 2711/5000\n",
      "31/31 - 0s - loss: 1.3501 - mae: 0.9235 - val_loss: 0.8907 - val_mae: 0.8813 - 35ms/epoch - 1ms/step\n",
      "Epoch 2712/5000\n",
      "31/31 - 0s - loss: 19.3635 - mae: 2.1356 - val_loss: 5.4466 - val_mae: 2.3098 - 37ms/epoch - 1ms/step\n",
      "Epoch 2713/5000\n",
      "31/31 - 0s - loss: 1.5175 - mae: 1.0323 - val_loss: 0.4605 - val_mae: 0.5918 - 37ms/epoch - 1ms/step\n",
      "Epoch 2714/5000\n",
      "31/31 - 0s - loss: 11.7571 - mae: 1.9948 - val_loss: 0.1919 - val_mae: 0.3252 - 38ms/epoch - 1ms/step\n",
      "Epoch 2715/5000\n",
      "31/31 - 0s - loss: 0.4292 - mae: 0.5425 - val_loss: 0.1085 - val_mae: 0.2886 - 36ms/epoch - 1ms/step\n",
      "Epoch 2716/5000\n",
      "31/31 - 0s - loss: 28.2212 - mae: 2.4267 - val_loss: 0.7305 - val_mae: 0.7911 - 35ms/epoch - 1ms/step\n",
      "Epoch 2717/5000\n",
      "31/31 - 0s - loss: 2.4948 - mae: 1.3093 - val_loss: 0.6262 - val_mae: 0.7205 - 35ms/epoch - 1ms/step\n",
      "Epoch 2718/5000\n",
      "31/31 - 0s - loss: 9.8436 - mae: 1.7636 - val_loss: 0.1605 - val_mae: 0.2946 - 38ms/epoch - 1ms/step\n",
      "Epoch 2719/5000\n",
      "31/31 - 0s - loss: 1.8131 - mae: 1.0475 - val_loss: 2.0998 - val_mae: 1.4145 - 35ms/epoch - 1ms/step\n",
      "Epoch 2720/5000\n",
      "31/31 - 0s - loss: 14.6705 - mae: 1.9871 - val_loss: 0.4915 - val_mae: 0.6185 - 36ms/epoch - 1ms/step\n",
      "Epoch 2721/5000\n",
      "31/31 - 0s - loss: 0.9553 - mae: 0.7701 - val_loss: 0.1100 - val_mae: 0.2876 - 37ms/epoch - 1ms/step\n",
      "Epoch 2722/5000\n",
      "31/31 - 0s - loss: 11.5484 - mae: 2.0113 - val_loss: 0.1130 - val_mae: 0.2900 - 37ms/epoch - 1ms/step\n",
      "Epoch 2723/5000\n",
      "31/31 - 0s - loss: 1.1478 - mae: 0.9229 - val_loss: 0.1054 - val_mae: 0.2816 - 36ms/epoch - 1ms/step\n",
      "Epoch 2724/5000\n",
      "31/31 - 0s - loss: 16.1966 - mae: 1.8998 - val_loss: 1.0935 - val_mae: 0.9937 - 38ms/epoch - 1ms/step\n",
      "Epoch 2725/5000\n",
      "31/31 - 0s - loss: 0.9962 - mae: 0.7348 - val_loss: 0.9557 - val_mae: 0.9221 - 35ms/epoch - 1ms/step\n",
      "Epoch 2726/5000\n",
      "31/31 - 0s - loss: 19.0655 - mae: 2.3539 - val_loss: 0.1079 - val_mae: 0.2856 - 34ms/epoch - 1ms/step\n",
      "Epoch 2727/5000\n",
      "31/31 - 0s - loss: 0.9196 - mae: 0.7726 - val_loss: 15.5655 - val_mae: 3.9325 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2728/5000\n",
      "31/31 - 0s - loss: 3.9641 - mae: 1.6026 - val_loss: 1.5678 - val_mae: 1.2086 - 37ms/epoch - 1ms/step\n",
      "Epoch 2729/5000\n",
      "31/31 - 0s - loss: 14.8738 - mae: 2.0702 - val_loss: 0.5365 - val_mae: 0.6549 - 35ms/epoch - 1ms/step\n",
      "Epoch 2730/5000\n",
      "31/31 - 0s - loss: 1.3362 - mae: 0.9489 - val_loss: 0.3213 - val_mae: 0.4625 - 36ms/epoch - 1ms/step\n",
      "Epoch 2731/5000\n",
      "31/31 - 0s - loss: 19.0630 - mae: 2.2477 - val_loss: 0.1159 - val_mae: 0.2922 - 36ms/epoch - 1ms/step\n",
      "Epoch 2732/5000\n",
      "31/31 - 0s - loss: 1.2260 - mae: 0.9270 - val_loss: 2.5360 - val_mae: 1.5589 - 36ms/epoch - 1ms/step\n",
      "Epoch 2733/5000\n",
      "31/31 - 0s - loss: 16.6642 - mae: 2.4245 - val_loss: 1.8362 - val_mae: 1.3159 - 36ms/epoch - 1ms/step\n",
      "Epoch 2734/5000\n",
      "31/31 - 0s - loss: 0.5619 - mae: 0.6011 - val_loss: 0.6794 - val_mae: 0.7566 - 36ms/epoch - 1ms/step\n",
      "Epoch 2735/5000\n",
      "31/31 - 0s - loss: 0.7561 - mae: 0.7406 - val_loss: 2.9952 - val_mae: 1.6996 - 37ms/epoch - 1ms/step\n",
      "Epoch 2736/5000\n",
      "31/31 - 0s - loss: 13.7691 - mae: 2.0309 - val_loss: 1.8404 - val_mae: 1.3175 - 37ms/epoch - 1ms/step\n",
      "Epoch 2737/5000\n",
      "31/31 - 0s - loss: 9.2898 - mae: 1.8982 - val_loss: 33.1809 - val_mae: 5.7509 - 36ms/epoch - 1ms/step\n",
      "Epoch 2738/5000\n",
      "31/31 - 0s - loss: 3.0137 - mae: 1.1781 - val_loss: 0.4092 - val_mae: 0.5523 - 38ms/epoch - 1ms/step\n",
      "Epoch 2739/5000\n",
      "31/31 - 0s - loss: 21.1985 - mae: 2.4110 - val_loss: 1.3753 - val_mae: 1.1263 - 36ms/epoch - 1ms/step\n",
      "Epoch 2740/5000\n",
      "31/31 - 0s - loss: 1.2349 - mae: 0.8701 - val_loss: 0.4515 - val_mae: 0.5850 - 37ms/epoch - 1ms/step\n",
      "Epoch 2741/5000\n",
      "31/31 - 0s - loss: 0.8546 - mae: 0.7401 - val_loss: 5.6306 - val_mae: 2.3520 - 36ms/epoch - 1ms/step\n",
      "Epoch 2742/5000\n",
      "31/31 - 0s - loss: 28.5108 - mae: 2.4086 - val_loss: 0.8072 - val_mae: 0.8345 - 35ms/epoch - 1ms/step\n",
      "Epoch 2743/5000\n",
      "31/31 - 0s - loss: 1.6420 - mae: 1.0756 - val_loss: 0.2766 - val_mae: 0.4113 - 35ms/epoch - 1ms/step\n",
      "Epoch 2744/5000\n",
      "31/31 - 0s - loss: 18.6456 - mae: 1.6625 - val_loss: 0.2497 - val_mae: 0.3883 - 35ms/epoch - 1ms/step\n",
      "Epoch 2745/5000\n",
      "31/31 - 0s - loss: 2.2200 - mae: 1.0960 - val_loss: 2.1981 - val_mae: 1.4477 - 36ms/epoch - 1ms/step\n",
      "Epoch 2746/5000\n",
      "31/31 - 0s - loss: 0.7903 - mae: 0.7845 - val_loss: 0.2352 - val_mae: 0.3634 - 35ms/epoch - 1ms/step\n",
      "Epoch 2747/5000\n",
      "31/31 - 0s - loss: 25.4086 - mae: 2.0758 - val_loss: 0.2111 - val_mae: 0.4102 - 37ms/epoch - 1ms/step\n",
      "Epoch 2748/5000\n",
      "31/31 - 0s - loss: 1.5418 - mae: 1.1590 - val_loss: 0.7002 - val_mae: 0.7723 - 36ms/epoch - 1ms/step\n",
      "Epoch 2749/5000\n",
      "31/31 - 0s - loss: 15.8956 - mae: 1.9162 - val_loss: 0.1638 - val_mae: 0.3016 - 36ms/epoch - 1ms/step\n",
      "Epoch 2750/5000\n",
      "31/31 - 0s - loss: 3.0880 - mae: 1.3642 - val_loss: 2.2403 - val_mae: 1.4613 - 36ms/epoch - 1ms/step\n",
      "Epoch 2751/5000\n",
      "31/31 - 0s - loss: 14.1039 - mae: 2.0445 - val_loss: 0.1300 - val_mae: 0.2958 - 36ms/epoch - 1ms/step\n",
      "Epoch 2752/5000\n",
      "31/31 - 0s - loss: 0.5967 - mae: 0.6687 - val_loss: 0.4622 - val_mae: 0.5928 - 35ms/epoch - 1ms/step\n",
      "Epoch 2753/5000\n",
      "31/31 - 0s - loss: 23.8175 - mae: 2.5797 - val_loss: 0.1312 - val_mae: 0.3294 - 36ms/epoch - 1ms/step\n",
      "Epoch 2754/5000\n",
      "31/31 - 0s - loss: 1.5859 - mae: 0.8932 - val_loss: 0.3996 - val_mae: 0.5417 - 34ms/epoch - 1ms/step\n",
      "Epoch 2755/5000\n",
      "31/31 - 0s - loss: 0.7928 - mae: 0.7328 - val_loss: 5.2956 - val_mae: 2.2754 - 37ms/epoch - 1ms/step\n",
      "Epoch 2756/5000\n",
      "31/31 - 0s - loss: 11.1643 - mae: 2.2014 - val_loss: 0.1319 - val_mae: 0.3319 - 35ms/epoch - 1ms/step\n",
      "Epoch 2757/5000\n",
      "31/31 - 0s - loss: 10.5523 - mae: 2.2931 - val_loss: 9.7543 - val_mae: 3.1081 - 36ms/epoch - 1ms/step\n",
      "Epoch 2758/5000\n",
      "31/31 - 0s - loss: 2.3612 - mae: 1.1926 - val_loss: 0.1866 - val_mae: 0.3169 - 36ms/epoch - 1ms/step\n",
      "Epoch 2759/5000\n",
      "31/31 - 0s - loss: 9.6750 - mae: 1.6319 - val_loss: 1.3087 - val_mae: 1.0945 - 35ms/epoch - 1ms/step\n",
      "Epoch 2760/5000\n",
      "31/31 - 0s - loss: 1.9498 - mae: 1.0397 - val_loss: 0.3995 - val_mae: 0.5436 - 36ms/epoch - 1ms/step\n",
      "Epoch 2761/5000\n",
      "31/31 - 0s - loss: 21.7577 - mae: 2.0692 - val_loss: 0.3818 - val_mae: 0.5244 - 35ms/epoch - 1ms/step\n",
      "Epoch 2762/5000\n",
      "31/31 - 0s - loss: 1.8849 - mae: 1.0625 - val_loss: 0.6037 - val_mae: 0.7041 - 37ms/epoch - 1ms/step\n",
      "Epoch 2763/5000\n",
      "31/31 - 0s - loss: 12.8824 - mae: 1.8675 - val_loss: 0.1112 - val_mae: 0.2906 - 36ms/epoch - 1ms/step\n",
      "Epoch 2764/5000\n",
      "31/31 - 0s - loss: 1.1547 - mae: 0.8824 - val_loss: 0.4989 - val_mae: 0.6218 - 37ms/epoch - 1ms/step\n",
      "Epoch 2765/5000\n",
      "31/31 - 0s - loss: 7.5502 - mae: 1.7680 - val_loss: 6.9806 - val_mae: 2.6214 - 36ms/epoch - 1ms/step\n",
      "Epoch 2766/5000\n",
      "31/31 - 0s - loss: 1.5340 - mae: 1.0476 - val_loss: 0.1837 - val_mae: 0.3868 - 34ms/epoch - 1ms/step\n",
      "Epoch 2767/5000\n",
      "31/31 - 0s - loss: 13.2801 - mae: 2.1912 - val_loss: 2.5774 - val_mae: 1.5703 - 37ms/epoch - 1ms/step\n",
      "Epoch 2768/5000\n",
      "31/31 - 0s - loss: 1.1915 - mae: 0.8136 - val_loss: 0.2974 - val_mae: 0.4663 - 38ms/epoch - 1ms/step\n",
      "Epoch 2769/5000\n",
      "31/31 - 0s - loss: 13.9030 - mae: 2.0103 - val_loss: 1.3374 - val_mae: 1.1098 - 37ms/epoch - 1ms/step\n",
      "Epoch 2770/5000\n",
      "31/31 - 0s - loss: 12.0074 - mae: 2.1330 - val_loss: 2.4890 - val_mae: 1.5441 - 37ms/epoch - 1ms/step\n",
      "Epoch 2771/5000\n",
      "31/31 - 0s - loss: 1.5921 - mae: 1.1211 - val_loss: 0.1271 - val_mae: 0.3206 - 34ms/epoch - 1ms/step\n",
      "Epoch 2772/5000\n",
      "31/31 - 0s - loss: 16.0935 - mae: 1.9263 - val_loss: 0.5138 - val_mae: 0.6390 - 34ms/epoch - 1ms/step\n",
      "Epoch 2773/5000\n",
      "31/31 - 0s - loss: 1.4381 - mae: 0.9804 - val_loss: 2.5762 - val_mae: 1.5723 - 36ms/epoch - 1ms/step\n",
      "Epoch 2774/5000\n",
      "31/31 - 0s - loss: 7.7566 - mae: 1.5524 - val_loss: 0.1469 - val_mae: 0.2845 - 36ms/epoch - 1ms/step\n",
      "Epoch 2775/5000\n",
      "31/31 - 0s - loss: 0.4140 - mae: 0.4630 - val_loss: 0.1810 - val_mae: 0.3848 - 39ms/epoch - 1ms/step\n",
      "Epoch 2776/5000\n",
      "31/31 - 0s - loss: 16.6424 - mae: 1.9169 - val_loss: 0.1785 - val_mae: 0.3161 - 35ms/epoch - 1ms/step\n",
      "Epoch 2777/5000\n",
      "31/31 - 0s - loss: 2.1988 - mae: 1.1322 - val_loss: 0.1057 - val_mae: 0.2844 - 37ms/epoch - 1ms/step\n",
      "Epoch 2778/5000\n",
      "31/31 - 0s - loss: 12.2453 - mae: 1.8326 - val_loss: 0.2467 - val_mae: 0.4359 - 37ms/epoch - 1ms/step\n",
      "Epoch 2779/5000\n",
      "31/31 - 0s - loss: 1.4231 - mae: 0.9093 - val_loss: 0.1922 - val_mae: 0.3945 - 36ms/epoch - 1ms/step\n",
      "Epoch 2780/5000\n",
      "31/31 - 0s - loss: 11.5693 - mae: 2.2638 - val_loss: 1.8890 - val_mae: 1.3345 - 38ms/epoch - 1ms/step\n",
      "Epoch 2781/5000\n",
      "31/31 - 0s - loss: 1.1930 - mae: 0.8678 - val_loss: 0.5242 - val_mae: 0.6473 - 37ms/epoch - 1ms/step\n",
      "Epoch 2782/5000\n",
      "31/31 - 0s - loss: 26.1137 - mae: 2.1257 - val_loss: 0.7767 - val_mae: 0.8208 - 39ms/epoch - 1ms/step\n",
      "Epoch 2783/5000\n",
      "31/31 - 0s - loss: 1.5982 - mae: 1.0448 - val_loss: 0.1350 - val_mae: 0.2894 - 37ms/epoch - 1ms/step\n",
      "Epoch 2784/5000\n",
      "31/31 - 0s - loss: 15.7909 - mae: 2.1239 - val_loss: 0.7470 - val_mae: 0.8008 - 36ms/epoch - 1ms/step\n",
      "Epoch 2785/5000\n",
      "31/31 - 0s - loss: 0.9162 - mae: 0.6455 - val_loss: 2.1884 - val_mae: 1.4434 - 36ms/epoch - 1ms/step\n",
      "Epoch 2786/5000\n",
      "31/31 - 0s - loss: 10.1108 - mae: 1.7647 - val_loss: 8.1496 - val_mae: 2.8352 - 36ms/epoch - 1ms/step\n",
      "Epoch 2787/5000\n",
      "31/31 - 0s - loss: 0.8757 - mae: 0.7116 - val_loss: 0.1740 - val_mae: 0.3778 - 38ms/epoch - 1ms/step\n",
      "Epoch 2788/5000\n",
      "31/31 - 0s - loss: 9.2554 - mae: 1.8993 - val_loss: 0.1090 - val_mae: 0.2820 - 37ms/epoch - 1ms/step\n",
      "Epoch 2789/5000\n",
      "31/31 - 0s - loss: 5.1344 - mae: 1.6902 - val_loss: 0.1192 - val_mae: 0.3096 - 36ms/epoch - 1ms/step\n",
      "Epoch 2790/5000\n",
      "31/31 - 0s - loss: 0.8491 - mae: 0.7827 - val_loss: 3.2876 - val_mae: 1.7823 - 36ms/epoch - 1ms/step\n",
      "Epoch 2791/5000\n",
      "31/31 - 0s - loss: 14.0822 - mae: 1.9541 - val_loss: 4.5435 - val_mae: 2.1063 - 37ms/epoch - 1ms/step\n",
      "Epoch 2792/5000\n",
      "31/31 - 0s - loss: 2.0430 - mae: 1.1724 - val_loss: 128.4560 - val_mae: 11.3283 - 36ms/epoch - 1ms/step\n",
      "Epoch 2793/5000\n",
      "31/31 - 0s - loss: 18.7852 - mae: 2.3005 - val_loss: 1.2199 - val_mae: 1.0555 - 36ms/epoch - 1ms/step\n",
      "Epoch 2794/5000\n",
      "31/31 - 0s - loss: 2.2733 - mae: 1.2952 - val_loss: 5.9541 - val_mae: 2.4155 - 35ms/epoch - 1ms/step\n",
      "Epoch 2795/5000\n",
      "31/31 - 0s - loss: 13.4050 - mae: 1.7797 - val_loss: 0.3001 - val_mae: 0.4381 - 36ms/epoch - 1ms/step\n",
      "Epoch 2796/5000\n",
      "31/31 - 0s - loss: 9.3190 - mae: 1.4442 - val_loss: 234.0584 - val_mae: 15.2954 - 36ms/epoch - 1ms/step\n",
      "Epoch 2797/5000\n",
      "31/31 - 0s - loss: 13.7235 - mae: 1.6479 - val_loss: 3.7440 - val_mae: 1.9083 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2798/5000\n",
      "31/31 - 0s - loss: 0.9422 - mae: 0.8352 - val_loss: 1.7776 - val_mae: 1.2941 - 36ms/epoch - 1ms/step\n",
      "Epoch 2799/5000\n",
      "31/31 - 0s - loss: 17.1627 - mae: 1.9418 - val_loss: 1.2134 - val_mae: 1.0514 - 36ms/epoch - 1ms/step\n",
      "Epoch 2800/5000\n",
      "31/31 - 0s - loss: 2.2374 - mae: 1.2193 - val_loss: 0.2369 - val_mae: 0.3615 - 35ms/epoch - 1ms/step\n",
      "Epoch 2801/5000\n",
      "31/31 - 0s - loss: 8.1201 - mae: 1.8641 - val_loss: 6.8314 - val_mae: 2.5925 - 36ms/epoch - 1ms/step\n",
      "Epoch 2802/5000\n",
      "31/31 - 0s - loss: 2.0621 - mae: 1.1352 - val_loss: 3.5355 - val_mae: 1.8542 - 45ms/epoch - 1ms/step\n",
      "Epoch 2803/5000\n",
      "31/31 - 0s - loss: 11.2041 - mae: 1.9693 - val_loss: 1.7439 - val_mae: 1.2818 - 38ms/epoch - 1ms/step\n",
      "Epoch 2804/5000\n",
      "31/31 - 0s - loss: 6.1624 - mae: 1.7080 - val_loss: 3.3465 - val_mae: 1.8003 - 39ms/epoch - 1ms/step\n",
      "Epoch 2805/5000\n",
      "31/31 - 0s - loss: 1.3694 - mae: 0.9267 - val_loss: 0.5722 - val_mae: 0.6821 - 36ms/epoch - 1ms/step\n",
      "Epoch 2806/5000\n",
      "31/31 - 0s - loss: 20.5927 - mae: 2.4399 - val_loss: 2.0545 - val_mae: 1.3961 - 36ms/epoch - 1ms/step\n",
      "Epoch 2807/5000\n",
      "31/31 - 0s - loss: 1.4424 - mae: 0.9750 - val_loss: 3.5788 - val_mae: 1.8637 - 35ms/epoch - 1ms/step\n",
      "Epoch 2808/5000\n",
      "31/31 - 0s - loss: 13.7458 - mae: 1.9166 - val_loss: 0.5396 - val_mae: 0.6565 - 36ms/epoch - 1ms/step\n",
      "Epoch 2809/5000\n",
      "31/31 - 0s - loss: 1.1462 - mae: 0.8870 - val_loss: 12.2184 - val_mae: 3.4815 - 36ms/epoch - 1ms/step\n",
      "Epoch 2810/5000\n",
      "31/31 - 0s - loss: 12.2685 - mae: 1.9502 - val_loss: 10.3884 - val_mae: 3.2071 - 35ms/epoch - 1ms/step\n",
      "Epoch 2811/5000\n",
      "31/31 - 0s - loss: 8.0159 - mae: 1.8707 - val_loss: 0.2247 - val_mae: 0.3547 - 36ms/epoch - 1ms/step\n",
      "Epoch 2812/5000\n",
      "31/31 - 0s - loss: 1.1689 - mae: 0.9038 - val_loss: 0.1202 - val_mae: 0.2802 - 35ms/epoch - 1ms/step\n",
      "Epoch 2813/5000\n",
      "31/31 - 0s - loss: 7.0278 - mae: 1.6103 - val_loss: 0.1776 - val_mae: 0.3813 - 36ms/epoch - 1ms/step\n",
      "Epoch 2814/5000\n",
      "31/31 - 0s - loss: 18.1100 - mae: 2.5643 - val_loss: 0.2198 - val_mae: 0.3472 - 39ms/epoch - 1ms/step\n",
      "Epoch 2815/5000\n",
      "31/31 - 0s - loss: 0.9299 - mae: 0.6330 - val_loss: 6.3639 - val_mae: 2.5025 - 37ms/epoch - 1ms/step\n",
      "Epoch 2816/5000\n",
      "31/31 - 0s - loss: 3.6034 - mae: 1.2733 - val_loss: 105.6225 - val_mae: 10.2721 - 38ms/epoch - 1ms/step\n",
      "Epoch 2817/5000\n",
      "31/31 - 0s - loss: 6.9174 - mae: 1.5266 - val_loss: 0.7729 - val_mae: 0.8178 - 37ms/epoch - 1ms/step\n",
      "Epoch 2818/5000\n",
      "31/31 - 0s - loss: 13.4521 - mae: 1.7967 - val_loss: 53.5277 - val_mae: 7.3083 - 38ms/epoch - 1ms/step\n",
      "Epoch 2819/5000\n",
      "31/31 - 0s - loss: 4.6135 - mae: 1.5913 - val_loss: 0.7348 - val_mae: 0.7919 - 35ms/epoch - 1ms/step\n",
      "Epoch 2820/5000\n",
      "31/31 - 0s - loss: 1.8887 - mae: 1.1127 - val_loss: 2.1315 - val_mae: 1.4243 - 36ms/epoch - 1ms/step\n",
      "Epoch 2821/5000\n",
      "31/31 - 0s - loss: 14.5174 - mae: 1.9409 - val_loss: 0.1093 - val_mae: 0.2792 - 36ms/epoch - 1ms/step\n",
      "Epoch 2822/5000\n",
      "31/31 - 0s - loss: 0.7910 - mae: 0.7563 - val_loss: 2.0888 - val_mae: 1.4086 - 37ms/epoch - 1ms/step\n",
      "Epoch 2823/5000\n",
      "31/31 - 0s - loss: 8.9826 - mae: 1.9078 - val_loss: 0.2848 - val_mae: 0.4598 - 35ms/epoch - 1ms/step\n",
      "Epoch 2824/5000\n",
      "31/31 - 0s - loss: 6.7461 - mae: 1.7762 - val_loss: 0.3580 - val_mae: 0.5006 - 35ms/epoch - 1ms/step\n",
      "Epoch 2825/5000\n",
      "31/31 - 0s - loss: 1.8324 - mae: 1.1936 - val_loss: 0.8754 - val_mae: 0.8743 - 35ms/epoch - 1ms/step\n",
      "Epoch 2826/5000\n",
      "31/31 - 0s - loss: 17.4598 - mae: 2.1705 - val_loss: 1.7692 - val_mae: 1.2870 - 36ms/epoch - 1ms/step\n",
      "Epoch 2827/5000\n",
      "31/31 - 0s - loss: 0.6960 - mae: 0.7003 - val_loss: 2.1099 - val_mae: 1.4157 - 35ms/epoch - 1ms/step\n",
      "Epoch 2828/5000\n",
      "31/31 - 0s - loss: 17.0759 - mae: 2.0077 - val_loss: 0.2298 - val_mae: 0.4226 - 35ms/epoch - 1ms/step\n",
      "Epoch 2829/5000\n",
      "31/31 - 0s - loss: 1.1555 - mae: 0.8435 - val_loss: 1.5341 - val_mae: 1.1954 - 35ms/epoch - 1ms/step\n",
      "Epoch 2830/5000\n",
      "31/31 - 0s - loss: 13.8150 - mae: 2.1809 - val_loss: 0.1081 - val_mae: 0.2876 - 35ms/epoch - 1ms/step\n",
      "Epoch 2831/5000\n",
      "31/31 - 0s - loss: 2.3676 - mae: 1.0598 - val_loss: 0.2252 - val_mae: 0.4200 - 36ms/epoch - 1ms/step\n",
      "Epoch 2832/5000\n",
      "31/31 - 0s - loss: 19.5242 - mae: 1.9457 - val_loss: 1.5805 - val_mae: 1.2188 - 36ms/epoch - 1ms/step\n",
      "Epoch 2833/5000\n",
      "31/31 - 0s - loss: 1.6840 - mae: 0.9757 - val_loss: 3.1517 - val_mae: 1.7458 - 34ms/epoch - 1ms/step\n",
      "Epoch 2834/5000\n",
      "31/31 - 0s - loss: 0.8449 - mae: 0.8031 - val_loss: 0.3751 - val_mae: 0.5187 - 36ms/epoch - 1ms/step\n",
      "Epoch 2835/5000\n",
      "31/31 - 0s - loss: 28.8243 - mae: 2.0634 - val_loss: 0.3954 - val_mae: 0.5359 - 36ms/epoch - 1ms/step\n",
      "Epoch 2836/5000\n",
      "31/31 - 0s - loss: 1.6272 - mae: 1.0075 - val_loss: 0.1434 - val_mae: 0.3409 - 35ms/epoch - 1ms/step\n",
      "Epoch 2837/5000\n",
      "31/31 - 0s - loss: 10.8526 - mae: 1.8843 - val_loss: 0.3243 - val_mae: 0.4810 - 36ms/epoch - 1ms/step\n",
      "Epoch 2838/5000\n",
      "31/31 - 0s - loss: 0.9688 - mae: 0.8734 - val_loss: 1.3986 - val_mae: 1.1348 - 36ms/epoch - 1ms/step\n",
      "Epoch 2839/5000\n",
      "31/31 - 0s - loss: 24.5622 - mae: 2.1120 - val_loss: 1.4817 - val_mae: 1.1716 - 37ms/epoch - 1ms/step\n",
      "Epoch 2840/5000\n",
      "31/31 - 0s - loss: 2.0682 - mae: 1.2354 - val_loss: 16.2845 - val_mae: 4.0214 - 38ms/epoch - 1ms/step\n",
      "Epoch 2841/5000\n",
      "31/31 - 0s - loss: 8.1327 - mae: 1.7706 - val_loss: 0.9055 - val_mae: 0.8945 - 38ms/epoch - 1ms/step\n",
      "Epoch 2842/5000\n",
      "31/31 - 0s - loss: 11.9468 - mae: 1.8330 - val_loss: 0.1031 - val_mae: 0.2792 - 36ms/epoch - 1ms/step\n",
      "Epoch 2843/5000\n",
      "31/31 - 0s - loss: 2.0460 - mae: 1.1812 - val_loss: 2.0480 - val_mae: 1.3949 - 35ms/epoch - 1ms/step\n",
      "Epoch 2844/5000\n",
      "31/31 - 0s - loss: 15.1806 - mae: 2.0147 - val_loss: 0.6759 - val_mae: 0.7638 - 37ms/epoch - 1ms/step\n",
      "Epoch 2845/5000\n",
      "31/31 - 0s - loss: 2.1656 - mae: 1.2091 - val_loss: 0.8796 - val_mae: 0.8795 - 37ms/epoch - 1ms/step\n",
      "Epoch 2846/5000\n",
      "31/31 - 0s - loss: 4.5904 - mae: 1.2272 - val_loss: 21.5603 - val_mae: 4.6302 - 36ms/epoch - 1ms/step\n",
      "Epoch 2847/5000\n",
      "31/31 - 0s - loss: 6.3281 - mae: 1.3078 - val_loss: 0.2975 - val_mae: 0.4403 - 34ms/epoch - 1ms/step\n",
      "Epoch 2848/5000\n",
      "31/31 - 0s - loss: 10.7339 - mae: 1.9042 - val_loss: 0.2668 - val_mae: 0.4484 - 34ms/epoch - 1ms/step\n",
      "Epoch 2849/5000\n",
      "31/31 - 0s - loss: 1.5237 - mae: 1.0668 - val_loss: 2.3015 - val_mae: 1.4829 - 37ms/epoch - 1ms/step\n",
      "Epoch 2850/5000\n",
      "31/31 - 0s - loss: 9.2743 - mae: 1.8856 - val_loss: 2.3044 - val_mae: 1.4837 - 37ms/epoch - 1ms/step\n",
      "Epoch 2851/5000\n",
      "31/31 - 0s - loss: 0.5357 - mae: 0.5584 - val_loss: 0.1060 - val_mae: 0.2834 - 36ms/epoch - 1ms/step\n",
      "Epoch 2852/5000\n",
      "31/31 - 0s - loss: 21.7243 - mae: 1.9798 - val_loss: 0.2700 - val_mae: 0.4500 - 36ms/epoch - 1ms/step\n",
      "Epoch 2853/5000\n",
      "31/31 - 0s - loss: 2.0785 - mae: 0.9739 - val_loss: 0.2139 - val_mae: 0.3431 - 36ms/epoch - 1ms/step\n",
      "Epoch 2854/5000\n",
      "31/31 - 0s - loss: 27.9775 - mae: 2.1401 - val_loss: 0.3244 - val_mae: 0.4669 - 36ms/epoch - 1ms/step\n",
      "Epoch 2855/5000\n",
      "31/31 - 0s - loss: 1.2689 - mae: 0.7406 - val_loss: 18.5455 - val_mae: 4.2943 - 34ms/epoch - 1ms/step\n",
      "Epoch 2856/5000\n",
      "31/31 - 0s - loss: 1.1334 - mae: 0.7555 - val_loss: 0.9980 - val_mae: 0.9412 - 36ms/epoch - 1ms/step\n",
      "Epoch 2857/5000\n",
      "31/31 - 0s - loss: 8.7017 - mae: 2.1345 - val_loss: 4.4544 - val_mae: 2.0834 - 38ms/epoch - 1ms/step\n",
      "Epoch 2858/5000\n",
      "31/31 - 0s - loss: 1.4836 - mae: 0.9799 - val_loss: 4.3087 - val_mae: 2.0492 - 36ms/epoch - 1ms/step\n",
      "Epoch 2859/5000\n",
      "31/31 - 0s - loss: 11.3087 - mae: 2.1600 - val_loss: 3.8993 - val_mae: 1.9491 - 34ms/epoch - 1ms/step\n",
      "Epoch 2860/5000\n",
      "31/31 - 0s - loss: 10.0659 - mae: 1.9168 - val_loss: 0.5674 - val_mae: 0.6780 - 35ms/epoch - 1ms/step\n",
      "Epoch 2861/5000\n",
      "31/31 - 0s - loss: 2.0780 - mae: 1.1703 - val_loss: 1.2558 - val_mae: 1.0735 - 38ms/epoch - 1ms/step\n",
      "Epoch 2862/5000\n",
      "31/31 - 0s - loss: 9.5241 - mae: 1.5991 - val_loss: 0.5448 - val_mae: 0.6589 - 38ms/epoch - 1ms/step\n",
      "Epoch 2863/5000\n",
      "31/31 - 0s - loss: 2.9576 - mae: 1.2745 - val_loss: 1.2089 - val_mae: 1.0498 - 36ms/epoch - 1ms/step\n",
      "Epoch 2864/5000\n",
      "31/31 - 0s - loss: 13.5959 - mae: 2.2448 - val_loss: 4.4788 - val_mae: 2.0914 - 33ms/epoch - 1ms/step\n",
      "Epoch 2865/5000\n",
      "31/31 - 0s - loss: 5.7590 - mae: 1.8344 - val_loss: 13.8679 - val_mae: 3.7073 - 37ms/epoch - 1ms/step\n",
      "Epoch 2866/5000\n",
      "31/31 - 0s - loss: 3.7583 - mae: 1.1125 - val_loss: 0.9934 - val_mae: 0.9445 - 36ms/epoch - 1ms/step\n",
      "Epoch 2867/5000\n",
      "31/31 - 0s - loss: 6.8297 - mae: 1.3881 - val_loss: 98.2428 - val_mae: 9.9057 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2868/5000\n",
      "31/31 - 0s - loss: 16.0002 - mae: 1.7230 - val_loss: 1.1376 - val_mae: 1.0147 - 35ms/epoch - 1ms/step\n",
      "Epoch 2869/5000\n",
      "31/31 - 0s - loss: 0.7769 - mae: 0.6364 - val_loss: 0.7793 - val_mae: 0.8227 - 36ms/epoch - 1ms/step\n",
      "Epoch 2870/5000\n",
      "31/31 - 0s - loss: 15.2836 - mae: 2.1128 - val_loss: 0.2502 - val_mae: 0.4388 - 37ms/epoch - 1ms/step\n",
      "Epoch 2871/5000\n",
      "31/31 - 0s - loss: 1.4588 - mae: 0.8785 - val_loss: 0.1703 - val_mae: 0.3745 - 35ms/epoch - 1ms/step\n",
      "Epoch 2872/5000\n",
      "31/31 - 0s - loss: 18.8287 - mae: 2.0473 - val_loss: 0.6522 - val_mae: 0.7389 - 34ms/epoch - 1ms/step\n",
      "Epoch 2873/5000\n",
      "31/31 - 0s - loss: 1.8030 - mae: 1.1103 - val_loss: 0.1193 - val_mae: 0.2860 - 38ms/epoch - 1ms/step\n",
      "Epoch 2874/5000\n",
      "31/31 - 0s - loss: 16.2576 - mae: 2.0805 - val_loss: 0.4901 - val_mae: 0.6234 - 36ms/epoch - 1ms/step\n",
      "Epoch 2875/5000\n",
      "31/31 - 0s - loss: 1.4135 - mae: 0.9435 - val_loss: 1.5532 - val_mae: 1.2033 - 36ms/epoch - 1ms/step\n",
      "Epoch 2876/5000\n",
      "31/31 - 0s - loss: 19.4565 - mae: 2.1743 - val_loss: 1.2077 - val_mae: 1.0484 - 36ms/epoch - 1ms/step\n",
      "Epoch 2877/5000\n",
      "31/31 - 0s - loss: 1.2967 - mae: 0.9946 - val_loss: 0.4631 - val_mae: 0.5971 - 36ms/epoch - 1ms/step\n",
      "Epoch 2878/5000\n",
      "31/31 - 0s - loss: 13.0203 - mae: 2.1192 - val_loss: 0.9770 - val_mae: 0.9321 - 35ms/epoch - 1ms/step\n",
      "Epoch 2879/5000\n",
      "31/31 - 0s - loss: 3.6082 - mae: 1.5119 - val_loss: 0.1125 - val_mae: 0.2909 - 35ms/epoch - 1ms/step\n",
      "Epoch 2880/5000\n",
      "31/31 - 0s - loss: 27.1483 - mae: 2.2835 - val_loss: 0.3312 - val_mae: 0.4730 - 36ms/epoch - 1ms/step\n",
      "Epoch 2881/5000\n",
      "31/31 - 0s - loss: 1.7185 - mae: 0.9931 - val_loss: 0.9239 - val_mae: 0.9040 - 35ms/epoch - 1ms/step\n",
      "Epoch 2882/5000\n",
      "31/31 - 0s - loss: 0.6088 - mae: 0.6730 - val_loss: 0.1054 - val_mae: 0.2773 - 35ms/epoch - 1ms/step\n",
      "Epoch 2883/5000\n",
      "31/31 - 0s - loss: 24.6841 - mae: 2.3609 - val_loss: 0.6139 - val_mae: 0.7093 - 35ms/epoch - 1ms/step\n",
      "Epoch 2884/5000\n",
      "31/31 - 0s - loss: 2.6861 - mae: 1.2995 - val_loss: 2.1865 - val_mae: 1.4428 - 36ms/epoch - 1ms/step\n",
      "Epoch 2885/5000\n",
      "31/31 - 0s - loss: 19.8726 - mae: 2.1435 - val_loss: 0.4993 - val_mae: 0.6298 - 38ms/epoch - 1ms/step\n",
      "Epoch 2886/5000\n",
      "31/31 - 0s - loss: 0.5997 - mae: 0.6146 - val_loss: 0.5093 - val_mae: 0.6355 - 39ms/epoch - 1ms/step\n",
      "Epoch 2887/5000\n",
      "31/31 - 0s - loss: 11.8398 - mae: 1.8819 - val_loss: 1.0916 - val_mae: 0.9871 - 37ms/epoch - 1ms/step\n",
      "Epoch 2888/5000\n",
      "31/31 - 0s - loss: 3.0958 - mae: 1.4491 - val_loss: 5.6030 - val_mae: 2.3443 - 37ms/epoch - 1ms/step\n",
      "Epoch 2889/5000\n",
      "31/31 - 0s - loss: 14.8302 - mae: 2.0997 - val_loss: 0.6786 - val_mae: 0.7586 - 36ms/epoch - 1ms/step\n",
      "Epoch 2890/5000\n",
      "31/31 - 0s - loss: 0.8533 - mae: 0.7332 - val_loss: 3.7467 - val_mae: 1.9089 - 35ms/epoch - 1ms/step\n",
      "Epoch 2891/5000\n",
      "31/31 - 0s - loss: 16.2219 - mae: 2.2171 - val_loss: 0.1797 - val_mae: 0.3841 - 35ms/epoch - 1ms/step\n",
      "Epoch 2892/5000\n",
      "31/31 - 0s - loss: 1.9078 - mae: 1.0556 - val_loss: 0.8804 - val_mae: 0.8784 - 35ms/epoch - 1ms/step\n",
      "Epoch 2893/5000\n",
      "31/31 - 0s - loss: 14.9590 - mae: 2.1578 - val_loss: 0.5199 - val_mae: 0.6484 - 35ms/epoch - 1ms/step\n",
      "Epoch 2894/5000\n",
      "31/31 - 0s - loss: 1.3715 - mae: 0.9895 - val_loss: 0.4837 - val_mae: 0.6175 - 36ms/epoch - 1ms/step\n",
      "Epoch 2895/5000\n",
      "31/31 - 0s - loss: 11.0063 - mae: 2.0442 - val_loss: 5.5053 - val_mae: 2.3248 - 37ms/epoch - 1ms/step\n",
      "Epoch 2896/5000\n",
      "31/31 - 0s - loss: 1.8536 - mae: 1.0240 - val_loss: 4.9601 - val_mae: 2.2042 - 36ms/epoch - 1ms/step\n",
      "Epoch 2897/5000\n",
      "31/31 - 0s - loss: 20.9760 - mae: 2.2563 - val_loss: 1.5775 - val_mae: 1.2145 - 37ms/epoch - 1ms/step\n",
      "Epoch 2898/5000\n",
      "31/31 - 0s - loss: 1.7917 - mae: 1.1818 - val_loss: 0.1069 - val_mae: 0.2850 - 35ms/epoch - 1ms/step\n",
      "Epoch 2899/5000\n",
      "31/31 - 0s - loss: 19.2574 - mae: 1.6764 - val_loss: 38.8882 - val_mae: 6.2275 - 37ms/epoch - 1ms/step\n",
      "Epoch 2900/5000\n",
      "31/31 - 0s - loss: 3.2135 - mae: 1.2015 - val_loss: 6.0809 - val_mae: 2.4454 - 35ms/epoch - 1ms/step\n",
      "Epoch 2901/5000\n",
      "31/31 - 0s - loss: 1.5861 - mae: 1.0631 - val_loss: 0.6460 - val_mae: 0.7350 - 37ms/epoch - 1ms/step\n",
      "Epoch 2902/5000\n",
      "31/31 - 0s - loss: 20.4104 - mae: 1.9776 - val_loss: 4.9491 - val_mae: 2.2006 - 36ms/epoch - 1ms/step\n",
      "Epoch 2903/5000\n",
      "31/31 - 0s - loss: 0.9488 - mae: 0.7916 - val_loss: 4.9709 - val_mae: 2.2053 - 37ms/epoch - 1ms/step\n",
      "Epoch 2904/5000\n",
      "31/31 - 0s - loss: 8.0016 - mae: 1.4177 - val_loss: 0.4061 - val_mae: 0.5478 - 36ms/epoch - 1ms/step\n",
      "Epoch 2905/5000\n",
      "31/31 - 0s - loss: 18.5401 - mae: 2.0884 - val_loss: 0.4620 - val_mae: 0.5978 - 37ms/epoch - 1ms/step\n",
      "Epoch 2906/5000\n",
      "31/31 - 0s - loss: 0.9950 - mae: 0.7013 - val_loss: 0.2060 - val_mae: 0.4051 - 36ms/epoch - 1ms/step\n",
      "Epoch 2907/5000\n",
      "31/31 - 0s - loss: 0.6156 - mae: 0.6526 - val_loss: 0.9932 - val_mae: 0.9421 - 36ms/epoch - 1ms/step\n",
      "Epoch 2908/5000\n",
      "31/31 - 0s - loss: 20.6689 - mae: 2.0255 - val_loss: 0.1548 - val_mae: 0.3592 - 35ms/epoch - 1ms/step\n",
      "Epoch 2909/5000\n",
      "31/31 - 0s - loss: 1.1327 - mae: 0.7999 - val_loss: 0.4792 - val_mae: 0.6115 - 36ms/epoch - 1ms/step\n",
      "Epoch 2910/5000\n",
      "31/31 - 0s - loss: 10.0282 - mae: 2.0675 - val_loss: 1.6453 - val_mae: 1.2388 - 40ms/epoch - 1ms/step\n",
      "Epoch 2911/5000\n",
      "31/31 - 0s - loss: 5.2627 - mae: 1.5695 - val_loss: 30.0310 - val_mae: 5.4709 - 35ms/epoch - 1ms/step\n",
      "Epoch 2912/5000\n",
      "31/31 - 0s - loss: 4.4229 - mae: 1.5741 - val_loss: 0.7470 - val_mae: 0.7996 - 36ms/epoch - 1ms/step\n",
      "Epoch 2913/5000\n",
      "31/31 - 0s - loss: 7.8784 - mae: 2.0433 - val_loss: 1.1459 - val_mae: 1.0158 - 37ms/epoch - 1ms/step\n",
      "Epoch 2914/5000\n",
      "31/31 - 0s - loss: 2.1135 - mae: 1.2295 - val_loss: 0.2836 - val_mae: 0.4247 - 48ms/epoch - 2ms/step\n",
      "Epoch 2915/5000\n",
      "31/31 - 0s - loss: 17.4937 - mae: 1.9410 - val_loss: 0.1506 - val_mae: 0.3531 - 37ms/epoch - 1ms/step\n",
      "Epoch 2916/5000\n",
      "31/31 - 0s - loss: 0.9711 - mae: 0.8529 - val_loss: 0.1070 - val_mae: 0.2848 - 36ms/epoch - 1ms/step\n",
      "Epoch 2917/5000\n",
      "31/31 - 0s - loss: 11.3828 - mae: 1.8609 - val_loss: 3.1751 - val_mae: 1.7533 - 35ms/epoch - 1ms/step\n",
      "Epoch 2918/5000\n",
      "31/31 - 0s - loss: 3.2920 - mae: 1.6759 - val_loss: 0.2537 - val_mae: 0.4391 - 36ms/epoch - 1ms/step\n",
      "Epoch 2919/5000\n",
      "31/31 - 0s - loss: 8.6733 - mae: 1.6578 - val_loss: 1.6479 - val_mae: 1.2455 - 35ms/epoch - 1ms/step\n",
      "Epoch 2920/5000\n",
      "31/31 - 0s - loss: 2.5968 - mae: 1.0548 - val_loss: 10.8491 - val_mae: 3.2773 - 36ms/epoch - 1ms/step\n",
      "Epoch 2921/5000\n",
      "31/31 - 0s - loss: 6.8800 - mae: 1.5110 - val_loss: 0.4137 - val_mae: 0.5544 - 36ms/epoch - 1ms/step\n",
      "Epoch 2922/5000\n",
      "31/31 - 0s - loss: 10.8872 - mae: 1.7605 - val_loss: 0.2250 - val_mae: 0.4182 - 36ms/epoch - 1ms/step\n",
      "Epoch 2923/5000\n",
      "31/31 - 0s - loss: 2.8489 - mae: 1.3645 - val_loss: 1.1858 - val_mae: 1.0410 - 35ms/epoch - 1ms/step\n",
      "Epoch 2924/5000\n",
      "31/31 - 0s - loss: 17.3239 - mae: 2.1096 - val_loss: 0.4053 - val_mae: 0.5488 - 37ms/epoch - 1ms/step\n",
      "Epoch 2925/5000\n",
      "31/31 - 0s - loss: 1.6847 - mae: 1.0846 - val_loss: 6.7311 - val_mae: 2.5748 - 35ms/epoch - 1ms/step\n",
      "Epoch 2926/5000\n",
      "31/31 - 0s - loss: 10.3974 - mae: 1.9609 - val_loss: 0.1114 - val_mae: 0.2888 - 37ms/epoch - 1ms/step\n",
      "Epoch 2927/5000\n",
      "31/31 - 0s - loss: 1.3032 - mae: 0.9050 - val_loss: 2.9662 - val_mae: 1.6873 - 37ms/epoch - 1ms/step\n",
      "Epoch 2928/5000\n",
      "31/31 - 0s - loss: 19.0452 - mae: 1.9669 - val_loss: 5.8815 - val_mae: 2.4035 - 36ms/epoch - 1ms/step\n",
      "Epoch 2929/5000\n",
      "31/31 - 0s - loss: 1.4470 - mae: 0.8806 - val_loss: 31.4135 - val_mae: 5.5935 - 35ms/epoch - 1ms/step\n",
      "Epoch 2930/5000\n",
      "31/31 - 0s - loss: 13.1461 - mae: 1.7656 - val_loss: 0.9668 - val_mae: 0.9288 - 36ms/epoch - 1ms/step\n",
      "Epoch 2931/5000\n",
      "31/31 - 0s - loss: 5.3341 - mae: 1.2992 - val_loss: 398.0955 - val_mae: 19.9501 - 36ms/epoch - 1ms/step\n",
      "Epoch 2932/5000\n",
      "31/31 - 0s - loss: 15.6115 - mae: 1.7776 - val_loss: 1.8101 - val_mae: 1.3066 - 35ms/epoch - 1ms/step\n",
      "Epoch 2933/5000\n",
      "31/31 - 0s - loss: 1.0171 - mae: 0.8208 - val_loss: 4.2655 - val_mae: 2.0398 - 39ms/epoch - 1ms/step\n",
      "Epoch 2934/5000\n",
      "31/31 - 0s - loss: 19.5379 - mae: 2.1239 - val_loss: 4.4404 - val_mae: 2.0828 - 36ms/epoch - 1ms/step\n",
      "Epoch 2935/5000\n",
      "31/31 - 0s - loss: 0.9652 - mae: 0.8453 - val_loss: 0.6189 - val_mae: 0.7137 - 35ms/epoch - 1ms/step\n",
      "Epoch 2936/5000\n",
      "31/31 - 0s - loss: 10.4723 - mae: 1.9287 - val_loss: 0.7967 - val_mae: 0.8295 - 36ms/epoch - 1ms/step\n",
      "Epoch 2937/5000\n",
      "31/31 - 0s - loss: 11.3054 - mae: 2.0580 - val_loss: 0.1474 - val_mae: 0.2891 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2938/5000\n",
      "31/31 - 0s - loss: 0.6680 - mae: 0.6954 - val_loss: 1.7987 - val_mae: 1.3011 - 36ms/epoch - 1ms/step\n",
      "Epoch 2939/5000\n",
      "31/31 - 0s - loss: 9.3681 - mae: 2.1653 - val_loss: 1.3544 - val_mae: 1.1140 - 36ms/epoch - 1ms/step\n",
      "Epoch 2940/5000\n",
      "31/31 - 0s - loss: 1.7262 - mae: 1.0303 - val_loss: 4.3081 - val_mae: 2.0515 - 36ms/epoch - 1ms/step\n",
      "Epoch 2941/5000\n",
      "31/31 - 0s - loss: 19.6556 - mae: 2.3130 - val_loss: 0.1020 - val_mae: 0.2773 - 35ms/epoch - 1ms/step\n",
      "Epoch 2942/5000\n",
      "31/31 - 0s - loss: 0.8835 - mae: 0.7877 - val_loss: 3.4060 - val_mae: 1.8153 - 35ms/epoch - 1ms/step\n",
      "Epoch 2943/5000\n",
      "31/31 - 0s - loss: 13.0081 - mae: 1.9337 - val_loss: 0.1110 - val_mae: 0.2854 - 37ms/epoch - 1ms/step\n",
      "Epoch 2944/5000\n",
      "31/31 - 0s - loss: 2.4009 - mae: 1.1598 - val_loss: 7.4191 - val_mae: 2.7028 - 38ms/epoch - 1ms/step\n",
      "Epoch 2945/5000\n",
      "31/31 - 0s - loss: 5.7598 - mae: 1.7226 - val_loss: 1.9095 - val_mae: 1.3406 - 35ms/epoch - 1ms/step\n",
      "Epoch 2946/5000\n",
      "31/31 - 0s - loss: 1.8715 - mae: 1.0204 - val_loss: 20.5988 - val_mae: 4.5261 - 37ms/epoch - 1ms/step\n",
      "Epoch 2947/5000\n",
      "31/31 - 0s - loss: 8.7783 - mae: 2.1868 - val_loss: 0.1130 - val_mae: 0.2956 - 37ms/epoch - 1ms/step\n",
      "Epoch 2948/5000\n",
      "31/31 - 0s - loss: 18.7615 - mae: 2.4601 - val_loss: 0.5203 - val_mae: 0.6485 - 35ms/epoch - 1ms/step\n",
      "Epoch 2949/5000\n",
      "31/31 - 0s - loss: 2.4877 - mae: 1.1888 - val_loss: 0.2845 - val_mae: 0.4225 - 36ms/epoch - 1ms/step\n",
      "Epoch 2950/5000\n",
      "31/31 - 0s - loss: 2.1856 - mae: 1.1147 - val_loss: 3.2340 - val_mae: 1.7687 - 36ms/epoch - 1ms/step\n",
      "Epoch 2951/5000\n",
      "31/31 - 0s - loss: 14.9151 - mae: 2.0178 - val_loss: 0.3351 - val_mae: 0.4877 - 38ms/epoch - 1ms/step\n",
      "Epoch 2952/5000\n",
      "31/31 - 0s - loss: 3.4927 - mae: 1.2681 - val_loss: 0.4217 - val_mae: 0.5632 - 37ms/epoch - 1ms/step\n",
      "Epoch 2953/5000\n",
      "31/31 - 0s - loss: 9.9318 - mae: 1.5194 - val_loss: 2.2314 - val_mae: 1.4541 - 36ms/epoch - 1ms/step\n",
      "Epoch 2954/5000\n",
      "31/31 - 0s - loss: 1.9209 - mae: 0.8625 - val_loss: 0.3541 - val_mae: 0.4963 - 36ms/epoch - 1ms/step\n",
      "Epoch 2955/5000\n",
      "31/31 - 0s - loss: 6.6148 - mae: 1.7420 - val_loss: 0.1654 - val_mae: 0.3019 - 36ms/epoch - 1ms/step\n",
      "Epoch 2956/5000\n",
      "31/31 - 0s - loss: 0.6199 - mae: 0.5882 - val_loss: 0.4306 - val_mae: 0.5714 - 36ms/epoch - 1ms/step\n",
      "Epoch 2957/5000\n",
      "31/31 - 0s - loss: 18.9975 - mae: 2.2104 - val_loss: 5.7344 - val_mae: 2.3702 - 36ms/epoch - 1ms/step\n",
      "Epoch 2958/5000\n",
      "31/31 - 0s - loss: 1.9094 - mae: 1.1887 - val_loss: 1.9223 - val_mae: 1.3477 - 35ms/epoch - 1ms/step\n",
      "Epoch 2959/5000\n",
      "31/31 - 0s - loss: 19.8601 - mae: 2.1850 - val_loss: 0.1034 - val_mae: 0.2810 - 37ms/epoch - 1ms/step\n",
      "Epoch 2960/5000\n",
      "31/31 - 0s - loss: 1.2737 - mae: 0.9080 - val_loss: 0.8850 - val_mae: 0.8838 - 38ms/epoch - 1ms/step\n",
      "Epoch 2961/5000\n",
      "31/31 - 0s - loss: 16.2871 - mae: 2.1845 - val_loss: 0.1093 - val_mae: 0.2862 - 36ms/epoch - 1ms/step\n",
      "Epoch 2962/5000\n",
      "31/31 - 0s - loss: 0.8122 - mae: 0.7443 - val_loss: 0.1229 - val_mae: 0.2841 - 39ms/epoch - 1ms/step\n",
      "Epoch 2963/5000\n",
      "31/31 - 0s - loss: 11.7760 - mae: 1.7206 - val_loss: 1.4092 - val_mae: 1.1385 - 37ms/epoch - 1ms/step\n",
      "Epoch 2964/5000\n",
      "31/31 - 0s - loss: 2.3648 - mae: 1.1227 - val_loss: 4.6542 - val_mae: 2.1332 - 38ms/epoch - 1ms/step\n",
      "Epoch 2965/5000\n",
      "31/31 - 0s - loss: 10.5127 - mae: 2.2685 - val_loss: 3.8978 - val_mae: 1.9463 - 37ms/epoch - 1ms/step\n",
      "Epoch 2966/5000\n",
      "31/31 - 0s - loss: 1.7695 - mae: 1.1003 - val_loss: 0.3575 - val_mae: 0.4993 - 36ms/epoch - 1ms/step\n",
      "Epoch 2967/5000\n",
      "31/31 - 0s - loss: 14.4042 - mae: 2.0534 - val_loss: 1.6734 - val_mae: 1.2496 - 34ms/epoch - 1ms/step\n",
      "Epoch 2968/5000\n",
      "31/31 - 0s - loss: 3.1154 - mae: 1.4648 - val_loss: 0.2376 - val_mae: 0.3622 - 35ms/epoch - 1ms/step\n",
      "Epoch 2969/5000\n",
      "31/31 - 0s - loss: 12.2036 - mae: 1.8433 - val_loss: 1.7899 - val_mae: 1.2958 - 36ms/epoch - 1ms/step\n",
      "Epoch 2970/5000\n",
      "31/31 - 0s - loss: 1.8928 - mae: 1.1959 - val_loss: 0.6822 - val_mae: 0.7591 - 37ms/epoch - 1ms/step\n",
      "Epoch 2971/5000\n",
      "31/31 - 0s - loss: 6.9010 - mae: 1.8876 - val_loss: 5.2306 - val_mae: 2.2633 - 38ms/epoch - 1ms/step\n",
      "Epoch 2972/5000\n",
      "31/31 - 0s - loss: 1.5135 - mae: 0.9832 - val_loss: 1.8650 - val_mae: 1.3263 - 36ms/epoch - 1ms/step\n",
      "Epoch 2973/5000\n",
      "31/31 - 0s - loss: 11.5862 - mae: 2.0821 - val_loss: 0.4205 - val_mae: 0.5621 - 35ms/epoch - 1ms/step\n",
      "Epoch 2974/5000\n",
      "31/31 - 0s - loss: 21.6807 - mae: 2.7299 - val_loss: 1.3345 - val_mae: 1.1091 - 37ms/epoch - 1ms/step\n",
      "Epoch 2975/5000\n",
      "31/31 - 0s - loss: 1.2266 - mae: 0.7981 - val_loss: 0.7973 - val_mae: 0.8302 - 36ms/epoch - 1ms/step\n",
      "Epoch 2976/5000\n",
      "31/31 - 0s - loss: 1.3599 - mae: 1.0134 - val_loss: 4.4682 - val_mae: 2.0906 - 38ms/epoch - 1ms/step\n",
      "Epoch 2977/5000\n",
      "31/31 - 0s - loss: 14.8826 - mae: 2.1209 - val_loss: 0.9061 - val_mae: 0.8961 - 36ms/epoch - 1ms/step\n",
      "Epoch 2978/5000\n",
      "31/31 - 0s - loss: 1.3541 - mae: 0.9916 - val_loss: 0.4922 - val_mae: 0.6242 - 36ms/epoch - 1ms/step\n",
      "Epoch 2979/5000\n",
      "31/31 - 0s - loss: 12.0499 - mae: 1.9352 - val_loss: 0.3168 - val_mae: 0.4517 - 34ms/epoch - 1ms/step\n",
      "Epoch 2980/5000\n",
      "31/31 - 0s - loss: 2.2933 - mae: 1.0476 - val_loss: 0.2027 - val_mae: 0.4028 - 38ms/epoch - 1ms/step\n",
      "Epoch 2981/5000\n",
      "31/31 - 0s - loss: 16.7009 - mae: 2.0863 - val_loss: 1.9445 - val_mae: 1.3555 - 36ms/epoch - 1ms/step\n",
      "Epoch 2982/5000\n",
      "31/31 - 0s - loss: 1.4957 - mae: 0.9488 - val_loss: 0.1385 - val_mae: 0.3393 - 36ms/epoch - 1ms/step\n",
      "Epoch 2983/5000\n",
      "31/31 - 0s - loss: 13.7708 - mae: 1.8604 - val_loss: 0.1600 - val_mae: 0.2978 - 37ms/epoch - 1ms/step\n",
      "Epoch 2984/5000\n",
      "31/31 - 0s - loss: 1.1956 - mae: 0.9079 - val_loss: 2.9879 - val_mae: 1.6983 - 38ms/epoch - 1ms/step\n",
      "Epoch 2985/5000\n",
      "31/31 - 0s - loss: 13.6160 - mae: 1.9004 - val_loss: 3.8896 - val_mae: 1.9468 - 38ms/epoch - 1ms/step\n",
      "Epoch 2986/5000\n",
      "31/31 - 0s - loss: 1.2102 - mae: 0.8810 - val_loss: 0.9130 - val_mae: 0.8992 - 38ms/epoch - 1ms/step\n",
      "Epoch 2987/5000\n",
      "31/31 - 0s - loss: 23.4119 - mae: 2.1098 - val_loss: 0.1175 - val_mae: 0.3078 - 38ms/epoch - 1ms/step\n",
      "Epoch 2988/5000\n",
      "31/31 - 0s - loss: 1.6008 - mae: 0.9223 - val_loss: 0.1823 - val_mae: 0.3148 - 35ms/epoch - 1ms/step\n",
      "Epoch 2989/5000\n",
      "31/31 - 0s - loss: 10.2724 - mae: 1.6475 - val_loss: 91.3915 - val_mae: 9.5550 - 36ms/epoch - 1ms/step\n",
      "Epoch 2990/5000\n",
      "31/31 - 0s - loss: 4.7287 - mae: 1.3494 - val_loss: 6.9915 - val_mae: 2.6253 - 35ms/epoch - 1ms/step\n",
      "Epoch 2991/5000\n",
      "31/31 - 0s - loss: 11.0496 - mae: 2.1925 - val_loss: 0.3278 - val_mae: 0.4803 - 37ms/epoch - 1ms/step\n",
      "Epoch 2992/5000\n",
      "31/31 - 0s - loss: 1.3138 - mae: 0.9844 - val_loss: 0.3245 - val_mae: 0.4695 - 35ms/epoch - 1ms/step\n",
      "Epoch 2993/5000\n",
      "31/31 - 0s - loss: 16.4520 - mae: 1.9073 - val_loss: 0.6947 - val_mae: 0.7659 - 39ms/epoch - 1ms/step\n",
      "Epoch 2994/5000\n",
      "31/31 - 0s - loss: 0.8794 - mae: 0.8186 - val_loss: 2.1880 - val_mae: 1.4441 - 36ms/epoch - 1ms/step\n",
      "Epoch 2995/5000\n",
      "31/31 - 0s - loss: 22.2234 - mae: 2.2454 - val_loss: 0.1157 - val_mae: 0.2911 - 36ms/epoch - 1ms/step\n",
      "Epoch 2996/5000\n",
      "31/31 - 0s - loss: 1.9011 - mae: 1.0897 - val_loss: 0.8702 - val_mae: 0.8775 - 38ms/epoch - 1ms/step\n",
      "Epoch 2997/5000\n",
      "31/31 - 0s - loss: 16.6651 - mae: 1.9524 - val_loss: 1.0271 - val_mae: 0.9637 - 36ms/epoch - 1ms/step\n",
      "Epoch 2998/5000\n",
      "31/31 - 0s - loss: 1.8321 - mae: 1.2265 - val_loss: 0.2714 - val_mae: 0.4500 - 36ms/epoch - 1ms/step\n",
      "Epoch 2999/5000\n",
      "31/31 - 0s - loss: 11.9426 - mae: 1.9160 - val_loss: 0.3860 - val_mae: 0.5278 - 36ms/epoch - 1ms/step\n",
      "Epoch 3000/5000\n",
      "31/31 - 0s - loss: 1.7801 - mae: 1.0996 - val_loss: 2.8426 - val_mae: 1.6531 - 36ms/epoch - 1ms/step\n",
      "Epoch 3001/5000\n",
      "31/31 - 0s - loss: 9.0830 - mae: 1.7317 - val_loss: 0.1193 - val_mae: 0.2808 - 37ms/epoch - 1ms/step\n",
      "Epoch 3002/5000\n",
      "31/31 - 0s - loss: 10.9817 - mae: 2.0205 - val_loss: 2.3555 - val_mae: 1.5009 - 36ms/epoch - 1ms/step\n",
      "Epoch 3003/5000\n",
      "31/31 - 0s - loss: 0.3534 - mae: 0.5010 - val_loss: 3.0424 - val_mae: 1.7146 - 37ms/epoch - 1ms/step\n",
      "Epoch 3004/5000\n",
      "31/31 - 0s - loss: 14.4488 - mae: 2.1105 - val_loss: 1.1042 - val_mae: 1.0012 - 37ms/epoch - 1ms/step\n",
      "Epoch 3005/5000\n",
      "31/31 - 0s - loss: 2.2080 - mae: 1.2130 - val_loss: 0.5099 - val_mae: 0.6379 - 35ms/epoch - 1ms/step\n",
      "Epoch 3006/5000\n",
      "31/31 - 0s - loss: 21.6871 - mae: 2.0855 - val_loss: 0.3306 - val_mae: 0.4776 - 34ms/epoch - 1ms/step\n",
      "Epoch 3007/5000\n",
      "31/31 - 0s - loss: 1.6030 - mae: 0.8972 - val_loss: 0.1302 - val_mae: 0.3300 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3008/5000\n",
      "31/31 - 0s - loss: 2.3586 - mae: 0.9904 - val_loss: 310.9115 - val_mae: 17.6292 - 48ms/epoch - 2ms/step\n",
      "Epoch 3009/5000\n",
      "31/31 - 0s - loss: 17.0241 - mae: 2.0081 - val_loss: 0.2832 - val_mae: 0.4579 - 37ms/epoch - 1ms/step\n",
      "Epoch 3010/5000\n",
      "31/31 - 0s - loss: 0.8054 - mae: 0.7250 - val_loss: 1.8895 - val_mae: 1.3359 - 38ms/epoch - 1ms/step\n",
      "Epoch 3011/5000\n",
      "31/31 - 0s - loss: 13.5825 - mae: 1.9606 - val_loss: 0.8276 - val_mae: 0.8489 - 38ms/epoch - 1ms/step\n",
      "Epoch 3012/5000\n",
      "31/31 - 0s - loss: 2.1274 - mae: 1.1986 - val_loss: 1.8110 - val_mae: 1.3066 - 36ms/epoch - 1ms/step\n",
      "Epoch 3013/5000\n",
      "31/31 - 0s - loss: 24.2553 - mae: 2.0814 - val_loss: 0.2990 - val_mae: 0.4674 - 36ms/epoch - 1ms/step\n",
      "Epoch 3014/5000\n",
      "31/31 - 0s - loss: 1.4637 - mae: 0.9391 - val_loss: 0.6261 - val_mae: 0.7186 - 36ms/epoch - 1ms/step\n",
      "Epoch 3015/5000\n",
      "31/31 - 0s - loss: 13.1694 - mae: 2.0219 - val_loss: 1.1198 - val_mae: 1.0074 - 37ms/epoch - 1ms/step\n",
      "Epoch 3016/5000\n",
      "31/31 - 0s - loss: 0.5784 - mae: 0.6705 - val_loss: 1.1173 - val_mae: 1.0053 - 36ms/epoch - 1ms/step\n",
      "Epoch 3017/5000\n",
      "31/31 - 0s - loss: 16.7508 - mae: 2.1555 - val_loss: 0.7872 - val_mae: 0.8287 - 35ms/epoch - 1ms/step\n",
      "Epoch 3018/5000\n",
      "31/31 - 0s - loss: 0.8531 - mae: 0.7719 - val_loss: 0.2816 - val_mae: 0.4562 - 36ms/epoch - 1ms/step\n",
      "Epoch 3019/5000\n",
      "31/31 - 0s - loss: 18.9253 - mae: 2.1408 - val_loss: 0.3786 - val_mae: 0.5196 - 36ms/epoch - 1ms/step\n",
      "Epoch 3020/5000\n",
      "31/31 - 0s - loss: 0.9710 - mae: 0.7891 - val_loss: 0.5639 - val_mae: 0.6766 - 35ms/epoch - 1ms/step\n",
      "Epoch 3021/5000\n",
      "31/31 - 0s - loss: 1.3218 - mae: 0.9541 - val_loss: 3.1572 - val_mae: 1.7457 - 36ms/epoch - 1ms/step\n",
      "Epoch 3022/5000\n",
      "31/31 - 0s - loss: 12.6052 - mae: 2.0996 - val_loss: 8.0765 - val_mae: 2.8245 - 36ms/epoch - 1ms/step\n",
      "Epoch 3023/5000\n",
      "31/31 - 0s - loss: 11.2446 - mae: 1.9899 - val_loss: 121.1388 - val_mae: 11.0017 - 36ms/epoch - 1ms/step\n",
      "Epoch 3024/5000\n",
      "31/31 - 0s - loss: 6.3053 - mae: 1.1721 - val_loss: 2.4350 - val_mae: 1.5268 - 34ms/epoch - 1ms/step\n",
      "Epoch 3025/5000\n",
      "31/31 - 0s - loss: 10.8150 - mae: 1.9005 - val_loss: 0.5860 - val_mae: 0.6935 - 38ms/epoch - 1ms/step\n",
      "Epoch 3026/5000\n",
      "31/31 - 0s - loss: 1.5222 - mae: 1.0067 - val_loss: 0.1564 - val_mae: 0.2922 - 36ms/epoch - 1ms/step\n",
      "Epoch 3027/5000\n",
      "31/31 - 0s - loss: 7.3759 - mae: 1.7735 - val_loss: 2.6446 - val_mae: 1.5916 - 36ms/epoch - 1ms/step\n",
      "Epoch 3028/5000\n",
      "31/31 - 0s - loss: 1.6475 - mae: 1.0267 - val_loss: 255.5784 - val_mae: 15.9827 - 36ms/epoch - 1ms/step\n",
      "Epoch 3029/5000\n",
      "31/31 - 0s - loss: 17.1868 - mae: 1.9473 - val_loss: 3.0893 - val_mae: 1.7271 - 35ms/epoch - 1ms/step\n",
      "Epoch 3030/5000\n",
      "31/31 - 0s - loss: 0.9563 - mae: 0.7010 - val_loss: 0.3203 - val_mae: 0.4787 - 36ms/epoch - 1ms/step\n",
      "Epoch 3031/5000\n",
      "31/31 - 0s - loss: 31.0717 - mae: 2.2899 - val_loss: 0.9770 - val_mae: 0.9341 - 35ms/epoch - 1ms/step\n",
      "Epoch 3032/5000\n",
      "31/31 - 0s - loss: 1.9334 - mae: 1.1335 - val_loss: 4.6490 - val_mae: 2.1328 - 35ms/epoch - 1ms/step\n",
      "Epoch 3033/5000\n",
      "31/31 - 0s - loss: 18.6730 - mae: 2.2548 - val_loss: 0.4153 - val_mae: 0.5579 - 36ms/epoch - 1ms/step\n",
      "Epoch 3034/5000\n",
      "31/31 - 0s - loss: 0.6742 - mae: 0.6210 - val_loss: 0.4863 - val_mae: 0.6168 - 36ms/epoch - 1ms/step\n",
      "Epoch 3035/5000\n",
      "31/31 - 0s - loss: 0.7822 - mae: 0.6994 - val_loss: 0.1944 - val_mae: 0.3265 - 36ms/epoch - 1ms/step\n",
      "Epoch 3036/5000\n",
      "31/31 - 0s - loss: 16.1479 - mae: 2.0149 - val_loss: 0.1074 - val_mae: 0.2811 - 36ms/epoch - 1ms/step\n",
      "Epoch 3037/5000\n",
      "31/31 - 0s - loss: 1.0982 - mae: 0.8935 - val_loss: 2.0530 - val_mae: 1.3967 - 37ms/epoch - 1ms/step\n",
      "Epoch 3038/5000\n",
      "31/31 - 0s - loss: 30.7579 - mae: 2.0433 - val_loss: 0.8070 - val_mae: 0.8416 - 35ms/epoch - 1ms/step\n",
      "Epoch 3039/5000\n",
      "31/31 - 0s - loss: 1.5127 - mae: 0.9927 - val_loss: 0.4661 - val_mae: 0.6049 - 37ms/epoch - 1ms/step\n",
      "Epoch 3040/5000\n",
      "31/31 - 0s - loss: 2.7007 - mae: 1.2094 - val_loss: 0.1428 - val_mae: 0.3439 - 37ms/epoch - 1ms/step\n",
      "Epoch 3041/5000\n",
      "31/31 - 0s - loss: 7.3987 - mae: 1.7978 - val_loss: 3.4374 - val_mae: 1.8247 - 35ms/epoch - 1ms/step\n",
      "Epoch 3042/5000\n",
      "31/31 - 0s - loss: 1.4289 - mae: 1.0110 - val_loss: 0.4997 - val_mae: 0.6256 - 44ms/epoch - 1ms/step\n",
      "Epoch 3043/5000\n",
      "31/31 - 0s - loss: 13.0948 - mae: 2.7703 - val_loss: 6.6361 - val_mae: 2.5532 - 40ms/epoch - 1ms/step\n",
      "Epoch 3044/5000\n",
      "31/31 - 0s - loss: 2.2112 - mae: 1.3455 - val_loss: 0.7310 - val_mae: 0.7890 - 39ms/epoch - 1ms/step\n",
      "Epoch 3045/5000\n",
      "31/31 - 0s - loss: 9.9264 - mae: 1.8456 - val_loss: 0.1136 - val_mae: 0.2910 - 40ms/epoch - 1ms/step\n",
      "Epoch 3046/5000\n",
      "31/31 - 0s - loss: 2.6393 - mae: 1.1821 - val_loss: 0.6655 - val_mae: 0.7445 - 41ms/epoch - 1ms/step\n",
      "Epoch 3047/5000\n",
      "31/31 - 0s - loss: 11.5516 - mae: 2.0070 - val_loss: 4.4963 - val_mae: 2.0934 - 39ms/epoch - 1ms/step\n",
      "Epoch 3048/5000\n",
      "31/31 - 0s - loss: 2.7590 - mae: 1.2181 - val_loss: 18.2349 - val_mae: 4.2581 - 42ms/epoch - 1ms/step\n",
      "Epoch 3049/5000\n",
      "31/31 - 0s - loss: 10.4297 - mae: 1.6732 - val_loss: 2.7697 - val_mae: 1.6340 - 43ms/epoch - 1ms/step\n",
      "Epoch 3050/5000\n",
      "31/31 - 0s - loss: 0.8234 - mae: 0.7484 - val_loss: 0.2228 - val_mae: 0.4183 - 41ms/epoch - 1ms/step\n",
      "Epoch 3051/5000\n",
      "31/31 - 0s - loss: 9.9806 - mae: 1.8346 - val_loss: 3.6609 - val_mae: 1.8849 - 43ms/epoch - 1ms/step\n",
      "Epoch 3052/5000\n",
      "31/31 - 0s - loss: 1.6078 - mae: 1.0919 - val_loss: 8.8816 - val_mae: 2.9628 - 43ms/epoch - 1ms/step\n",
      "Epoch 3053/5000\n",
      "31/31 - 0s - loss: 21.2497 - mae: 2.2393 - val_loss: 5.2729 - val_mae: 2.2725 - 43ms/epoch - 1ms/step\n",
      "Epoch 3054/5000\n",
      "31/31 - 0s - loss: 0.8470 - mae: 0.6284 - val_loss: 5.3571 - val_mae: 2.2897 - 50ms/epoch - 2ms/step\n",
      "Epoch 3055/5000\n",
      "31/31 - 0s - loss: 8.1268 - mae: 2.0774 - val_loss: 0.6032 - val_mae: 0.7058 - 43ms/epoch - 1ms/step\n",
      "Epoch 3056/5000\n",
      "31/31 - 0s - loss: 21.5233 - mae: 2.2330 - val_loss: 0.2592 - val_mae: 0.4004 - 43ms/epoch - 1ms/step\n",
      "Epoch 3057/5000\n",
      "31/31 - 0s - loss: 1.4469 - mae: 1.0215 - val_loss: 5.4955 - val_mae: 2.3227 - 39ms/epoch - 1ms/step\n",
      "Epoch 3058/5000\n",
      "31/31 - 0s - loss: 7.7057 - mae: 1.8536 - val_loss: 0.1576 - val_mae: 0.3610 - 40ms/epoch - 1ms/step\n",
      "Epoch 3059/5000\n",
      "31/31 - 0s - loss: 0.9299 - mae: 0.8380 - val_loss: 0.3388 - val_mae: 0.4824 - 51ms/epoch - 2ms/step\n",
      "Epoch 3060/5000\n",
      "31/31 - 0s - loss: 14.2447 - mae: 2.0514 - val_loss: 0.6375 - val_mae: 0.7285 - 47ms/epoch - 2ms/step\n",
      "Epoch 3061/5000\n",
      "31/31 - 0s - loss: 2.2326 - mae: 1.1319 - val_loss: 1.5706 - val_mae: 1.2114 - 48ms/epoch - 2ms/step\n",
      "Epoch 3062/5000\n",
      "31/31 - 0s - loss: 24.8742 - mae: 2.2782 - val_loss: 0.1969 - val_mae: 0.3987 - 45ms/epoch - 1ms/step\n",
      "Epoch 3063/5000\n",
      "31/31 - 0s - loss: 1.2935 - mae: 0.9887 - val_loss: 0.7570 - val_mae: 0.8080 - 45ms/epoch - 1ms/step\n",
      "Epoch 3064/5000\n",
      "31/31 - 0s - loss: 8.0646 - mae: 1.6609 - val_loss: 2.2079 - val_mae: 1.4517 - 46ms/epoch - 1ms/step\n",
      "Epoch 3065/5000\n",
      "31/31 - 0s - loss: 16.8973 - mae: 1.9087 - val_loss: 0.3116 - val_mae: 0.4546 - 48ms/epoch - 2ms/step\n",
      "Epoch 3066/5000\n",
      "31/31 - 0s - loss: 1.0477 - mae: 0.7908 - val_loss: 1.2131 - val_mae: 1.0539 - 42ms/epoch - 1ms/step\n",
      "Epoch 3067/5000\n",
      "31/31 - 0s - loss: 8.9085 - mae: 1.6779 - val_loss: 0.4152 - val_mae: 0.5601 - 45ms/epoch - 1ms/step\n",
      "Epoch 3068/5000\n",
      "31/31 - 0s - loss: 1.3532 - mae: 0.9856 - val_loss: 9.0561 - val_mae: 2.9927 - 47ms/epoch - 2ms/step\n",
      "Epoch 3069/5000\n",
      "31/31 - 0s - loss: 9.7798 - mae: 2.0721 - val_loss: 10.7200 - val_mae: 3.2591 - 46ms/epoch - 1ms/step\n",
      "Epoch 3070/5000\n",
      "31/31 - 0s - loss: 1.2092 - mae: 0.8884 - val_loss: 3.3328 - val_mae: 1.7981 - 38ms/epoch - 1ms/step\n",
      "Epoch 3071/5000\n",
      "31/31 - 0s - loss: 15.8880 - mae: 1.7783 - val_loss: 0.3685 - val_mae: 0.5102 - 39ms/epoch - 1ms/step\n",
      "Epoch 3072/5000\n",
      "31/31 - 0s - loss: 1.1993 - mae: 0.8821 - val_loss: 0.4389 - val_mae: 0.5778 - 40ms/epoch - 1ms/step\n",
      "Epoch 3073/5000\n",
      "31/31 - 0s - loss: 16.5963 - mae: 2.1711 - val_loss: 0.8039 - val_mae: 0.8325 - 40ms/epoch - 1ms/step\n",
      "Epoch 3074/5000\n",
      "31/31 - 0s - loss: 1.2219 - mae: 0.8345 - val_loss: 0.7455 - val_mae: 0.7986 - 37ms/epoch - 1ms/step\n",
      "Epoch 3075/5000\n",
      "31/31 - 0s - loss: 8.0300 - mae: 1.9557 - val_loss: 0.5642 - val_mae: 0.6723 - 38ms/epoch - 1ms/step\n",
      "Epoch 3076/5000\n",
      "31/31 - 0s - loss: 19.2388 - mae: 2.2306 - val_loss: 0.2907 - val_mae: 0.4345 - 37ms/epoch - 1ms/step\n",
      "Epoch 3077/5000\n",
      "31/31 - 0s - loss: 1.2576 - mae: 0.7821 - val_loss: 3.1263 - val_mae: 1.7384 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3078/5000\n",
      "31/31 - 0s - loss: 6.5469 - mae: 1.6170 - val_loss: 0.4875 - val_mae: 0.6203 - 39ms/epoch - 1ms/step\n",
      "Epoch 3079/5000\n",
      "31/31 - 0s - loss: 0.5312 - mae: 0.5877 - val_loss: 0.6821 - val_mae: 0.7598 - 37ms/epoch - 1ms/step\n",
      "Epoch 3080/5000\n",
      "31/31 - 0s - loss: 9.8638 - mae: 1.7807 - val_loss: 0.2481 - val_mae: 0.3764 - 39ms/epoch - 1ms/step\n",
      "Epoch 3081/5000\n",
      "31/31 - 0s - loss: 8.6366 - mae: 1.4993 - val_loss: 76.9998 - val_mae: 8.7684 - 37ms/epoch - 1ms/step\n",
      "Epoch 3082/5000\n",
      "31/31 - 0s - loss: 5.9137 - mae: 1.5666 - val_loss: 0.4866 - val_mae: 0.6209 - 36ms/epoch - 1ms/step\n",
      "Epoch 3083/5000\n",
      "31/31 - 0s - loss: 11.2460 - mae: 1.7838 - val_loss: 1.1995 - val_mae: 1.0447 - 38ms/epoch - 1ms/step\n",
      "Epoch 3084/5000\n",
      "31/31 - 0s - loss: 2.0036 - mae: 1.1974 - val_loss: 0.1401 - val_mae: 0.2879 - 36ms/epoch - 1ms/step\n",
      "Epoch 3085/5000\n",
      "31/31 - 0s - loss: 5.7793 - mae: 1.7963 - val_loss: 2.2331 - val_mae: 1.4572 - 36ms/epoch - 1ms/step\n",
      "Epoch 3086/5000\n",
      "31/31 - 0s - loss: 5.3075 - mae: 1.4239 - val_loss: 439.3876 - val_mae: 20.9590 - 35ms/epoch - 1ms/step\n",
      "Epoch 3087/5000\n",
      "31/31 - 0s - loss: 20.1626 - mae: 1.8828 - val_loss: 0.1068 - val_mae: 0.2819 - 37ms/epoch - 1ms/step\n",
      "Epoch 3088/5000\n",
      "31/31 - 0s - loss: 0.7842 - mae: 0.7786 - val_loss: 1.8315 - val_mae: 1.3138 - 37ms/epoch - 1ms/step\n",
      "Epoch 3089/5000\n",
      "31/31 - 0s - loss: 28.2447 - mae: 2.5576 - val_loss: 1.1723 - val_mae: 1.0321 - 37ms/epoch - 1ms/step\n",
      "Epoch 3090/5000\n",
      "31/31 - 0s - loss: 1.6950 - mae: 1.0655 - val_loss: 8.3597 - val_mae: 2.8731 - 36ms/epoch - 1ms/step\n",
      "Epoch 3091/5000\n",
      "31/31 - 0s - loss: 18.0778 - mae: 2.2497 - val_loss: 1.3581 - val_mae: 1.1197 - 37ms/epoch - 1ms/step\n",
      "Epoch 3092/5000\n",
      "31/31 - 0s - loss: 1.6482 - mae: 1.0916 - val_loss: 4.8591 - val_mae: 2.1813 - 39ms/epoch - 1ms/step\n",
      "Epoch 3093/5000\n",
      "31/31 - 0s - loss: 10.5880 - mae: 2.0636 - val_loss: 1.2824 - val_mae: 1.0830 - 37ms/epoch - 1ms/step\n",
      "Epoch 3094/5000\n",
      "31/31 - 0s - loss: 1.1119 - mae: 0.8098 - val_loss: 0.4762 - val_mae: 0.6116 - 37ms/epoch - 1ms/step\n",
      "Epoch 3095/5000\n",
      "31/31 - 0s - loss: 20.8498 - mae: 2.0783 - val_loss: 0.2979 - val_mae: 0.4423 - 36ms/epoch - 1ms/step\n",
      "Epoch 3096/5000\n",
      "31/31 - 0s - loss: 1.0605 - mae: 0.8554 - val_loss: 3.5572 - val_mae: 1.8576 - 37ms/epoch - 1ms/step\n",
      "Epoch 3097/5000\n",
      "31/31 - 0s - loss: 6.7373 - mae: 1.6849 - val_loss: 0.7306 - val_mae: 0.7860 - 37ms/epoch - 1ms/step\n",
      "Epoch 3098/5000\n",
      "31/31 - 0s - loss: 1.7022 - mae: 1.0190 - val_loss: 1.8855 - val_mae: 1.3335 - 37ms/epoch - 1ms/step\n",
      "Epoch 3099/5000\n",
      "31/31 - 0s - loss: 17.9223 - mae: 1.8366 - val_loss: 1.2392 - val_mae: 1.0626 - 39ms/epoch - 1ms/step\n",
      "Epoch 3100/5000\n",
      "31/31 - 0s - loss: 2.5231 - mae: 1.2548 - val_loss: 0.7802 - val_mae: 0.8181 - 36ms/epoch - 1ms/step\n",
      "Epoch 3101/5000\n",
      "31/31 - 0s - loss: 26.6449 - mae: 2.0883 - val_loss: 0.2431 - val_mae: 0.3728 - 36ms/epoch - 1ms/step\n",
      "Epoch 3102/5000\n",
      "31/31 - 0s - loss: 1.8562 - mae: 0.8893 - val_loss: 0.1176 - val_mae: 0.2925 - 36ms/epoch - 1ms/step\n",
      "Epoch 3103/5000\n",
      "31/31 - 0s - loss: 6.9385 - mae: 1.6248 - val_loss: 0.6898 - val_mae: 0.7701 - 36ms/epoch - 1ms/step\n",
      "Epoch 3104/5000\n",
      "31/31 - 0s - loss: 1.0735 - mae: 0.9388 - val_loss: 2.9295 - val_mae: 1.6820 - 37ms/epoch - 1ms/step\n",
      "Epoch 3105/5000\n",
      "31/31 - 0s - loss: 11.8671 - mae: 1.8243 - val_loss: 3.4527 - val_mae: 1.8319 - 36ms/epoch - 1ms/step\n",
      "Epoch 3106/5000\n",
      "31/31 - 0s - loss: 2.5452 - mae: 1.3290 - val_loss: 2.0187 - val_mae: 1.3839 - 36ms/epoch - 1ms/step\n",
      "Epoch 3107/5000\n",
      "31/31 - 0s - loss: 23.2898 - mae: 2.3120 - val_loss: 6.5444 - val_mae: 2.5354 - 38ms/epoch - 1ms/step\n",
      "Epoch 3108/5000\n",
      "31/31 - 0s - loss: 3.7929 - mae: 1.6468 - val_loss: 0.3461 - val_mae: 0.4867 - 36ms/epoch - 1ms/step\n",
      "Epoch 3109/5000\n",
      "31/31 - 0s - loss: 4.2021 - mae: 1.4330 - val_loss: 0.1320 - val_mae: 0.3267 - 37ms/epoch - 1ms/step\n",
      "Epoch 3110/5000\n",
      "31/31 - 0s - loss: 26.3665 - mae: 2.0648 - val_loss: 23.9124 - val_mae: 4.8797 - 37ms/epoch - 1ms/step\n",
      "Epoch 3111/5000\n",
      "31/31 - 0s - loss: 1.9634 - mae: 0.9904 - val_loss: 0.5363 - val_mae: 0.6564 - 34ms/epoch - 1ms/step\n",
      "Epoch 3112/5000\n",
      "31/31 - 0s - loss: 6.4436 - mae: 1.7088 - val_loss: 1.8981 - val_mae: 1.3411 - 36ms/epoch - 1ms/step\n",
      "Epoch 3113/5000\n",
      "31/31 - 0s - loss: 0.5829 - mae: 0.5718 - val_loss: 1.5901 - val_mae: 1.2159 - 36ms/epoch - 1ms/step\n",
      "Epoch 3114/5000\n",
      "31/31 - 0s - loss: 15.5736 - mae: 2.1998 - val_loss: 1.0016 - val_mae: 0.9417 - 38ms/epoch - 1ms/step\n",
      "Epoch 3115/5000\n",
      "31/31 - 0s - loss: 2.8194 - mae: 1.3722 - val_loss: 18.6793 - val_mae: 4.3092 - 35ms/epoch - 1ms/step\n",
      "Epoch 3116/5000\n",
      "31/31 - 0s - loss: 8.8366 - mae: 1.6412 - val_loss: 0.3500 - val_mae: 0.4953 - 36ms/epoch - 1ms/step\n",
      "Epoch 3117/5000\n",
      "31/31 - 0s - loss: 21.9239 - mae: 1.8680 - val_loss: 0.1172 - val_mae: 0.2971 - 39ms/epoch - 1ms/step\n",
      "Epoch 3118/5000\n",
      "31/31 - 0s - loss: 1.0755 - mae: 0.7855 - val_loss: 1.8723 - val_mae: 1.3276 - 51ms/epoch - 2ms/step\n",
      "Epoch 3119/5000\n",
      "31/31 - 0s - loss: 1.2411 - mae: 0.8709 - val_loss: 1.3683 - val_mae: 1.1201 - 37ms/epoch - 1ms/step\n",
      "Epoch 3120/5000\n",
      "31/31 - 0s - loss: 13.1645 - mae: 2.0117 - val_loss: 5.5363 - val_mae: 2.3314 - 36ms/epoch - 1ms/step\n",
      "Epoch 3121/5000\n",
      "31/31 - 0s - loss: 1.5695 - mae: 0.9981 - val_loss: 74.7653 - val_mae: 8.6405 - 37ms/epoch - 1ms/step\n",
      "Epoch 3122/5000\n",
      "31/31 - 0s - loss: 8.3685 - mae: 1.9454 - val_loss: 4.4827 - val_mae: 2.0930 - 37ms/epoch - 1ms/step\n",
      "Epoch 3123/5000\n",
      "31/31 - 0s - loss: 15.5714 - mae: 2.1857 - val_loss: 0.1157 - val_mae: 0.2917 - 34ms/epoch - 1ms/step\n",
      "Epoch 3124/5000\n",
      "31/31 - 0s - loss: 2.5408 - mae: 1.3789 - val_loss: 1.4750 - val_mae: 1.1684 - 35ms/epoch - 1ms/step\n",
      "Epoch 3125/5000\n",
      "31/31 - 0s - loss: 7.5804 - mae: 1.9126 - val_loss: 0.1325 - val_mae: 0.3253 - 37ms/epoch - 1ms/step\n",
      "Epoch 3126/5000\n",
      "31/31 - 0s - loss: 1.2540 - mae: 0.9214 - val_loss: 1.9180 - val_mae: 1.3446 - 37ms/epoch - 1ms/step\n",
      "Epoch 3127/5000\n",
      "31/31 - 0s - loss: 11.4516 - mae: 2.0744 - val_loss: 16.8750 - val_mae: 4.0952 - 37ms/epoch - 1ms/step\n",
      "Epoch 3128/5000\n",
      "31/31 - 0s - loss: 19.1045 - mae: 2.3856 - val_loss: 1.4454 - val_mae: 1.1592 - 36ms/epoch - 1ms/step\n",
      "Epoch 3129/5000\n",
      "31/31 - 0s - loss: 0.3469 - mae: 0.4956 - val_loss: 2.9803 - val_mae: 1.6969 - 36ms/epoch - 1ms/step\n",
      "Epoch 3130/5000\n",
      "31/31 - 0s - loss: 0.7782 - mae: 0.7060 - val_loss: 0.1166 - val_mae: 0.3011 - 36ms/epoch - 1ms/step\n",
      "Epoch 3131/5000\n",
      "31/31 - 0s - loss: 14.8800 - mae: 2.1209 - val_loss: 1.0785 - val_mae: 0.9853 - 36ms/epoch - 1ms/step\n",
      "Epoch 3132/5000\n",
      "31/31 - 0s - loss: 1.4707 - mae: 0.9778 - val_loss: 1.1729 - val_mae: 1.0324 - 38ms/epoch - 1ms/step\n",
      "Epoch 3133/5000\n",
      "31/31 - 0s - loss: 11.6371 - mae: 2.0195 - val_loss: 2.5845 - val_mae: 1.5738 - 38ms/epoch - 1ms/step\n",
      "Epoch 3134/5000\n",
      "31/31 - 0s - loss: 1.9447 - mae: 1.2270 - val_loss: 103.6531 - val_mae: 10.1749 - 36ms/epoch - 1ms/step\n",
      "Epoch 3135/5000\n",
      "31/31 - 0s - loss: 11.9613 - mae: 1.9099 - val_loss: 0.1639 - val_mae: 0.2997 - 36ms/epoch - 1ms/step\n",
      "Epoch 3136/5000\n",
      "31/31 - 0s - loss: 19.7078 - mae: 2.0560 - val_loss: 0.4566 - val_mae: 0.5903 - 35ms/epoch - 1ms/step\n",
      "Epoch 3137/5000\n",
      "31/31 - 0s - loss: 1.8353 - mae: 1.1164 - val_loss: 0.1786 - val_mae: 0.3140 - 35ms/epoch - 1ms/step\n",
      "Epoch 3138/5000\n",
      "31/31 - 0s - loss: 12.9378 - mae: 2.0673 - val_loss: 0.1138 - val_mae: 0.2889 - 38ms/epoch - 1ms/step\n",
      "Epoch 3139/5000\n",
      "31/31 - 0s - loss: 0.7369 - mae: 0.6205 - val_loss: 0.1347 - val_mae: 0.2895 - 36ms/epoch - 1ms/step\n",
      "Epoch 3140/5000\n",
      "31/31 - 0s - loss: 1.7578 - mae: 0.9934 - val_loss: 0.9068 - val_mae: 0.8968 - 38ms/epoch - 1ms/step\n",
      "Epoch 3141/5000\n",
      "31/31 - 0s - loss: 8.0634 - mae: 2.1366 - val_loss: 7.9925 - val_mae: 2.8085 - 37ms/epoch - 1ms/step\n",
      "Epoch 3142/5000\n",
      "31/31 - 0s - loss: 2.0085 - mae: 1.1382 - val_loss: 0.1231 - val_mae: 0.2891 - 37ms/epoch - 1ms/step\n",
      "Epoch 3143/5000\n",
      "31/31 - 0s - loss: 24.2311 - mae: 2.1315 - val_loss: 1.6729 - val_mae: 1.2522 - 36ms/epoch - 1ms/step\n",
      "Epoch 3144/5000\n",
      "31/31 - 0s - loss: 1.9157 - mae: 1.1029 - val_loss: 0.1917 - val_mae: 0.3279 - 36ms/epoch - 1ms/step\n",
      "Epoch 3145/5000\n",
      "31/31 - 0s - loss: 6.2545 - mae: 1.9627 - val_loss: 0.3192 - val_mae: 0.4675 - 38ms/epoch - 1ms/step\n",
      "Epoch 3146/5000\n",
      "31/31 - 0s - loss: 0.5964 - mae: 0.6060 - val_loss: 2.2207 - val_mae: 1.4533 - 36ms/epoch - 1ms/step\n",
      "Epoch 3147/5000\n",
      "31/31 - 0s - loss: 38.9271 - mae: 2.2195 - val_loss: 4.1703 - val_mae: 2.0174 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3148/5000\n",
      "31/31 - 0s - loss: 1.9479 - mae: 0.9710 - val_loss: 10.6406 - val_mae: 3.2465 - 39ms/epoch - 1ms/step\n",
      "Epoch 3149/5000\n",
      "31/31 - 0s - loss: 10.1126 - mae: 2.0845 - val_loss: 10.3526 - val_mae: 3.2031 - 38ms/epoch - 1ms/step\n",
      "Epoch 3150/5000\n",
      "31/31 - 0s - loss: 2.4070 - mae: 1.1672 - val_loss: 0.1342 - val_mae: 0.2799 - 37ms/epoch - 1ms/step\n",
      "Epoch 3151/5000\n",
      "31/31 - 0s - loss: 13.7462 - mae: 2.1795 - val_loss: 0.3139 - val_mae: 0.4776 - 38ms/epoch - 1ms/step\n",
      "Epoch 3152/5000\n",
      "31/31 - 0s - loss: 0.7831 - mae: 0.7113 - val_loss: 0.5956 - val_mae: 0.7010 - 37ms/epoch - 1ms/step\n",
      "Epoch 3153/5000\n",
      "31/31 - 0s - loss: 9.7233 - mae: 1.7333 - val_loss: 0.2098 - val_mae: 0.4089 - 37ms/epoch - 1ms/step\n",
      "Epoch 3154/5000\n",
      "31/31 - 0s - loss: 0.5092 - mae: 0.5889 - val_loss: 0.1060 - val_mae: 0.2793 - 36ms/epoch - 1ms/step\n",
      "Epoch 3155/5000\n",
      "31/31 - 0s - loss: 20.6335 - mae: 2.2373 - val_loss: 1.1942 - val_mae: 1.0436 - 36ms/epoch - 1ms/step\n",
      "Epoch 3156/5000\n",
      "31/31 - 0s - loss: 1.5336 - mae: 0.9165 - val_loss: 4.8671 - val_mae: 2.1806 - 37ms/epoch - 1ms/step\n",
      "Epoch 3157/5000\n",
      "31/31 - 0s - loss: 8.0315 - mae: 1.9177 - val_loss: 0.8193 - val_mae: 0.8442 - 36ms/epoch - 1ms/step\n",
      "Epoch 3158/5000\n",
      "31/31 - 0s - loss: 14.0042 - mae: 1.4763 - val_loss: 39.3660 - val_mae: 6.2654 - 36ms/epoch - 1ms/step\n",
      "Epoch 3159/5000\n",
      "31/31 - 0s - loss: 3.6700 - mae: 1.1095 - val_loss: 2.5824 - val_mae: 1.5741 - 37ms/epoch - 1ms/step\n",
      "Epoch 3160/5000\n",
      "31/31 - 0s - loss: 6.4758 - mae: 2.0603 - val_loss: 0.5941 - val_mae: 0.7062 - 37ms/epoch - 1ms/step\n",
      "Epoch 3161/5000\n",
      "31/31 - 0s - loss: 0.6487 - mae: 0.6098 - val_loss: 0.3885 - val_mae: 0.5294 - 37ms/epoch - 1ms/step\n",
      "Epoch 3162/5000\n",
      "31/31 - 0s - loss: 24.3662 - mae: 2.1961 - val_loss: 0.1729 - val_mae: 0.3771 - 37ms/epoch - 1ms/step\n",
      "Epoch 3163/5000\n",
      "31/31 - 0s - loss: 0.9764 - mae: 0.8624 - val_loss: 1.4771 - val_mae: 1.1691 - 35ms/epoch - 1ms/step\n",
      "Epoch 3164/5000\n",
      "31/31 - 0s - loss: 19.3452 - mae: 2.1306 - val_loss: 0.2683 - val_mae: 0.4012 - 35ms/epoch - 1ms/step\n",
      "Epoch 3165/5000\n",
      "31/31 - 0s - loss: 0.8820 - mae: 0.8072 - val_loss: 8.1843 - val_mae: 2.8411 - 38ms/epoch - 1ms/step\n",
      "Epoch 3166/5000\n",
      "31/31 - 0s - loss: 15.1851 - mae: 2.2104 - val_loss: 0.2177 - val_mae: 0.3465 - 37ms/epoch - 1ms/step\n",
      "Epoch 3167/5000\n",
      "31/31 - 0s - loss: 0.9726 - mae: 0.7713 - val_loss: 1.7097 - val_mae: 1.2680 - 37ms/epoch - 1ms/step\n",
      "Epoch 3168/5000\n",
      "31/31 - 0s - loss: 20.6893 - mae: 2.2136 - val_loss: 0.1055 - val_mae: 0.2810 - 35ms/epoch - 1ms/step\n",
      "Epoch 3169/5000\n",
      "31/31 - 0s - loss: 0.8469 - mae: 0.6668 - val_loss: 0.6907 - val_mae: 0.7654 - 38ms/epoch - 1ms/step\n",
      "Epoch 3170/5000\n",
      "31/31 - 0s - loss: 2.5030 - mae: 0.9292 - val_loss: 3.7715 - val_mae: 1.9184 - 35ms/epoch - 1ms/step\n",
      "Epoch 3171/5000\n",
      "31/31 - 0s - loss: 8.0348 - mae: 1.8869 - val_loss: 0.1427 - val_mae: 0.3441 - 35ms/epoch - 1ms/step\n",
      "Epoch 3172/5000\n",
      "31/31 - 0s - loss: 22.1922 - mae: 2.0978 - val_loss: 0.1224 - val_mae: 0.2889 - 35ms/epoch - 1ms/step\n",
      "Epoch 3173/5000\n",
      "31/31 - 0s - loss: 1.1531 - mae: 0.9293 - val_loss: 0.3906 - val_mae: 0.5339 - 39ms/epoch - 1ms/step\n",
      "Epoch 3174/5000\n",
      "31/31 - 0s - loss: 15.4810 - mae: 1.9950 - val_loss: 0.4631 - val_mae: 0.5993 - 38ms/epoch - 1ms/step\n",
      "Epoch 3175/5000\n",
      "31/31 - 0s - loss: 0.7745 - mae: 0.6487 - val_loss: 2.0618 - val_mae: 1.4008 - 35ms/epoch - 1ms/step\n",
      "Epoch 3176/5000\n",
      "31/31 - 0s - loss: 15.0387 - mae: 1.8816 - val_loss: 0.3565 - val_mae: 0.4950 - 36ms/epoch - 1ms/step\n",
      "Epoch 3177/5000\n",
      "31/31 - 0s - loss: 1.9954 - mae: 0.9577 - val_loss: 0.4364 - val_mae: 0.5725 - 38ms/epoch - 1ms/step\n",
      "Epoch 3178/5000\n",
      "31/31 - 0s - loss: 7.9231 - mae: 1.7476 - val_loss: 3.4210 - val_mae: 1.8212 - 36ms/epoch - 1ms/step\n",
      "Epoch 3179/5000\n",
      "31/31 - 0s - loss: 1.4787 - mae: 0.9675 - val_loss: 0.6221 - val_mae: 0.7223 - 37ms/epoch - 1ms/step\n",
      "Epoch 3180/5000\n",
      "31/31 - 0s - loss: 8.4128 - mae: 1.8674 - val_loss: 4.7141 - val_mae: 2.1476 - 35ms/epoch - 1ms/step\n",
      "Epoch 3181/5000\n",
      "31/31 - 0s - loss: 15.0136 - mae: 2.3064 - val_loss: 3.2439 - val_mae: 1.7719 - 35ms/epoch - 1ms/step\n",
      "Epoch 3182/5000\n",
      "31/31 - 0s - loss: 1.7423 - mae: 1.0662 - val_loss: 0.3607 - val_mae: 0.5078 - 37ms/epoch - 1ms/step\n",
      "Epoch 3183/5000\n",
      "31/31 - 0s - loss: 8.8835 - mae: 1.8652 - val_loss: 0.2993 - val_mae: 0.4684 - 36ms/epoch - 1ms/step\n",
      "Epoch 3184/5000\n",
      "31/31 - 0s - loss: 1.6504 - mae: 0.9219 - val_loss: 1.2373 - val_mae: 1.0636 - 36ms/epoch - 1ms/step\n",
      "Epoch 3185/5000\n",
      "31/31 - 0s - loss: 17.5135 - mae: 2.0863 - val_loss: 0.3738 - val_mae: 0.5154 - 37ms/epoch - 1ms/step\n",
      "Epoch 3186/5000\n",
      "31/31 - 0s - loss: 1.1837 - mae: 0.9410 - val_loss: 0.2705 - val_mae: 0.4501 - 37ms/epoch - 1ms/step\n",
      "Epoch 3187/5000\n",
      "31/31 - 0s - loss: 20.9103 - mae: 2.0554 - val_loss: 69.6003 - val_mae: 8.3368 - 35ms/epoch - 1ms/step\n",
      "Epoch 3188/5000\n",
      "31/31 - 0s - loss: 3.2415 - mae: 1.1506 - val_loss: 4.4369 - val_mae: 2.0826 - 35ms/epoch - 1ms/step\n",
      "Epoch 3189/5000\n",
      "31/31 - 0s - loss: 8.7707 - mae: 1.8980 - val_loss: 0.1073 - val_mae: 0.2843 - 35ms/epoch - 1ms/step\n",
      "Epoch 3190/5000\n",
      "31/31 - 0s - loss: 0.7081 - mae: 0.6787 - val_loss: 3.1148 - val_mae: 1.7358 - 38ms/epoch - 1ms/step\n",
      "Epoch 3191/5000\n",
      "31/31 - 0s - loss: 14.5634 - mae: 1.9797 - val_loss: 1.5863 - val_mae: 1.2151 - 37ms/epoch - 1ms/step\n",
      "Epoch 3192/5000\n",
      "31/31 - 0s - loss: 3.1725 - mae: 1.2094 - val_loss: 16.2830 - val_mae: 4.0215 - 39ms/epoch - 1ms/step\n",
      "Epoch 3193/5000\n",
      "31/31 - 0s - loss: 1.9457 - mae: 1.0198 - val_loss: 0.4111 - val_mae: 0.5542 - 39ms/epoch - 1ms/step\n",
      "Epoch 3194/5000\n",
      "31/31 - 0s - loss: 29.3062 - mae: 1.9419 - val_loss: 2.1175 - val_mae: 1.4196 - 40ms/epoch - 1ms/step\n",
      "Epoch 3195/5000\n",
      "31/31 - 0s - loss: 1.2351 - mae: 0.9058 - val_loss: 1.1238 - val_mae: 1.0067 - 36ms/epoch - 1ms/step\n",
      "Epoch 3196/5000\n",
      "31/31 - 0s - loss: 4.6062 - mae: 1.4241 - val_loss: 0.9896 - val_mae: 0.9420 - 38ms/epoch - 1ms/step\n",
      "Epoch 3197/5000\n",
      "31/31 - 0s - loss: 17.7211 - mae: 1.9679 - val_loss: 0.7402 - val_mae: 0.7975 - 36ms/epoch - 1ms/step\n",
      "Epoch 3198/5000\n",
      "31/31 - 0s - loss: 0.9280 - mae: 0.7746 - val_loss: 1.4565 - val_mae: 1.1635 - 38ms/epoch - 1ms/step\n",
      "Epoch 3199/5000\n",
      "31/31 - 0s - loss: 21.5486 - mae: 2.4163 - val_loss: 0.3980 - val_mae: 0.5387 - 37ms/epoch - 1ms/step\n",
      "Epoch 3200/5000\n",
      "31/31 - 0s - loss: 0.5369 - mae: 0.5022 - val_loss: 6.1061 - val_mae: 2.4496 - 37ms/epoch - 1ms/step\n",
      "Epoch 3201/5000\n",
      "31/31 - 0s - loss: 7.3301 - mae: 1.9493 - val_loss: 1.1633 - val_mae: 1.0259 - 35ms/epoch - 1ms/step\n",
      "Epoch 3202/5000\n",
      "31/31 - 0s - loss: 1.4740 - mae: 1.0009 - val_loss: 1.3381 - val_mae: 1.1086 - 34ms/epoch - 1ms/step\n",
      "Epoch 3203/5000\n",
      "31/31 - 0s - loss: 7.9092 - mae: 1.7445 - val_loss: 0.1266 - val_mae: 0.2957 - 35ms/epoch - 1ms/step\n",
      "Epoch 3204/5000\n",
      "31/31 - 0s - loss: 2.2737 - mae: 1.2522 - val_loss: 0.1097 - val_mae: 0.2846 - 35ms/epoch - 1ms/step\n",
      "Epoch 3205/5000\n",
      "31/31 - 0s - loss: 15.9490 - mae: 1.8549 - val_loss: 0.6712 - val_mae: 0.7521 - 35ms/epoch - 1ms/step\n",
      "Epoch 3206/5000\n",
      "31/31 - 0s - loss: 2.7160 - mae: 1.2406 - val_loss: 0.8813 - val_mae: 0.8793 - 37ms/epoch - 1ms/step\n",
      "Epoch 3207/5000\n",
      "31/31 - 0s - loss: 7.3344 - mae: 1.8547 - val_loss: 0.7858 - val_mae: 0.8242 - 36ms/epoch - 1ms/step\n",
      "Epoch 3208/5000\n",
      "31/31 - 0s - loss: 0.7699 - mae: 0.6430 - val_loss: 0.1374 - val_mae: 0.3327 - 37ms/epoch - 1ms/step\n",
      "Epoch 3209/5000\n",
      "31/31 - 0s - loss: 16.5364 - mae: 1.8952 - val_loss: 3.3457 - val_mae: 1.8013 - 36ms/epoch - 1ms/step\n",
      "Epoch 3210/5000\n",
      "31/31 - 0s - loss: 8.8004 - mae: 1.6741 - val_loss: 51.9391 - val_mae: 7.1994 - 35ms/epoch - 1ms/step\n",
      "Epoch 3211/5000\n",
      "31/31 - 0s - loss: 3.3701 - mae: 0.9850 - val_loss: 0.1476 - val_mae: 0.3499 - 37ms/epoch - 1ms/step\n",
      "Epoch 3212/5000\n",
      "31/31 - 0s - loss: 17.3272 - mae: 2.2157 - val_loss: 0.1079 - val_mae: 0.2876 - 35ms/epoch - 1ms/step\n",
      "Epoch 3213/5000\n",
      "31/31 - 0s - loss: 0.6051 - mae: 0.5946 - val_loss: 0.5979 - val_mae: 0.7008 - 47ms/epoch - 2ms/step\n",
      "Epoch 3214/5000\n",
      "31/31 - 0s - loss: 15.2141 - mae: 1.8079 - val_loss: 56.2115 - val_mae: 7.4907 - 35ms/epoch - 1ms/step\n",
      "Epoch 3215/5000\n",
      "31/31 - 0s - loss: 4.1174 - mae: 1.3707 - val_loss: 0.1880 - val_mae: 0.3213 - 37ms/epoch - 1ms/step\n",
      "Epoch 3216/5000\n",
      "31/31 - 0s - loss: 3.3776 - mae: 1.4397 - val_loss: 0.6179 - val_mae: 0.7152 - 37ms/epoch - 1ms/step\n",
      "Epoch 3217/5000\n",
      "31/31 - 0s - loss: 16.2092 - mae: 1.9778 - val_loss: 1.0610 - val_mae: 0.9798 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3218/5000\n",
      "31/31 - 0s - loss: 1.4550 - mae: 1.0088 - val_loss: 1.3201 - val_mae: 1.1043 - 36ms/epoch - 1ms/step\n",
      "Epoch 3219/5000\n",
      "31/31 - 0s - loss: 10.6189 - mae: 1.6770 - val_loss: 2.9017 - val_mae: 1.6729 - 37ms/epoch - 1ms/step\n",
      "Epoch 3220/5000\n",
      "31/31 - 0s - loss: 3.0009 - mae: 1.4130 - val_loss: 0.6036 - val_mae: 0.7086 - 38ms/epoch - 1ms/step\n",
      "Epoch 3221/5000\n",
      "31/31 - 0s - loss: 0.7666 - mae: 0.6743 - val_loss: 0.5521 - val_mae: 0.6743 - 36ms/epoch - 1ms/step\n",
      "Epoch 3222/5000\n",
      "31/31 - 0s - loss: 17.8819 - mae: 2.1734 - val_loss: 3.1858 - val_mae: 1.7562 - 36ms/epoch - 1ms/step\n",
      "Epoch 3223/5000\n",
      "31/31 - 0s - loss: 1.2208 - mae: 0.7977 - val_loss: 1.4398 - val_mae: 1.1557 - 38ms/epoch - 1ms/step\n",
      "Epoch 3224/5000\n",
      "31/31 - 0s - loss: 19.0275 - mae: 2.2846 - val_loss: 5.3708 - val_mae: 2.2963 - 36ms/epoch - 1ms/step\n",
      "Epoch 3225/5000\n",
      "31/31 - 0s - loss: 1.4450 - mae: 0.9562 - val_loss: 0.2337 - val_mae: 0.3593 - 40ms/epoch - 1ms/step\n",
      "Epoch 3226/5000\n",
      "31/31 - 0s - loss: 13.9502 - mae: 1.7888 - val_loss: 0.1131 - val_mae: 0.2886 - 36ms/epoch - 1ms/step\n",
      "Epoch 3227/5000\n",
      "31/31 - 0s - loss: 0.7190 - mae: 0.6956 - val_loss: 0.1251 - val_mae: 0.3193 - 35ms/epoch - 1ms/step\n",
      "Epoch 3228/5000\n",
      "31/31 - 0s - loss: 10.1038 - mae: 1.6823 - val_loss: 0.2314 - val_mae: 0.3569 - 37ms/epoch - 1ms/step\n",
      "Epoch 3229/5000\n",
      "31/31 - 0s - loss: 0.7735 - mae: 0.7327 - val_loss: 1.6084 - val_mae: 1.2282 - 37ms/epoch - 1ms/step\n",
      "Epoch 3230/5000\n",
      "31/31 - 0s - loss: 26.1838 - mae: 2.2387 - val_loss: 0.1774 - val_mae: 0.3089 - 36ms/epoch - 1ms/step\n",
      "Epoch 3231/5000\n",
      "31/31 - 0s - loss: 2.2260 - mae: 0.9137 - val_loss: 1.2493 - val_mae: 1.0694 - 36ms/epoch - 1ms/step\n",
      "Epoch 3232/5000\n",
      "31/31 - 0s - loss: 13.4988 - mae: 2.1288 - val_loss: 0.5620 - val_mae: 0.6790 - 36ms/epoch - 1ms/step\n",
      "Epoch 3233/5000\n",
      "31/31 - 0s - loss: 0.6405 - mae: 0.6626 - val_loss: 1.0322 - val_mae: 0.9642 - 36ms/epoch - 1ms/step\n",
      "Epoch 3234/5000\n",
      "31/31 - 0s - loss: 5.4494 - mae: 1.2653 - val_loss: 81.7874 - val_mae: 9.0371 - 36ms/epoch - 1ms/step\n",
      "Epoch 3235/5000\n",
      "31/31 - 0s - loss: 13.6784 - mae: 2.1793 - val_loss: 6.4881 - val_mae: 2.5260 - 37ms/epoch - 1ms/step\n",
      "Epoch 3236/5000\n",
      "31/31 - 0s - loss: 1.8491 - mae: 0.9041 - val_loss: 0.9247 - val_mae: 0.9056 - 37ms/epoch - 1ms/step\n",
      "Epoch 3237/5000\n",
      "31/31 - 0s - loss: 24.1692 - mae: 2.1790 - val_loss: 0.9236 - val_mae: 0.9014 - 37ms/epoch - 1ms/step\n",
      "Epoch 3238/5000\n",
      "31/31 - 0s - loss: 2.1938 - mae: 1.1417 - val_loss: 1.8634 - val_mae: 1.3253 - 37ms/epoch - 1ms/step\n",
      "Epoch 3239/5000\n",
      "31/31 - 0s - loss: 7.0791 - mae: 1.8663 - val_loss: 4.1257 - val_mae: 2.0061 - 36ms/epoch - 1ms/step\n",
      "Epoch 3240/5000\n",
      "31/31 - 0s - loss: 1.1705 - mae: 0.9086 - val_loss: 1.3696 - val_mae: 1.1297 - 36ms/epoch - 1ms/step\n",
      "Epoch 3241/5000\n",
      "31/31 - 0s - loss: 16.7852 - mae: 1.6907 - val_loss: 7.7876 - val_mae: 2.7728 - 35ms/epoch - 1ms/step\n",
      "Epoch 3242/5000\n",
      "31/31 - 0s - loss: 1.5357 - mae: 0.8367 - val_loss: 0.1550 - val_mae: 0.2888 - 36ms/epoch - 1ms/step\n",
      "Epoch 3243/5000\n",
      "31/31 - 0s - loss: 20.2809 - mae: 1.9275 - val_loss: 1.3305 - val_mae: 1.1053 - 35ms/epoch - 1ms/step\n",
      "Epoch 3244/5000\n",
      "31/31 - 0s - loss: 3.4882 - mae: 1.4788 - val_loss: 14.2070 - val_mae: 3.7544 - 36ms/epoch - 1ms/step\n",
      "Epoch 3245/5000\n",
      "31/31 - 0s - loss: 1.7421 - mae: 1.0405 - val_loss: 0.1813 - val_mae: 0.3853 - 37ms/epoch - 1ms/step\n",
      "Epoch 3246/5000\n",
      "31/31 - 0s - loss: 9.6226 - mae: 1.7685 - val_loss: 0.1057 - val_mae: 0.2827 - 38ms/epoch - 1ms/step\n",
      "Epoch 3247/5000\n",
      "31/31 - 0s - loss: 2.4155 - mae: 1.0373 - val_loss: 319.2412 - val_mae: 17.8648 - 37ms/epoch - 1ms/step\n",
      "Epoch 3248/5000\n",
      "31/31 - 0s - loss: 17.5383 - mae: 1.9993 - val_loss: 0.6180 - val_mae: 0.7169 - 36ms/epoch - 1ms/step\n",
      "Epoch 3249/5000\n",
      "31/31 - 0s - loss: 7.1692 - mae: 1.6116 - val_loss: 45.8039 - val_mae: 6.7608 - 37ms/epoch - 1ms/step\n",
      "Epoch 3250/5000\n",
      "31/31 - 0s - loss: 2.2369 - mae: 1.0184 - val_loss: 0.9070 - val_mae: 0.8967 - 37ms/epoch - 1ms/step\n",
      "Epoch 3251/5000\n",
      "31/31 - 0s - loss: 17.1528 - mae: 2.0616 - val_loss: 2.6924 - val_mae: 1.6075 - 36ms/epoch - 1ms/step\n",
      "Epoch 3252/5000\n",
      "31/31 - 0s - loss: 2.9543 - mae: 1.4869 - val_loss: 0.2509 - val_mae: 0.4389 - 36ms/epoch - 1ms/step\n",
      "Epoch 3253/5000\n",
      "31/31 - 0s - loss: 1.8079 - mae: 1.0018 - val_loss: 0.4509 - val_mae: 0.5927 - 36ms/epoch - 1ms/step\n",
      "Epoch 3254/5000\n",
      "31/31 - 0s - loss: 14.2782 - mae: 2.3126 - val_loss: 0.3034 - val_mae: 0.4689 - 35ms/epoch - 1ms/step\n",
      "Epoch 3255/5000\n",
      "31/31 - 0s - loss: 0.7557 - mae: 0.6359 - val_loss: 0.1980 - val_mae: 0.3276 - 33ms/epoch - 1ms/step\n",
      "Epoch 3256/5000\n",
      "31/31 - 0s - loss: 20.0638 - mae: 2.0408 - val_loss: 0.1067 - val_mae: 0.2853 - 37ms/epoch - 1ms/step\n",
      "Epoch 3257/5000\n",
      "31/31 - 0s - loss: 1.6210 - mae: 0.9993 - val_loss: 0.3063 - val_mae: 0.4514 - 36ms/epoch - 1ms/step\n",
      "Epoch 3258/5000\n",
      "31/31 - 0s - loss: 31.4233 - mae: 2.0699 - val_loss: 3.0452 - val_mae: 1.7161 - 37ms/epoch - 1ms/step\n",
      "Epoch 3259/5000\n",
      "31/31 - 0s - loss: 2.2100 - mae: 1.1463 - val_loss: 0.9258 - val_mae: 0.9069 - 36ms/epoch - 1ms/step\n",
      "Epoch 3260/5000\n",
      "31/31 - 0s - loss: 1.7370 - mae: 1.0666 - val_loss: 9.7792 - val_mae: 3.1105 - 36ms/epoch - 1ms/step\n",
      "Epoch 3261/5000\n",
      "31/31 - 0s - loss: 10.9995 - mae: 2.2143 - val_loss: 3.0624 - val_mae: 1.7193 - 35ms/epoch - 1ms/step\n",
      "Epoch 3262/5000\n",
      "31/31 - 0s - loss: 1.0841 - mae: 0.7972 - val_loss: 0.7893 - val_mae: 0.8283 - 37ms/epoch - 1ms/step\n",
      "Epoch 3263/5000\n",
      "31/31 - 0s - loss: 18.4408 - mae: 2.1850 - val_loss: 2.3116 - val_mae: 1.4872 - 37ms/epoch - 1ms/step\n",
      "Epoch 3264/5000\n",
      "31/31 - 0s - loss: 1.0853 - mae: 0.7387 - val_loss: 0.5496 - val_mae: 0.6681 - 38ms/epoch - 1ms/step\n",
      "Epoch 3265/5000\n",
      "31/31 - 0s - loss: 8.7687 - mae: 1.7032 - val_loss: 0.5451 - val_mae: 0.6641 - 36ms/epoch - 1ms/step\n",
      "Epoch 3266/5000\n",
      "31/31 - 0s - loss: 3.6729 - mae: 1.1042 - val_loss: 5.0419 - val_mae: 2.2182 - 37ms/epoch - 1ms/step\n",
      "Epoch 3267/5000\n",
      "31/31 - 0s - loss: 3.7672 - mae: 1.5117 - val_loss: 2.2873 - val_mae: 1.4781 - 36ms/epoch - 1ms/step\n",
      "Epoch 3268/5000\n",
      "31/31 - 0s - loss: 13.4765 - mae: 1.7256 - val_loss: 0.9195 - val_mae: 0.9052 - 36ms/epoch - 1ms/step\n",
      "Epoch 3269/5000\n",
      "31/31 - 0s - loss: 0.6602 - mae: 0.6126 - val_loss: 0.2130 - val_mae: 0.3401 - 35ms/epoch - 1ms/step\n",
      "Epoch 3270/5000\n",
      "31/31 - 0s - loss: 15.7803 - mae: 1.8828 - val_loss: 0.5741 - val_mae: 0.6849 - 37ms/epoch - 1ms/step\n",
      "Epoch 3271/5000\n",
      "31/31 - 0s - loss: 1.0264 - mae: 0.7852 - val_loss: 15.6885 - val_mae: 3.9473 - 35ms/epoch - 1ms/step\n",
      "Epoch 3272/5000\n",
      "31/31 - 0s - loss: 8.0230 - mae: 1.8336 - val_loss: 0.7914 - val_mae: 0.8265 - 36ms/epoch - 1ms/step\n",
      "Epoch 3273/5000\n",
      "31/31 - 0s - loss: 5.6272 - mae: 1.9044 - val_loss: 0.5077 - val_mae: 0.6310 - 35ms/epoch - 1ms/step\n",
      "Epoch 3274/5000\n",
      "31/31 - 0s - loss: 1.0725 - mae: 0.8135 - val_loss: 0.1097 - val_mae: 0.2803 - 37ms/epoch - 1ms/step\n",
      "Epoch 3275/5000\n",
      "31/31 - 0s - loss: 11.5154 - mae: 1.8990 - val_loss: 1.6151 - val_mae: 1.2278 - 36ms/epoch - 1ms/step\n",
      "Epoch 3276/5000\n",
      "31/31 - 0s - loss: 0.4860 - mae: 0.5867 - val_loss: 2.8121 - val_mae: 1.6460 - 36ms/epoch - 1ms/step\n",
      "Epoch 3277/5000\n",
      "31/31 - 0s - loss: 9.9579 - mae: 1.8440 - val_loss: 4.8298 - val_mae: 2.1759 - 37ms/epoch - 1ms/step\n",
      "Epoch 3278/5000\n",
      "31/31 - 0s - loss: 17.4950 - mae: 2.3149 - val_loss: 0.1687 - val_mae: 0.3744 - 36ms/epoch - 1ms/step\n",
      "Epoch 3279/5000\n",
      "31/31 - 0s - loss: 1.1106 - mae: 0.8704 - val_loss: 3.5295 - val_mae: 1.8518 - 36ms/epoch - 1ms/step\n",
      "Epoch 3280/5000\n",
      "31/31 - 0s - loss: 8.6854 - mae: 1.7805 - val_loss: 62.5900 - val_mae: 7.9052 - 35ms/epoch - 1ms/step\n",
      "Epoch 3281/5000\n",
      "31/31 - 0s - loss: 4.8118 - mae: 1.3278 - val_loss: 1.6526 - val_mae: 1.2456 - 36ms/epoch - 1ms/step\n",
      "Epoch 3282/5000\n",
      "31/31 - 0s - loss: 17.7151 - mae: 2.0817 - val_loss: 0.2063 - val_mae: 0.3355 - 35ms/epoch - 1ms/step\n",
      "Epoch 3283/5000\n",
      "31/31 - 0s - loss: 1.7845 - mae: 1.0213 - val_loss: 0.3582 - val_mae: 0.5000 - 36ms/epoch - 1ms/step\n",
      "Epoch 3284/5000\n",
      "31/31 - 0s - loss: 14.1757 - mae: 2.1320 - val_loss: 0.2428 - val_mae: 0.3735 - 36ms/epoch - 1ms/step\n",
      "Epoch 3285/5000\n",
      "31/31 - 0s - loss: 0.4983 - mae: 0.5727 - val_loss: 0.5684 - val_mae: 0.6819 - 36ms/epoch - 1ms/step\n",
      "Epoch 3286/5000\n",
      "31/31 - 0s - loss: 13.4404 - mae: 1.8454 - val_loss: 0.3702 - val_mae: 0.5119 - 36ms/epoch - 1ms/step\n",
      "Epoch 3287/5000\n",
      "31/31 - 0s - loss: 0.9009 - mae: 0.8284 - val_loss: 0.1700 - val_mae: 0.3755 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3288/5000\n",
      "31/31 - 0s - loss: 14.8021 - mae: 1.9522 - val_loss: 0.1065 - val_mae: 0.2854 - 37ms/epoch - 1ms/step\n",
      "Epoch 3289/5000\n",
      "31/31 - 0s - loss: 1.2783 - mae: 0.8404 - val_loss: 32.6264 - val_mae: 5.7017 - 34ms/epoch - 1ms/step\n",
      "Epoch 3290/5000\n",
      "31/31 - 0s - loss: 9.9065 - mae: 1.5989 - val_loss: 2.0875 - val_mae: 1.4078 - 36ms/epoch - 1ms/step\n",
      "Epoch 3291/5000\n",
      "31/31 - 0s - loss: 0.8617 - mae: 0.6463 - val_loss: 1.0823 - val_mae: 0.9848 - 37ms/epoch - 1ms/step\n",
      "Epoch 3292/5000\n",
      "31/31 - 0s - loss: 20.8665 - mae: 2.0951 - val_loss: 13.4547 - val_mae: 3.6546 - 37ms/epoch - 1ms/step\n",
      "Epoch 3293/5000\n",
      "31/31 - 0s - loss: 1.4342 - mae: 0.8713 - val_loss: 0.1029 - val_mae: 0.2768 - 36ms/epoch - 1ms/step\n",
      "Epoch 3294/5000\n",
      "31/31 - 0s - loss: 17.3632 - mae: 2.0836 - val_loss: 2.7010 - val_mae: 1.6101 - 37ms/epoch - 1ms/step\n",
      "Epoch 3295/5000\n",
      "31/31 - 0s - loss: 1.7190 - mae: 0.8883 - val_loss: 3.2225 - val_mae: 1.7668 - 37ms/epoch - 1ms/step\n",
      "Epoch 3296/5000\n",
      "31/31 - 0s - loss: 10.9816 - mae: 2.0483 - val_loss: 15.7916 - val_mae: 3.9587 - 35ms/epoch - 1ms/step\n",
      "Epoch 3297/5000\n",
      "31/31 - 0s - loss: 3.6685 - mae: 1.6081 - val_loss: 0.4919 - val_mae: 0.6201 - 35ms/epoch - 1ms/step\n",
      "Epoch 3298/5000\n",
      "31/31 - 0s - loss: 17.4535 - mae: 2.2553 - val_loss: 0.1007 - val_mae: 0.2754 - 36ms/epoch - 1ms/step\n",
      "Epoch 3299/5000\n",
      "31/31 - 0s - loss: 1.6035 - mae: 1.0446 - val_loss: 0.3584 - val_mae: 0.5001 - 36ms/epoch - 1ms/step\n",
      "Epoch 3300/5000\n",
      "31/31 - 0s - loss: 16.7750 - mae: 2.1527 - val_loss: 0.1106 - val_mae: 0.2882 - 37ms/epoch - 1ms/step\n",
      "Epoch 3301/5000\n",
      "31/31 - 0s - loss: 0.7108 - mae: 0.6584 - val_loss: 0.1987 - val_mae: 0.3301 - 37ms/epoch - 1ms/step\n",
      "Epoch 3302/5000\n",
      "31/31 - 0s - loss: 2.2797 - mae: 1.1298 - val_loss: 615.5845 - val_mae: 24.8086 - 36ms/epoch - 1ms/step\n",
      "Epoch 3303/5000\n",
      "31/31 - 0s - loss: 26.0973 - mae: 2.1358 - val_loss: 1.2209 - val_mae: 1.0584 - 37ms/epoch - 1ms/step\n",
      "Epoch 3304/5000\n",
      "31/31 - 0s - loss: 0.8336 - mae: 0.6733 - val_loss: 0.2571 - val_mae: 0.3940 - 36ms/epoch - 1ms/step\n",
      "Epoch 3305/5000\n",
      "31/31 - 0s - loss: 17.7826 - mae: 2.1383 - val_loss: 1.6342 - val_mae: 1.2360 - 35ms/epoch - 1ms/step\n",
      "Epoch 3306/5000\n",
      "31/31 - 0s - loss: 0.9626 - mae: 0.8024 - val_loss: 0.3861 - val_mae: 0.5316 - 37ms/epoch - 1ms/step\n",
      "Epoch 3307/5000\n",
      "31/31 - 0s - loss: 11.5462 - mae: 1.7567 - val_loss: 14.9473 - val_mae: 3.8527 - 38ms/epoch - 1ms/step\n",
      "Epoch 3308/5000\n",
      "31/31 - 0s - loss: 3.1672 - mae: 1.3866 - val_loss: 0.1038 - val_mae: 0.2806 - 36ms/epoch - 1ms/step\n",
      "Epoch 3309/5000\n",
      "31/31 - 0s - loss: 19.3576 - mae: 2.4081 - val_loss: 1.9591 - val_mae: 1.3627 - 35ms/epoch - 1ms/step\n",
      "Epoch 3310/5000\n",
      "31/31 - 0s - loss: 2.6061 - mae: 1.2607 - val_loss: 0.5533 - val_mae: 0.6692 - 35ms/epoch - 1ms/step\n",
      "Epoch 3311/5000\n",
      "31/31 - 0s - loss: 10.0192 - mae: 1.7432 - val_loss: 0.2560 - val_mae: 0.4014 - 37ms/epoch - 1ms/step\n",
      "Epoch 3312/5000\n",
      "31/31 - 0s - loss: 2.1844 - mae: 1.0401 - val_loss: 1.1188 - val_mae: 1.0079 - 37ms/epoch - 1ms/step\n",
      "Epoch 3313/5000\n",
      "31/31 - 0s - loss: 20.0481 - mae: 2.3582 - val_loss: 0.1344 - val_mae: 0.2836 - 36ms/epoch - 1ms/step\n",
      "Epoch 3314/5000\n",
      "31/31 - 0s - loss: 2.4428 - mae: 1.2000 - val_loss: 1.3616 - val_mae: 1.1171 - 36ms/epoch - 1ms/step\n",
      "Epoch 3315/5000\n",
      "31/31 - 0s - loss: 12.6258 - mae: 2.0132 - val_loss: 0.2636 - val_mae: 0.3980 - 38ms/epoch - 1ms/step\n",
      "Epoch 3316/5000\n",
      "31/31 - 0s - loss: 0.6889 - mae: 0.6312 - val_loss: 0.7984 - val_mae: 0.8341 - 37ms/epoch - 1ms/step\n",
      "Epoch 3317/5000\n",
      "31/31 - 0s - loss: 12.1584 - mae: 1.6561 - val_loss: 0.1270 - val_mae: 0.3182 - 36ms/epoch - 1ms/step\n",
      "Epoch 3318/5000\n",
      "31/31 - 0s - loss: 2.5627 - mae: 1.1253 - val_loss: 0.9941 - val_mae: 0.9389 - 36ms/epoch - 1ms/step\n",
      "Epoch 3319/5000\n",
      "31/31 - 0s - loss: 17.2827 - mae: 2.2324 - val_loss: 6.2297 - val_mae: 2.4750 - 36ms/epoch - 1ms/step\n",
      "Epoch 3320/5000\n",
      "31/31 - 0s - loss: 1.4294 - mae: 0.9042 - val_loss: 0.6503 - val_mae: 0.7389 - 37ms/epoch - 1ms/step\n",
      "Epoch 3321/5000\n",
      "31/31 - 0s - loss: 16.1783 - mae: 1.9527 - val_loss: 5.5458 - val_mae: 2.3313 - 35ms/epoch - 1ms/step\n",
      "Epoch 3322/5000\n",
      "31/31 - 0s - loss: 2.2123 - mae: 1.1468 - val_loss: 3.8437 - val_mae: 1.9316 - 36ms/epoch - 1ms/step\n",
      "Epoch 3323/5000\n",
      "31/31 - 0s - loss: 10.5114 - mae: 2.0466 - val_loss: 1.0570 - val_mae: 0.9745 - 36ms/epoch - 1ms/step\n",
      "Epoch 3324/5000\n",
      "31/31 - 0s - loss: 0.8371 - mae: 0.7241 - val_loss: 1.2211 - val_mae: 1.0574 - 36ms/epoch - 1ms/step\n",
      "Epoch 3325/5000\n",
      "31/31 - 0s - loss: 24.1450 - mae: 2.2122 - val_loss: 4.4192 - val_mae: 2.0782 - 36ms/epoch - 1ms/step\n",
      "Epoch 3326/5000\n",
      "31/31 - 0s - loss: 1.3845 - mae: 0.9138 - val_loss: 0.5029 - val_mae: 0.6299 - 42ms/epoch - 1ms/step\n",
      "Epoch 3327/5000\n",
      "31/31 - 0s - loss: 14.6005 - mae: 2.2585 - val_loss: 0.1519 - val_mae: 0.3530 - 39ms/epoch - 1ms/step\n",
      "Epoch 3328/5000\n",
      "31/31 - 0s - loss: 0.7744 - mae: 0.6117 - val_loss: 0.9959 - val_mae: 0.9447 - 39ms/epoch - 1ms/step\n",
      "Epoch 3329/5000\n",
      "31/31 - 0s - loss: 11.9219 - mae: 1.8376 - val_loss: 0.3652 - val_mae: 0.5049 - 37ms/epoch - 1ms/step\n",
      "Epoch 3330/5000\n",
      "31/31 - 0s - loss: 1.5207 - mae: 1.1053 - val_loss: 0.7439 - val_mae: 0.7987 - 37ms/epoch - 1ms/step\n",
      "Epoch 3331/5000\n",
      "31/31 - 0s - loss: 30.3018 - mae: 2.2409 - val_loss: 0.5249 - val_mae: 0.6461 - 36ms/epoch - 1ms/step\n",
      "Epoch 3332/5000\n",
      "31/31 - 0s - loss: 1.5098 - mae: 0.7971 - val_loss: 0.5983 - val_mae: 0.7045 - 37ms/epoch - 1ms/step\n",
      "Epoch 3333/5000\n",
      "31/31 - 0s - loss: 14.9938 - mae: 2.2328 - val_loss: 0.0978 - val_mae: 0.2706 - 37ms/epoch - 1ms/step\n",
      "Epoch 3334/5000\n",
      "31/31 - 0s - loss: 0.6106 - mae: 0.5927 - val_loss: 6.5631 - val_mae: 2.5423 - 36ms/epoch - 1ms/step\n",
      "Epoch 3335/5000\n",
      "31/31 - 0s - loss: 22.9339 - mae: 2.1729 - val_loss: 0.3714 - val_mae: 0.5220 - 38ms/epoch - 1ms/step\n",
      "Epoch 3336/5000\n",
      "31/31 - 0s - loss: 1.4051 - mae: 0.9302 - val_loss: 1.8639 - val_mae: 1.3263 - 36ms/epoch - 1ms/step\n",
      "Epoch 3337/5000\n",
      "31/31 - 0s - loss: 1.3328 - mae: 0.9627 - val_loss: 1.2266 - val_mae: 1.0603 - 37ms/epoch - 1ms/step\n",
      "Epoch 3338/5000\n",
      "31/31 - 0s - loss: 12.0371 - mae: 1.9880 - val_loss: 0.2164 - val_mae: 0.3438 - 35ms/epoch - 1ms/step\n",
      "Epoch 3339/5000\n",
      "31/31 - 0s - loss: 2.4090 - mae: 1.1989 - val_loss: 0.6408 - val_mae: 0.7333 - 38ms/epoch - 1ms/step\n",
      "Epoch 3340/5000\n",
      "31/31 - 0s - loss: 19.0902 - mae: 2.2601 - val_loss: 0.7389 - val_mae: 0.8007 - 37ms/epoch - 1ms/step\n",
      "Epoch 3341/5000\n",
      "31/31 - 0s - loss: 0.7662 - mae: 0.6067 - val_loss: 0.1050 - val_mae: 0.2806 - 36ms/epoch - 1ms/step\n",
      "Epoch 3342/5000\n",
      "31/31 - 0s - loss: 17.3559 - mae: 2.1408 - val_loss: 1.7117 - val_mae: 1.2715 - 36ms/epoch - 1ms/step\n",
      "Epoch 3343/5000\n",
      "31/31 - 0s - loss: 2.0830 - mae: 1.1266 - val_loss: 0.3557 - val_mae: 0.5064 - 36ms/epoch - 1ms/step\n",
      "Epoch 3344/5000\n",
      "31/31 - 0s - loss: 5.5056 - mae: 1.7081 - val_loss: 3.3380 - val_mae: 1.7978 - 36ms/epoch - 1ms/step\n",
      "Epoch 3345/5000\n",
      "31/31 - 0s - loss: 0.5282 - mae: 0.5913 - val_loss: 17.7947 - val_mae: 4.2071 - 36ms/epoch - 1ms/step\n",
      "Epoch 3346/5000\n",
      "31/31 - 0s - loss: 25.3088 - mae: 2.2383 - val_loss: 0.1319 - val_mae: 0.3273 - 35ms/epoch - 1ms/step\n",
      "Epoch 3347/5000\n",
      "31/31 - 0s - loss: 2.1819 - mae: 1.0644 - val_loss: 0.7200 - val_mae: 0.7871 - 37ms/epoch - 1ms/step\n",
      "Epoch 3348/5000\n",
      "31/31 - 0s - loss: 17.9419 - mae: 1.9326 - val_loss: 0.3605 - val_mae: 0.5023 - 37ms/epoch - 1ms/step\n",
      "Epoch 3349/5000\n",
      "31/31 - 0s - loss: 0.9069 - mae: 0.7964 - val_loss: 0.1489 - val_mae: 0.2856 - 38ms/epoch - 1ms/step\n",
      "Epoch 3350/5000\n",
      "31/31 - 0s - loss: 13.4177 - mae: 2.0661 - val_loss: 3.9720 - val_mae: 1.9678 - 33ms/epoch - 1ms/step\n",
      "Epoch 3351/5000\n",
      "31/31 - 0s - loss: 2.9164 - mae: 1.3982 - val_loss: 5.7773 - val_mae: 2.3826 - 36ms/epoch - 1ms/step\n",
      "Epoch 3352/5000\n",
      "31/31 - 0s - loss: 20.1311 - mae: 2.1609 - val_loss: 0.3173 - val_mae: 0.4617 - 38ms/epoch - 1ms/step\n",
      "Epoch 3353/5000\n",
      "31/31 - 0s - loss: 2.3649 - mae: 1.1590 - val_loss: 2.1876 - val_mae: 1.4444 - 37ms/epoch - 1ms/step\n",
      "Epoch 3354/5000\n",
      "31/31 - 0s - loss: 11.0509 - mae: 2.2342 - val_loss: 3.2063 - val_mae: 1.7629 - 35ms/epoch - 1ms/step\n",
      "Epoch 3355/5000\n",
      "31/31 - 0s - loss: 0.8828 - mae: 0.6774 - val_loss: 0.3208 - val_mae: 0.4685 - 35ms/epoch - 1ms/step\n",
      "Epoch 3356/5000\n",
      "31/31 - 0s - loss: 1.1691 - mae: 0.6906 - val_loss: 219.1102 - val_mae: 14.7994 - 36ms/epoch - 1ms/step\n",
      "Epoch 3357/5000\n",
      "31/31 - 0s - loss: 23.9899 - mae: 2.2491 - val_loss: 5.9353 - val_mae: 2.4162 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3358/5000\n",
      "31/31 - 0s - loss: 1.1168 - mae: 0.7800 - val_loss: 0.6013 - val_mae: 0.7054 - 37ms/epoch - 1ms/step\n",
      "Epoch 3359/5000\n",
      "31/31 - 0s - loss: 7.8699 - mae: 1.6372 - val_loss: 0.3381 - val_mae: 0.4892 - 37ms/epoch - 1ms/step\n",
      "Epoch 3360/5000\n",
      "31/31 - 0s - loss: 0.6074 - mae: 0.6517 - val_loss: 0.6678 - val_mae: 0.7518 - 37ms/epoch - 1ms/step\n",
      "Epoch 3361/5000\n",
      "31/31 - 0s - loss: 34.5531 - mae: 2.2565 - val_loss: 1.5770 - val_mae: 1.2160 - 36ms/epoch - 1ms/step\n",
      "Epoch 3362/5000\n",
      "31/31 - 0s - loss: 2.3586 - mae: 1.0155 - val_loss: 2.8374 - val_mae: 1.6534 - 37ms/epoch - 1ms/step\n",
      "Epoch 3363/5000\n",
      "31/31 - 0s - loss: 18.9194 - mae: 2.3026 - val_loss: 2.4355 - val_mae: 1.5266 - 36ms/epoch - 1ms/step\n",
      "Epoch 3364/5000\n",
      "31/31 - 0s - loss: 1.1184 - mae: 0.7709 - val_loss: 0.1136 - val_mae: 0.2791 - 38ms/epoch - 1ms/step\n",
      "Epoch 3365/5000\n",
      "31/31 - 0s - loss: 0.4920 - mae: 0.5947 - val_loss: 0.2182 - val_mae: 0.3464 - 36ms/epoch - 1ms/step\n",
      "Epoch 3366/5000\n",
      "31/31 - 0s - loss: 29.3328 - mae: 2.4690 - val_loss: 0.2298 - val_mae: 0.3542 - 36ms/epoch - 1ms/step\n",
      "Epoch 3367/5000\n",
      "31/31 - 0s - loss: 1.5323 - mae: 0.9211 - val_loss: 3.3695 - val_mae: 1.8071 - 35ms/epoch - 1ms/step\n",
      "Epoch 3368/5000\n",
      "31/31 - 0s - loss: 9.2104 - mae: 2.0153 - val_loss: 0.4663 - val_mae: 0.6039 - 36ms/epoch - 1ms/step\n",
      "Epoch 3369/5000\n",
      "31/31 - 0s - loss: 0.7482 - mae: 0.6832 - val_loss: 2.8868 - val_mae: 1.6649 - 39ms/epoch - 1ms/step\n",
      "Epoch 3370/5000\n",
      "31/31 - 0s - loss: 12.8570 - mae: 2.1979 - val_loss: 3.1803 - val_mae: 1.7521 - 36ms/epoch - 1ms/step\n",
      "Epoch 3371/5000\n",
      "31/31 - 0s - loss: 15.7134 - mae: 2.4254 - val_loss: 0.1104 - val_mae: 0.2856 - 35ms/epoch - 1ms/step\n",
      "Epoch 3372/5000\n",
      "31/31 - 0s - loss: 0.8731 - mae: 0.6921 - val_loss: 0.6539 - val_mae: 0.7420 - 35ms/epoch - 1ms/step\n",
      "Epoch 3373/5000\n",
      "31/31 - 0s - loss: 8.7123 - mae: 1.4114 - val_loss: 184.1908 - val_mae: 13.5681 - 39ms/epoch - 1ms/step\n",
      "Epoch 3374/5000\n",
      "31/31 - 0s - loss: 6.5498 - mae: 1.1296 - val_loss: 0.1330 - val_mae: 0.2810 - 36ms/epoch - 1ms/step\n",
      "Epoch 3375/5000\n",
      "31/31 - 0s - loss: 10.0270 - mae: 1.8580 - val_loss: 0.1411 - val_mae: 0.2764 - 38ms/epoch - 1ms/step\n",
      "Epoch 3376/5000\n",
      "31/31 - 0s - loss: 1.2223 - mae: 0.8313 - val_loss: 0.3191 - val_mae: 0.4766 - 38ms/epoch - 1ms/step\n",
      "Epoch 3377/5000\n",
      "31/31 - 0s - loss: 17.3263 - mae: 2.1219 - val_loss: 0.1322 - val_mae: 0.3266 - 36ms/epoch - 1ms/step\n",
      "Epoch 3378/5000\n",
      "31/31 - 0s - loss: 1.8713 - mae: 1.1338 - val_loss: 9.7662 - val_mae: 3.1066 - 35ms/epoch - 1ms/step\n",
      "Epoch 3379/5000\n",
      "31/31 - 0s - loss: 2.0057 - mae: 1.0312 - val_loss: 0.9954 - val_mae: 0.9435 - 37ms/epoch - 1ms/step\n",
      "Epoch 3380/5000\n",
      "31/31 - 0s - loss: 11.3269 - mae: 2.2330 - val_loss: 0.1710 - val_mae: 0.3754 - 37ms/epoch - 1ms/step\n",
      "Epoch 3381/5000\n",
      "31/31 - 0s - loss: 18.2634 - mae: 2.1416 - val_loss: 1.9171 - val_mae: 1.3474 - 36ms/epoch - 1ms/step\n",
      "Epoch 3382/5000\n",
      "31/31 - 0s - loss: 2.3203 - mae: 1.1539 - val_loss: 0.1668 - val_mae: 0.3709 - 35ms/epoch - 1ms/step\n",
      "Epoch 3383/5000\n",
      "31/31 - 0s - loss: 0.9645 - mae: 0.7862 - val_loss: 0.4440 - val_mae: 0.5856 - 36ms/epoch - 1ms/step\n",
      "Epoch 3384/5000\n",
      "31/31 - 0s - loss: 12.2184 - mae: 1.7899 - val_loss: 1.4329 - val_mae: 1.1496 - 37ms/epoch - 1ms/step\n",
      "Epoch 3385/5000\n",
      "31/31 - 0s - loss: 1.4790 - mae: 0.9049 - val_loss: 1.0541 - val_mae: 0.9752 - 36ms/epoch - 1ms/step\n",
      "Epoch 3386/5000\n",
      "31/31 - 0s - loss: 5.1397 - mae: 1.5177 - val_loss: 0.3949 - val_mae: 0.5389 - 36ms/epoch - 1ms/step\n",
      "Epoch 3387/5000\n",
      "31/31 - 0s - loss: 14.0592 - mae: 1.9473 - val_loss: 0.8662 - val_mae: 0.8744 - 36ms/epoch - 1ms/step\n",
      "Epoch 3388/5000\n",
      "31/31 - 0s - loss: 0.5749 - mae: 0.5356 - val_loss: 0.1412 - val_mae: 0.2808 - 36ms/epoch - 1ms/step\n",
      "Epoch 3389/5000\n",
      "31/31 - 0s - loss: 24.0373 - mae: 2.1821 - val_loss: 0.1325 - val_mae: 0.2798 - 37ms/epoch - 1ms/step\n",
      "Epoch 3390/5000\n",
      "31/31 - 0s - loss: 1.1837 - mae: 0.8030 - val_loss: 0.8209 - val_mae: 0.8473 - 37ms/epoch - 1ms/step\n",
      "Epoch 3391/5000\n",
      "31/31 - 0s - loss: 5.1082 - mae: 1.7631 - val_loss: 0.1258 - val_mae: 0.3176 - 36ms/epoch - 1ms/step\n",
      "Epoch 3392/5000\n",
      "31/31 - 0s - loss: 0.8800 - mae: 0.8329 - val_loss: 0.2240 - val_mae: 0.4195 - 37ms/epoch - 1ms/step\n",
      "Epoch 3393/5000\n",
      "31/31 - 0s - loss: 14.8883 - mae: 2.3604 - val_loss: 0.1218 - val_mae: 0.2786 - 35ms/epoch - 1ms/step\n",
      "Epoch 3394/5000\n",
      "31/31 - 0s - loss: 1.9728 - mae: 1.0999 - val_loss: 0.1041 - val_mae: 0.2810 - 36ms/epoch - 1ms/step\n",
      "Epoch 3395/5000\n",
      "31/31 - 0s - loss: 11.5655 - mae: 1.7269 - val_loss: 0.1075 - val_mae: 0.2801 - 36ms/epoch - 1ms/step\n",
      "Epoch 3396/5000\n",
      "31/31 - 0s - loss: 1.6139 - mae: 1.0921 - val_loss: 0.1089 - val_mae: 0.2836 - 36ms/epoch - 1ms/step\n",
      "Epoch 3397/5000\n",
      "31/31 - 0s - loss: 10.9098 - mae: 1.8576 - val_loss: 1.9060 - val_mae: 1.3422 - 39ms/epoch - 1ms/step\n",
      "Epoch 3398/5000\n",
      "31/31 - 0s - loss: 2.9788 - mae: 1.2543 - val_loss: 1.2549 - val_mae: 1.0710 - 36ms/epoch - 1ms/step\n",
      "Epoch 3399/5000\n",
      "31/31 - 0s - loss: 13.5373 - mae: 1.9691 - val_loss: 0.1158 - val_mae: 0.2869 - 36ms/epoch - 1ms/step\n",
      "Epoch 3400/5000\n",
      "31/31 - 0s - loss: 1.3198 - mae: 0.9842 - val_loss: 5.1564 - val_mae: 2.2489 - 37ms/epoch - 1ms/step\n",
      "Epoch 3401/5000\n",
      "31/31 - 0s - loss: 12.6666 - mae: 1.9383 - val_loss: 1.3923 - val_mae: 1.1346 - 35ms/epoch - 1ms/step\n",
      "Epoch 3402/5000\n",
      "31/31 - 0s - loss: 2.8499 - mae: 1.0381 - val_loss: 87.9180 - val_mae: 9.3713 - 36ms/epoch - 1ms/step\n",
      "Epoch 3403/5000\n",
      "31/31 - 0s - loss: 4.2524 - mae: 1.1633 - val_loss: 0.2377 - val_mae: 0.4285 - 36ms/epoch - 1ms/step\n",
      "Epoch 3404/5000\n",
      "31/31 - 0s - loss: 27.5535 - mae: 2.4675 - val_loss: 1.8662 - val_mae: 1.3265 - 36ms/epoch - 1ms/step\n",
      "Epoch 3405/5000\n",
      "31/31 - 0s - loss: 1.5956 - mae: 0.9651 - val_loss: 0.1632 - val_mae: 0.3670 - 37ms/epoch - 1ms/step\n",
      "Epoch 3406/5000\n",
      "31/31 - 0s - loss: 7.7542 - mae: 1.4696 - val_loss: 22.6771 - val_mae: 4.7497 - 37ms/epoch - 1ms/step\n",
      "Epoch 3407/5000\n",
      "31/31 - 0s - loss: 1.1755 - mae: 0.7425 - val_loss: 3.1607 - val_mae: 1.7481 - 37ms/epoch - 1ms/step\n",
      "Epoch 3408/5000\n",
      "31/31 - 0s - loss: 9.6163 - mae: 1.9420 - val_loss: 9.9985 - val_mae: 3.1446 - 38ms/epoch - 1ms/step\n",
      "Epoch 3409/5000\n",
      "31/31 - 0s - loss: 12.3935 - mae: 2.4157 - val_loss: 0.8433 - val_mae: 0.8597 - 37ms/epoch - 1ms/step\n",
      "Epoch 3410/5000\n",
      "31/31 - 0s - loss: 0.5665 - mae: 0.5724 - val_loss: 0.7392 - val_mae: 0.7977 - 36ms/epoch - 1ms/step\n",
      "Epoch 3411/5000\n",
      "31/31 - 0s - loss: 10.2232 - mae: 2.0086 - val_loss: 0.2148 - val_mae: 0.3406 - 37ms/epoch - 1ms/step\n",
      "Epoch 3412/5000\n",
      "31/31 - 0s - loss: 0.6386 - mae: 0.6139 - val_loss: 0.7252 - val_mae: 0.7892 - 35ms/epoch - 1ms/step\n",
      "Epoch 3413/5000\n",
      "31/31 - 0s - loss: 28.0557 - mae: 2.3459 - val_loss: 0.1280 - val_mae: 0.2813 - 37ms/epoch - 1ms/step\n",
      "Epoch 3414/5000\n",
      "31/31 - 0s - loss: 2.0329 - mae: 1.2769 - val_loss: 6.6853 - val_mae: 2.5652 - 36ms/epoch - 1ms/step\n",
      "Epoch 3415/5000\n",
      "31/31 - 0s - loss: 9.2673 - mae: 2.0798 - val_loss: 1.0065 - val_mae: 0.9534 - 37ms/epoch - 1ms/step\n",
      "Epoch 3416/5000\n",
      "31/31 - 0s - loss: 0.9439 - mae: 0.7579 - val_loss: 0.2169 - val_mae: 0.3449 - 37ms/epoch - 1ms/step\n",
      "Epoch 3417/5000\n",
      "31/31 - 0s - loss: 10.2457 - mae: 1.8286 - val_loss: 0.1251 - val_mae: 0.3152 - 36ms/epoch - 1ms/step\n",
      "Epoch 3418/5000\n",
      "31/31 - 0s - loss: 0.9964 - mae: 0.8265 - val_loss: 4.3758 - val_mae: 2.0660 - 35ms/epoch - 1ms/step\n",
      "Epoch 3419/5000\n",
      "31/31 - 0s - loss: 21.1916 - mae: 2.3355 - val_loss: 0.7085 - val_mae: 0.7738 - 37ms/epoch - 1ms/step\n",
      "Epoch 3420/5000\n",
      "31/31 - 0s - loss: 1.0638 - mae: 0.8224 - val_loss: 0.1643 - val_mae: 0.3686 - 37ms/epoch - 1ms/step\n",
      "Epoch 3421/5000\n",
      "31/31 - 0s - loss: 9.5444 - mae: 2.2053 - val_loss: 0.4730 - val_mae: 0.6109 - 36ms/epoch - 1ms/step\n",
      "Epoch 3422/5000\n",
      "31/31 - 0s - loss: 1.1509 - mae: 0.7743 - val_loss: 8.5282 - val_mae: 2.9030 - 46ms/epoch - 1ms/step\n",
      "Epoch 3423/5000\n",
      "31/31 - 0s - loss: 24.9968 - mae: 2.7513 - val_loss: 0.9312 - val_mae: 0.9087 - 37ms/epoch - 1ms/step\n",
      "Epoch 3424/5000\n",
      "31/31 - 0s - loss: 0.9226 - mae: 0.8686 - val_loss: 0.1461 - val_mae: 0.2839 - 37ms/epoch - 1ms/step\n",
      "Epoch 3425/5000\n",
      "31/31 - 0s - loss: 29.0200 - mae: 2.3102 - val_loss: 0.3688 - val_mae: 0.5181 - 37ms/epoch - 1ms/step\n",
      "Epoch 3426/5000\n",
      "31/31 - 0s - loss: 1.9446 - mae: 0.9234 - val_loss: 0.1209 - val_mae: 0.2798 - 37ms/epoch - 1ms/step\n",
      "Epoch 3427/5000\n",
      "31/31 - 0s - loss: 0.7838 - mae: 0.7242 - val_loss: 1.3852 - val_mae: 1.1326 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3428/5000\n",
      "31/31 - 0s - loss: 22.1240 - mae: 2.0384 - val_loss: 0.5357 - val_mae: 0.6552 - 37ms/epoch - 1ms/step\n",
      "Epoch 3429/5000\n",
      "31/31 - 0s - loss: 1.4103 - mae: 0.9136 - val_loss: 0.1076 - val_mae: 0.2834 - 36ms/epoch - 1ms/step\n",
      "Epoch 3430/5000\n",
      "31/31 - 0s - loss: 15.8453 - mae: 1.8520 - val_loss: 3.4164 - val_mae: 1.8214 - 34ms/epoch - 1ms/step\n",
      "Epoch 3431/5000\n",
      "31/31 - 0s - loss: 1.1466 - mae: 0.8629 - val_loss: 1.0753 - val_mae: 0.9860 - 39ms/epoch - 1ms/step\n",
      "Epoch 3432/5000\n",
      "31/31 - 0s - loss: 13.8560 - mae: 2.2696 - val_loss: 9.1933 - val_mae: 3.0162 - 36ms/epoch - 1ms/step\n",
      "Epoch 3433/5000\n",
      "31/31 - 0s - loss: 13.0942 - mae: 2.1405 - val_loss: 0.1086 - val_mae: 0.2775 - 37ms/epoch - 1ms/step\n",
      "Epoch 3434/5000\n",
      "31/31 - 0s - loss: 1.1398 - mae: 0.8472 - val_loss: 6.6293 - val_mae: 2.5553 - 36ms/epoch - 1ms/step\n",
      "Epoch 3435/5000\n",
      "31/31 - 0s - loss: 11.5397 - mae: 1.9541 - val_loss: 80.1846 - val_mae: 8.9482 - 37ms/epoch - 1ms/step\n",
      "Epoch 3436/5000\n",
      "31/31 - 0s - loss: 3.3310 - mae: 0.9807 - val_loss: 0.7898 - val_mae: 0.8269 - 38ms/epoch - 1ms/step\n",
      "Epoch 3437/5000\n",
      "31/31 - 0s - loss: 0.9895 - mae: 0.8620 - val_loss: 0.4223 - val_mae: 0.5613 - 35ms/epoch - 1ms/step\n",
      "Epoch 3438/5000\n",
      "31/31 - 0s - loss: 23.6608 - mae: 2.2881 - val_loss: 10.8899 - val_mae: 3.2850 - 36ms/epoch - 1ms/step\n",
      "Epoch 3439/5000\n",
      "31/31 - 0s - loss: 2.3618 - mae: 1.2487 - val_loss: 0.4305 - val_mae: 0.5722 - 37ms/epoch - 1ms/step\n",
      "Epoch 3440/5000\n",
      "31/31 - 0s - loss: 24.9528 - mae: 2.1043 - val_loss: 0.5903 - val_mae: 0.7028 - 36ms/epoch - 1ms/step\n",
      "Epoch 3441/5000\n",
      "31/31 - 0s - loss: 1.9831 - mae: 1.0177 - val_loss: 1.8825 - val_mae: 1.3341 - 36ms/epoch - 1ms/step\n",
      "Epoch 3442/5000\n",
      "31/31 - 0s - loss: 12.8256 - mae: 2.1322 - val_loss: 0.1360 - val_mae: 0.3377 - 39ms/epoch - 1ms/step\n",
      "Epoch 3443/5000\n",
      "31/31 - 0s - loss: 1.0859 - mae: 0.8909 - val_loss: 0.6451 - val_mae: 0.7351 - 36ms/epoch - 1ms/step\n",
      "Epoch 3444/5000\n",
      "31/31 - 0s - loss: 25.4076 - mae: 2.1854 - val_loss: 0.1444 - val_mae: 0.2762 - 36ms/epoch - 1ms/step\n",
      "Epoch 3445/5000\n",
      "31/31 - 0s - loss: 0.5522 - mae: 0.5874 - val_loss: 7.0379 - val_mae: 2.6346 - 34ms/epoch - 1ms/step\n",
      "Epoch 3446/5000\n",
      "31/31 - 0s - loss: 5.5313 - mae: 1.6213 - val_loss: 86.5890 - val_mae: 9.3000 - 36ms/epoch - 1ms/step\n",
      "Epoch 3447/5000\n",
      "31/31 - 0s - loss: 7.9302 - mae: 1.3559 - val_loss: 0.9892 - val_mae: 0.9393 - 36ms/epoch - 1ms/step\n",
      "Epoch 3448/5000\n",
      "31/31 - 0s - loss: 0.5682 - mae: 0.5654 - val_loss: 8.9506 - val_mae: 2.9730 - 36ms/epoch - 1ms/step\n",
      "Epoch 3449/5000\n",
      "31/31 - 0s - loss: 19.3013 - mae: 2.3388 - val_loss: 0.1180 - val_mae: 0.2731 - 36ms/epoch - 1ms/step\n",
      "Epoch 3450/5000\n",
      "31/31 - 0s - loss: 2.4740 - mae: 1.1291 - val_loss: 0.2207 - val_mae: 0.4167 - 37ms/epoch - 1ms/step\n",
      "Epoch 3451/5000\n",
      "31/31 - 0s - loss: 13.0203 - mae: 2.0588 - val_loss: 0.5434 - val_mae: 0.6585 - 36ms/epoch - 1ms/step\n",
      "Epoch 3452/5000\n",
      "31/31 - 0s - loss: 1.1687 - mae: 0.9007 - val_loss: 0.6839 - val_mae: 0.7597 - 37ms/epoch - 1ms/step\n",
      "Epoch 3453/5000\n",
      "31/31 - 0s - loss: 23.6484 - mae: 2.3114 - val_loss: 1.1770 - val_mae: 1.0341 - 37ms/epoch - 1ms/step\n",
      "Epoch 3454/5000\n",
      "31/31 - 0s - loss: 1.4097 - mae: 1.0280 - val_loss: 5.9729 - val_mae: 2.4240 - 37ms/epoch - 1ms/step\n",
      "Epoch 3455/5000\n",
      "31/31 - 0s - loss: 9.9510 - mae: 1.7860 - val_loss: 0.1074 - val_mae: 0.2848 - 37ms/epoch - 1ms/step\n",
      "Epoch 3456/5000\n",
      "31/31 - 0s - loss: 1.4893 - mae: 0.9324 - val_loss: 88.2495 - val_mae: 9.3880 - 36ms/epoch - 1ms/step\n",
      "Epoch 3457/5000\n",
      "31/31 - 0s - loss: 18.8962 - mae: 2.1035 - val_loss: 0.5148 - val_mae: 0.6390 - 36ms/epoch - 1ms/step\n",
      "Epoch 3458/5000\n",
      "31/31 - 0s - loss: 1.0869 - mae: 0.8999 - val_loss: 18.4059 - val_mae: 4.2771 - 37ms/epoch - 1ms/step\n",
      "Epoch 3459/5000\n",
      "31/31 - 0s - loss: 15.8775 - mae: 2.5071 - val_loss: 1.9197 - val_mae: 1.3474 - 39ms/epoch - 1ms/step\n",
      "Epoch 3460/5000\n",
      "31/31 - 0s - loss: 1.2821 - mae: 0.8651 - val_loss: 0.3198 - val_mae: 0.4596 - 41ms/epoch - 1ms/step\n",
      "Epoch 3461/5000\n",
      "31/31 - 0s - loss: 21.3957 - mae: 2.2042 - val_loss: 1.5325 - val_mae: 1.1938 - 40ms/epoch - 1ms/step\n",
      "Epoch 3462/5000\n",
      "31/31 - 0s - loss: 1.7534 - mae: 0.9865 - val_loss: 0.5312 - val_mae: 0.6534 - 39ms/epoch - 1ms/step\n",
      "Epoch 3463/5000\n",
      "31/31 - 0s - loss: 20.5973 - mae: 2.1956 - val_loss: 1.9051 - val_mae: 1.3406 - 41ms/epoch - 1ms/step\n",
      "Epoch 3464/5000\n",
      "31/31 - 0s - loss: 3.8495 - mae: 1.6981 - val_loss: 1.3199 - val_mae: 1.1022 - 40ms/epoch - 1ms/step\n",
      "Epoch 3465/5000\n",
      "31/31 - 0s - loss: 0.7082 - mae: 0.6923 - val_loss: 0.1056 - val_mae: 0.2831 - 44ms/epoch - 1ms/step\n",
      "Epoch 3466/5000\n",
      "31/31 - 0s - loss: 25.0883 - mae: 2.2248 - val_loss: 0.5527 - val_mae: 0.6729 - 43ms/epoch - 1ms/step\n",
      "Epoch 3467/5000\n",
      "31/31 - 0s - loss: 1.4378 - mae: 0.9270 - val_loss: 8.9375 - val_mae: 2.9717 - 41ms/epoch - 1ms/step\n",
      "Epoch 3468/5000\n",
      "31/31 - 0s - loss: 9.7344 - mae: 1.7853 - val_loss: 4.2427 - val_mae: 2.0348 - 42ms/epoch - 1ms/step\n",
      "Epoch 3469/5000\n",
      "31/31 - 0s - loss: 1.5842 - mae: 0.8701 - val_loss: 0.1897 - val_mae: 0.3215 - 53ms/epoch - 2ms/step\n",
      "Epoch 3470/5000\n",
      "31/31 - 0s - loss: 25.4166 - mae: 2.2009 - val_loss: 4.5261 - val_mae: 2.1032 - 55ms/epoch - 2ms/step\n",
      "Epoch 3471/5000\n",
      "31/31 - 0s - loss: 1.3955 - mae: 0.9246 - val_loss: 0.5320 - val_mae: 0.6548 - 44ms/epoch - 1ms/step\n",
      "Epoch 3472/5000\n",
      "31/31 - 0s - loss: 18.6401 - mae: 2.0828 - val_loss: 0.2498 - val_mae: 0.3837 - 43ms/epoch - 1ms/step\n",
      "Epoch 3473/5000\n",
      "31/31 - 0s - loss: 0.9527 - mae: 0.7210 - val_loss: 2.7439 - val_mae: 1.6265 - 41ms/epoch - 1ms/step\n",
      "Epoch 3474/5000\n",
      "31/31 - 0s - loss: 14.5741 - mae: 1.7437 - val_loss: 2.9039 - val_mae: 1.6727 - 40ms/epoch - 1ms/step\n",
      "Epoch 3475/5000\n",
      "31/31 - 0s - loss: 2.7800 - mae: 1.2873 - val_loss: 1.6436 - val_mae: 1.2395 - 40ms/epoch - 1ms/step\n",
      "Epoch 3476/5000\n",
      "31/31 - 0s - loss: 15.7132 - mae: 1.9610 - val_loss: 2.0419 - val_mae: 1.3929 - 40ms/epoch - 1ms/step\n",
      "Epoch 3477/5000\n",
      "31/31 - 0s - loss: 1.2415 - mae: 0.8871 - val_loss: 0.3029 - val_mae: 0.4474 - 47ms/epoch - 2ms/step\n",
      "Epoch 3478/5000\n",
      "31/31 - 0s - loss: 17.1637 - mae: 2.1106 - val_loss: 0.2326 - val_mae: 0.4253 - 42ms/epoch - 1ms/step\n",
      "Epoch 3479/5000\n",
      "31/31 - 0s - loss: 1.2376 - mae: 0.8314 - val_loss: 0.4762 - val_mae: 0.6069 - 42ms/epoch - 1ms/step\n",
      "Epoch 3480/5000\n",
      "31/31 - 0s - loss: 16.3320 - mae: 2.2535 - val_loss: 25.8622 - val_mae: 5.0761 - 44ms/epoch - 1ms/step\n",
      "Epoch 3481/5000\n",
      "31/31 - 0s - loss: 1.8274 - mae: 0.9584 - val_loss: 2.2896 - val_mae: 1.4784 - 41ms/epoch - 1ms/step\n",
      "Epoch 3482/5000\n",
      "31/31 - 0s - loss: 10.0446 - mae: 1.8512 - val_loss: 0.1468 - val_mae: 0.2889 - 45ms/epoch - 1ms/step\n",
      "Epoch 3483/5000\n",
      "31/31 - 0s - loss: 2.0142 - mae: 1.1538 - val_loss: 0.5309 - val_mae: 0.6515 - 45ms/epoch - 1ms/step\n",
      "Epoch 3484/5000\n",
      "31/31 - 0s - loss: 5.0571 - mae: 1.4610 - val_loss: 0.4741 - val_mae: 0.6055 - 44ms/epoch - 1ms/step\n",
      "Epoch 3485/5000\n",
      "31/31 - 0s - loss: 1.8253 - mae: 1.0736 - val_loss: 118.8822 - val_mae: 10.8988 - 47ms/epoch - 2ms/step\n",
      "Epoch 3486/5000\n",
      "31/31 - 0s - loss: 17.7680 - mae: 1.8448 - val_loss: 1.6997 - val_mae: 1.2616 - 45ms/epoch - 1ms/step\n",
      "Epoch 3487/5000\n",
      "31/31 - 0s - loss: 1.1988 - mae: 0.8771 - val_loss: 1.8557 - val_mae: 1.3236 - 49ms/epoch - 2ms/step\n",
      "Epoch 3488/5000\n",
      "31/31 - 0s - loss: 19.7042 - mae: 2.0846 - val_loss: 0.2822 - val_mae: 0.4241 - 41ms/epoch - 1ms/step\n",
      "Epoch 3489/5000\n",
      "31/31 - 0s - loss: 1.4061 - mae: 0.9521 - val_loss: 0.2968 - val_mae: 0.4657 - 39ms/epoch - 1ms/step\n",
      "Epoch 3490/5000\n",
      "31/31 - 0s - loss: 19.5004 - mae: 2.0689 - val_loss: 0.7137 - val_mae: 0.7807 - 39ms/epoch - 1ms/step\n",
      "Epoch 3491/5000\n",
      "31/31 - 0s - loss: 1.3257 - mae: 0.9273 - val_loss: 2.6415 - val_mae: 1.5937 - 40ms/epoch - 1ms/step\n",
      "Epoch 3492/5000\n",
      "31/31 - 0s - loss: 1.0369 - mae: 0.7265 - val_loss: 0.8234 - val_mae: 0.8418 - 37ms/epoch - 1ms/step\n",
      "Epoch 3493/5000\n",
      "31/31 - 0s - loss: 18.1260 - mae: 2.3083 - val_loss: 0.4108 - val_mae: 0.5562 - 39ms/epoch - 1ms/step\n",
      "Epoch 3494/5000\n",
      "31/31 - 0s - loss: 1.8335 - mae: 1.1064 - val_loss: 5.5671 - val_mae: 2.3389 - 37ms/epoch - 1ms/step\n",
      "Epoch 3495/5000\n",
      "31/31 - 0s - loss: 16.7866 - mae: 2.4228 - val_loss: 0.3477 - val_mae: 0.4976 - 37ms/epoch - 1ms/step\n",
      "Epoch 3496/5000\n",
      "31/31 - 0s - loss: 0.9843 - mae: 0.7341 - val_loss: 0.1335 - val_mae: 0.2766 - 37ms/epoch - 1ms/step\n",
      "Epoch 3497/5000\n",
      "31/31 - 0s - loss: 15.8341 - mae: 2.3969 - val_loss: 0.7958 - val_mae: 0.8310 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3498/5000\n",
      "31/31 - 0s - loss: 1.2898 - mae: 0.9600 - val_loss: 3.7466 - val_mae: 1.9099 - 36ms/epoch - 1ms/step\n",
      "Epoch 3499/5000\n",
      "31/31 - 0s - loss: 17.3740 - mae: 2.1491 - val_loss: 0.1699 - val_mae: 0.3734 - 37ms/epoch - 1ms/step\n",
      "Epoch 3500/5000\n",
      "31/31 - 0s - loss: 1.1102 - mae: 0.8680 - val_loss: 0.5878 - val_mae: 0.6888 - 38ms/epoch - 1ms/step\n",
      "Epoch 3501/5000\n",
      "31/31 - 0s - loss: 10.5873 - mae: 1.7264 - val_loss: 0.1197 - val_mae: 0.2787 - 35ms/epoch - 1ms/step\n",
      "Epoch 3502/5000\n",
      "31/31 - 0s - loss: 1.2340 - mae: 0.9948 - val_loss: 0.1532 - val_mae: 0.2862 - 37ms/epoch - 1ms/step\n",
      "Epoch 3503/5000\n",
      "31/31 - 0s - loss: 11.4108 - mae: 2.0323 - val_loss: 8.6972 - val_mae: 2.9323 - 37ms/epoch - 1ms/step\n",
      "Epoch 3504/5000\n",
      "31/31 - 0s - loss: 1.8060 - mae: 1.0740 - val_loss: 2.7115 - val_mae: 1.6153 - 35ms/epoch - 1ms/step\n",
      "Epoch 3505/5000\n",
      "31/31 - 0s - loss: 15.0701 - mae: 2.2081 - val_loss: 0.4128 - val_mae: 0.5534 - 36ms/epoch - 1ms/step\n",
      "Epoch 3506/5000\n",
      "31/31 - 0s - loss: 2.5103 - mae: 1.3260 - val_loss: 1.1039 - val_mae: 0.9985 - 38ms/epoch - 1ms/step\n",
      "Epoch 3507/5000\n",
      "31/31 - 0s - loss: 14.1677 - mae: 1.9424 - val_loss: 0.3343 - val_mae: 0.4819 - 38ms/epoch - 1ms/step\n",
      "Epoch 3508/5000\n",
      "31/31 - 0s - loss: 0.7138 - mae: 0.6796 - val_loss: 0.8855 - val_mae: 0.8851 - 37ms/epoch - 1ms/step\n",
      "Epoch 3509/5000\n",
      "31/31 - 0s - loss: 6.3561 - mae: 1.4802 - val_loss: 0.1927 - val_mae: 0.3949 - 38ms/epoch - 1ms/step\n",
      "Epoch 3510/5000\n",
      "31/31 - 0s - loss: 6.6551 - mae: 1.7637 - val_loss: 13.3386 - val_mae: 3.6370 - 37ms/epoch - 1ms/step\n",
      "Epoch 3511/5000\n",
      "31/31 - 0s - loss: 1.3858 - mae: 0.7822 - val_loss: 0.2113 - val_mae: 0.3434 - 37ms/epoch - 1ms/step\n",
      "Epoch 3512/5000\n",
      "31/31 - 0s - loss: 23.4137 - mae: 2.0334 - val_loss: 0.3581 - val_mae: 0.5031 - 36ms/epoch - 1ms/step\n",
      "Epoch 3513/5000\n",
      "31/31 - 0s - loss: 1.6893 - mae: 0.7839 - val_loss: 0.1830 - val_mae: 0.3860 - 38ms/epoch - 1ms/step\n",
      "Epoch 3514/5000\n",
      "31/31 - 0s - loss: 5.6623 - mae: 1.4613 - val_loss: 0.1262 - val_mae: 0.3215 - 36ms/epoch - 1ms/step\n",
      "Epoch 3515/5000\n",
      "31/31 - 0s - loss: 0.7792 - mae: 0.6313 - val_loss: 2.9997 - val_mae: 1.6993 - 35ms/epoch - 1ms/step\n",
      "Epoch 3516/5000\n",
      "31/31 - 0s - loss: 18.8320 - mae: 2.3388 - val_loss: 0.1679 - val_mae: 0.3704 - 36ms/epoch - 1ms/step\n",
      "Epoch 3517/5000\n",
      "31/31 - 0s - loss: 1.2080 - mae: 0.8344 - val_loss: 1.9825 - val_mae: 1.3690 - 37ms/epoch - 1ms/step\n",
      "Epoch 3518/5000\n",
      "31/31 - 0s - loss: 13.8587 - mae: 1.9505 - val_loss: 1.3937 - val_mae: 1.1346 - 37ms/epoch - 1ms/step\n",
      "Epoch 3519/5000\n",
      "31/31 - 0s - loss: 0.8537 - mae: 0.7837 - val_loss: 2.8341 - val_mae: 1.6519 - 36ms/epoch - 1ms/step\n",
      "Epoch 3520/5000\n",
      "31/31 - 0s - loss: 12.1114 - mae: 2.0787 - val_loss: 2.6308 - val_mae: 1.5878 - 36ms/epoch - 1ms/step\n",
      "Epoch 3521/5000\n",
      "31/31 - 0s - loss: 2.2040 - mae: 1.2709 - val_loss: 0.4653 - val_mae: 0.6015 - 37ms/epoch - 1ms/step\n",
      "Epoch 3522/5000\n",
      "31/31 - 0s - loss: 9.7869 - mae: 2.2732 - val_loss: 2.5060 - val_mae: 1.5482 - 38ms/epoch - 1ms/step\n",
      "Epoch 3523/5000\n",
      "31/31 - 0s - loss: 10.5235 - mae: 2.1857 - val_loss: 1.2374 - val_mae: 1.0663 - 36ms/epoch - 1ms/step\n",
      "Epoch 3524/5000\n",
      "31/31 - 0s - loss: 0.9315 - mae: 0.7762 - val_loss: 1.1545 - val_mae: 1.0222 - 37ms/epoch - 1ms/step\n",
      "Epoch 3525/5000\n",
      "31/31 - 0s - loss: 19.0524 - mae: 2.2216 - val_loss: 0.7894 - val_mae: 0.8276 - 38ms/epoch - 1ms/step\n",
      "Epoch 3526/5000\n",
      "31/31 - 0s - loss: 1.3161 - mae: 0.8195 - val_loss: 3.3244 - val_mae: 1.7952 - 36ms/epoch - 1ms/step\n",
      "Epoch 3527/5000\n",
      "31/31 - 0s - loss: 12.3102 - mae: 2.0367 - val_loss: 0.2087 - val_mae: 0.4080 - 36ms/epoch - 1ms/step\n",
      "Epoch 3528/5000\n",
      "31/31 - 0s - loss: 1.3137 - mae: 0.9208 - val_loss: 1.0693 - val_mae: 0.9834 - 36ms/epoch - 1ms/step\n",
      "Epoch 3529/5000\n",
      "31/31 - 0s - loss: 24.6350 - mae: 2.3550 - val_loss: 0.1051 - val_mae: 0.2787 - 47ms/epoch - 2ms/step\n",
      "Epoch 3530/5000\n",
      "31/31 - 0s - loss: 3.4282 - mae: 1.3644 - val_loss: 0.1578 - val_mae: 0.2903 - 38ms/epoch - 1ms/step\n",
      "Epoch 3531/5000\n",
      "31/31 - 0s - loss: 0.2310 - mae: 0.4008 - val_loss: 1.2340 - val_mae: 1.0629 - 38ms/epoch - 1ms/step\n",
      "Epoch 3532/5000\n",
      "31/31 - 0s - loss: 25.3601 - mae: 2.2153 - val_loss: 0.3652 - val_mae: 0.5093 - 35ms/epoch - 1ms/step\n",
      "Epoch 3533/5000\n",
      "31/31 - 0s - loss: 1.1965 - mae: 0.8708 - val_loss: 0.4038 - val_mae: 0.5481 - 37ms/epoch - 1ms/step\n",
      "Epoch 3534/5000\n",
      "31/31 - 0s - loss: 12.8324 - mae: 1.9124 - val_loss: 0.3366 - val_mae: 0.4889 - 37ms/epoch - 1ms/step\n",
      "Epoch 3535/5000\n",
      "31/31 - 0s - loss: 1.5177 - mae: 0.9936 - val_loss: 1.2069 - val_mae: 1.0503 - 35ms/epoch - 1ms/step\n",
      "Epoch 3536/5000\n",
      "31/31 - 0s - loss: 14.2445 - mae: 1.8991 - val_loss: 0.1089 - val_mae: 0.2843 - 36ms/epoch - 1ms/step\n",
      "Epoch 3537/5000\n",
      "31/31 - 0s - loss: 1.2452 - mae: 0.8328 - val_loss: 0.5373 - val_mae: 0.6566 - 37ms/epoch - 1ms/step\n",
      "Epoch 3538/5000\n",
      "31/31 - 0s - loss: 6.5853 - mae: 1.7885 - val_loss: 0.7174 - val_mae: 0.7783 - 35ms/epoch - 1ms/step\n",
      "Epoch 3539/5000\n",
      "31/31 - 0s - loss: 1.2646 - mae: 0.9411 - val_loss: 0.2003 - val_mae: 0.3316 - 36ms/epoch - 1ms/step\n",
      "Epoch 3540/5000\n",
      "31/31 - 0s - loss: 22.4477 - mae: 2.0807 - val_loss: 13.8638 - val_mae: 3.7099 - 36ms/epoch - 1ms/step\n",
      "Epoch 3541/5000\n",
      "31/31 - 0s - loss: 1.6017 - mae: 0.9105 - val_loss: 8.1062 - val_mae: 2.8288 - 37ms/epoch - 1ms/step\n",
      "Epoch 3542/5000\n",
      "31/31 - 0s - loss: 8.3107 - mae: 1.8559 - val_loss: 0.7735 - val_mae: 0.8170 - 37ms/epoch - 1ms/step\n",
      "Epoch 3543/5000\n",
      "31/31 - 0s - loss: 15.3132 - mae: 2.1890 - val_loss: 0.6952 - val_mae: 0.7699 - 38ms/epoch - 1ms/step\n",
      "Epoch 3544/5000\n",
      "31/31 - 0s - loss: 0.8862 - mae: 0.7359 - val_loss: 0.1576 - val_mae: 0.3635 - 37ms/epoch - 1ms/step\n",
      "Epoch 3545/5000\n",
      "31/31 - 0s - loss: 6.6169 - mae: 1.8718 - val_loss: 6.4653 - val_mae: 2.5223 - 37ms/epoch - 1ms/step\n",
      "Epoch 3546/5000\n",
      "31/31 - 0s - loss: 5.1267 - mae: 1.5701 - val_loss: 114.4431 - val_mae: 10.6937 - 35ms/epoch - 1ms/step\n",
      "Epoch 3547/5000\n",
      "31/31 - 0s - loss: 4.7558 - mae: 1.3008 - val_loss: 4.0598 - val_mae: 1.9904 - 36ms/epoch - 1ms/step\n",
      "Epoch 3548/5000\n",
      "31/31 - 0s - loss: 18.8261 - mae: 2.1117 - val_loss: 0.3536 - val_mae: 0.5009 - 38ms/epoch - 1ms/step\n",
      "Epoch 3549/5000\n",
      "31/31 - 0s - loss: 1.5370 - mae: 0.8693 - val_loss: 0.5071 - val_mae: 0.6365 - 38ms/epoch - 1ms/step\n",
      "Epoch 3550/5000\n",
      "31/31 - 0s - loss: 0.8647 - mae: 0.7213 - val_loss: 0.1299 - val_mae: 0.3321 - 36ms/epoch - 1ms/step\n",
      "Epoch 3551/5000\n",
      "31/31 - 0s - loss: 15.0853 - mae: 2.1296 - val_loss: 0.6597 - val_mae: 0.7453 - 37ms/epoch - 1ms/step\n",
      "Epoch 3552/5000\n",
      "31/31 - 0s - loss: 3.4049 - mae: 1.1484 - val_loss: 214.1581 - val_mae: 14.6301 - 36ms/epoch - 1ms/step\n",
      "Epoch 3553/5000\n",
      "31/31 - 0s - loss: 13.4304 - mae: 1.5708 - val_loss: 0.1051 - val_mae: 0.2829 - 35ms/epoch - 1ms/step\n",
      "Epoch 3554/5000\n",
      "31/31 - 0s - loss: 1.3624 - mae: 0.9095 - val_loss: 0.1426 - val_mae: 0.3462 - 35ms/epoch - 1ms/step\n",
      "Epoch 3555/5000\n",
      "31/31 - 0s - loss: 8.5705 - mae: 2.0692 - val_loss: 1.1023 - val_mae: 0.9995 - 35ms/epoch - 1ms/step\n",
      "Epoch 3556/5000\n",
      "31/31 - 0s - loss: 9.3946 - mae: 2.0593 - val_loss: 0.5401 - val_mae: 0.6613 - 34ms/epoch - 1ms/step\n",
      "Epoch 3557/5000\n",
      "31/31 - 0s - loss: 1.3992 - mae: 0.9313 - val_loss: 4.2649 - val_mae: 2.0367 - 35ms/epoch - 1ms/step\n",
      "Epoch 3558/5000\n",
      "31/31 - 0s - loss: 11.2125 - mae: 2.1107 - val_loss: 1.9084 - val_mae: 1.3432 - 37ms/epoch - 1ms/step\n",
      "Epoch 3559/5000\n",
      "31/31 - 0s - loss: 1.0228 - mae: 0.7972 - val_loss: 0.7056 - val_mae: 0.7773 - 35ms/epoch - 1ms/step\n",
      "Epoch 3560/5000\n",
      "31/31 - 0s - loss: 21.5407 - mae: 2.1284 - val_loss: 1.1693 - val_mae: 1.0310 - 36ms/epoch - 1ms/step\n",
      "Epoch 3561/5000\n",
      "31/31 - 0s - loss: 2.1897 - mae: 1.1745 - val_loss: 0.4599 - val_mae: 0.5923 - 36ms/epoch - 1ms/step\n",
      "Epoch 3562/5000\n",
      "31/31 - 0s - loss: 10.9088 - mae: 1.9707 - val_loss: 0.3576 - val_mae: 0.5037 - 36ms/epoch - 1ms/step\n",
      "Epoch 3563/5000\n",
      "31/31 - 0s - loss: 0.5411 - mae: 0.5637 - val_loss: 1.0752 - val_mae: 0.9868 - 35ms/epoch - 1ms/step\n",
      "Epoch 3564/5000\n",
      "31/31 - 0s - loss: 27.8450 - mae: 2.2688 - val_loss: 0.1495 - val_mae: 0.3491 - 36ms/epoch - 1ms/step\n",
      "Epoch 3565/5000\n",
      "31/31 - 0s - loss: 2.5098 - mae: 1.1653 - val_loss: 0.1262 - val_mae: 0.2851 - 35ms/epoch - 1ms/step\n",
      "Epoch 3566/5000\n",
      "31/31 - 0s - loss: 0.7219 - mae: 0.6323 - val_loss: 6.4492 - val_mae: 2.5192 - 37ms/epoch - 1ms/step\n",
      "Epoch 3567/5000\n",
      "31/31 - 0s - loss: 10.4916 - mae: 2.2538 - val_loss: 0.1440 - val_mae: 0.3451 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3568/5000\n",
      "31/31 - 0s - loss: 12.6817 - mae: 2.1708 - val_loss: 0.1168 - val_mae: 0.2987 - 35ms/epoch - 1ms/step\n",
      "Epoch 3569/5000\n",
      "31/31 - 0s - loss: 1.4047 - mae: 0.9432 - val_loss: 0.3375 - val_mae: 0.4884 - 35ms/epoch - 1ms/step\n",
      "Epoch 3570/5000\n",
      "31/31 - 0s - loss: 2.8600 - mae: 1.3448 - val_loss: 0.1090 - val_mae: 0.2858 - 37ms/epoch - 1ms/step\n",
      "Epoch 3571/5000\n",
      "31/31 - 0s - loss: 7.8502 - mae: 1.6230 - val_loss: 1.5798 - val_mae: 1.2142 - 36ms/epoch - 1ms/step\n",
      "Epoch 3572/5000\n",
      "31/31 - 0s - loss: 2.5189 - mae: 1.4208 - val_loss: 2.3203 - val_mae: 1.4913 - 35ms/epoch - 1ms/step\n",
      "Epoch 3573/5000\n",
      "31/31 - 0s - loss: 16.5604 - mae: 2.1925 - val_loss: 0.3319 - val_mae: 0.4849 - 35ms/epoch - 1ms/step\n",
      "Epoch 3574/5000\n",
      "31/31 - 0s - loss: 2.6167 - mae: 1.1889 - val_loss: 267.3542 - val_mae: 16.3476 - 36ms/epoch - 1ms/step\n",
      "Epoch 3575/5000\n",
      "31/31 - 0s - loss: 10.4531 - mae: 1.5662 - val_loss: 0.6688 - val_mae: 0.7508 - 37ms/epoch - 1ms/step\n",
      "Epoch 3576/5000\n",
      "31/31 - 0s - loss: 16.9320 - mae: 2.2159 - val_loss: 4.1151 - val_mae: 2.0054 - 37ms/epoch - 1ms/step\n",
      "Epoch 3577/5000\n",
      "31/31 - 0s - loss: 0.8279 - mae: 0.7123 - val_loss: 0.5489 - val_mae: 0.6709 - 37ms/epoch - 1ms/step\n",
      "Epoch 3578/5000\n",
      "31/31 - 0s - loss: 1.2180 - mae: 0.9714 - val_loss: 0.4280 - val_mae: 0.5658 - 36ms/epoch - 1ms/step\n",
      "Epoch 3579/5000\n",
      "31/31 - 0s - loss: 15.7418 - mae: 2.0537 - val_loss: 0.5901 - val_mae: 0.7004 - 37ms/epoch - 1ms/step\n",
      "Epoch 3580/5000\n",
      "31/31 - 0s - loss: 0.9899 - mae: 0.7806 - val_loss: 0.8212 - val_mae: 0.8485 - 36ms/epoch - 1ms/step\n",
      "Epoch 3581/5000\n",
      "31/31 - 0s - loss: 12.7754 - mae: 1.9781 - val_loss: 0.1736 - val_mae: 0.3779 - 34ms/epoch - 1ms/step\n",
      "Epoch 3582/5000\n",
      "31/31 - 0s - loss: 2.1595 - mae: 1.2048 - val_loss: 6.3865 - val_mae: 2.5067 - 35ms/epoch - 1ms/step\n",
      "Epoch 3583/5000\n",
      "31/31 - 0s - loss: 10.9518 - mae: 2.0394 - val_loss: 0.1854 - val_mae: 0.3189 - 37ms/epoch - 1ms/step\n",
      "Epoch 3584/5000\n",
      "31/31 - 0s - loss: 1.2825 - mae: 0.8340 - val_loss: 10.2531 - val_mae: 3.1863 - 36ms/epoch - 1ms/step\n",
      "Epoch 3585/5000\n",
      "31/31 - 0s - loss: 27.4902 - mae: 2.0674 - val_loss: 1.2917 - val_mae: 1.0894 - 37ms/epoch - 1ms/step\n",
      "Epoch 3586/5000\n",
      "31/31 - 0s - loss: 1.4351 - mae: 0.9062 - val_loss: 0.5498 - val_mae: 0.6701 - 39ms/epoch - 1ms/step\n",
      "Epoch 3587/5000\n",
      "31/31 - 0s - loss: 21.1047 - mae: 2.0494 - val_loss: 1.2452 - val_mae: 1.0690 - 38ms/epoch - 1ms/step\n",
      "Epoch 3588/5000\n",
      "31/31 - 0s - loss: 1.5018 - mae: 0.9880 - val_loss: 2.3513 - val_mae: 1.5011 - 36ms/epoch - 1ms/step\n",
      "Epoch 3589/5000\n",
      "31/31 - 0s - loss: 15.6338 - mae: 2.0566 - val_loss: 0.1111 - val_mae: 0.2912 - 37ms/epoch - 1ms/step\n",
      "Epoch 3590/5000\n",
      "31/31 - 0s - loss: 0.8713 - mae: 0.6609 - val_loss: 1.6985 - val_mae: 1.2628 - 35ms/epoch - 1ms/step\n",
      "Epoch 3591/5000\n",
      "31/31 - 0s - loss: 9.6355 - mae: 1.8904 - val_loss: 3.3157 - val_mae: 1.7911 - 38ms/epoch - 1ms/step\n",
      "Epoch 3592/5000\n",
      "31/31 - 0s - loss: 1.8141 - mae: 1.1217 - val_loss: 5.6271 - val_mae: 2.3484 - 36ms/epoch - 1ms/step\n",
      "Epoch 3593/5000\n",
      "31/31 - 0s - loss: 21.2405 - mae: 2.4644 - val_loss: 0.1255 - val_mae: 0.2736 - 36ms/epoch - 1ms/step\n",
      "Epoch 3594/5000\n",
      "31/31 - 0s - loss: 2.3517 - mae: 1.0295 - val_loss: 4.7828 - val_mae: 2.1633 - 36ms/epoch - 1ms/step\n",
      "Epoch 3595/5000\n",
      "31/31 - 0s - loss: 11.7839 - mae: 1.8932 - val_loss: 13.7983 - val_mae: 3.6998 - 37ms/epoch - 1ms/step\n",
      "Epoch 3596/5000\n",
      "31/31 - 0s - loss: 16.9763 - mae: 2.4490 - val_loss: 0.6271 - val_mae: 0.7266 - 37ms/epoch - 1ms/step\n",
      "Epoch 3597/5000\n",
      "31/31 - 0s - loss: 1.1079 - mae: 0.6388 - val_loss: 0.4956 - val_mae: 0.6281 - 38ms/epoch - 1ms/step\n",
      "Epoch 3598/5000\n",
      "31/31 - 0s - loss: 19.3132 - mae: 2.1955 - val_loss: 1.2941 - val_mae: 1.0909 - 37ms/epoch - 1ms/step\n",
      "Epoch 3599/5000\n",
      "31/31 - 0s - loss: 0.8389 - mae: 0.7063 - val_loss: 2.3198 - val_mae: 1.4877 - 36ms/epoch - 1ms/step\n",
      "Epoch 3600/5000\n",
      "31/31 - 0s - loss: 0.5644 - mae: 0.5724 - val_loss: 0.1363 - val_mae: 0.3392 - 37ms/epoch - 1ms/step\n",
      "Epoch 3601/5000\n",
      "31/31 - 0s - loss: 30.1102 - mae: 2.3339 - val_loss: 5.0361 - val_mae: 2.2196 - 36ms/epoch - 1ms/step\n",
      "Epoch 3602/5000\n",
      "31/31 - 0s - loss: 1.4935 - mae: 1.0012 - val_loss: 1.8507 - val_mae: 1.3235 - 37ms/epoch - 1ms/step\n",
      "Epoch 3603/5000\n",
      "31/31 - 0s - loss: 2.7950 - mae: 1.2041 - val_loss: 0.6287 - val_mae: 0.7261 - 38ms/epoch - 1ms/step\n",
      "Epoch 3604/5000\n",
      "31/31 - 0s - loss: 13.7669 - mae: 1.7346 - val_loss: 4.6489 - val_mae: 2.1312 - 36ms/epoch - 1ms/step\n",
      "Epoch 3605/5000\n",
      "31/31 - 0s - loss: 3.6815 - mae: 1.5673 - val_loss: 44.7609 - val_mae: 6.6829 - 35ms/epoch - 1ms/step\n",
      "Epoch 3606/5000\n",
      "31/31 - 0s - loss: 6.2049 - mae: 1.3542 - val_loss: 0.3819 - val_mae: 0.5308 - 35ms/epoch - 1ms/step\n",
      "Epoch 3607/5000\n",
      "31/31 - 0s - loss: 17.6398 - mae: 2.1554 - val_loss: 0.2803 - val_mae: 0.4230 - 36ms/epoch - 1ms/step\n",
      "Epoch 3608/5000\n",
      "31/31 - 0s - loss: 0.6932 - mae: 0.5940 - val_loss: 0.2815 - val_mae: 0.4220 - 34ms/epoch - 1ms/step\n",
      "Epoch 3609/5000\n",
      "31/31 - 0s - loss: 1.9674 - mae: 0.9505 - val_loss: 86.2121 - val_mae: 9.2798 - 36ms/epoch - 1ms/step\n",
      "Epoch 3610/5000\n",
      "31/31 - 0s - loss: 8.5746 - mae: 1.6020 - val_loss: 0.4029 - val_mae: 0.5487 - 35ms/epoch - 1ms/step\n",
      "Epoch 3611/5000\n",
      "31/31 - 0s - loss: 15.7646 - mae: 1.8639 - val_loss: 0.9979 - val_mae: 0.9451 - 37ms/epoch - 1ms/step\n",
      "Epoch 3612/5000\n",
      "31/31 - 0s - loss: 1.1461 - mae: 0.7484 - val_loss: 4.6751 - val_mae: 2.1379 - 35ms/epoch - 1ms/step\n",
      "Epoch 3613/5000\n",
      "31/31 - 0s - loss: 22.1283 - mae: 2.2403 - val_loss: 0.1748 - val_mae: 0.3111 - 34ms/epoch - 1ms/step\n",
      "Epoch 3614/5000\n",
      "31/31 - 0s - loss: 1.1318 - mae: 0.8197 - val_loss: 1.1361 - val_mae: 1.0163 - 36ms/epoch - 1ms/step\n",
      "Epoch 3615/5000\n",
      "31/31 - 0s - loss: 22.5501 - mae: 2.1174 - val_loss: 0.1585 - val_mae: 0.2927 - 36ms/epoch - 1ms/step\n",
      "Epoch 3616/5000\n",
      "31/31 - 0s - loss: 1.4749 - mae: 0.8851 - val_loss: 0.1739 - val_mae: 0.3078 - 36ms/epoch - 1ms/step\n",
      "Epoch 3617/5000\n",
      "31/31 - 0s - loss: 0.7872 - mae: 0.5922 - val_loss: 102.4352 - val_mae: 10.1153 - 36ms/epoch - 1ms/step\n",
      "Epoch 3618/5000\n",
      "31/31 - 0s - loss: 21.0019 - mae: 2.2091 - val_loss: 0.6614 - val_mae: 0.7487 - 34ms/epoch - 1ms/step\n",
      "Epoch 3619/5000\n",
      "31/31 - 0s - loss: 7.9259 - mae: 1.7097 - val_loss: 187.9953 - val_mae: 13.7071 - 36ms/epoch - 1ms/step\n",
      "Epoch 3620/5000\n",
      "31/31 - 0s - loss: 7.6556 - mae: 1.1594 - val_loss: 1.9273 - val_mae: 1.3492 - 37ms/epoch - 1ms/step\n",
      "Epoch 3621/5000\n",
      "31/31 - 0s - loss: 1.3088 - mae: 0.8812 - val_loss: 4.3233 - val_mae: 2.0550 - 36ms/epoch - 1ms/step\n",
      "Epoch 3622/5000\n",
      "31/31 - 0s - loss: 14.4747 - mae: 2.3062 - val_loss: 0.4200 - val_mae: 0.5655 - 35ms/epoch - 1ms/step\n",
      "Epoch 3623/5000\n",
      "31/31 - 0s - loss: 2.9804 - mae: 1.3855 - val_loss: 0.0992 - val_mae: 0.2726 - 35ms/epoch - 1ms/step\n",
      "Epoch 3624/5000\n",
      "31/31 - 0s - loss: 22.1127 - mae: 2.0357 - val_loss: 0.1401 - val_mae: 0.3427 - 36ms/epoch - 1ms/step\n",
      "Epoch 3625/5000\n",
      "31/31 - 0s - loss: 1.0077 - mae: 0.8281 - val_loss: 0.1037 - val_mae: 0.2795 - 38ms/epoch - 1ms/step\n",
      "Epoch 3626/5000\n",
      "31/31 - 0s - loss: 19.3144 - mae: 2.2949 - val_loss: 1.1430 - val_mae: 1.0228 - 37ms/epoch - 1ms/step\n",
      "Epoch 3627/5000\n",
      "31/31 - 0s - loss: 1.0340 - mae: 0.7529 - val_loss: 0.1427 - val_mae: 0.2740 - 38ms/epoch - 1ms/step\n",
      "Epoch 3628/5000\n",
      "31/31 - 0s - loss: 16.4188 - mae: 2.1846 - val_loss: 0.2426 - val_mae: 0.3760 - 36ms/epoch - 1ms/step\n",
      "Epoch 3629/5000\n",
      "31/31 - 0s - loss: 0.5888 - mae: 0.6055 - val_loss: 2.3306 - val_mae: 1.4935 - 48ms/epoch - 2ms/step\n",
      "Epoch 3630/5000\n",
      "31/31 - 0s - loss: 12.2717 - mae: 1.8897 - val_loss: 0.1800 - val_mae: 0.3146 - 36ms/epoch - 1ms/step\n",
      "Epoch 3631/5000\n",
      "31/31 - 0s - loss: 2.8371 - mae: 1.0965 - val_loss: 0.2215 - val_mae: 0.3529 - 36ms/epoch - 1ms/step\n",
      "Epoch 3632/5000\n",
      "31/31 - 0s - loss: 12.5842 - mae: 1.9326 - val_loss: 0.2215 - val_mae: 0.3496 - 37ms/epoch - 1ms/step\n",
      "Epoch 3633/5000\n",
      "31/31 - 0s - loss: 0.6359 - mae: 0.6668 - val_loss: 0.2713 - val_mae: 0.4076 - 38ms/epoch - 1ms/step\n",
      "Epoch 3634/5000\n",
      "31/31 - 0s - loss: 25.3128 - mae: 2.5656 - val_loss: 3.4522 - val_mae: 1.8282 - 37ms/epoch - 1ms/step\n",
      "Epoch 3635/5000\n",
      "31/31 - 0s - loss: 1.3705 - mae: 0.8867 - val_loss: 1.8675 - val_mae: 1.3259 - 36ms/epoch - 1ms/step\n",
      "Epoch 3636/5000\n",
      "31/31 - 0s - loss: 8.4756 - mae: 1.7754 - val_loss: 139.8510 - val_mae: 11.8219 - 37ms/epoch - 1ms/step\n",
      "Epoch 3637/5000\n",
      "31/31 - 0s - loss: 6.1648 - mae: 1.3524 - val_loss: 1.3028 - val_mae: 1.0964 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3638/5000\n",
      "31/31 - 0s - loss: 12.7517 - mae: 2.0123 - val_loss: 0.4237 - val_mae: 0.5641 - 36ms/epoch - 1ms/step\n",
      "Epoch 3639/5000\n",
      "31/31 - 0s - loss: 1.0073 - mae: 0.7643 - val_loss: 5.8793 - val_mae: 2.4042 - 35ms/epoch - 1ms/step\n",
      "Epoch 3640/5000\n",
      "31/31 - 0s - loss: 13.5377 - mae: 1.9829 - val_loss: 0.4151 - val_mae: 0.5538 - 37ms/epoch - 1ms/step\n",
      "Epoch 3641/5000\n",
      "31/31 - 0s - loss: 1.6497 - mae: 1.0299 - val_loss: 0.1333 - val_mae: 0.2833 - 37ms/epoch - 1ms/step\n",
      "Epoch 3642/5000\n",
      "31/31 - 0s - loss: 1.5527 - mae: 0.9242 - val_loss: 225.9592 - val_mae: 15.0289 - 36ms/epoch - 1ms/step\n",
      "Epoch 3643/5000\n",
      "31/31 - 0s - loss: 16.8994 - mae: 2.0377 - val_loss: 1.0298 - val_mae: 0.9625 - 38ms/epoch - 1ms/step\n",
      "Epoch 3644/5000\n",
      "31/31 - 0s - loss: 0.6718 - mae: 0.6526 - val_loss: 0.5010 - val_mae: 0.6323 - 37ms/epoch - 1ms/step\n",
      "Epoch 3645/5000\n",
      "31/31 - 0s - loss: 11.6645 - mae: 1.9390 - val_loss: 0.3857 - val_mae: 0.5222 - 37ms/epoch - 1ms/step\n",
      "Epoch 3646/5000\n",
      "31/31 - 0s - loss: 3.2641 - mae: 1.3989 - val_loss: 74.5221 - val_mae: 8.6261 - 39ms/epoch - 1ms/step\n",
      "Epoch 3647/5000\n",
      "31/31 - 0s - loss: 19.0462 - mae: 2.1465 - val_loss: 0.4497 - val_mae: 0.5863 - 37ms/epoch - 1ms/step\n",
      "Epoch 3648/5000\n",
      "31/31 - 0s - loss: 4.1631 - mae: 1.4634 - val_loss: 0.2297 - val_mae: 0.3554 - 36ms/epoch - 1ms/step\n",
      "Epoch 3649/5000\n",
      "31/31 - 0s - loss: 11.2395 - mae: 1.5517 - val_loss: 0.3094 - val_mae: 0.4724 - 37ms/epoch - 1ms/step\n",
      "Epoch 3650/5000\n",
      "31/31 - 0s - loss: 1.9951 - mae: 1.2208 - val_loss: 0.1007 - val_mae: 0.2748 - 36ms/epoch - 1ms/step\n",
      "Epoch 3651/5000\n",
      "31/31 - 0s - loss: 13.3772 - mae: 1.9432 - val_loss: 0.5021 - val_mae: 0.6337 - 37ms/epoch - 1ms/step\n",
      "Epoch 3652/5000\n",
      "31/31 - 0s - loss: 0.9916 - mae: 0.7311 - val_loss: 0.5641 - val_mae: 0.6783 - 36ms/epoch - 1ms/step\n",
      "Epoch 3653/5000\n",
      "31/31 - 0s - loss: 8.2086 - mae: 2.0645 - val_loss: 0.2712 - val_mae: 0.4487 - 36ms/epoch - 1ms/step\n",
      "Epoch 3654/5000\n",
      "31/31 - 0s - loss: 1.9050 - mae: 1.0829 - val_loss: 0.1048 - val_mae: 0.2820 - 36ms/epoch - 1ms/step\n",
      "Epoch 3655/5000\n",
      "31/31 - 0s - loss: 33.0419 - mae: 2.3536 - val_loss: 0.2445 - val_mae: 0.3800 - 36ms/epoch - 1ms/step\n",
      "Epoch 3656/5000\n",
      "31/31 - 0s - loss: 2.9211 - mae: 1.2880 - val_loss: 1.5473 - val_mae: 1.2011 - 37ms/epoch - 1ms/step\n",
      "Epoch 3657/5000\n",
      "31/31 - 0s - loss: 7.6101 - mae: 1.6810 - val_loss: 103.8303 - val_mae: 10.1850 - 37ms/epoch - 1ms/step\n",
      "Epoch 3658/5000\n",
      "31/31 - 0s - loss: 6.0257 - mae: 1.3580 - val_loss: 4.6372 - val_mae: 2.1283 - 38ms/epoch - 1ms/step\n",
      "Epoch 3659/5000\n",
      "31/31 - 0s - loss: 1.9674 - mae: 1.0035 - val_loss: 718.1210 - val_mae: 26.7955 - 36ms/epoch - 1ms/step\n",
      "Epoch 3660/5000\n",
      "31/31 - 0s - loss: 30.3347 - mae: 2.5644 - val_loss: 0.4406 - val_mae: 0.5846 - 35ms/epoch - 1ms/step\n",
      "Epoch 3661/5000\n",
      "31/31 - 0s - loss: 1.0551 - mae: 0.9035 - val_loss: 5.0489 - val_mae: 2.2252 - 34ms/epoch - 1ms/step\n",
      "Epoch 3662/5000\n",
      "31/31 - 0s - loss: 7.2670 - mae: 1.8843 - val_loss: 0.6134 - val_mae: 0.7124 - 35ms/epoch - 1ms/step\n",
      "Epoch 3663/5000\n",
      "31/31 - 0s - loss: 16.4492 - mae: 2.2309 - val_loss: 0.2330 - val_mae: 0.3581 - 36ms/epoch - 1ms/step\n",
      "Epoch 3664/5000\n",
      "31/31 - 0s - loss: 1.0765 - mae: 0.7694 - val_loss: 0.1999 - val_mae: 0.3321 - 37ms/epoch - 1ms/step\n",
      "Epoch 3665/5000\n",
      "31/31 - 0s - loss: 4.1970 - mae: 1.5889 - val_loss: 0.1300 - val_mae: 0.3261 - 36ms/epoch - 1ms/step\n",
      "Epoch 3666/5000\n",
      "31/31 - 0s - loss: 7.3322 - mae: 1.0997 - val_loss: 3.8546 - val_mae: 1.9356 - 36ms/epoch - 1ms/step\n",
      "Epoch 3667/5000\n",
      "31/31 - 0s - loss: 15.1467 - mae: 1.5957 - val_loss: 2.8231 - val_mae: 1.6502 - 37ms/epoch - 1ms/step\n",
      "Epoch 3668/5000\n",
      "31/31 - 0s - loss: 1.2968 - mae: 0.7366 - val_loss: 2.9767 - val_mae: 1.6955 - 36ms/epoch - 1ms/step\n",
      "Epoch 3669/5000\n",
      "31/31 - 0s - loss: 29.3820 - mae: 2.1127 - val_loss: 0.3937 - val_mae: 0.5437 - 36ms/epoch - 1ms/step\n",
      "Epoch 3670/5000\n",
      "31/31 - 0s - loss: 1.7010 - mae: 0.9176 - val_loss: 27.7829 - val_mae: 5.2602 - 34ms/epoch - 1ms/step\n",
      "Epoch 3671/5000\n",
      "31/31 - 0s - loss: 4.3409 - mae: 1.1087 - val_loss: 0.2420 - val_mae: 0.4319 - 38ms/epoch - 1ms/step\n",
      "Epoch 3672/5000\n",
      "31/31 - 0s - loss: 17.1093 - mae: 1.7669 - val_loss: 1.2349 - val_mae: 1.0675 - 36ms/epoch - 1ms/step\n",
      "Epoch 3673/5000\n",
      "31/31 - 0s - loss: 1.6135 - mae: 1.0083 - val_loss: 0.5937 - val_mae: 0.7002 - 37ms/epoch - 1ms/step\n",
      "Epoch 3674/5000\n",
      "31/31 - 0s - loss: 19.5154 - mae: 2.2549 - val_loss: 0.5047 - val_mae: 0.6354 - 36ms/epoch - 1ms/step\n",
      "Epoch 3675/5000\n",
      "31/31 - 0s - loss: 0.7412 - mae: 0.6490 - val_loss: 6.5758 - val_mae: 2.5439 - 36ms/epoch - 1ms/step\n",
      "Epoch 3676/5000\n",
      "31/31 - 0s - loss: 1.2504 - mae: 0.8423 - val_loss: 88.8914 - val_mae: 9.4232 - 35ms/epoch - 1ms/step\n",
      "Epoch 3677/5000\n",
      "31/31 - 0s - loss: 13.1660 - mae: 2.3460 - val_loss: 6.8514 - val_mae: 2.5963 - 35ms/epoch - 1ms/step\n",
      "Epoch 3678/5000\n",
      "31/31 - 0s - loss: 10.9104 - mae: 2.2450 - val_loss: 0.1439 - val_mae: 0.2836 - 36ms/epoch - 1ms/step\n",
      "Epoch 3679/5000\n",
      "31/31 - 0s - loss: 0.5705 - mae: 0.6274 - val_loss: 0.6219 - val_mae: 0.7194 - 37ms/epoch - 1ms/step\n",
      "Epoch 3680/5000\n",
      "31/31 - 0s - loss: 33.6783 - mae: 2.2172 - val_loss: 1.7447 - val_mae: 1.2834 - 36ms/epoch - 1ms/step\n",
      "Epoch 3681/5000\n",
      "31/31 - 0s - loss: 2.3408 - mae: 1.2585 - val_loss: 0.1983 - val_mae: 0.4004 - 37ms/epoch - 1ms/step\n",
      "Epoch 3682/5000\n",
      "31/31 - 0s - loss: 1.8069 - mae: 0.9660 - val_loss: 0.1189 - val_mae: 0.3067 - 35ms/epoch - 1ms/step\n",
      "Epoch 3683/5000\n",
      "31/31 - 0s - loss: 15.7300 - mae: 1.9168 - val_loss: 0.1841 - val_mae: 0.3186 - 36ms/epoch - 1ms/step\n",
      "Epoch 3684/5000\n",
      "31/31 - 0s - loss: 0.4803 - mae: 0.4481 - val_loss: 0.1053 - val_mae: 0.2797 - 36ms/epoch - 1ms/step\n",
      "Epoch 3685/5000\n",
      "31/31 - 0s - loss: 12.3743 - mae: 1.5483 - val_loss: 0.2082 - val_mae: 0.3404 - 36ms/epoch - 1ms/step\n",
      "Epoch 3686/5000\n",
      "31/31 - 0s - loss: 5.8849 - mae: 1.9409 - val_loss: 0.9284 - val_mae: 0.9103 - 35ms/epoch - 1ms/step\n",
      "Epoch 3687/5000\n",
      "31/31 - 0s - loss: 1.6333 - mae: 0.9322 - val_loss: 0.4196 - val_mae: 0.5612 - 34ms/epoch - 1ms/step\n",
      "Epoch 3688/5000\n",
      "31/31 - 0s - loss: 20.4487 - mae: 1.9472 - val_loss: 0.8625 - val_mae: 0.8688 - 36ms/epoch - 1ms/step\n",
      "Epoch 3689/5000\n",
      "31/31 - 0s - loss: 0.8757 - mae: 0.5844 - val_loss: 0.2390 - val_mae: 0.4305 - 36ms/epoch - 1ms/step\n",
      "Epoch 3690/5000\n",
      "31/31 - 0s - loss: 15.3007 - mae: 2.0729 - val_loss: 0.2212 - val_mae: 0.3604 - 35ms/epoch - 1ms/step\n",
      "Epoch 3691/5000\n",
      "31/31 - 0s - loss: 2.5564 - mae: 1.3436 - val_loss: 1.3583 - val_mae: 1.1232 - 35ms/epoch - 1ms/step\n",
      "Epoch 3692/5000\n",
      "31/31 - 0s - loss: 13.0106 - mae: 2.1199 - val_loss: 0.2458 - val_mae: 0.3704 - 35ms/epoch - 1ms/step\n",
      "Epoch 3693/5000\n",
      "31/31 - 0s - loss: 1.3000 - mae: 0.9970 - val_loss: 0.1414 - val_mae: 0.2842 - 36ms/epoch - 1ms/step\n",
      "Epoch 3694/5000\n",
      "31/31 - 0s - loss: 6.3042 - mae: 1.7103 - val_loss: 0.6361 - val_mae: 0.7277 - 35ms/epoch - 1ms/step\n",
      "Epoch 3695/5000\n",
      "31/31 - 0s - loss: 11.3616 - mae: 2.0464 - val_loss: 1.1312 - val_mae: 1.0094 - 38ms/epoch - 1ms/step\n",
      "Epoch 3696/5000\n",
      "31/31 - 0s - loss: 2.1976 - mae: 1.2467 - val_loss: 0.4802 - val_mae: 0.6093 - 34ms/epoch - 1ms/step\n",
      "Epoch 3697/5000\n",
      "31/31 - 0s - loss: 19.5381 - mae: 2.0523 - val_loss: 0.4213 - val_mae: 0.5648 - 36ms/epoch - 1ms/step\n",
      "Epoch 3698/5000\n",
      "31/31 - 0s - loss: 1.0263 - mae: 0.8280 - val_loss: 1.9234 - val_mae: 1.3506 - 36ms/epoch - 1ms/step\n",
      "Epoch 3699/5000\n",
      "31/31 - 0s - loss: 14.6311 - mae: 2.0529 - val_loss: 0.4277 - val_mae: 0.5658 - 37ms/epoch - 1ms/step\n",
      "Epoch 3700/5000\n",
      "31/31 - 0s - loss: 0.7178 - mae: 0.6580 - val_loss: 0.4423 - val_mae: 0.5810 - 36ms/epoch - 1ms/step\n",
      "Epoch 3701/5000\n",
      "31/31 - 0s - loss: 16.3915 - mae: 2.1093 - val_loss: 9.2306 - val_mae: 3.0218 - 35ms/epoch - 1ms/step\n",
      "Epoch 3702/5000\n",
      "31/31 - 0s - loss: 2.2792 - mae: 1.2170 - val_loss: 0.2109 - val_mae: 0.3370 - 36ms/epoch - 1ms/step\n",
      "Epoch 3703/5000\n",
      "31/31 - 0s - loss: 3.2598 - mae: 1.0704 - val_loss: 0.4210 - val_mae: 0.5633 - 38ms/epoch - 1ms/step\n",
      "Epoch 3704/5000\n",
      "31/31 - 0s - loss: 7.4883 - mae: 1.6016 - val_loss: 0.1442 - val_mae: 0.2840 - 36ms/epoch - 1ms/step\n",
      "Epoch 3705/5000\n",
      "31/31 - 0s - loss: 2.7358 - mae: 1.1693 - val_loss: 6.5247 - val_mae: 2.5336 - 38ms/epoch - 1ms/step\n",
      "Epoch 3706/5000\n",
      "31/31 - 0s - loss: 4.4777 - mae: 1.3030 - val_loss: 0.1875 - val_mae: 0.3910 - 38ms/epoch - 1ms/step\n",
      "Epoch 3707/5000\n",
      "31/31 - 0s - loss: 17.5372 - mae: 1.8064 - val_loss: 0.6423 - val_mae: 0.7402 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3708/5000\n",
      "31/31 - 0s - loss: 1.6258 - mae: 1.0509 - val_loss: 0.3710 - val_mae: 0.5217 - 37ms/epoch - 1ms/step\n",
      "Epoch 3709/5000\n",
      "31/31 - 0s - loss: 13.1536 - mae: 1.9785 - val_loss: 1.6438 - val_mae: 1.2413 - 35ms/epoch - 1ms/step\n",
      "Epoch 3710/5000\n",
      "31/31 - 0s - loss: 1.8192 - mae: 1.0075 - val_loss: 0.5285 - val_mae: 0.6514 - 35ms/epoch - 1ms/step\n",
      "Epoch 3711/5000\n",
      "31/31 - 0s - loss: 20.4659 - mae: 1.8879 - val_loss: 0.1234 - val_mae: 0.2756 - 36ms/epoch - 1ms/step\n",
      "Epoch 3712/5000\n",
      "31/31 - 0s - loss: 1.2543 - mae: 0.7754 - val_loss: 0.2711 - val_mae: 0.4507 - 35ms/epoch - 1ms/step\n",
      "Epoch 3713/5000\n",
      "31/31 - 0s - loss: 17.2573 - mae: 2.1864 - val_loss: 0.6238 - val_mae: 0.7208 - 37ms/epoch - 1ms/step\n",
      "Epoch 3714/5000\n",
      "31/31 - 0s - loss: 0.8227 - mae: 0.6867 - val_loss: 2.2322 - val_mae: 1.4607 - 37ms/epoch - 1ms/step\n",
      "Epoch 3715/5000\n",
      "31/31 - 0s - loss: 14.9396 - mae: 2.0715 - val_loss: 0.1104 - val_mae: 0.2919 - 37ms/epoch - 1ms/step\n",
      "Epoch 3716/5000\n",
      "31/31 - 0s - loss: 1.1111 - mae: 0.6709 - val_loss: 6.9764 - val_mae: 2.6208 - 36ms/epoch - 1ms/step\n",
      "Epoch 3717/5000\n",
      "31/31 - 0s - loss: 2.0266 - mae: 1.0288 - val_loss: 154.5662 - val_mae: 12.4288 - 36ms/epoch - 1ms/step\n",
      "Epoch 3718/5000\n",
      "31/31 - 0s - loss: 9.0277 - mae: 1.9714 - val_loss: 5.5010 - val_mae: 2.3222 - 35ms/epoch - 1ms/step\n",
      "Epoch 3719/5000\n",
      "31/31 - 0s - loss: 8.6834 - mae: 2.0509 - val_loss: 0.3832 - val_mae: 0.5317 - 36ms/epoch - 1ms/step\n",
      "Epoch 3720/5000\n",
      "31/31 - 0s - loss: 0.8206 - mae: 0.7740 - val_loss: 0.1058 - val_mae: 0.2799 - 36ms/epoch - 1ms/step\n",
      "Epoch 3721/5000\n",
      "31/31 - 0s - loss: 20.7996 - mae: 2.0546 - val_loss: 3.2275 - val_mae: 1.7680 - 36ms/epoch - 1ms/step\n",
      "Epoch 3722/5000\n",
      "31/31 - 0s - loss: 0.9533 - mae: 0.7834 - val_loss: 3.1352 - val_mae: 1.7424 - 37ms/epoch - 1ms/step\n",
      "Epoch 3723/5000\n",
      "31/31 - 0s - loss: 18.4877 - mae: 2.1117 - val_loss: 0.2103 - val_mae: 0.4108 - 36ms/epoch - 1ms/step\n",
      "Epoch 3724/5000\n",
      "31/31 - 0s - loss: 0.8076 - mae: 0.6636 - val_loss: 0.2027 - val_mae: 0.3330 - 36ms/epoch - 1ms/step\n",
      "Epoch 3725/5000\n",
      "31/31 - 0s - loss: 15.1815 - mae: 1.6700 - val_loss: 58.2197 - val_mae: 7.6227 - 36ms/epoch - 1ms/step\n",
      "Epoch 3726/5000\n",
      "31/31 - 0s - loss: 2.5637 - mae: 0.8433 - val_loss: 3.1197 - val_mae: 1.7366 - 37ms/epoch - 1ms/step\n",
      "Epoch 3727/5000\n",
      "31/31 - 0s - loss: 2.5676 - mae: 0.9851 - val_loss: 0.3092 - val_mae: 0.4582 - 37ms/epoch - 1ms/step\n",
      "Epoch 3728/5000\n",
      "31/31 - 0s - loss: 6.1961 - mae: 1.6429 - val_loss: 0.3305 - val_mae: 0.4846 - 35ms/epoch - 1ms/step\n",
      "Epoch 3729/5000\n",
      "31/31 - 0s - loss: 21.2223 - mae: 2.4479 - val_loss: 0.8168 - val_mae: 0.8468 - 37ms/epoch - 1ms/step\n",
      "Epoch 3730/5000\n",
      "31/31 - 0s - loss: 2.6415 - mae: 1.2822 - val_loss: 0.1476 - val_mae: 0.3519 - 37ms/epoch - 1ms/step\n",
      "Epoch 3731/5000\n",
      "31/31 - 0s - loss: 10.2252 - mae: 1.9226 - val_loss: 1.0195 - val_mae: 0.9584 - 39ms/epoch - 1ms/step\n",
      "Epoch 3732/5000\n",
      "31/31 - 0s - loss: 2.5946 - mae: 1.3006 - val_loss: 26.4237 - val_mae: 5.1309 - 36ms/epoch - 1ms/step\n",
      "Epoch 3733/5000\n",
      "31/31 - 0s - loss: 3.4741 - mae: 1.2552 - val_loss: 2.6991 - val_mae: 1.6116 - 37ms/epoch - 1ms/step\n",
      "Epoch 3734/5000\n",
      "31/31 - 0s - loss: 25.2002 - mae: 2.1568 - val_loss: 0.1421 - val_mae: 0.2954 - 37ms/epoch - 1ms/step\n",
      "Epoch 3735/5000\n",
      "31/31 - 0s - loss: 1.1039 - mae: 0.7480 - val_loss: 0.7655 - val_mae: 0.8127 - 37ms/epoch - 1ms/step\n",
      "Epoch 3736/5000\n",
      "31/31 - 0s - loss: 12.5816 - mae: 2.0108 - val_loss: 1.8999 - val_mae: 1.3416 - 37ms/epoch - 1ms/step\n",
      "Epoch 3737/5000\n",
      "31/31 - 0s - loss: 0.5798 - mae: 0.5706 - val_loss: 5.5600 - val_mae: 2.3365 - 37ms/epoch - 1ms/step\n",
      "Epoch 3738/5000\n",
      "31/31 - 0s - loss: 23.0567 - mae: 1.9974 - val_loss: 6.5055 - val_mae: 2.5290 - 38ms/epoch - 1ms/step\n",
      "Epoch 3739/5000\n",
      "31/31 - 0s - loss: 1.9464 - mae: 1.1654 - val_loss: 0.1671 - val_mae: 0.2988 - 38ms/epoch - 1ms/step\n",
      "Epoch 3740/5000\n",
      "31/31 - 0s - loss: 2.3299 - mae: 1.1913 - val_loss: 0.1494 - val_mae: 0.3527 - 48ms/epoch - 2ms/step\n",
      "Epoch 3741/5000\n",
      "31/31 - 0s - loss: 22.5199 - mae: 2.1114 - val_loss: 0.8899 - val_mae: 0.8885 - 36ms/epoch - 1ms/step\n",
      "Epoch 3742/5000\n",
      "31/31 - 0s - loss: 1.0549 - mae: 0.9023 - val_loss: 0.1547 - val_mae: 0.2885 - 36ms/epoch - 1ms/step\n",
      "Epoch 3743/5000\n",
      "31/31 - 0s - loss: 0.5931 - mae: 0.6459 - val_loss: 0.2215 - val_mae: 0.4178 - 35ms/epoch - 1ms/step\n",
      "Epoch 3744/5000\n",
      "31/31 - 0s - loss: 20.1261 - mae: 2.1737 - val_loss: 0.1751 - val_mae: 0.3802 - 36ms/epoch - 1ms/step\n",
      "Epoch 3745/5000\n",
      "31/31 - 0s - loss: 0.9101 - mae: 0.8031 - val_loss: 0.6325 - val_mae: 0.7255 - 36ms/epoch - 1ms/step\n",
      "Epoch 3746/5000\n",
      "31/31 - 0s - loss: 24.4234 - mae: 2.3166 - val_loss: 0.8130 - val_mae: 0.8433 - 36ms/epoch - 1ms/step\n",
      "Epoch 3747/5000\n",
      "31/31 - 0s - loss: 1.3433 - mae: 0.9842 - val_loss: 1.8919 - val_mae: 1.3356 - 34ms/epoch - 1ms/step\n",
      "Epoch 3748/5000\n",
      "31/31 - 0s - loss: 23.0008 - mae: 2.3437 - val_loss: 0.1062 - val_mae: 0.2786 - 35ms/epoch - 1ms/step\n",
      "Epoch 3749/5000\n",
      "31/31 - 0s - loss: 1.8307 - mae: 0.9291 - val_loss: 0.1096 - val_mae: 0.2870 - 36ms/epoch - 1ms/step\n",
      "Epoch 3750/5000\n",
      "31/31 - 0s - loss: 1.6205 - mae: 0.7492 - val_loss: 1.0941 - val_mae: 0.9915 - 38ms/epoch - 1ms/step\n",
      "Epoch 3751/5000\n",
      "31/31 - 0s - loss: 6.1098 - mae: 1.5705 - val_loss: 4.3121 - val_mae: 2.0501 - 36ms/epoch - 1ms/step\n",
      "Epoch 3752/5000\n",
      "31/31 - 0s - loss: 15.9479 - mae: 2.0809 - val_loss: 0.3253 - val_mae: 0.4815 - 36ms/epoch - 1ms/step\n",
      "Epoch 3753/5000\n",
      "31/31 - 0s - loss: 1.4532 - mae: 1.0480 - val_loss: 0.3000 - val_mae: 0.4683 - 37ms/epoch - 1ms/step\n",
      "Epoch 3754/5000\n",
      "31/31 - 0s - loss: 7.5019 - mae: 1.6867 - val_loss: 0.1807 - val_mae: 0.3858 - 37ms/epoch - 1ms/step\n",
      "Epoch 3755/5000\n",
      "31/31 - 0s - loss: 0.6511 - mae: 0.5709 - val_loss: 0.3301 - val_mae: 0.4848 - 36ms/epoch - 1ms/step\n",
      "Epoch 3756/5000\n",
      "31/31 - 0s - loss: 23.0696 - mae: 2.0170 - val_loss: 0.1607 - val_mae: 0.2959 - 35ms/epoch - 1ms/step\n",
      "Epoch 3757/5000\n",
      "31/31 - 0s - loss: 1.5181 - mae: 0.8552 - val_loss: 0.2836 - val_mae: 0.4590 - 39ms/epoch - 1ms/step\n",
      "Epoch 3758/5000\n",
      "31/31 - 0s - loss: 12.6248 - mae: 2.2245 - val_loss: 1.0361 - val_mae: 0.9655 - 36ms/epoch - 1ms/step\n",
      "Epoch 3759/5000\n",
      "31/31 - 0s - loss: 1.9638 - mae: 1.1529 - val_loss: 6.8734 - val_mae: 2.6020 - 36ms/epoch - 1ms/step\n",
      "Epoch 3760/5000\n",
      "31/31 - 0s - loss: 10.4903 - mae: 1.5847 - val_loss: 1.7867 - val_mae: 1.2983 - 35ms/epoch - 1ms/step\n",
      "Epoch 3761/5000\n",
      "31/31 - 0s - loss: 13.7417 - mae: 2.0920 - val_loss: 0.8517 - val_mae: 0.8665 - 36ms/epoch - 1ms/step\n",
      "Epoch 3762/5000\n",
      "31/31 - 0s - loss: 0.8380 - mae: 0.7234 - val_loss: 0.2460 - val_mae: 0.3773 - 37ms/epoch - 1ms/step\n",
      "Epoch 3763/5000\n",
      "31/31 - 0s - loss: 8.7226 - mae: 1.7544 - val_loss: 2.2589 - val_mae: 1.4718 - 35ms/epoch - 1ms/step\n",
      "Epoch 3764/5000\n",
      "31/31 - 0s - loss: 3.3377 - mae: 1.2207 - val_loss: 1.5977 - val_mae: 1.2233 - 38ms/epoch - 1ms/step\n",
      "Epoch 3765/5000\n",
      "31/31 - 0s - loss: 11.4983 - mae: 1.9774 - val_loss: 4.5695 - val_mae: 2.1150 - 39ms/epoch - 1ms/step\n",
      "Epoch 3766/5000\n",
      "31/31 - 0s - loss: 0.7795 - mae: 0.6544 - val_loss: 1.4760 - val_mae: 1.1716 - 38ms/epoch - 1ms/step\n",
      "Epoch 3767/5000\n",
      "31/31 - 0s - loss: 26.6973 - mae: 2.1217 - val_loss: 0.8474 - val_mae: 0.8660 - 36ms/epoch - 1ms/step\n",
      "Epoch 3768/5000\n",
      "31/31 - 0s - loss: 1.4287 - mae: 0.9082 - val_loss: 2.5773 - val_mae: 1.5731 - 36ms/epoch - 1ms/step\n",
      "Epoch 3769/5000\n",
      "31/31 - 0s - loss: 25.3523 - mae: 2.3589 - val_loss: 0.9879 - val_mae: 0.9398 - 35ms/epoch - 1ms/step\n",
      "Epoch 3770/5000\n",
      "31/31 - 0s - loss: 1.3718 - mae: 0.9527 - val_loss: 6.5801 - val_mae: 2.5456 - 36ms/epoch - 1ms/step\n",
      "Epoch 3771/5000\n",
      "31/31 - 0s - loss: 15.2221 - mae: 2.0215 - val_loss: 0.9978 - val_mae: 0.9459 - 37ms/epoch - 1ms/step\n",
      "Epoch 3772/5000\n",
      "31/31 - 0s - loss: 1.7115 - mae: 1.0582 - val_loss: 0.1652 - val_mae: 0.3016 - 36ms/epoch - 1ms/step\n",
      "Epoch 3773/5000\n",
      "31/31 - 0s - loss: 2.5208 - mae: 1.2464 - val_loss: 0.2649 - val_mae: 0.4016 - 36ms/epoch - 1ms/step\n",
      "Epoch 3774/5000\n",
      "31/31 - 0s - loss: 18.3312 - mae: 2.0031 - val_loss: 0.4013 - val_mae: 0.5381 - 35ms/epoch - 1ms/step\n",
      "Epoch 3775/5000\n",
      "31/31 - 0s - loss: 1.4710 - mae: 0.8365 - val_loss: 0.1712 - val_mae: 0.3052 - 36ms/epoch - 1ms/step\n",
      "Epoch 3776/5000\n",
      "31/31 - 0s - loss: 19.3989 - mae: 2.2909 - val_loss: 0.4348 - val_mae: 0.5742 - 39ms/epoch - 1ms/step\n",
      "Epoch 3777/5000\n",
      "31/31 - 0s - loss: 1.3926 - mae: 1.0197 - val_loss: 0.9788 - val_mae: 0.9337 - 38ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3778/5000\n",
      "31/31 - 0s - loss: 10.4465 - mae: 1.9669 - val_loss: 7.6602 - val_mae: 2.7491 - 35ms/epoch - 1ms/step\n",
      "Epoch 3779/5000\n",
      "31/31 - 0s - loss: 1.1093 - mae: 0.9104 - val_loss: 3.1829 - val_mae: 1.7555 - 39ms/epoch - 1ms/step\n",
      "Epoch 3780/5000\n",
      "31/31 - 0s - loss: 20.9976 - mae: 2.1817 - val_loss: 0.3265 - val_mae: 0.4743 - 36ms/epoch - 1ms/step\n",
      "Epoch 3781/5000\n",
      "31/31 - 0s - loss: 1.7819 - mae: 1.0272 - val_loss: 0.1104 - val_mae: 0.2906 - 36ms/epoch - 1ms/step\n",
      "Epoch 3782/5000\n",
      "31/31 - 0s - loss: 25.4053 - mae: 2.3230 - val_loss: 0.1894 - val_mae: 0.3192 - 34ms/epoch - 1ms/step\n",
      "Epoch 3783/5000\n",
      "31/31 - 0s - loss: 1.4911 - mae: 0.9428 - val_loss: 0.6183 - val_mae: 0.7178 - 37ms/epoch - 1ms/step\n",
      "Epoch 3784/5000\n",
      "31/31 - 0s - loss: 3.6318 - mae: 1.1470 - val_loss: 0.5292 - val_mae: 0.6538 - 36ms/epoch - 1ms/step\n",
      "Epoch 3785/5000\n",
      "31/31 - 0s - loss: 9.1933 - mae: 1.5296 - val_loss: 0.1863 - val_mae: 0.3216 - 37ms/epoch - 1ms/step\n",
      "Epoch 3786/5000\n",
      "31/31 - 0s - loss: 1.9144 - mae: 1.0845 - val_loss: 0.5585 - val_mae: 0.6714 - 36ms/epoch - 1ms/step\n",
      "Epoch 3787/5000\n",
      "31/31 - 0s - loss: 13.7871 - mae: 1.7960 - val_loss: 0.2462 - val_mae: 0.4350 - 36ms/epoch - 1ms/step\n",
      "Epoch 3788/5000\n",
      "31/31 - 0s - loss: 4.3204 - mae: 1.3764 - val_loss: 5.8006 - val_mae: 2.3857 - 37ms/epoch - 1ms/step\n",
      "Epoch 3789/5000\n",
      "31/31 - 0s - loss: 18.8147 - mae: 2.3044 - val_loss: 0.3131 - val_mae: 0.4595 - 35ms/epoch - 1ms/step\n",
      "Epoch 3790/5000\n",
      "31/31 - 0s - loss: 1.6555 - mae: 0.9961 - val_loss: 0.5952 - val_mae: 0.6981 - 38ms/epoch - 1ms/step\n",
      "Epoch 3791/5000\n",
      "31/31 - 0s - loss: 12.4902 - mae: 1.9048 - val_loss: 0.1268 - val_mae: 0.3181 - 38ms/epoch - 1ms/step\n",
      "Epoch 3792/5000\n",
      "31/31 - 0s - loss: 2.0618 - mae: 1.1972 - val_loss: 9.5918 - val_mae: 3.0795 - 35ms/epoch - 1ms/step\n",
      "Epoch 3793/5000\n",
      "31/31 - 0s - loss: 7.8505 - mae: 1.8842 - val_loss: 10.3376 - val_mae: 3.1981 - 35ms/epoch - 1ms/step\n",
      "Epoch 3794/5000\n",
      "31/31 - 0s - loss: 2.7440 - mae: 1.2551 - val_loss: 0.1397 - val_mae: 0.2862 - 34ms/epoch - 1ms/step\n",
      "Epoch 3795/5000\n",
      "31/31 - 0s - loss: 16.7286 - mae: 2.0314 - val_loss: 0.1719 - val_mae: 0.3063 - 37ms/epoch - 1ms/step\n",
      "Epoch 3796/5000\n",
      "31/31 - 0s - loss: 1.0187 - mae: 0.8474 - val_loss: 6.4370 - val_mae: 2.5173 - 36ms/epoch - 1ms/step\n",
      "Epoch 3797/5000\n",
      "31/31 - 0s - loss: 6.6825 - mae: 1.8742 - val_loss: 5.4002 - val_mae: 2.3024 - 36ms/epoch - 1ms/step\n",
      "Epoch 3798/5000\n",
      "31/31 - 0s - loss: 4.6698 - mae: 1.1739 - val_loss: 783.6424 - val_mae: 27.9922 - 36ms/epoch - 1ms/step\n",
      "Epoch 3799/5000\n",
      "31/31 - 0s - loss: 26.8998 - mae: 1.8389 - val_loss: 12.0989 - val_mae: 3.4638 - 36ms/epoch - 1ms/step\n",
      "Epoch 3800/5000\n",
      "31/31 - 0s - loss: 1.6779 - mae: 1.0446 - val_loss: 6.7534 - val_mae: 2.5785 - 36ms/epoch - 1ms/step\n",
      "Epoch 3801/5000\n",
      "31/31 - 0s - loss: 1.4840 - mae: 0.8425 - val_loss: 75.8040 - val_mae: 8.7015 - 37ms/epoch - 1ms/step\n",
      "Epoch 3802/5000\n",
      "31/31 - 0s - loss: 5.7603 - mae: 1.5136 - val_loss: 0.1073 - val_mae: 0.2800 - 37ms/epoch - 1ms/step\n",
      "Epoch 3803/5000\n",
      "31/31 - 0s - loss: 44.1315 - mae: 2.1302 - val_loss: 1.0680 - val_mae: 0.9834 - 36ms/epoch - 1ms/step\n",
      "Epoch 3804/5000\n",
      "31/31 - 0s - loss: 1.9618 - mae: 1.0697 - val_loss: 2.1975 - val_mae: 1.4479 - 36ms/epoch - 1ms/step\n",
      "Epoch 3805/5000\n",
      "31/31 - 0s - loss: 1.3038 - mae: 0.9253 - val_loss: 0.1057 - val_mae: 0.2842 - 35ms/epoch - 1ms/step\n",
      "Epoch 3806/5000\n",
      "31/31 - 0s - loss: 16.9941 - mae: 2.0527 - val_loss: 4.3345 - val_mae: 2.0574 - 36ms/epoch - 1ms/step\n",
      "Epoch 3807/5000\n",
      "31/31 - 0s - loss: 1.3692 - mae: 0.9617 - val_loss: 0.1119 - val_mae: 0.2816 - 35ms/epoch - 1ms/step\n",
      "Epoch 3808/5000\n",
      "31/31 - 0s - loss: 13.5276 - mae: 1.5330 - val_loss: 33.8012 - val_mae: 5.8045 - 36ms/epoch - 1ms/step\n",
      "Epoch 3809/5000\n",
      "31/31 - 0s - loss: 4.1870 - mae: 1.0452 - val_loss: 0.1575 - val_mae: 0.3614 - 36ms/epoch - 1ms/step\n",
      "Epoch 3810/5000\n",
      "31/31 - 0s - loss: 15.7401 - mae: 2.0777 - val_loss: 0.3264 - val_mae: 0.4683 - 37ms/epoch - 1ms/step\n",
      "Epoch 3811/5000\n",
      "31/31 - 0s - loss: 0.9831 - mae: 0.8479 - val_loss: 3.6798 - val_mae: 1.8915 - 36ms/epoch - 1ms/step\n",
      "Epoch 3812/5000\n",
      "31/31 - 0s - loss: 12.9291 - mae: 1.9204 - val_loss: 0.4141 - val_mae: 0.5548 - 36ms/epoch - 1ms/step\n",
      "Epoch 3813/5000\n",
      "31/31 - 0s - loss: 2.0752 - mae: 1.1560 - val_loss: 3.6420 - val_mae: 1.8807 - 37ms/epoch - 1ms/step\n",
      "Epoch 3814/5000\n",
      "31/31 - 0s - loss: 15.6967 - mae: 2.0348 - val_loss: 0.1134 - val_mae: 0.2910 - 38ms/epoch - 1ms/step\n",
      "Epoch 3815/5000\n",
      "31/31 - 0s - loss: 1.4750 - mae: 1.0115 - val_loss: 5.7158 - val_mae: 2.3690 - 35ms/epoch - 1ms/step\n",
      "Epoch 3816/5000\n",
      "31/31 - 0s - loss: 5.6716 - mae: 1.5903 - val_loss: 0.5580 - val_mae: 0.6737 - 36ms/epoch - 1ms/step\n",
      "Epoch 3817/5000\n",
      "31/31 - 0s - loss: 8.4803 - mae: 1.6270 - val_loss: 0.4929 - val_mae: 0.6269 - 36ms/epoch - 1ms/step\n",
      "Epoch 3818/5000\n",
      "31/31 - 0s - loss: 1.1852 - mae: 0.8277 - val_loss: 3.2722 - val_mae: 1.7812 - 37ms/epoch - 1ms/step\n",
      "Epoch 3819/5000\n",
      "31/31 - 0s - loss: 13.2720 - mae: 2.1180 - val_loss: 0.1086 - val_mae: 0.2746 - 35ms/epoch - 1ms/step\n",
      "Epoch 3820/5000\n",
      "31/31 - 0s - loss: 1.8792 - mae: 0.9622 - val_loss: 3.8895 - val_mae: 1.9443 - 37ms/epoch - 1ms/step\n",
      "Epoch 3821/5000\n",
      "31/31 - 0s - loss: 7.8660 - mae: 1.7252 - val_loss: 0.3669 - val_mae: 0.5142 - 36ms/epoch - 1ms/step\n",
      "Epoch 3822/5000\n",
      "31/31 - 0s - loss: 19.6569 - mae: 2.2285 - val_loss: 0.1998 - val_mae: 0.4002 - 36ms/epoch - 1ms/step\n",
      "Epoch 3823/5000\n",
      "31/31 - 0s - loss: 1.7470 - mae: 0.9049 - val_loss: 0.6785 - val_mae: 0.7618 - 37ms/epoch - 1ms/step\n",
      "Epoch 3824/5000\n",
      "31/31 - 0s - loss: 5.4353 - mae: 1.5278 - val_loss: 0.4096 - val_mae: 0.5517 - 36ms/epoch - 1ms/step\n",
      "Epoch 3825/5000\n",
      "31/31 - 0s - loss: 26.4543 - mae: 2.4242 - val_loss: 0.1054 - val_mae: 0.2831 - 36ms/epoch - 1ms/step\n",
      "Epoch 3826/5000\n",
      "31/31 - 0s - loss: 1.2197 - mae: 0.7618 - val_loss: 0.1322 - val_mae: 0.3292 - 38ms/epoch - 1ms/step\n",
      "Epoch 3827/5000\n",
      "31/31 - 0s - loss: 0.9702 - mae: 0.7954 - val_loss: 0.1061 - val_mae: 0.2832 - 35ms/epoch - 1ms/step\n",
      "Epoch 3828/5000\n",
      "31/31 - 0s - loss: 24.2765 - mae: 2.1580 - val_loss: 0.8629 - val_mae: 0.8688 - 35ms/epoch - 1ms/step\n",
      "Epoch 3829/5000\n",
      "31/31 - 0s - loss: 2.1844 - mae: 1.1679 - val_loss: 0.2119 - val_mae: 0.3440 - 36ms/epoch - 1ms/step\n",
      "Epoch 3830/5000\n",
      "31/31 - 0s - loss: 11.3233 - mae: 1.8891 - val_loss: 0.2924 - val_mae: 0.4347 - 36ms/epoch - 1ms/step\n",
      "Epoch 3831/5000\n",
      "31/31 - 0s - loss: 1.3782 - mae: 0.9946 - val_loss: 0.4718 - val_mae: 0.6082 - 36ms/epoch - 1ms/step\n",
      "Epoch 3832/5000\n",
      "31/31 - 0s - loss: 19.8220 - mae: 2.1588 - val_loss: 0.2219 - val_mae: 0.3539 - 35ms/epoch - 1ms/step\n",
      "Epoch 3833/5000\n",
      "31/31 - 0s - loss: 1.9100 - mae: 1.0105 - val_loss: 0.1782 - val_mae: 0.3157 - 37ms/epoch - 1ms/step\n",
      "Epoch 3834/5000\n",
      "31/31 - 0s - loss: 0.9540 - mae: 0.7441 - val_loss: 0.4617 - val_mae: 0.6007 - 36ms/epoch - 1ms/step\n",
      "Epoch 3835/5000\n",
      "31/31 - 0s - loss: 18.7544 - mae: 1.9376 - val_loss: 0.8957 - val_mae: 0.8888 - 38ms/epoch - 1ms/step\n",
      "Epoch 3836/5000\n",
      "31/31 - 0s - loss: 0.9772 - mae: 0.7452 - val_loss: 1.3067 - val_mae: 1.0981 - 35ms/epoch - 1ms/step\n",
      "Epoch 3837/5000\n",
      "31/31 - 0s - loss: 20.2144 - mae: 2.1380 - val_loss: 0.4690 - val_mae: 0.6018 - 36ms/epoch - 1ms/step\n",
      "Epoch 3838/5000\n",
      "31/31 - 0s - loss: 1.4872 - mae: 0.9628 - val_loss: 0.3024 - val_mae: 0.4466 - 37ms/epoch - 1ms/step\n",
      "Epoch 3839/5000\n",
      "31/31 - 0s - loss: 13.4722 - mae: 1.7389 - val_loss: 1.0688 - val_mae: 0.9780 - 46ms/epoch - 1ms/step\n",
      "Epoch 3840/5000\n",
      "31/31 - 0s - loss: 2.2060 - mae: 1.1866 - val_loss: 0.9639 - val_mae: 0.9266 - 38ms/epoch - 1ms/step\n",
      "Epoch 3841/5000\n",
      "31/31 - 0s - loss: 7.4530 - mae: 1.3190 - val_loss: 24.8312 - val_mae: 4.9738 - 35ms/epoch - 1ms/step\n",
      "Epoch 3842/5000\n",
      "31/31 - 0s - loss: 11.3277 - mae: 1.6672 - val_loss: 2.0251 - val_mae: 1.3869 - 36ms/epoch - 1ms/step\n",
      "Epoch 3843/5000\n",
      "31/31 - 0s - loss: 1.1747 - mae: 0.8698 - val_loss: 2.2544 - val_mae: 1.4677 - 39ms/epoch - 1ms/step\n",
      "Epoch 3844/5000\n",
      "31/31 - 0s - loss: 9.0819 - mae: 1.9979 - val_loss: 3.5391 - val_mae: 1.8524 - 37ms/epoch - 1ms/step\n",
      "Epoch 3845/5000\n",
      "31/31 - 0s - loss: 7.7826 - mae: 1.6945 - val_loss: 59.2155 - val_mae: 7.6892 - 34ms/epoch - 1ms/step\n",
      "Epoch 3846/5000\n",
      "31/31 - 0s - loss: 3.3417 - mae: 1.2598 - val_loss: 0.3007 - val_mae: 0.4673 - 35ms/epoch - 1ms/step\n",
      "Epoch 3847/5000\n",
      "31/31 - 0s - loss: 11.7688 - mae: 2.3461 - val_loss: 0.1179 - val_mae: 0.3127 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3848/5000\n",
      "31/31 - 0s - loss: 3.3746 - mae: 1.2954 - val_loss: 1.0676 - val_mae: 0.9817 - 37ms/epoch - 1ms/step\n",
      "Epoch 3849/5000\n",
      "31/31 - 0s - loss: 19.5448 - mae: 1.6733 - val_loss: 210.6885 - val_mae: 14.5119 - 35ms/epoch - 1ms/step\n",
      "Epoch 3850/5000\n",
      "31/31 - 0s - loss: 8.6785 - mae: 1.3355 - val_loss: 10.0666 - val_mae: 3.1570 - 37ms/epoch - 1ms/step\n",
      "Epoch 3851/5000\n",
      "31/31 - 0s - loss: 1.0981 - mae: 0.8814 - val_loss: 0.2782 - val_mae: 0.4215 - 36ms/epoch - 1ms/step\n",
      "Epoch 3852/5000\n",
      "31/31 - 0s - loss: 6.2331 - mae: 1.7997 - val_loss: 0.6620 - val_mae: 0.7461 - 37ms/epoch - 1ms/step\n",
      "Epoch 3853/5000\n",
      "31/31 - 0s - loss: 10.1264 - mae: 2.2228 - val_loss: 5.5356 - val_mae: 2.3311 - 38ms/epoch - 1ms/step\n",
      "Epoch 3854/5000\n",
      "31/31 - 0s - loss: 4.0040 - mae: 1.6064 - val_loss: 0.1885 - val_mae: 0.3914 - 36ms/epoch - 1ms/step\n",
      "Epoch 3855/5000\n",
      "31/31 - 0s - loss: 4.7017 - mae: 1.0657 - val_loss: 16.0633 - val_mae: 3.9963 - 36ms/epoch - 1ms/step\n",
      "Epoch 3856/5000\n",
      "31/31 - 0s - loss: 14.9031 - mae: 2.2787 - val_loss: 0.3849 - val_mae: 0.5369 - 36ms/epoch - 1ms/step\n",
      "Epoch 3857/5000\n",
      "31/31 - 0s - loss: 7.2531 - mae: 1.9072 - val_loss: 0.1493 - val_mae: 0.2804 - 35ms/epoch - 1ms/step\n",
      "Epoch 3858/5000\n",
      "31/31 - 0s - loss: 0.6371 - mae: 0.6053 - val_loss: 2.5845 - val_mae: 1.5761 - 37ms/epoch - 1ms/step\n",
      "Epoch 3859/5000\n",
      "31/31 - 0s - loss: 35.0703 - mae: 2.1739 - val_loss: 0.2110 - val_mae: 0.4101 - 36ms/epoch - 1ms/step\n",
      "Epoch 3860/5000\n",
      "31/31 - 0s - loss: 2.5138 - mae: 1.2321 - val_loss: 1.3706 - val_mae: 1.1246 - 36ms/epoch - 1ms/step\n",
      "Epoch 3861/5000\n",
      "31/31 - 0s - loss: 8.6325 - mae: 1.9209 - val_loss: 0.1816 - val_mae: 0.3141 - 36ms/epoch - 1ms/step\n",
      "Epoch 3862/5000\n",
      "31/31 - 0s - loss: 0.9469 - mae: 0.6856 - val_loss: 0.2332 - val_mae: 0.3623 - 37ms/epoch - 1ms/step\n",
      "Epoch 3863/5000\n",
      "31/31 - 0s - loss: 21.8399 - mae: 2.0780 - val_loss: 1.6958 - val_mae: 1.2592 - 36ms/epoch - 1ms/step\n",
      "Epoch 3864/5000\n",
      "31/31 - 0s - loss: 2.3930 - mae: 1.1756 - val_loss: 0.1104 - val_mae: 0.2823 - 39ms/epoch - 1ms/step\n",
      "Epoch 3865/5000\n",
      "31/31 - 0s - loss: 13.9324 - mae: 1.9528 - val_loss: 0.1563 - val_mae: 0.2907 - 35ms/epoch - 1ms/step\n",
      "Epoch 3866/5000\n",
      "31/31 - 0s - loss: 1.1613 - mae: 0.7602 - val_loss: 2.5789 - val_mae: 1.5744 - 35ms/epoch - 1ms/step\n",
      "Epoch 3867/5000\n",
      "31/31 - 0s - loss: 14.6087 - mae: 2.0696 - val_loss: 1.4718 - val_mae: 1.1720 - 37ms/epoch - 1ms/step\n",
      "Epoch 3868/5000\n",
      "31/31 - 0s - loss: 0.5080 - mae: 0.5309 - val_loss: 0.2849 - val_mae: 0.4582 - 39ms/epoch - 1ms/step\n",
      "Epoch 3869/5000\n",
      "31/31 - 0s - loss: 14.0656 - mae: 2.0164 - val_loss: 4.3179 - val_mae: 2.0545 - 37ms/epoch - 1ms/step\n",
      "Epoch 3870/5000\n",
      "31/31 - 0s - loss: 2.0332 - mae: 1.1942 - val_loss: 2.5512 - val_mae: 1.5661 - 36ms/epoch - 1ms/step\n",
      "Epoch 3871/5000\n",
      "31/31 - 0s - loss: 5.9693 - mae: 1.3205 - val_loss: 2.5716 - val_mae: 1.5738 - 37ms/epoch - 1ms/step\n",
      "Epoch 3872/5000\n",
      "31/31 - 0s - loss: 11.2457 - mae: 1.7142 - val_loss: 0.4524 - val_mae: 0.5913 - 37ms/epoch - 1ms/step\n",
      "Epoch 3873/5000\n",
      "31/31 - 0s - loss: 0.9153 - mae: 0.7897 - val_loss: 1.0752 - val_mae: 0.9887 - 39ms/epoch - 1ms/step\n",
      "Epoch 3874/5000\n",
      "31/31 - 0s - loss: 17.7669 - mae: 2.2280 - val_loss: 1.7058 - val_mae: 1.2679 - 38ms/epoch - 1ms/step\n",
      "Epoch 3875/5000\n",
      "31/31 - 0s - loss: 2.0235 - mae: 1.1351 - val_loss: 139.8978 - val_mae: 11.8239 - 33ms/epoch - 1ms/step\n",
      "Epoch 3876/5000\n",
      "31/31 - 0s - loss: 14.0024 - mae: 1.7777 - val_loss: 0.7695 - val_mae: 0.8182 - 36ms/epoch - 1ms/step\n",
      "Epoch 3877/5000\n",
      "31/31 - 0s - loss: 0.8107 - mae: 0.6662 - val_loss: 1.3231 - val_mae: 1.1069 - 36ms/epoch - 1ms/step\n",
      "Epoch 3878/5000\n",
      "31/31 - 0s - loss: 19.6801 - mae: 1.9544 - val_loss: 0.5059 - val_mae: 0.6349 - 40ms/epoch - 1ms/step\n",
      "Epoch 3879/5000\n",
      "31/31 - 0s - loss: 1.6499 - mae: 1.1022 - val_loss: 0.3090 - val_mae: 0.4537 - 39ms/epoch - 1ms/step\n",
      "Epoch 3880/5000\n",
      "31/31 - 0s - loss: 17.8825 - mae: 2.0164 - val_loss: 0.2381 - val_mae: 0.4297 - 44ms/epoch - 1ms/step\n",
      "Epoch 3881/5000\n",
      "31/31 - 0s - loss: 1.1468 - mae: 0.8768 - val_loss: 0.7253 - val_mae: 0.7903 - 35ms/epoch - 1ms/step\n",
      "Epoch 3882/5000\n",
      "31/31 - 0s - loss: 9.9565 - mae: 1.6859 - val_loss: 7.7386 - val_mae: 2.7650 - 42ms/epoch - 1ms/step\n",
      "Epoch 3883/5000\n",
      "31/31 - 0s - loss: 2.7739 - mae: 1.2796 - val_loss: 9.6306 - val_mae: 3.0881 - 38ms/epoch - 1ms/step\n",
      "Epoch 3884/5000\n",
      "31/31 - 0s - loss: 23.4070 - mae: 2.3306 - val_loss: 0.0995 - val_mae: 0.2731 - 41ms/epoch - 1ms/step\n",
      "Epoch 3885/5000\n",
      "31/31 - 0s - loss: 1.4517 - mae: 0.8443 - val_loss: 0.3535 - val_mae: 0.5039 - 45ms/epoch - 1ms/step\n",
      "Epoch 3886/5000\n",
      "31/31 - 0s - loss: 0.5996 - mae: 0.6359 - val_loss: 3.8938 - val_mae: 1.9488 - 40ms/epoch - 1ms/step\n",
      "Epoch 3887/5000\n",
      "31/31 - 0s - loss: 17.5494 - mae: 2.8509 - val_loss: 0.2089 - val_mae: 0.3355 - 40ms/epoch - 1ms/step\n",
      "Epoch 3888/5000\n",
      "31/31 - 0s - loss: 2.0298 - mae: 1.1047 - val_loss: 26.8313 - val_mae: 5.1708 - 42ms/epoch - 1ms/step\n",
      "Epoch 3889/5000\n",
      "31/31 - 0s - loss: 13.8537 - mae: 1.9809 - val_loss: 0.6821 - val_mae: 0.7617 - 41ms/epoch - 1ms/step\n",
      "Epoch 3890/5000\n",
      "31/31 - 0s - loss: 0.5305 - mae: 0.5942 - val_loss: 2.2386 - val_mae: 1.4617 - 42ms/epoch - 1ms/step\n",
      "Epoch 3891/5000\n",
      "31/31 - 0s - loss: 18.1228 - mae: 2.0890 - val_loss: 0.5883 - val_mae: 0.6924 - 50ms/epoch - 2ms/step\n",
      "Epoch 3892/5000\n",
      "31/31 - 0s - loss: 1.6868 - mae: 0.9946 - val_loss: 2.6356 - val_mae: 1.5919 - 53ms/epoch - 2ms/step\n",
      "Epoch 3893/5000\n",
      "31/31 - 0s - loss: 18.2410 - mae: 2.4944 - val_loss: 0.2610 - val_mae: 0.4053 - 43ms/epoch - 1ms/step\n",
      "Epoch 3894/5000\n",
      "31/31 - 0s - loss: 0.8926 - mae: 0.6777 - val_loss: 4.7412 - val_mae: 2.1544 - 41ms/epoch - 1ms/step\n",
      "Epoch 3895/5000\n",
      "31/31 - 0s - loss: 11.7353 - mae: 2.2215 - val_loss: 6.5100 - val_mae: 2.5325 - 41ms/epoch - 1ms/step\n",
      "Epoch 3896/5000\n",
      "31/31 - 0s - loss: 1.9985 - mae: 0.9786 - val_loss: 12.5159 - val_mae: 3.5239 - 45ms/epoch - 1ms/step\n",
      "Epoch 3897/5000\n",
      "31/31 - 0s - loss: 17.9531 - mae: 2.0530 - val_loss: 0.2567 - val_mae: 0.3971 - 40ms/epoch - 1ms/step\n",
      "Epoch 3898/5000\n",
      "31/31 - 0s - loss: 1.0241 - mae: 0.7786 - val_loss: 0.3918 - val_mae: 0.5358 - 45ms/epoch - 1ms/step\n",
      "Epoch 3899/5000\n",
      "31/31 - 0s - loss: 12.2489 - mae: 1.9414 - val_loss: 0.5965 - val_mae: 0.7029 - 44ms/epoch - 1ms/step\n",
      "Epoch 3900/5000\n",
      "31/31 - 0s - loss: 4.7620 - mae: 1.5588 - val_loss: 82.9638 - val_mae: 9.1023 - 43ms/epoch - 1ms/step\n",
      "Epoch 3901/5000\n",
      "31/31 - 0s - loss: 5.4360 - mae: 1.5670 - val_loss: 3.9398 - val_mae: 1.9586 - 50ms/epoch - 2ms/step\n",
      "Epoch 3902/5000\n",
      "31/31 - 0s - loss: 10.4263 - mae: 1.9116 - val_loss: 5.2097 - val_mae: 2.2577 - 50ms/epoch - 2ms/step\n",
      "Epoch 3903/5000\n",
      "31/31 - 0s - loss: 2.4336 - mae: 1.3003 - val_loss: 1.0506 - val_mae: 0.9725 - 41ms/epoch - 1ms/step\n",
      "Epoch 3904/5000\n",
      "31/31 - 0s - loss: 21.3432 - mae: 2.3975 - val_loss: 1.4803 - val_mae: 1.1726 - 54ms/epoch - 2ms/step\n",
      "Epoch 3905/5000\n",
      "31/31 - 0s - loss: 1.0090 - mae: 0.8644 - val_loss: 0.8257 - val_mae: 0.8493 - 44ms/epoch - 1ms/step\n",
      "Epoch 3906/5000\n",
      "31/31 - 0s - loss: 11.5763 - mae: 2.0837 - val_loss: 9.1167 - val_mae: 3.0012 - 43ms/epoch - 1ms/step\n",
      "Epoch 3907/5000\n",
      "31/31 - 0s - loss: 3.0879 - mae: 1.5283 - val_loss: 0.2486 - val_mae: 0.3763 - 38ms/epoch - 1ms/step\n",
      "Epoch 3908/5000\n",
      "31/31 - 0s - loss: 20.4339 - mae: 2.2378 - val_loss: 0.7423 - val_mae: 0.7972 - 39ms/epoch - 1ms/step\n",
      "Epoch 3909/5000\n",
      "31/31 - 0s - loss: 1.7850 - mae: 1.0136 - val_loss: 1.6712 - val_mae: 1.2531 - 38ms/epoch - 1ms/step\n",
      "Epoch 3910/5000\n",
      "31/31 - 0s - loss: 13.4030 - mae: 1.8831 - val_loss: 5.7208 - val_mae: 2.3709 - 37ms/epoch - 1ms/step\n",
      "Epoch 3911/5000\n",
      "31/31 - 0s - loss: 2.0330 - mae: 1.1872 - val_loss: 0.1238 - val_mae: 0.2824 - 36ms/epoch - 1ms/step\n",
      "Epoch 3912/5000\n",
      "31/31 - 0s - loss: 20.7331 - mae: 2.3173 - val_loss: 0.3328 - val_mae: 0.4814 - 38ms/epoch - 1ms/step\n",
      "Epoch 3913/5000\n",
      "31/31 - 0s - loss: 1.7300 - mae: 1.0638 - val_loss: 0.8752 - val_mae: 0.8751 - 39ms/epoch - 1ms/step\n",
      "Epoch 3914/5000\n",
      "31/31 - 0s - loss: 8.6329 - mae: 2.0027 - val_loss: 63.9447 - val_mae: 7.9908 - 40ms/epoch - 1ms/step\n",
      "Epoch 3915/5000\n",
      "31/31 - 0s - loss: 3.3085 - mae: 1.1281 - val_loss: 0.1550 - val_mae: 0.3592 - 37ms/epoch - 1ms/step\n",
      "Epoch 3916/5000\n",
      "31/31 - 0s - loss: 10.8660 - mae: 2.1892 - val_loss: 1.3611 - val_mae: 1.1208 - 38ms/epoch - 1ms/step\n",
      "Epoch 3917/5000\n",
      "31/31 - 0s - loss: 1.5727 - mae: 1.0691 - val_loss: 0.1146 - val_mae: 0.3027 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3918/5000\n",
      "31/31 - 0s - loss: 14.4633 - mae: 2.0569 - val_loss: 0.2400 - val_mae: 0.4303 - 36ms/epoch - 1ms/step\n",
      "Epoch 3919/5000\n",
      "31/31 - 0s - loss: 1.2437 - mae: 0.9493 - val_loss: 2.4257 - val_mae: 1.5263 - 37ms/epoch - 1ms/step\n",
      "Epoch 3920/5000\n",
      "31/31 - 0s - loss: 15.6139 - mae: 1.8471 - val_loss: 6.0918 - val_mae: 2.4463 - 38ms/epoch - 1ms/step\n",
      "Epoch 3921/5000\n",
      "31/31 - 0s - loss: 2.5217 - mae: 1.4167 - val_loss: 0.5416 - val_mae: 0.6628 - 38ms/epoch - 1ms/step\n",
      "Epoch 3922/5000\n",
      "31/31 - 0s - loss: 13.6380 - mae: 1.8262 - val_loss: 0.8768 - val_mae: 0.8818 - 36ms/epoch - 1ms/step\n",
      "Epoch 3923/5000\n",
      "31/31 - 0s - loss: 1.2437 - mae: 0.9448 - val_loss: 0.1004 - val_mae: 0.2734 - 36ms/epoch - 1ms/step\n",
      "Epoch 3924/5000\n",
      "31/31 - 0s - loss: 10.5206 - mae: 2.0768 - val_loss: 3.7293 - val_mae: 1.9056 - 36ms/epoch - 1ms/step\n",
      "Epoch 3925/5000\n",
      "31/31 - 0s - loss: 0.9489 - mae: 0.7340 - val_loss: 1.3855 - val_mae: 1.1323 - 35ms/epoch - 1ms/step\n",
      "Epoch 3926/5000\n",
      "31/31 - 0s - loss: 10.2868 - mae: 1.7812 - val_loss: 0.3052 - val_mae: 0.4717 - 35ms/epoch - 1ms/step\n",
      "Epoch 3927/5000\n",
      "31/31 - 0s - loss: 1.1491 - mae: 0.9078 - val_loss: 0.2727 - val_mae: 0.4151 - 37ms/epoch - 1ms/step\n",
      "Epoch 3928/5000\n",
      "31/31 - 0s - loss: 9.7896 - mae: 1.7316 - val_loss: 0.1110 - val_mae: 0.2846 - 36ms/epoch - 1ms/step\n",
      "Epoch 3929/5000\n",
      "31/31 - 0s - loss: 5.5499 - mae: 1.3883 - val_loss: 203.8793 - val_mae: 14.2745 - 34ms/epoch - 1ms/step\n",
      "Epoch 3930/5000\n",
      "31/31 - 0s - loss: 13.0331 - mae: 1.6663 - val_loss: 0.2918 - val_mae: 0.4361 - 36ms/epoch - 1ms/step\n",
      "Epoch 3931/5000\n",
      "31/31 - 0s - loss: 0.7973 - mae: 0.7997 - val_loss: 0.2700 - val_mae: 0.4502 - 35ms/epoch - 1ms/step\n",
      "Epoch 3932/5000\n",
      "31/31 - 0s - loss: 16.1697 - mae: 2.2241 - val_loss: 0.8448 - val_mae: 0.8600 - 37ms/epoch - 1ms/step\n",
      "Epoch 3933/5000\n",
      "31/31 - 0s - loss: 2.4009 - mae: 1.3734 - val_loss: 1.8368 - val_mae: 1.3157 - 37ms/epoch - 1ms/step\n",
      "Epoch 3934/5000\n",
      "31/31 - 0s - loss: 13.3310 - mae: 1.9304 - val_loss: 1.9770 - val_mae: 1.3679 - 35ms/epoch - 1ms/step\n",
      "Epoch 3935/5000\n",
      "31/31 - 0s - loss: 0.9573 - mae: 0.8045 - val_loss: 0.1833 - val_mae: 0.3179 - 35ms/epoch - 1ms/step\n",
      "Epoch 3936/5000\n",
      "31/31 - 0s - loss: 20.5408 - mae: 2.0297 - val_loss: 6.6650 - val_mae: 2.5630 - 36ms/epoch - 1ms/step\n",
      "Epoch 3937/5000\n",
      "31/31 - 0s - loss: 2.7638 - mae: 1.1437 - val_loss: 0.2584 - val_mae: 0.4420 - 37ms/epoch - 1ms/step\n",
      "Epoch 3938/5000\n",
      "31/31 - 0s - loss: 27.6731 - mae: 2.4921 - val_loss: 1.0602 - val_mae: 0.9771 - 34ms/epoch - 1ms/step\n",
      "Epoch 3939/5000\n",
      "31/31 - 0s - loss: 2.0692 - mae: 0.9072 - val_loss: 0.3148 - val_mae: 0.4764 - 36ms/epoch - 1ms/step\n",
      "Epoch 3940/5000\n",
      "31/31 - 0s - loss: 0.6386 - mae: 0.6434 - val_loss: 2.4694 - val_mae: 1.5386 - 36ms/epoch - 1ms/step\n",
      "Epoch 3941/5000\n",
      "31/31 - 0s - loss: 17.2168 - mae: 2.0934 - val_loss: 0.1368 - val_mae: 0.3366 - 37ms/epoch - 1ms/step\n",
      "Epoch 3942/5000\n",
      "31/31 - 0s - loss: 0.9261 - mae: 0.8399 - val_loss: 0.1133 - val_mae: 0.2963 - 36ms/epoch - 1ms/step\n",
      "Epoch 3943/5000\n",
      "31/31 - 0s - loss: 18.8746 - mae: 2.0159 - val_loss: 0.7544 - val_mae: 0.8042 - 35ms/epoch - 1ms/step\n",
      "Epoch 3944/5000\n",
      "31/31 - 0s - loss: 1.7973 - mae: 1.0493 - val_loss: 0.2941 - val_mae: 0.4334 - 38ms/epoch - 1ms/step\n",
      "Epoch 3945/5000\n",
      "31/31 - 0s - loss: 13.8458 - mae: 1.8376 - val_loss: 0.5835 - val_mae: 0.6919 - 48ms/epoch - 2ms/step\n",
      "Epoch 3946/5000\n",
      "31/31 - 0s - loss: 0.7495 - mae: 0.6880 - val_loss: 2.5278 - val_mae: 1.5577 - 37ms/epoch - 1ms/step\n",
      "Epoch 3947/5000\n",
      "31/31 - 0s - loss: 16.5343 - mae: 2.1046 - val_loss: 1.1371 - val_mae: 1.0157 - 38ms/epoch - 1ms/step\n",
      "Epoch 3948/5000\n",
      "31/31 - 0s - loss: 2.3182 - mae: 1.1509 - val_loss: 21.3136 - val_mae: 4.6049 - 39ms/epoch - 1ms/step\n",
      "Epoch 3949/5000\n",
      "31/31 - 0s - loss: 6.6816 - mae: 1.3438 - val_loss: 0.4007 - val_mae: 0.5462 - 36ms/epoch - 1ms/step\n",
      "Epoch 3950/5000\n",
      "31/31 - 0s - loss: 5.4251 - mae: 1.6059 - val_loss: 2.1408 - val_mae: 1.4274 - 38ms/epoch - 1ms/step\n",
      "Epoch 3951/5000\n",
      "31/31 - 0s - loss: 0.8792 - mae: 0.7352 - val_loss: 0.8977 - val_mae: 0.8889 - 36ms/epoch - 1ms/step\n",
      "Epoch 3952/5000\n",
      "31/31 - 0s - loss: 18.6375 - mae: 2.1186 - val_loss: 0.5425 - val_mae: 0.6619 - 36ms/epoch - 1ms/step\n",
      "Epoch 3953/5000\n",
      "31/31 - 0s - loss: 1.3463 - mae: 1.0284 - val_loss: 0.5034 - val_mae: 0.6319 - 36ms/epoch - 1ms/step\n",
      "Epoch 3954/5000\n",
      "31/31 - 0s - loss: 9.8294 - mae: 1.8901 - val_loss: 9.9939 - val_mae: 3.1459 - 35ms/epoch - 1ms/step\n",
      "Epoch 3955/5000\n",
      "31/31 - 0s - loss: 14.2232 - mae: 2.2006 - val_loss: 0.4144 - val_mae: 0.5597 - 37ms/epoch - 1ms/step\n",
      "Epoch 3956/5000\n",
      "31/31 - 0s - loss: 0.4094 - mae: 0.5260 - val_loss: 0.1794 - val_mae: 0.3111 - 36ms/epoch - 1ms/step\n",
      "Epoch 3957/5000\n",
      "31/31 - 0s - loss: 12.8965 - mae: 1.8149 - val_loss: 0.1475 - val_mae: 0.2817 - 37ms/epoch - 1ms/step\n",
      "Epoch 3958/5000\n",
      "31/31 - 0s - loss: 2.9257 - mae: 0.9686 - val_loss: 0.1252 - val_mae: 0.2795 - 36ms/epoch - 1ms/step\n",
      "Epoch 3959/5000\n",
      "31/31 - 0s - loss: 16.0616 - mae: 2.0026 - val_loss: 19.3825 - val_mae: 4.3919 - 36ms/epoch - 1ms/step\n",
      "Epoch 3960/5000\n",
      "31/31 - 0s - loss: 0.7354 - mae: 0.5860 - val_loss: 0.2419 - val_mae: 0.3765 - 35ms/epoch - 1ms/step\n",
      "Epoch 3961/5000\n",
      "31/31 - 0s - loss: 12.5404 - mae: 1.9242 - val_loss: 0.6901 - val_mae: 0.7695 - 37ms/epoch - 1ms/step\n",
      "Epoch 3962/5000\n",
      "31/31 - 0s - loss: 1.6842 - mae: 1.0133 - val_loss: 0.4751 - val_mae: 0.6140 - 36ms/epoch - 1ms/step\n",
      "Epoch 3963/5000\n",
      "31/31 - 0s - loss: 0.8630 - mae: 0.8062 - val_loss: 1.4760 - val_mae: 1.1718 - 34ms/epoch - 1ms/step\n",
      "Epoch 3964/5000\n",
      "31/31 - 0s - loss: 15.3501 - mae: 1.8582 - val_loss: 2.4500 - val_mae: 1.5295 - 35ms/epoch - 1ms/step\n",
      "Epoch 3965/5000\n",
      "31/31 - 0s - loss: 1.6463 - mae: 0.9825 - val_loss: 6.1887 - val_mae: 2.4642 - 35ms/epoch - 1ms/step\n",
      "Epoch 3966/5000\n",
      "31/31 - 0s - loss: 6.1181 - mae: 1.5880 - val_loss: 1.3795 - val_mae: 1.1298 - 36ms/epoch - 1ms/step\n",
      "Epoch 3967/5000\n",
      "31/31 - 0s - loss: 18.7788 - mae: 2.1463 - val_loss: 0.1207 - val_mae: 0.2867 - 36ms/epoch - 1ms/step\n",
      "Epoch 3968/5000\n",
      "31/31 - 0s - loss: 0.8714 - mae: 0.6603 - val_loss: 0.1781 - val_mae: 0.3099 - 37ms/epoch - 1ms/step\n",
      "Epoch 3969/5000\n",
      "31/31 - 0s - loss: 19.5407 - mae: 2.1169 - val_loss: 0.2290 - val_mae: 0.3530 - 37ms/epoch - 1ms/step\n",
      "Epoch 3970/5000\n",
      "31/31 - 0s - loss: 1.1070 - mae: 0.7687 - val_loss: 0.1047 - val_mae: 0.2821 - 38ms/epoch - 1ms/step\n",
      "Epoch 3971/5000\n",
      "31/31 - 0s - loss: 0.9231 - mae: 0.7008 - val_loss: 10.5362 - val_mae: 3.2314 - 37ms/epoch - 1ms/step\n",
      "Epoch 3972/5000\n",
      "31/31 - 0s - loss: 18.9537 - mae: 1.9926 - val_loss: 4.1365 - val_mae: 2.0086 - 38ms/epoch - 1ms/step\n",
      "Epoch 3973/5000\n",
      "31/31 - 0s - loss: 1.0049 - mae: 0.7169 - val_loss: 0.6764 - val_mae: 0.7581 - 39ms/epoch - 1ms/step\n",
      "Epoch 3974/5000\n",
      "31/31 - 0s - loss: 11.2007 - mae: 1.9734 - val_loss: 2.8107 - val_mae: 1.6451 - 36ms/epoch - 1ms/step\n",
      "Epoch 3975/5000\n",
      "31/31 - 0s - loss: 10.3863 - mae: 2.1884 - val_loss: 0.1840 - val_mae: 0.3869 - 37ms/epoch - 1ms/step\n",
      "Epoch 3976/5000\n",
      "31/31 - 0s - loss: 1.3287 - mae: 0.9134 - val_loss: 0.2136 - val_mae: 0.3407 - 36ms/epoch - 1ms/step\n",
      "Epoch 3977/5000\n",
      "31/31 - 0s - loss: 10.5365 - mae: 1.9139 - val_loss: 0.1128 - val_mae: 0.2990 - 38ms/epoch - 1ms/step\n",
      "Epoch 3978/5000\n",
      "31/31 - 0s - loss: 0.9771 - mae: 0.8083 - val_loss: 0.2162 - val_mae: 0.4139 - 34ms/epoch - 1ms/step\n",
      "Epoch 3979/5000\n",
      "31/31 - 0s - loss: 22.2028 - mae: 2.1980 - val_loss: 1.4913 - val_mae: 1.1773 - 37ms/epoch - 1ms/step\n",
      "Epoch 3980/5000\n",
      "31/31 - 0s - loss: 1.4896 - mae: 0.9928 - val_loss: 0.5231 - val_mae: 0.6486 - 36ms/epoch - 1ms/step\n",
      "Epoch 3981/5000\n",
      "31/31 - 0s - loss: 1.1806 - mae: 0.8746 - val_loss: 0.4643 - val_mae: 0.5999 - 38ms/epoch - 1ms/step\n",
      "Epoch 3982/5000\n",
      "31/31 - 0s - loss: 16.5691 - mae: 2.0573 - val_loss: 0.4864 - val_mae: 0.6179 - 35ms/epoch - 1ms/step\n",
      "Epoch 3983/5000\n",
      "31/31 - 0s - loss: 1.1970 - mae: 0.9564 - val_loss: 0.1248 - val_mae: 0.2840 - 35ms/epoch - 1ms/step\n",
      "Epoch 3984/5000\n",
      "31/31 - 0s - loss: 11.3941 - mae: 1.6486 - val_loss: 14.8131 - val_mae: 3.8364 - 36ms/epoch - 1ms/step\n",
      "Epoch 3985/5000\n",
      "31/31 - 0s - loss: 3.2796 - mae: 1.2194 - val_loss: 4.7236 - val_mae: 2.1500 - 37ms/epoch - 1ms/step\n",
      "Epoch 3986/5000\n",
      "31/31 - 0s - loss: 2.8445 - mae: 1.2094 - val_loss: 0.1538 - val_mae: 0.2871 - 36ms/epoch - 1ms/step\n",
      "Epoch 3987/5000\n",
      "31/31 - 0s - loss: 37.5375 - mae: 2.2525 - val_loss: 0.1556 - val_mae: 0.3567 - 39ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3988/5000\n",
      "31/31 - 0s - loss: 1.6230 - mae: 1.0393 - val_loss: 0.1077 - val_mae: 0.2807 - 35ms/epoch - 1ms/step\n",
      "Epoch 3989/5000\n",
      "31/31 - 0s - loss: 0.6208 - mae: 0.5987 - val_loss: 0.4153 - val_mae: 0.5599 - 36ms/epoch - 1ms/step\n",
      "Epoch 3990/5000\n",
      "31/31 - 0s - loss: 11.3537 - mae: 1.7033 - val_loss: 2.3510 - val_mae: 1.5000 - 37ms/epoch - 1ms/step\n",
      "Epoch 3991/5000\n",
      "31/31 - 0s - loss: 0.8452 - mae: 0.7412 - val_loss: 1.1863 - val_mae: 1.0417 - 37ms/epoch - 1ms/step\n",
      "Epoch 3992/5000\n",
      "31/31 - 0s - loss: 16.4050 - mae: 2.0278 - val_loss: 1.5380 - val_mae: 1.1997 - 37ms/epoch - 1ms/step\n",
      "Epoch 3993/5000\n",
      "31/31 - 0s - loss: 0.5557 - mae: 0.5764 - val_loss: 2.6097 - val_mae: 1.5844 - 37ms/epoch - 1ms/step\n",
      "Epoch 3994/5000\n",
      "31/31 - 0s - loss: 13.9003 - mae: 2.0477 - val_loss: 0.1936 - val_mae: 0.3958 - 35ms/epoch - 1ms/step\n",
      "Epoch 3995/5000\n",
      "31/31 - 0s - loss: 2.1954 - mae: 1.1616 - val_loss: 20.1168 - val_mae: 4.4730 - 37ms/epoch - 1ms/step\n",
      "Epoch 3996/5000\n",
      "31/31 - 0s - loss: 9.6338 - mae: 1.4566 - val_loss: 0.1189 - val_mae: 0.3097 - 35ms/epoch - 1ms/step\n",
      "Epoch 3997/5000\n",
      "31/31 - 0s - loss: 7.3158 - mae: 1.4225 - val_loss: 5.7058 - val_mae: 2.3678 - 37ms/epoch - 1ms/step\n",
      "Epoch 3998/5000\n",
      "31/31 - 0s - loss: 2.4771 - mae: 1.3231 - val_loss: 0.1451 - val_mae: 0.3482 - 34ms/epoch - 1ms/step\n",
      "Epoch 3999/5000\n",
      "31/31 - 0s - loss: 14.7616 - mae: 1.8925 - val_loss: 0.4082 - val_mae: 0.5504 - 35ms/epoch - 1ms/step\n",
      "Epoch 4000/5000\n",
      "31/31 - 0s - loss: 3.1152 - mae: 1.5345 - val_loss: 2.1030 - val_mae: 1.4143 - 35ms/epoch - 1ms/step\n",
      "Epoch 4001/5000\n",
      "31/31 - 0s - loss: 20.9900 - mae: 2.3093 - val_loss: 0.1103 - val_mae: 0.2892 - 36ms/epoch - 1ms/step\n",
      "Epoch 4002/5000\n",
      "31/31 - 0s - loss: 1.3221 - mae: 1.0252 - val_loss: 0.1431 - val_mae: 0.3460 - 36ms/epoch - 1ms/step\n",
      "Epoch 4003/5000\n",
      "31/31 - 0s - loss: 17.6259 - mae: 2.0520 - val_loss: 0.8890 - val_mae: 0.8878 - 36ms/epoch - 1ms/step\n",
      "Epoch 4004/5000\n",
      "31/31 - 0s - loss: 0.8250 - mae: 0.7960 - val_loss: 3.3936 - val_mae: 1.8147 - 36ms/epoch - 1ms/step\n",
      "Epoch 4005/5000\n",
      "31/31 - 0s - loss: 20.2221 - mae: 2.1314 - val_loss: 0.1723 - val_mae: 0.3108 - 36ms/epoch - 1ms/step\n",
      "Epoch 4006/5000\n",
      "31/31 - 0s - loss: 1.3399 - mae: 0.9077 - val_loss: 0.3316 - val_mae: 0.4744 - 36ms/epoch - 1ms/step\n",
      "Epoch 4007/5000\n",
      "31/31 - 0s - loss: 6.3579 - mae: 1.8922 - val_loss: 1.5248 - val_mae: 1.1937 - 37ms/epoch - 1ms/step\n",
      "Epoch 4008/5000\n",
      "31/31 - 0s - loss: 0.4517 - mae: 0.5140 - val_loss: 0.2237 - val_mae: 0.4193 - 37ms/epoch - 1ms/step\n",
      "Epoch 4009/5000\n",
      "31/31 - 0s - loss: 22.1290 - mae: 2.1747 - val_loss: 1.7313 - val_mae: 1.2749 - 37ms/epoch - 1ms/step\n",
      "Epoch 4010/5000\n",
      "31/31 - 0s - loss: 2.6333 - mae: 1.3378 - val_loss: 0.7110 - val_mae: 0.7776 - 38ms/epoch - 1ms/step\n",
      "Epoch 4011/5000\n",
      "31/31 - 0s - loss: 0.5333 - mae: 0.5871 - val_loss: 0.3141 - val_mae: 0.4575 - 34ms/epoch - 1ms/step\n",
      "Epoch 4012/5000\n",
      "31/31 - 0s - loss: 33.2241 - mae: 2.5671 - val_loss: 8.2019 - val_mae: 2.8470 - 36ms/epoch - 1ms/step\n",
      "Epoch 4013/5000\n",
      "31/31 - 0s - loss: 1.5088 - mae: 1.0454 - val_loss: 0.6193 - val_mae: 0.7188 - 35ms/epoch - 1ms/step\n",
      "Epoch 4014/5000\n",
      "31/31 - 0s - loss: 12.8970 - mae: 2.1276 - val_loss: 1.8729 - val_mae: 1.3285 - 36ms/epoch - 1ms/step\n",
      "Epoch 4015/5000\n",
      "31/31 - 0s - loss: 2.2328 - mae: 1.0951 - val_loss: 4.3683 - val_mae: 2.0648 - 37ms/epoch - 1ms/step\n",
      "Epoch 4016/5000\n",
      "31/31 - 0s - loss: 11.6944 - mae: 2.0030 - val_loss: 0.2891 - val_mae: 0.4625 - 35ms/epoch - 1ms/step\n",
      "Epoch 4017/5000\n",
      "31/31 - 0s - loss: 0.9562 - mae: 0.6556 - val_loss: 0.5181 - val_mae: 0.6438 - 35ms/epoch - 1ms/step\n",
      "Epoch 4018/5000\n",
      "31/31 - 0s - loss: 23.1931 - mae: 2.0259 - val_loss: 0.1121 - val_mae: 0.2798 - 36ms/epoch - 1ms/step\n",
      "Epoch 4019/5000\n",
      "31/31 - 0s - loss: 1.5550 - mae: 1.0075 - val_loss: 0.1070 - val_mae: 0.2798 - 36ms/epoch - 1ms/step\n",
      "Epoch 4020/5000\n",
      "31/31 - 0s - loss: 0.7111 - mae: 0.6845 - val_loss: 36.3295 - val_mae: 6.0199 - 35ms/epoch - 1ms/step\n",
      "Epoch 4021/5000\n",
      "31/31 - 0s - loss: 20.7162 - mae: 2.3655 - val_loss: 0.2991 - val_mae: 0.4662 - 35ms/epoch - 1ms/step\n",
      "Epoch 4022/5000\n",
      "31/31 - 0s - loss: 1.1300 - mae: 0.7668 - val_loss: 0.1066 - val_mae: 0.2741 - 36ms/epoch - 1ms/step\n",
      "Epoch 4023/5000\n",
      "31/31 - 0s - loss: 23.8356 - mae: 2.0567 - val_loss: 0.5380 - val_mae: 0.6566 - 35ms/epoch - 1ms/step\n",
      "Epoch 4024/5000\n",
      "31/31 - 0s - loss: 1.9465 - mae: 0.9098 - val_loss: 0.1118 - val_mae: 0.2853 - 37ms/epoch - 1ms/step\n",
      "Epoch 4025/5000\n",
      "31/31 - 0s - loss: 10.3425 - mae: 1.8921 - val_loss: 0.9569 - val_mae: 0.9251 - 38ms/epoch - 1ms/step\n",
      "Epoch 4026/5000\n",
      "31/31 - 0s - loss: 1.4226 - mae: 0.9177 - val_loss: 0.5329 - val_mae: 0.6555 - 36ms/epoch - 1ms/step\n",
      "Epoch 4027/5000\n",
      "31/31 - 0s - loss: 18.8390 - mae: 2.1126 - val_loss: 0.2288 - val_mae: 0.3573 - 38ms/epoch - 1ms/step\n",
      "Epoch 4028/5000\n",
      "31/31 - 0s - loss: 2.1937 - mae: 1.3319 - val_loss: 1.3278 - val_mae: 1.1062 - 38ms/epoch - 1ms/step\n",
      "Epoch 4029/5000\n",
      "31/31 - 0s - loss: 9.1100 - mae: 1.8011 - val_loss: 9.9630 - val_mae: 3.1396 - 39ms/epoch - 1ms/step\n",
      "Epoch 4030/5000\n",
      "31/31 - 0s - loss: 3.1874 - mae: 1.2804 - val_loss: 15.8584 - val_mae: 3.9684 - 36ms/epoch - 1ms/step\n",
      "Epoch 4031/5000\n",
      "31/31 - 0s - loss: 5.4331 - mae: 1.8224 - val_loss: 0.6424 - val_mae: 0.7331 - 36ms/epoch - 1ms/step\n",
      "Epoch 4032/5000\n",
      "31/31 - 0s - loss: 13.2720 - mae: 1.9401 - val_loss: 1.5335 - val_mae: 1.1983 - 35ms/epoch - 1ms/step\n",
      "Epoch 4033/5000\n",
      "31/31 - 0s - loss: 1.5267 - mae: 1.0822 - val_loss: 0.1133 - val_mae: 0.2800 - 37ms/epoch - 1ms/step\n",
      "Epoch 4034/5000\n",
      "31/31 - 0s - loss: 18.8269 - mae: 2.1826 - val_loss: 0.5514 - val_mae: 0.6668 - 35ms/epoch - 1ms/step\n",
      "Epoch 4035/5000\n",
      "31/31 - 0s - loss: 1.1944 - mae: 0.8568 - val_loss: 0.1099 - val_mae: 0.2834 - 37ms/epoch - 1ms/step\n",
      "Epoch 4036/5000\n",
      "31/31 - 0s - loss: 15.4192 - mae: 1.9503 - val_loss: 0.1739 - val_mae: 0.3792 - 34ms/epoch - 1ms/step\n",
      "Epoch 4037/5000\n",
      "31/31 - 0s - loss: 0.9366 - mae: 0.7501 - val_loss: 0.3616 - val_mae: 0.5070 - 36ms/epoch - 1ms/step\n",
      "Epoch 4038/5000\n",
      "31/31 - 0s - loss: 26.7239 - mae: 2.2005 - val_loss: 0.1600 - val_mae: 0.3625 - 35ms/epoch - 1ms/step\n",
      "Epoch 4039/5000\n",
      "31/31 - 0s - loss: 1.6288 - mae: 1.0167 - val_loss: 0.8726 - val_mae: 0.8748 - 37ms/epoch - 1ms/step\n",
      "Epoch 4040/5000\n",
      "31/31 - 0s - loss: 4.9716 - mae: 1.6325 - val_loss: 26.9051 - val_mae: 5.1772 - 36ms/epoch - 1ms/step\n",
      "Epoch 4041/5000\n",
      "31/31 - 0s - loss: 8.0167 - mae: 1.4386 - val_loss: 10.4339 - val_mae: 3.2147 - 36ms/epoch - 1ms/step\n",
      "Epoch 4042/5000\n",
      "31/31 - 0s - loss: 10.7018 - mae: 1.9041 - val_loss: 0.8073 - val_mae: 0.8375 - 36ms/epoch - 1ms/step\n",
      "Epoch 4043/5000\n",
      "31/31 - 0s - loss: 1.5350 - mae: 1.1562 - val_loss: 6.2720 - val_mae: 2.4841 - 36ms/epoch - 1ms/step\n",
      "Epoch 4044/5000\n",
      "31/31 - 0s - loss: 18.0549 - mae: 2.3579 - val_loss: 0.2934 - val_mae: 0.4336 - 38ms/epoch - 1ms/step\n",
      "Epoch 4045/5000\n",
      "31/31 - 0s - loss: 1.3558 - mae: 0.9270 - val_loss: 5.0492 - val_mae: 2.2247 - 42ms/epoch - 1ms/step\n",
      "Epoch 4046/5000\n",
      "31/31 - 0s - loss: 10.5033 - mae: 1.9204 - val_loss: 31.8858 - val_mae: 5.6366 - 38ms/epoch - 1ms/step\n",
      "Epoch 4047/5000\n",
      "31/31 - 0s - loss: 3.6526 - mae: 1.5655 - val_loss: 2.2273 - val_mae: 1.4575 - 37ms/epoch - 1ms/step\n",
      "Epoch 4048/5000\n",
      "31/31 - 0s - loss: 18.5109 - mae: 2.4771 - val_loss: 0.1103 - val_mae: 0.2881 - 38ms/epoch - 1ms/step\n",
      "Epoch 4049/5000\n",
      "31/31 - 0s - loss: 0.9747 - mae: 0.8172 - val_loss: 0.9791 - val_mae: 0.9338 - 37ms/epoch - 1ms/step\n",
      "Epoch 4050/5000\n",
      "31/31 - 0s - loss: 15.1620 - mae: 2.2341 - val_loss: 0.7670 - val_mae: 0.8148 - 35ms/epoch - 1ms/step\n",
      "Epoch 4051/5000\n",
      "31/31 - 0s - loss: 0.7435 - mae: 0.5947 - val_loss: 0.1275 - val_mae: 0.3230 - 35ms/epoch - 1ms/step\n",
      "Epoch 4052/5000\n",
      "31/31 - 0s - loss: 26.8628 - mae: 2.0564 - val_loss: 0.2419 - val_mae: 0.4310 - 38ms/epoch - 1ms/step\n",
      "Epoch 4053/5000\n",
      "31/31 - 0s - loss: 1.7451 - mae: 0.8722 - val_loss: 0.5007 - val_mae: 0.6320 - 38ms/epoch - 1ms/step\n",
      "Epoch 4054/5000\n",
      "31/31 - 0s - loss: 0.9382 - mae: 0.7521 - val_loss: 1.2761 - val_mae: 1.0827 - 37ms/epoch - 1ms/step\n",
      "Epoch 4055/5000\n",
      "31/31 - 0s - loss: 20.2972 - mae: 2.0976 - val_loss: 0.9499 - val_mae: 0.9218 - 35ms/epoch - 1ms/step\n",
      "Epoch 4056/5000\n",
      "31/31 - 0s - loss: 1.3550 - mae: 0.8990 - val_loss: 1.3484 - val_mae: 1.1176 - 36ms/epoch - 1ms/step\n",
      "Epoch 4057/5000\n",
      "31/31 - 0s - loss: 20.3870 - mae: 2.1493 - val_loss: 0.1712 - val_mae: 0.3752 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4058/5000\n",
      "31/31 - 0s - loss: 3.0579 - mae: 1.5234 - val_loss: 9.4925 - val_mae: 3.0655 - 38ms/epoch - 1ms/step\n",
      "Epoch 4059/5000\n",
      "31/31 - 0s - loss: 2.2060 - mae: 1.1348 - val_loss: 208.6537 - val_mae: 14.4412 - 37ms/epoch - 1ms/step\n",
      "Epoch 4060/5000\n",
      "31/31 - 0s - loss: 15.8413 - mae: 1.8278 - val_loss: 0.6199 - val_mae: 0.7189 - 37ms/epoch - 1ms/step\n",
      "Epoch 4061/5000\n",
      "31/31 - 0s - loss: 0.7803 - mae: 0.6822 - val_loss: 5.5787 - val_mae: 2.3384 - 35ms/epoch - 1ms/step\n",
      "Epoch 4062/5000\n",
      "31/31 - 0s - loss: 11.7680 - mae: 2.0940 - val_loss: 0.6183 - val_mae: 0.7135 - 36ms/epoch - 1ms/step\n",
      "Epoch 4063/5000\n",
      "31/31 - 0s - loss: 1.1361 - mae: 0.9375 - val_loss: 2.4588 - val_mae: 1.5364 - 36ms/epoch - 1ms/step\n",
      "Epoch 4064/5000\n",
      "31/31 - 0s - loss: 23.6501 - mae: 2.3194 - val_loss: 0.1926 - val_mae: 0.3260 - 36ms/epoch - 1ms/step\n",
      "Epoch 4065/5000\n",
      "31/31 - 0s - loss: 1.3823 - mae: 0.8604 - val_loss: 0.1041 - val_mae: 0.2786 - 36ms/epoch - 1ms/step\n",
      "Epoch 4066/5000\n",
      "31/31 - 0s - loss: 17.5309 - mae: 1.9891 - val_loss: 0.5274 - val_mae: 0.6509 - 37ms/epoch - 1ms/step\n",
      "Epoch 4067/5000\n",
      "31/31 - 0s - loss: 1.3403 - mae: 0.8732 - val_loss: 0.2087 - val_mae: 0.4087 - 37ms/epoch - 1ms/step\n",
      "Epoch 4068/5000\n",
      "31/31 - 0s - loss: 6.5389 - mae: 1.6053 - val_loss: 5.6358 - val_mae: 2.3512 - 37ms/epoch - 1ms/step\n",
      "Epoch 4069/5000\n",
      "31/31 - 0s - loss: 16.6789 - mae: 1.8582 - val_loss: 1.2017 - val_mae: 1.0486 - 35ms/epoch - 1ms/step\n",
      "Epoch 4070/5000\n",
      "31/31 - 0s - loss: 1.1985 - mae: 0.7724 - val_loss: 0.1179 - val_mae: 0.3058 - 36ms/epoch - 1ms/step\n",
      "Epoch 4071/5000\n",
      "31/31 - 0s - loss: 1.1351 - mae: 0.8368 - val_loss: 34.1393 - val_mae: 5.8329 - 36ms/epoch - 1ms/step\n",
      "Epoch 4072/5000\n",
      "31/31 - 0s - loss: 23.0057 - mae: 2.3320 - val_loss: 0.3038 - val_mae: 0.4715 - 36ms/epoch - 1ms/step\n",
      "Epoch 4073/5000\n",
      "31/31 - 0s - loss: 1.3879 - mae: 1.0291 - val_loss: 0.8396 - val_mae: 0.8575 - 35ms/epoch - 1ms/step\n",
      "Epoch 4074/5000\n",
      "31/31 - 0s - loss: 7.5385 - mae: 1.8693 - val_loss: 0.1612 - val_mae: 0.3656 - 36ms/epoch - 1ms/step\n",
      "Epoch 4075/5000\n",
      "31/31 - 0s - loss: 12.8456 - mae: 1.9781 - val_loss: 1.4548 - val_mae: 1.1635 - 35ms/epoch - 1ms/step\n",
      "Epoch 4076/5000\n",
      "31/31 - 0s - loss: 1.8917 - mae: 1.0896 - val_loss: 0.2045 - val_mae: 0.3364 - 36ms/epoch - 1ms/step\n",
      "Epoch 4077/5000\n",
      "31/31 - 0s - loss: 0.8403 - mae: 0.6814 - val_loss: 25.2199 - val_mae: 5.0118 - 35ms/epoch - 1ms/step\n",
      "Epoch 4078/5000\n",
      "31/31 - 0s - loss: 29.7771 - mae: 2.1991 - val_loss: 0.1146 - val_mae: 0.2918 - 36ms/epoch - 1ms/step\n",
      "Epoch 4079/5000\n",
      "31/31 - 0s - loss: 2.2889 - mae: 1.2580 - val_loss: 1.2423 - val_mae: 1.0670 - 38ms/epoch - 1ms/step\n",
      "Epoch 4080/5000\n",
      "31/31 - 0s - loss: 6.3643 - mae: 1.6735 - val_loss: 1.3628 - val_mae: 1.1215 - 36ms/epoch - 1ms/step\n",
      "Epoch 4081/5000\n",
      "31/31 - 0s - loss: 1.4682 - mae: 0.9532 - val_loss: 0.3094 - val_mae: 0.4731 - 38ms/epoch - 1ms/step\n",
      "Epoch 4082/5000\n",
      "31/31 - 0s - loss: 17.8243 - mae: 2.0125 - val_loss: 5.0175 - val_mae: 2.2162 - 36ms/epoch - 1ms/step\n",
      "Epoch 4083/5000\n",
      "31/31 - 0s - loss: 2.1933 - mae: 1.1642 - val_loss: 1.9910 - val_mae: 1.3747 - 36ms/epoch - 1ms/step\n",
      "Epoch 4084/5000\n",
      "31/31 - 0s - loss: 2.5580 - mae: 0.8947 - val_loss: 277.2311 - val_mae: 16.6473 - 36ms/epoch - 1ms/step\n",
      "Epoch 4085/5000\n",
      "31/31 - 0s - loss: 17.7453 - mae: 2.2561 - val_loss: 4.4234 - val_mae: 2.0767 - 36ms/epoch - 1ms/step\n",
      "Epoch 4086/5000\n",
      "31/31 - 0s - loss: 1.7415 - mae: 1.1666 - val_loss: 0.1122 - val_mae: 0.2944 - 36ms/epoch - 1ms/step\n",
      "Epoch 4087/5000\n",
      "31/31 - 0s - loss: 19.2758 - mae: 2.1066 - val_loss: 0.2239 - val_mae: 0.3486 - 36ms/epoch - 1ms/step\n",
      "Epoch 4088/5000\n",
      "31/31 - 0s - loss: 1.3990 - mae: 0.7777 - val_loss: 2.8659 - val_mae: 1.6621 - 36ms/epoch - 1ms/step\n",
      "Epoch 4089/5000\n",
      "31/31 - 0s - loss: 14.2747 - mae: 1.7894 - val_loss: 0.4093 - val_mae: 0.5630 - 37ms/epoch - 1ms/step\n",
      "Epoch 4090/5000\n",
      "31/31 - 0s - loss: 4.1565 - mae: 1.7500 - val_loss: 2.9699 - val_mae: 1.6942 - 37ms/epoch - 1ms/step\n",
      "Epoch 4091/5000\n",
      "31/31 - 0s - loss: 11.6054 - mae: 2.4729 - val_loss: 0.6194 - val_mae: 0.7232 - 39ms/epoch - 1ms/step\n",
      "Epoch 4092/5000\n",
      "31/31 - 0s - loss: 0.7688 - mae: 0.6547 - val_loss: 2.3149 - val_mae: 1.4875 - 37ms/epoch - 1ms/step\n",
      "Epoch 4093/5000\n",
      "31/31 - 0s - loss: 12.5649 - mae: 1.5537 - val_loss: 340.4319 - val_mae: 18.4478 - 35ms/epoch - 1ms/step\n",
      "Epoch 4094/5000\n",
      "31/31 - 0s - loss: 13.7980 - mae: 1.3228 - val_loss: 0.1179 - val_mae: 0.3043 - 36ms/epoch - 1ms/step\n",
      "Epoch 4095/5000\n",
      "31/31 - 0s - loss: 0.9918 - mae: 0.8132 - val_loss: 1.4723 - val_mae: 1.1692 - 35ms/epoch - 1ms/step\n",
      "Epoch 4096/5000\n",
      "31/31 - 0s - loss: 19.8476 - mae: 2.4368 - val_loss: 0.1203 - val_mae: 0.2833 - 35ms/epoch - 1ms/step\n",
      "Epoch 4097/5000\n",
      "31/31 - 0s - loss: 1.8947 - mae: 0.9447 - val_loss: 0.8479 - val_mae: 0.8622 - 36ms/epoch - 1ms/step\n",
      "Epoch 4098/5000\n",
      "31/31 - 0s - loss: 22.7768 - mae: 2.0724 - val_loss: 0.2762 - val_mae: 0.4543 - 37ms/epoch - 1ms/step\n",
      "Epoch 4099/5000\n",
      "31/31 - 0s - loss: 1.3103 - mae: 0.8507 - val_loss: 2.0217 - val_mae: 1.3849 - 39ms/epoch - 1ms/step\n",
      "Epoch 4100/5000\n",
      "31/31 - 0s - loss: 2.0525 - mae: 1.1783 - val_loss: 1.9392 - val_mae: 1.3560 - 37ms/epoch - 1ms/step\n",
      "Epoch 4101/5000\n",
      "31/31 - 0s - loss: 15.7177 - mae: 2.0829 - val_loss: 0.3289 - val_mae: 0.4837 - 34ms/epoch - 1ms/step\n",
      "Epoch 4102/5000\n",
      "31/31 - 0s - loss: 0.6484 - mae: 0.5645 - val_loss: 0.1671 - val_mae: 0.3006 - 37ms/epoch - 1ms/step\n",
      "Epoch 4103/5000\n",
      "31/31 - 0s - loss: 18.5875 - mae: 2.2138 - val_loss: 3.4318 - val_mae: 1.8262 - 36ms/epoch - 1ms/step\n",
      "Epoch 4104/5000\n",
      "31/31 - 0s - loss: 1.3853 - mae: 0.9162 - val_loss: 0.2130 - val_mae: 0.3396 - 36ms/epoch - 1ms/step\n",
      "Epoch 4105/5000\n",
      "31/31 - 0s - loss: 16.7720 - mae: 1.9848 - val_loss: 0.1295 - val_mae: 0.3228 - 40ms/epoch - 1ms/step\n",
      "Epoch 4106/5000\n",
      "31/31 - 0s - loss: 1.2691 - mae: 1.0136 - val_loss: 1.0727 - val_mae: 0.9822 - 37ms/epoch - 1ms/step\n",
      "Epoch 4107/5000\n",
      "31/31 - 0s - loss: 23.5223 - mae: 2.0316 - val_loss: 0.3877 - val_mae: 0.5337 - 36ms/epoch - 1ms/step\n",
      "Epoch 4108/5000\n",
      "31/31 - 0s - loss: 1.8419 - mae: 1.1068 - val_loss: 0.2275 - val_mae: 0.3535 - 34ms/epoch - 1ms/step\n",
      "Epoch 4109/5000\n",
      "31/31 - 0s - loss: 13.2780 - mae: 1.9991 - val_loss: 0.1035 - val_mae: 0.2785 - 36ms/epoch - 1ms/step\n",
      "Epoch 4110/5000\n",
      "31/31 - 0s - loss: 0.9183 - mae: 0.8081 - val_loss: 0.1290 - val_mae: 0.2751 - 39ms/epoch - 1ms/step\n",
      "Epoch 4111/5000\n",
      "31/31 - 0s - loss: 12.0216 - mae: 1.8136 - val_loss: 1.3173 - val_mae: 1.1032 - 38ms/epoch - 1ms/step\n",
      "Epoch 4112/5000\n",
      "31/31 - 0s - loss: 0.9374 - mae: 0.8313 - val_loss: 0.1254 - val_mae: 0.3179 - 35ms/epoch - 1ms/step\n",
      "Epoch 4113/5000\n",
      "31/31 - 0s - loss: 7.8459 - mae: 1.9914 - val_loss: 0.1104 - val_mae: 0.2812 - 36ms/epoch - 1ms/step\n",
      "Epoch 4114/5000\n",
      "31/31 - 0s - loss: 13.8054 - mae: 2.0850 - val_loss: 0.6122 - val_mae: 0.7138 - 34ms/epoch - 1ms/step\n",
      "Epoch 4115/5000\n",
      "31/31 - 0s - loss: 1.0626 - mae: 0.8208 - val_loss: 0.4881 - val_mae: 0.6201 - 36ms/epoch - 1ms/step\n",
      "Epoch 4116/5000\n",
      "31/31 - 0s - loss: 19.6905 - mae: 2.3170 - val_loss: 0.3459 - val_mae: 0.4939 - 36ms/epoch - 1ms/step\n",
      "Epoch 4117/5000\n",
      "31/31 - 0s - loss: 1.8798 - mae: 1.0792 - val_loss: 1.2625 - val_mae: 1.0786 - 35ms/epoch - 1ms/step\n",
      "Epoch 4118/5000\n",
      "31/31 - 0s - loss: 13.9901 - mae: 2.0134 - val_loss: 0.1403 - val_mae: 0.2753 - 39ms/epoch - 1ms/step\n",
      "Epoch 4119/5000\n",
      "31/31 - 0s - loss: 1.2936 - mae: 0.9024 - val_loss: 0.7691 - val_mae: 0.8192 - 36ms/epoch - 1ms/step\n",
      "Epoch 4120/5000\n",
      "31/31 - 0s - loss: 2.3776 - mae: 1.1300 - val_loss: 1.2511 - val_mae: 1.0709 - 36ms/epoch - 1ms/step\n",
      "Epoch 4121/5000\n",
      "31/31 - 0s - loss: 23.1831 - mae: 2.1248 - val_loss: 0.2232 - val_mae: 0.4191 - 33ms/epoch - 1ms/step\n",
      "Epoch 4122/5000\n",
      "31/31 - 0s - loss: 0.9191 - mae: 0.7237 - val_loss: 0.4622 - val_mae: 0.6023 - 36ms/epoch - 1ms/step\n",
      "Epoch 4123/5000\n",
      "31/31 - 0s - loss: 20.3297 - mae: 2.0477 - val_loss: 0.5598 - val_mae: 0.6730 - 38ms/epoch - 1ms/step\n",
      "Epoch 4124/5000\n",
      "31/31 - 0s - loss: 1.0830 - mae: 0.8308 - val_loss: 3.0748 - val_mae: 1.7244 - 35ms/epoch - 1ms/step\n",
      "Epoch 4125/5000\n",
      "31/31 - 0s - loss: 15.8276 - mae: 2.0815 - val_loss: 0.1085 - val_mae: 0.2824 - 36ms/epoch - 1ms/step\n",
      "Epoch 4126/5000\n",
      "31/31 - 0s - loss: 1.4273 - mae: 1.0325 - val_loss: 4.6799 - val_mae: 2.1402 - 34ms/epoch - 1ms/step\n",
      "Epoch 4127/5000\n",
      "31/31 - 0s - loss: 8.4060 - mae: 2.1254 - val_loss: 5.1265 - val_mae: 2.2416 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4128/5000\n",
      "31/31 - 0s - loss: 0.6545 - mae: 0.5772 - val_loss: 0.2506 - val_mae: 0.3852 - 39ms/epoch - 1ms/step\n",
      "Epoch 4129/5000\n",
      "31/31 - 0s - loss: 27.1107 - mae: 2.1533 - val_loss: 1.3218 - val_mae: 1.1022 - 35ms/epoch - 1ms/step\n",
      "Epoch 4130/5000\n",
      "31/31 - 0s - loss: 0.9216 - mae: 0.7107 - val_loss: 0.1500 - val_mae: 0.3542 - 37ms/epoch - 1ms/step\n",
      "Epoch 4131/5000\n",
      "31/31 - 0s - loss: 10.6204 - mae: 1.6761 - val_loss: 0.2137 - val_mae: 0.3458 - 36ms/epoch - 1ms/step\n",
      "Epoch 4132/5000\n",
      "31/31 - 0s - loss: 2.6926 - mae: 1.2102 - val_loss: 0.3635 - val_mae: 0.5106 - 36ms/epoch - 1ms/step\n",
      "Epoch 4133/5000\n",
      "31/31 - 0s - loss: 13.8704 - mae: 1.8092 - val_loss: 14.7217 - val_mae: 3.8225 - 37ms/epoch - 1ms/step\n",
      "Epoch 4134/5000\n",
      "31/31 - 0s - loss: 2.2126 - mae: 1.0919 - val_loss: 2.7415 - val_mae: 1.6239 - 38ms/epoch - 1ms/step\n",
      "Epoch 4135/5000\n",
      "31/31 - 0s - loss: 0.7836 - mae: 0.7479 - val_loss: 0.3885 - val_mae: 0.5346 - 38ms/epoch - 1ms/step\n",
      "Epoch 4136/5000\n",
      "31/31 - 0s - loss: 17.4900 - mae: 2.1136 - val_loss: 0.2320 - val_mae: 0.3643 - 37ms/epoch - 1ms/step\n",
      "Epoch 4137/5000\n",
      "31/31 - 0s - loss: 1.0110 - mae: 0.8356 - val_loss: 0.2661 - val_mae: 0.4476 - 35ms/epoch - 1ms/step\n",
      "Epoch 4138/5000\n",
      "31/31 - 0s - loss: 11.7818 - mae: 1.7110 - val_loss: 3.5919 - val_mae: 1.8670 - 37ms/epoch - 1ms/step\n",
      "Epoch 4139/5000\n",
      "31/31 - 0s - loss: 1.5860 - mae: 0.9887 - val_loss: 2.0447 - val_mae: 1.3926 - 36ms/epoch - 1ms/step\n",
      "Epoch 4140/5000\n",
      "31/31 - 0s - loss: 8.6610 - mae: 1.9854 - val_loss: 0.1175 - val_mae: 0.3067 - 36ms/epoch - 1ms/step\n",
      "Epoch 4141/5000\n",
      "31/31 - 0s - loss: 2.0397 - mae: 0.8131 - val_loss: 6.6812 - val_mae: 2.5645 - 34ms/epoch - 1ms/step\n",
      "Epoch 4142/5000\n",
      "31/31 - 0s - loss: 19.2219 - mae: 2.2301 - val_loss: 1.4379 - val_mae: 1.1560 - 35ms/epoch - 1ms/step\n",
      "Epoch 4143/5000\n",
      "31/31 - 0s - loss: 2.0272 - mae: 1.0213 - val_loss: 4.5348 - val_mae: 2.1059 - 36ms/epoch - 1ms/step\n",
      "Epoch 4144/5000\n",
      "31/31 - 0s - loss: 11.1234 - mae: 1.8083 - val_loss: 3.5087 - val_mae: 1.8466 - 36ms/epoch - 1ms/step\n",
      "Epoch 4145/5000\n",
      "31/31 - 0s - loss: 3.4833 - mae: 1.3762 - val_loss: 3.7112 - val_mae: 1.8989 - 37ms/epoch - 1ms/step\n",
      "Epoch 4146/5000\n",
      "31/31 - 0s - loss: 0.9241 - mae: 0.8012 - val_loss: 74.2768 - val_mae: 8.6121 - 37ms/epoch - 1ms/step\n",
      "Epoch 4147/5000\n",
      "31/31 - 0s - loss: 24.7477 - mae: 2.3619 - val_loss: 6.4709 - val_mae: 2.5255 - 35ms/epoch - 1ms/step\n",
      "Epoch 4148/5000\n",
      "31/31 - 0s - loss: 9.3727 - mae: 1.9992 - val_loss: 0.3048 - val_mae: 0.4482 - 36ms/epoch - 1ms/step\n",
      "Epoch 4149/5000\n",
      "31/31 - 0s - loss: 0.5800 - mae: 0.6345 - val_loss: 0.1164 - val_mae: 0.2745 - 36ms/epoch - 1ms/step\n",
      "Epoch 4150/5000\n",
      "31/31 - 0s - loss: 10.6743 - mae: 2.1768 - val_loss: 3.6457 - val_mae: 1.8810 - 34ms/epoch - 1ms/step\n",
      "Epoch 4151/5000\n",
      "31/31 - 0s - loss: 1.9191 - mae: 0.9830 - val_loss: 0.4705 - val_mae: 0.6068 - 34ms/epoch - 1ms/step\n",
      "Epoch 4152/5000\n",
      "31/31 - 0s - loss: 9.3080 - mae: 1.9520 - val_loss: 0.1097 - val_mae: 0.2838 - 35ms/epoch - 1ms/step\n",
      "Epoch 4153/5000\n",
      "31/31 - 0s - loss: 3.2066 - mae: 1.4535 - val_loss: 14.0198 - val_mae: 3.7312 - 45ms/epoch - 1ms/step\n",
      "Epoch 4154/5000\n",
      "31/31 - 0s - loss: 11.7934 - mae: 1.8893 - val_loss: 0.2275 - val_mae: 0.3571 - 34ms/epoch - 1ms/step\n",
      "Epoch 4155/5000\n",
      "31/31 - 0s - loss: 0.8563 - mae: 0.7209 - val_loss: 1.4684 - val_mae: 1.1700 - 37ms/epoch - 1ms/step\n",
      "Epoch 4156/5000\n",
      "31/31 - 0s - loss: 17.7387 - mae: 2.0203 - val_loss: 4.7027 - val_mae: 2.1433 - 36ms/epoch - 1ms/step\n",
      "Epoch 4157/5000\n",
      "31/31 - 0s - loss: 2.7599 - mae: 1.3324 - val_loss: 1.6388 - val_mae: 1.2411 - 37ms/epoch - 1ms/step\n",
      "Epoch 4158/5000\n",
      "31/31 - 0s - loss: 21.8182 - mae: 2.1020 - val_loss: 0.3013 - val_mae: 0.4467 - 38ms/epoch - 1ms/step\n",
      "Epoch 4159/5000\n",
      "31/31 - 0s - loss: 0.4887 - mae: 0.4935 - val_loss: 2.1485 - val_mae: 1.4302 - 36ms/epoch - 1ms/step\n",
      "Epoch 4160/5000\n",
      "31/31 - 0s - loss: 2.2744 - mae: 1.0124 - val_loss: 0.6091 - val_mae: 0.7158 - 38ms/epoch - 1ms/step\n",
      "Epoch 4161/5000\n",
      "31/31 - 0s - loss: 14.4402 - mae: 2.2436 - val_loss: 0.7533 - val_mae: 0.8055 - 36ms/epoch - 1ms/step\n",
      "Epoch 4162/5000\n",
      "31/31 - 0s - loss: 8.3952 - mae: 1.8835 - val_loss: 0.1327 - val_mae: 0.2780 - 34ms/epoch - 1ms/step\n",
      "Epoch 4163/5000\n",
      "31/31 - 0s - loss: 0.4771 - mae: 0.6073 - val_loss: 0.2684 - val_mae: 0.4102 - 37ms/epoch - 1ms/step\n",
      "Epoch 4164/5000\n",
      "31/31 - 0s - loss: 14.6074 - mae: 1.9111 - val_loss: 4.7049 - val_mae: 2.1459 - 36ms/epoch - 1ms/step\n",
      "Epoch 4165/5000\n",
      "31/31 - 0s - loss: 1.4509 - mae: 0.9584 - val_loss: 1.3694 - val_mae: 1.1250 - 35ms/epoch - 1ms/step\n",
      "Epoch 4166/5000\n",
      "31/31 - 0s - loss: 16.7607 - mae: 2.1132 - val_loss: 0.1117 - val_mae: 0.2723 - 37ms/epoch - 1ms/step\n",
      "Epoch 4167/5000\n",
      "31/31 - 0s - loss: 1.5600 - mae: 1.0058 - val_loss: 2.8525 - val_mae: 1.6591 - 34ms/epoch - 1ms/step\n",
      "Epoch 4168/5000\n",
      "31/31 - 0s - loss: 10.5354 - mae: 2.0691 - val_loss: 0.1023 - val_mae: 0.2650 - 36ms/epoch - 1ms/step\n",
      "Epoch 4169/5000\n",
      "31/31 - 0s - loss: 5.9419 - mae: 1.7795 - val_loss: 154.8424 - val_mae: 12.4402 - 33ms/epoch - 1ms/step\n",
      "Epoch 4170/5000\n",
      "31/31 - 0s - loss: 5.2193 - mae: 0.9304 - val_loss: 1.3947 - val_mae: 1.1366 - 35ms/epoch - 1ms/step\n",
      "Epoch 4171/5000\n",
      "31/31 - 0s - loss: 21.4446 - mae: 2.1821 - val_loss: 0.1081 - val_mae: 0.2838 - 35ms/epoch - 1ms/step\n",
      "Epoch 4172/5000\n",
      "31/31 - 0s - loss: 0.9535 - mae: 0.7319 - val_loss: 0.1425 - val_mae: 0.3453 - 37ms/epoch - 1ms/step\n",
      "Epoch 4173/5000\n",
      "31/31 - 0s - loss: 10.4414 - mae: 1.7289 - val_loss: 2.2925 - val_mae: 1.4785 - 35ms/epoch - 1ms/step\n",
      "Epoch 4174/5000\n",
      "31/31 - 0s - loss: 1.8535 - mae: 1.1701 - val_loss: 9.0355 - val_mae: 2.9900 - 36ms/epoch - 1ms/step\n",
      "Epoch 4175/5000\n",
      "31/31 - 0s - loss: 9.5036 - mae: 1.7580 - val_loss: 0.2689 - val_mae: 0.4047 - 36ms/epoch - 1ms/step\n",
      "Epoch 4176/5000\n",
      "31/31 - 0s - loss: 1.7439 - mae: 0.8206 - val_loss: 23.1910 - val_mae: 4.8040 - 35ms/epoch - 1ms/step\n",
      "Epoch 4177/5000\n",
      "31/31 - 0s - loss: 8.1337 - mae: 1.8300 - val_loss: 2.6966 - val_mae: 1.6106 - 35ms/epoch - 1ms/step\n",
      "Epoch 4178/5000\n",
      "31/31 - 0s - loss: 16.7012 - mae: 2.3534 - val_loss: 0.2875 - val_mae: 0.4354 - 37ms/epoch - 1ms/step\n",
      "Epoch 4179/5000\n",
      "31/31 - 0s - loss: 1.8722 - mae: 1.1798 - val_loss: 0.1824 - val_mae: 0.3868 - 36ms/epoch - 1ms/step\n",
      "Epoch 4180/5000\n",
      "31/31 - 0s - loss: 21.2946 - mae: 2.0151 - val_loss: 1.4945 - val_mae: 1.1794 - 35ms/epoch - 1ms/step\n",
      "Epoch 4181/5000\n",
      "31/31 - 0s - loss: 1.6849 - mae: 0.9133 - val_loss: 0.2052 - val_mae: 0.3332 - 35ms/epoch - 1ms/step\n",
      "Epoch 4182/5000\n",
      "31/31 - 0s - loss: 5.8955 - mae: 1.8599 - val_loss: 0.1150 - val_mae: 0.2790 - 39ms/epoch - 1ms/step\n",
      "Epoch 4183/5000\n",
      "31/31 - 0s - loss: 14.9073 - mae: 2.2283 - val_loss: 0.1224 - val_mae: 0.2860 - 36ms/epoch - 1ms/step\n",
      "Epoch 4184/5000\n",
      "31/31 - 0s - loss: 0.7556 - mae: 0.6340 - val_loss: 0.3130 - val_mae: 0.4551 - 38ms/epoch - 1ms/step\n",
      "Epoch 4185/5000\n",
      "31/31 - 0s - loss: 14.4954 - mae: 2.0565 - val_loss: 3.3035 - val_mae: 1.7926 - 36ms/epoch - 1ms/step\n",
      "Epoch 4186/5000\n",
      "31/31 - 0s - loss: 3.0863 - mae: 1.3730 - val_loss: 1.9710 - val_mae: 1.3677 - 37ms/epoch - 1ms/step\n",
      "Epoch 4187/5000\n",
      "31/31 - 0s - loss: 0.8887 - mae: 0.7188 - val_loss: 0.1627 - val_mae: 0.2973 - 36ms/epoch - 1ms/step\n",
      "Epoch 4188/5000\n",
      "31/31 - 0s - loss: 38.9397 - mae: 2.3052 - val_loss: 1.0770 - val_mae: 0.9836 - 34ms/epoch - 1ms/step\n",
      "Epoch 4189/5000\n",
      "31/31 - 0s - loss: 1.7321 - mae: 1.0578 - val_loss: 1.4661 - val_mae: 1.1667 - 36ms/epoch - 1ms/step\n",
      "Epoch 4190/5000\n",
      "31/31 - 0s - loss: 10.9757 - mae: 1.9498 - val_loss: 0.1367 - val_mae: 0.2783 - 35ms/epoch - 1ms/step\n",
      "Epoch 4191/5000\n",
      "31/31 - 0s - loss: 0.8271 - mae: 0.7181 - val_loss: 1.5792 - val_mae: 1.2160 - 36ms/epoch - 1ms/step\n",
      "Epoch 4192/5000\n",
      "31/31 - 0s - loss: 18.7004 - mae: 2.0676 - val_loss: 2.9830 - val_mae: 1.6996 - 37ms/epoch - 1ms/step\n",
      "Epoch 4193/5000\n",
      "31/31 - 0s - loss: 2.0805 - mae: 1.1085 - val_loss: 0.7592 - val_mae: 0.8113 - 39ms/epoch - 1ms/step\n",
      "Epoch 4194/5000\n",
      "31/31 - 0s - loss: 13.7601 - mae: 1.7342 - val_loss: 55.0872 - val_mae: 7.4156 - 37ms/epoch - 1ms/step\n",
      "Epoch 4195/5000\n",
      "31/31 - 0s - loss: 3.9738 - mae: 1.1519 - val_loss: 1.3652 - val_mae: 1.1262 - 38ms/epoch - 1ms/step\n",
      "Epoch 4196/5000\n",
      "31/31 - 0s - loss: 5.8726 - mae: 1.2969 - val_loss: 66.0582 - val_mae: 8.1215 - 36ms/epoch - 1ms/step\n",
      "Epoch 4197/5000\n",
      "31/31 - 0s - loss: 4.4229 - mae: 1.4606 - val_loss: 1.2108 - val_mae: 1.0523 - 39ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4198/5000\n",
      "31/31 - 0s - loss: 10.2506 - mae: 1.7769 - val_loss: 0.1375 - val_mae: 0.3356 - 38ms/epoch - 1ms/step\n",
      "Epoch 4199/5000\n",
      "31/31 - 0s - loss: 1.6892 - mae: 1.0625 - val_loss: 0.2654 - val_mae: 0.4015 - 37ms/epoch - 1ms/step\n",
      "Epoch 4200/5000\n",
      "31/31 - 0s - loss: 18.1913 - mae: 1.9813 - val_loss: 3.8544 - val_mae: 1.9369 - 37ms/epoch - 1ms/step\n",
      "Epoch 4201/5000\n",
      "31/31 - 0s - loss: 2.8808 - mae: 1.3239 - val_loss: 0.3982 - val_mae: 0.5444 - 36ms/epoch - 1ms/step\n",
      "Epoch 4202/5000\n",
      "31/31 - 0s - loss: 4.9892 - mae: 1.7025 - val_loss: 3.5158 - val_mae: 1.8463 - 38ms/epoch - 1ms/step\n",
      "Epoch 4203/5000\n",
      "31/31 - 0s - loss: 29.0639 - mae: 1.8959 - val_loss: 74.0597 - val_mae: 8.5994 - 36ms/epoch - 1ms/step\n",
      "Epoch 4204/5000\n",
      "31/31 - 0s - loss: 4.5222 - mae: 1.2760 - val_loss: 0.4173 - val_mae: 0.5593 - 36ms/epoch - 1ms/step\n",
      "Epoch 4205/5000\n",
      "31/31 - 0s - loss: 2.8089 - mae: 1.3239 - val_loss: 1.1286 - val_mae: 1.0121 - 37ms/epoch - 1ms/step\n",
      "Epoch 4206/5000\n",
      "31/31 - 0s - loss: 12.0862 - mae: 2.0376 - val_loss: 0.5372 - val_mae: 0.6579 - 37ms/epoch - 1ms/step\n",
      "Epoch 4207/5000\n",
      "31/31 - 0s - loss: 1.1123 - mae: 0.7913 - val_loss: 0.1064 - val_mae: 0.2805 - 39ms/epoch - 1ms/step\n",
      "Epoch 4208/5000\n",
      "31/31 - 0s - loss: 10.5187 - mae: 1.8707 - val_loss: 9.0018 - val_mae: 2.9818 - 37ms/epoch - 1ms/step\n",
      "Epoch 4209/5000\n",
      "31/31 - 0s - loss: 8.9813 - mae: 2.2175 - val_loss: 10.1791 - val_mae: 3.1738 - 35ms/epoch - 1ms/step\n",
      "Epoch 4210/5000\n",
      "31/31 - 0s - loss: 0.8237 - mae: 0.5593 - val_loss: 0.3071 - val_mae: 0.4514 - 37ms/epoch - 1ms/step\n",
      "Epoch 4211/5000\n",
      "31/31 - 0s - loss: 11.1259 - mae: 1.7243 - val_loss: 0.5571 - val_mae: 0.6698 - 37ms/epoch - 1ms/step\n",
      "Epoch 4212/5000\n",
      "31/31 - 0s - loss: 4.0968 - mae: 1.4867 - val_loss: 0.4829 - val_mae: 0.6151 - 38ms/epoch - 1ms/step\n",
      "Epoch 4213/5000\n",
      "31/31 - 0s - loss: 20.8795 - mae: 2.0501 - val_loss: 0.1150 - val_mae: 0.2942 - 37ms/epoch - 1ms/step\n",
      "Epoch 4214/5000\n",
      "31/31 - 0s - loss: 1.0603 - mae: 0.8019 - val_loss: 0.1680 - val_mae: 0.3023 - 38ms/epoch - 1ms/step\n",
      "Epoch 4215/5000\n",
      "31/31 - 0s - loss: 2.4521 - mae: 1.2038 - val_loss: 21.0968 - val_mae: 4.5821 - 37ms/epoch - 1ms/step\n",
      "Epoch 4216/5000\n",
      "31/31 - 0s - loss: 17.7594 - mae: 1.8816 - val_loss: 4.9889 - val_mae: 2.2105 - 37ms/epoch - 1ms/step\n",
      "Epoch 4217/5000\n",
      "31/31 - 0s - loss: 0.8447 - mae: 0.7396 - val_loss: 0.9452 - val_mae: 0.9200 - 39ms/epoch - 1ms/step\n",
      "Epoch 4218/5000\n",
      "31/31 - 0s - loss: 16.0980 - mae: 2.0039 - val_loss: 1.2224 - val_mae: 1.0593 - 39ms/epoch - 1ms/step\n",
      "Epoch 4219/5000\n",
      "31/31 - 0s - loss: 0.9199 - mae: 0.6946 - val_loss: 0.2534 - val_mae: 0.3888 - 36ms/epoch - 1ms/step\n",
      "Epoch 4220/5000\n",
      "31/31 - 0s - loss: 12.7286 - mae: 2.7863 - val_loss: 0.3693 - val_mae: 0.5199 - 35ms/epoch - 1ms/step\n",
      "Epoch 4221/5000\n",
      "31/31 - 0s - loss: 2.7597 - mae: 1.3598 - val_loss: 37.3550 - val_mae: 6.1043 - 36ms/epoch - 1ms/step\n",
      "Epoch 4222/5000\n",
      "31/31 - 0s - loss: 16.3110 - mae: 1.7545 - val_loss: 1.0005 - val_mae: 0.9467 - 36ms/epoch - 1ms/step\n",
      "Epoch 4223/5000\n",
      "31/31 - 0s - loss: 6.4636 - mae: 1.7923 - val_loss: 0.3495 - val_mae: 0.4902 - 37ms/epoch - 1ms/step\n",
      "Epoch 4224/5000\n",
      "31/31 - 0s - loss: 1.5361 - mae: 0.9797 - val_loss: 0.2901 - val_mae: 0.4315 - 37ms/epoch - 1ms/step\n",
      "Epoch 4225/5000\n",
      "31/31 - 0s - loss: 17.1047 - mae: 1.9761 - val_loss: 0.1104 - val_mae: 0.2836 - 38ms/epoch - 1ms/step\n",
      "Epoch 4226/5000\n",
      "31/31 - 0s - loss: 1.4267 - mae: 0.8185 - val_loss: 0.4813 - val_mae: 0.6144 - 39ms/epoch - 1ms/step\n",
      "Epoch 4227/5000\n",
      "31/31 - 0s - loss: 18.6129 - mae: 2.0765 - val_loss: 0.3716 - val_mae: 0.5163 - 40ms/epoch - 1ms/step\n",
      "Epoch 4228/5000\n",
      "31/31 - 0s - loss: 0.5843 - mae: 0.5220 - val_loss: 0.1767 - val_mae: 0.3113 - 37ms/epoch - 1ms/step\n",
      "Epoch 4229/5000\n",
      "31/31 - 0s - loss: 13.8834 - mae: 2.1973 - val_loss: 0.3047 - val_mae: 0.4463 - 37ms/epoch - 1ms/step\n",
      "Epoch 4230/5000\n",
      "31/31 - 0s - loss: 0.7213 - mae: 0.6634 - val_loss: 0.7857 - val_mae: 0.8267 - 37ms/epoch - 1ms/step\n",
      "Epoch 4231/5000\n",
      "31/31 - 0s - loss: 12.4651 - mae: 2.0001 - val_loss: 0.1855 - val_mae: 0.3891 - 35ms/epoch - 1ms/step\n",
      "Epoch 4232/5000\n",
      "31/31 - 0s - loss: 0.3186 - mae: 0.4809 - val_loss: 0.6253 - val_mae: 0.7219 - 36ms/epoch - 1ms/step\n",
      "Epoch 4233/5000\n",
      "31/31 - 0s - loss: 15.1969 - mae: 2.4512 - val_loss: 0.7609 - val_mae: 0.8148 - 36ms/epoch - 1ms/step\n",
      "Epoch 4234/5000\n",
      "31/31 - 0s - loss: 0.7973 - mae: 0.6354 - val_loss: 8.9883 - val_mae: 2.9816 - 36ms/epoch - 1ms/step\n",
      "Epoch 4235/5000\n",
      "31/31 - 0s - loss: 8.1528 - mae: 1.7150 - val_loss: 0.5638 - val_mae: 0.6744 - 38ms/epoch - 1ms/step\n",
      "Epoch 4236/5000\n",
      "31/31 - 0s - loss: 2.2241 - mae: 1.1381 - val_loss: 0.1169 - val_mae: 0.3015 - 36ms/epoch - 1ms/step\n",
      "Epoch 4237/5000\n",
      "31/31 - 0s - loss: 16.1608 - mae: 2.1943 - val_loss: 3.9568 - val_mae: 1.9629 - 36ms/epoch - 1ms/step\n",
      "Epoch 4238/5000\n",
      "31/31 - 0s - loss: 1.1062 - mae: 0.9082 - val_loss: 1.5359 - val_mae: 1.1969 - 40ms/epoch - 1ms/step\n",
      "Epoch 4239/5000\n",
      "31/31 - 0s - loss: 11.7024 - mae: 1.7747 - val_loss: 0.2453 - val_mae: 0.3730 - 35ms/epoch - 1ms/step\n",
      "Epoch 4240/5000\n",
      "31/31 - 0s - loss: 1.2668 - mae: 0.8696 - val_loss: 0.1086 - val_mae: 0.2871 - 36ms/epoch - 1ms/step\n",
      "Epoch 4241/5000\n",
      "31/31 - 0s - loss: 12.2706 - mae: 1.9495 - val_loss: 0.1399 - val_mae: 0.2850 - 35ms/epoch - 1ms/step\n",
      "Epoch 4242/5000\n",
      "31/31 - 0s - loss: 1.2764 - mae: 0.8264 - val_loss: 2.9345 - val_mae: 1.6837 - 36ms/epoch - 1ms/step\n",
      "Epoch 4243/5000\n",
      "31/31 - 0s - loss: 13.7537 - mae: 1.8463 - val_loss: 0.1056 - val_mae: 0.2807 - 35ms/epoch - 1ms/step\n",
      "Epoch 4244/5000\n",
      "31/31 - 0s - loss: 0.8564 - mae: 0.7559 - val_loss: 0.5064 - val_mae: 0.6325 - 38ms/epoch - 1ms/step\n",
      "Epoch 4245/5000\n",
      "31/31 - 0s - loss: 13.6714 - mae: 1.8531 - val_loss: 0.9342 - val_mae: 0.9120 - 39ms/epoch - 1ms/step\n",
      "Epoch 4246/5000\n",
      "31/31 - 0s - loss: 2.8705 - mae: 1.2547 - val_loss: 0.4056 - val_mae: 0.5495 - 38ms/epoch - 1ms/step\n",
      "Epoch 4247/5000\n",
      "31/31 - 0s - loss: 24.8755 - mae: 2.1401 - val_loss: 0.1841 - val_mae: 0.3180 - 37ms/epoch - 1ms/step\n",
      "Epoch 4248/5000\n",
      "31/31 - 0s - loss: 1.1396 - mae: 0.7672 - val_loss: 0.9001 - val_mae: 0.8914 - 39ms/epoch - 1ms/step\n",
      "Epoch 4249/5000\n",
      "31/31 - 0s - loss: 0.6067 - mae: 0.6287 - val_loss: 8.0289 - val_mae: 2.8164 - 38ms/epoch - 1ms/step\n",
      "Epoch 4250/5000\n",
      "31/31 - 0s - loss: 23.9775 - mae: 2.2079 - val_loss: 1.5059 - val_mae: 1.1851 - 36ms/epoch - 1ms/step\n",
      "Epoch 4251/5000\n",
      "31/31 - 0s - loss: 2.1670 - mae: 1.0302 - val_loss: 4.9344 - val_mae: 2.1950 - 41ms/epoch - 1ms/step\n",
      "Epoch 4252/5000\n",
      "31/31 - 0s - loss: 6.4607 - mae: 1.6286 - val_loss: 0.9498 - val_mae: 0.9199 - 37ms/epoch - 1ms/step\n",
      "Epoch 4253/5000\n",
      "31/31 - 0s - loss: 20.8281 - mae: 1.8764 - val_loss: 0.1119 - val_mae: 0.2919 - 36ms/epoch - 1ms/step\n",
      "Epoch 4254/5000\n",
      "31/31 - 0s - loss: 1.8369 - mae: 0.9918 - val_loss: 6.9198 - val_mae: 2.6097 - 35ms/epoch - 1ms/step\n",
      "Epoch 4255/5000\n",
      "31/31 - 0s - loss: 1.8598 - mae: 1.0941 - val_loss: 48.6962 - val_mae: 6.9700 - 35ms/epoch - 1ms/step\n",
      "Epoch 4256/5000\n",
      "31/31 - 0s - loss: 21.8733 - mae: 2.0622 - val_loss: 3.3676 - val_mae: 1.8072 - 36ms/epoch - 1ms/step\n",
      "Epoch 4257/5000\n",
      "31/31 - 0s - loss: 1.8587 - mae: 1.0258 - val_loss: 0.8587 - val_mae: 0.8678 - 35ms/epoch - 1ms/step\n",
      "Epoch 4258/5000\n",
      "31/31 - 0s - loss: 13.0405 - mae: 2.1752 - val_loss: 0.6406 - val_mae: 0.7311 - 36ms/epoch - 1ms/step\n",
      "Epoch 4259/5000\n",
      "31/31 - 0s - loss: 1.0673 - mae: 0.8951 - val_loss: 3.8955 - val_mae: 1.9487 - 37ms/epoch - 1ms/step\n",
      "Epoch 4260/5000\n",
      "31/31 - 0s - loss: 20.2368 - mae: 2.0374 - val_loss: 0.3180 - val_mae: 0.4797 - 36ms/epoch - 1ms/step\n",
      "Epoch 4261/5000\n",
      "31/31 - 0s - loss: 1.4288 - mae: 0.9039 - val_loss: 0.7801 - val_mae: 0.8210 - 39ms/epoch - 1ms/step\n",
      "Epoch 4262/5000\n",
      "31/31 - 0s - loss: 20.7934 - mae: 1.9800 - val_loss: 0.1973 - val_mae: 0.3295 - 45ms/epoch - 1ms/step\n",
      "Epoch 4263/5000\n",
      "31/31 - 0s - loss: 1.1064 - mae: 0.8409 - val_loss: 0.2015 - val_mae: 0.3318 - 36ms/epoch - 1ms/step\n",
      "Epoch 4264/5000\n",
      "31/31 - 0s - loss: 24.8190 - mae: 2.1615 - val_loss: 0.2183 - val_mae: 0.3494 - 39ms/epoch - 1ms/step\n",
      "Epoch 4265/5000\n",
      "31/31 - 0s - loss: 1.4879 - mae: 0.9307 - val_loss: 1.5190 - val_mae: 1.1873 - 39ms/epoch - 1ms/step\n",
      "Epoch 4266/5000\n",
      "31/31 - 0s - loss: 5.4118 - mae: 1.5617 - val_loss: 0.1143 - val_mae: 0.2981 - 37ms/epoch - 1ms/step\n",
      "Epoch 4267/5000\n",
      "31/31 - 0s - loss: 10.0821 - mae: 1.7823 - val_loss: 0.6028 - val_mae: 0.7039 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4268/5000\n",
      "31/31 - 0s - loss: 0.9976 - mae: 0.8539 - val_loss: 2.1275 - val_mae: 1.4231 - 37ms/epoch - 1ms/step\n",
      "Epoch 4269/5000\n",
      "31/31 - 0s - loss: 11.8133 - mae: 1.8120 - val_loss: 0.3311 - val_mae: 0.4882 - 38ms/epoch - 1ms/step\n",
      "Epoch 4270/5000\n",
      "31/31 - 0s - loss: 1.9062 - mae: 1.0740 - val_loss: 0.4177 - val_mae: 0.5594 - 36ms/epoch - 1ms/step\n",
      "Epoch 4271/5000\n",
      "31/31 - 0s - loss: 7.8115 - mae: 2.1185 - val_loss: 0.1516 - val_mae: 0.2856 - 36ms/epoch - 1ms/step\n",
      "Epoch 4272/5000\n",
      "31/31 - 0s - loss: 16.3694 - mae: 2.6026 - val_loss: 0.1829 - val_mae: 0.3869 - 35ms/epoch - 1ms/step\n",
      "Epoch 4273/5000\n",
      "31/31 - 0s - loss: 0.9969 - mae: 0.7790 - val_loss: 0.5512 - val_mae: 0.6677 - 36ms/epoch - 1ms/step\n",
      "Epoch 4274/5000\n",
      "31/31 - 0s - loss: 12.6989 - mae: 1.9184 - val_loss: 0.3180 - val_mae: 0.4784 - 35ms/epoch - 1ms/step\n",
      "Epoch 4275/5000\n",
      "31/31 - 0s - loss: 1.2979 - mae: 0.8938 - val_loss: 0.1116 - val_mae: 0.2871 - 36ms/epoch - 1ms/step\n",
      "Epoch 4276/5000\n",
      "31/31 - 0s - loss: 11.3537 - mae: 2.0035 - val_loss: 23.3494 - val_mae: 4.8208 - 37ms/epoch - 1ms/step\n",
      "Epoch 4277/5000\n",
      "31/31 - 0s - loss: 1.6900 - mae: 0.9133 - val_loss: 1.9897 - val_mae: 1.3733 - 36ms/epoch - 1ms/step\n",
      "Epoch 4278/5000\n",
      "31/31 - 0s - loss: 19.6963 - mae: 1.8692 - val_loss: 24.1814 - val_mae: 4.9059 - 38ms/epoch - 1ms/step\n",
      "Epoch 4279/5000\n",
      "31/31 - 0s - loss: 2.0282 - mae: 0.9142 - val_loss: 0.6496 - val_mae: 0.7381 - 36ms/epoch - 1ms/step\n",
      "Epoch 4280/5000\n",
      "31/31 - 0s - loss: 6.6621 - mae: 1.5645 - val_loss: 22.8154 - val_mae: 4.7657 - 37ms/epoch - 1ms/step\n",
      "Epoch 4281/5000\n",
      "31/31 - 0s - loss: 2.4139 - mae: 0.9925 - val_loss: 4.8892 - val_mae: 2.1892 - 36ms/epoch - 1ms/step\n",
      "Epoch 4282/5000\n",
      "31/31 - 0s - loss: 12.3389 - mae: 2.0560 - val_loss: 0.1440 - val_mae: 0.2813 - 39ms/epoch - 1ms/step\n",
      "Epoch 4283/5000\n",
      "31/31 - 0s - loss: 2.0655 - mae: 0.9783 - val_loss: 0.4422 - val_mae: 0.5801 - 36ms/epoch - 1ms/step\n",
      "Epoch 4284/5000\n",
      "31/31 - 0s - loss: 23.7616 - mae: 2.4964 - val_loss: 8.8074 - val_mae: 2.9496 - 35ms/epoch - 1ms/step\n",
      "Epoch 4285/5000\n",
      "31/31 - 0s - loss: 2.0170 - mae: 1.0774 - val_loss: 0.1050 - val_mae: 0.2825 - 36ms/epoch - 1ms/step\n",
      "Epoch 4286/5000\n",
      "31/31 - 0s - loss: 15.4315 - mae: 1.9925 - val_loss: 1.8937 - val_mae: 1.3366 - 36ms/epoch - 1ms/step\n",
      "Epoch 4287/5000\n",
      "31/31 - 0s - loss: 1.0678 - mae: 0.7743 - val_loss: 0.3293 - val_mae: 0.4739 - 38ms/epoch - 1ms/step\n",
      "Epoch 4288/5000\n",
      "31/31 - 0s - loss: 28.4022 - mae: 2.0322 - val_loss: 0.5965 - val_mae: 0.7028 - 36ms/epoch - 1ms/step\n",
      "Epoch 4289/5000\n",
      "31/31 - 0s - loss: 2.3301 - mae: 0.9551 - val_loss: 2.8164 - val_mae: 1.6469 - 36ms/epoch - 1ms/step\n",
      "Epoch 4290/5000\n",
      "31/31 - 0s - loss: 7.7501 - mae: 1.5773 - val_loss: 33.2890 - val_mae: 5.7619 - 38ms/epoch - 1ms/step\n",
      "Epoch 4291/5000\n",
      "31/31 - 0s - loss: 3.7348 - mae: 1.6067 - val_loss: 2.4617 - val_mae: 1.5376 - 37ms/epoch - 1ms/step\n",
      "Epoch 4292/5000\n",
      "31/31 - 0s - loss: 18.3804 - mae: 2.0960 - val_loss: 29.0394 - val_mae: 5.3794 - 36ms/epoch - 1ms/step\n",
      "Epoch 4293/5000\n",
      "31/31 - 0s - loss: 1.8485 - mae: 0.9325 - val_loss: 0.1157 - val_mae: 0.3018 - 36ms/epoch - 1ms/step\n",
      "Epoch 4294/5000\n",
      "31/31 - 0s - loss: 0.9992 - mae: 0.8502 - val_loss: 0.1252 - val_mae: 0.2826 - 35ms/epoch - 1ms/step\n",
      "Epoch 4295/5000\n",
      "31/31 - 0s - loss: 21.0577 - mae: 2.0723 - val_loss: 2.0107 - val_mae: 1.3828 - 36ms/epoch - 1ms/step\n",
      "Epoch 4296/5000\n",
      "31/31 - 0s - loss: 1.6273 - mae: 1.0293 - val_loss: 0.1295 - val_mae: 0.2841 - 36ms/epoch - 1ms/step\n",
      "Epoch 4297/5000\n",
      "31/31 - 0s - loss: 3.3380 - mae: 1.3257 - val_loss: 0.4935 - val_mae: 0.6281 - 42ms/epoch - 1ms/step\n",
      "Epoch 4298/5000\n",
      "31/31 - 0s - loss: 31.2817 - mae: 2.1082 - val_loss: 0.1645 - val_mae: 0.3689 - 44ms/epoch - 1ms/step\n",
      "Epoch 4299/5000\n",
      "31/31 - 0s - loss: 1.4780 - mae: 0.7916 - val_loss: 0.9122 - val_mae: 0.9007 - 43ms/epoch - 1ms/step\n",
      "Epoch 4300/5000\n",
      "31/31 - 0s - loss: 5.0739 - mae: 1.6951 - val_loss: 0.8881 - val_mae: 0.8843 - 40ms/epoch - 1ms/step\n",
      "Epoch 4301/5000\n",
      "31/31 - 0s - loss: 0.9126 - mae: 0.7655 - val_loss: 1.3036 - val_mae: 1.0960 - 40ms/epoch - 1ms/step\n",
      "Epoch 4302/5000\n",
      "31/31 - 0s - loss: 21.0453 - mae: 2.2992 - val_loss: 0.1912 - val_mae: 0.3222 - 40ms/epoch - 1ms/step\n",
      "Epoch 4303/5000\n",
      "31/31 - 0s - loss: 1.8995 - mae: 1.0337 - val_loss: 0.2243 - val_mae: 0.4198 - 42ms/epoch - 1ms/step\n",
      "Epoch 4304/5000\n",
      "31/31 - 0s - loss: 16.8179 - mae: 1.9755 - val_loss: 0.1580 - val_mae: 0.2918 - 43ms/epoch - 1ms/step\n",
      "Epoch 4305/5000\n",
      "31/31 - 0s - loss: 0.9546 - mae: 0.8164 - val_loss: 2.2783 - val_mae: 1.4747 - 44ms/epoch - 1ms/step\n",
      "Epoch 4306/5000\n",
      "31/31 - 0s - loss: 0.9017 - mae: 0.8008 - val_loss: 1.0148 - val_mae: 0.9547 - 51ms/epoch - 2ms/step\n",
      "Epoch 4307/5000\n",
      "31/31 - 0s - loss: 18.7758 - mae: 2.4026 - val_loss: 0.9707 - val_mae: 0.9301 - 43ms/epoch - 1ms/step\n",
      "Epoch 4308/5000\n",
      "31/31 - 0s - loss: 2.7225 - mae: 1.3590 - val_loss: 29.6209 - val_mae: 5.4319 - 43ms/epoch - 1ms/step\n",
      "Epoch 4309/5000\n",
      "31/31 - 0s - loss: 7.0060 - mae: 1.3968 - val_loss: 0.5553 - val_mae: 0.6725 - 50ms/epoch - 2ms/step\n",
      "Epoch 4310/5000\n",
      "31/31 - 0s - loss: 20.4727 - mae: 1.7059 - val_loss: 242.8359 - val_mae: 15.5801 - 56ms/epoch - 2ms/step\n",
      "Epoch 4311/5000\n",
      "31/31 - 0s - loss: 10.9704 - mae: 1.7930 - val_loss: 1.9364 - val_mae: 1.3529 - 43ms/epoch - 1ms/step\n",
      "Epoch 4312/5000\n",
      "31/31 - 0s - loss: 4.0917 - mae: 1.4306 - val_loss: 18.6819 - val_mae: 4.3106 - 43ms/epoch - 1ms/step\n",
      "Epoch 4313/5000\n",
      "31/31 - 0s - loss: 3.2257 - mae: 1.1721 - val_loss: 0.8273 - val_mae: 0.8502 - 43ms/epoch - 1ms/step\n",
      "Epoch 4314/5000\n",
      "31/31 - 0s - loss: 22.9163 - mae: 2.0700 - val_loss: 0.1635 - val_mae: 0.3673 - 49ms/epoch - 2ms/step\n",
      "Epoch 4315/5000\n",
      "31/31 - 0s - loss: 1.7420 - mae: 1.0881 - val_loss: 0.6473 - val_mae: 0.7381 - 47ms/epoch - 2ms/step\n",
      "Epoch 4316/5000\n",
      "31/31 - 0s - loss: 14.9579 - mae: 2.0242 - val_loss: 0.6371 - val_mae: 0.7314 - 46ms/epoch - 1ms/step\n",
      "Epoch 4317/5000\n",
      "31/31 - 0s - loss: 0.6729 - mae: 0.6429 - val_loss: 1.5763 - val_mae: 1.2141 - 46ms/epoch - 1ms/step\n",
      "Epoch 4318/5000\n",
      "31/31 - 0s - loss: 15.6513 - mae: 1.8803 - val_loss: 0.3494 - val_mae: 0.4922 - 48ms/epoch - 2ms/step\n",
      "Epoch 4319/5000\n",
      "31/31 - 0s - loss: 2.1540 - mae: 1.0315 - val_loss: 7.3536 - val_mae: 2.6924 - 49ms/epoch - 2ms/step\n",
      "Epoch 4320/5000\n",
      "31/31 - 0s - loss: 21.4470 - mae: 2.4304 - val_loss: 0.4977 - val_mae: 0.6303 - 46ms/epoch - 1ms/step\n",
      "Epoch 4321/5000\n",
      "31/31 - 0s - loss: 0.9439 - mae: 0.7153 - val_loss: 2.0126 - val_mae: 1.3828 - 46ms/epoch - 1ms/step\n",
      "Epoch 4322/5000\n",
      "31/31 - 0s - loss: 5.4475 - mae: 1.0864 - val_loss: 0.1274 - val_mae: 0.2851 - 50ms/epoch - 2ms/step\n",
      "Epoch 4323/5000\n",
      "31/31 - 0s - loss: 3.6769 - mae: 1.2711 - val_loss: 8.0538 - val_mae: 2.8206 - 50ms/epoch - 2ms/step\n",
      "Epoch 4324/5000\n",
      "31/31 - 0s - loss: 18.7123 - mae: 2.2727 - val_loss: 0.1056 - val_mae: 0.2745 - 41ms/epoch - 1ms/step\n",
      "Epoch 4325/5000\n",
      "31/31 - 0s - loss: 1.6489 - mae: 0.9717 - val_loss: 0.1195 - val_mae: 0.3078 - 41ms/epoch - 1ms/step\n",
      "Epoch 4326/5000\n",
      "31/31 - 0s - loss: 1.2487 - mae: 0.8616 - val_loss: 0.4777 - val_mae: 0.6121 - 40ms/epoch - 1ms/step\n",
      "Epoch 4327/5000\n",
      "31/31 - 0s - loss: 28.2013 - mae: 2.3397 - val_loss: 0.1293 - val_mae: 0.3224 - 40ms/epoch - 1ms/step\n",
      "Epoch 4328/5000\n",
      "31/31 - 0s - loss: 3.8482 - mae: 1.4210 - val_loss: 7.9124 - val_mae: 2.7941 - 40ms/epoch - 1ms/step\n",
      "Epoch 4329/5000\n",
      "31/31 - 0s - loss: 0.6919 - mae: 0.5943 - val_loss: 0.7301 - val_mae: 0.7886 - 39ms/epoch - 1ms/step\n",
      "Epoch 4330/5000\n",
      "31/31 - 0s - loss: 15.4776 - mae: 1.9852 - val_loss: 0.1338 - val_mae: 0.2825 - 41ms/epoch - 1ms/step\n",
      "Epoch 4331/5000\n",
      "31/31 - 0s - loss: 0.7785 - mae: 0.6899 - val_loss: 0.3812 - val_mae: 0.5300 - 39ms/epoch - 1ms/step\n",
      "Epoch 4332/5000\n",
      "31/31 - 0s - loss: 16.9626 - mae: 1.8055 - val_loss: 0.1170 - val_mae: 0.2763 - 40ms/epoch - 1ms/step\n",
      "Epoch 4333/5000\n",
      "31/31 - 0s - loss: 1.3743 - mae: 0.8825 - val_loss: 0.5743 - val_mae: 0.6869 - 40ms/epoch - 1ms/step\n",
      "Epoch 4334/5000\n",
      "31/31 - 0s - loss: 5.6284 - mae: 1.6540 - val_loss: 0.1652 - val_mae: 0.2991 - 40ms/epoch - 1ms/step\n",
      "Epoch 4335/5000\n",
      "31/31 - 0s - loss: 1.1879 - mae: 0.7466 - val_loss: 0.3981 - val_mae: 0.5434 - 40ms/epoch - 1ms/step\n",
      "Epoch 4336/5000\n",
      "31/31 - 0s - loss: 29.6953 - mae: 2.0343 - val_loss: 0.1437 - val_mae: 0.3478 - 37ms/epoch - 1ms/step\n",
      "Epoch 4337/5000\n",
      "31/31 - 0s - loss: 1.6140 - mae: 1.0852 - val_loss: 4.5594 - val_mae: 2.1115 - 39ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4338/5000\n",
      "31/31 - 0s - loss: 13.7221 - mae: 1.5369 - val_loss: 759.8826 - val_mae: 27.5643 - 35ms/epoch - 1ms/step\n",
      "Epoch 4339/5000\n",
      "31/31 - 0s - loss: 28.7387 - mae: 2.1670 - val_loss: 2.1228 - val_mae: 1.4223 - 38ms/epoch - 1ms/step\n",
      "Epoch 4340/5000\n",
      "31/31 - 0s - loss: 1.6976 - mae: 1.0956 - val_loss: 3.4035 - val_mae: 1.8156 - 37ms/epoch - 1ms/step\n",
      "Epoch 4341/5000\n",
      "31/31 - 0s - loss: 17.6986 - mae: 2.1426 - val_loss: 0.6445 - val_mae: 0.7327 - 37ms/epoch - 1ms/step\n",
      "Epoch 4342/5000\n",
      "31/31 - 0s - loss: 0.9773 - mae: 0.6996 - val_loss: 0.7196 - val_mae: 0.7839 - 38ms/epoch - 1ms/step\n",
      "Epoch 4343/5000\n",
      "31/31 - 0s - loss: 12.5512 - mae: 1.9372 - val_loss: 0.1074 - val_mae: 0.2866 - 38ms/epoch - 1ms/step\n",
      "Epoch 4344/5000\n",
      "31/31 - 0s - loss: 0.5947 - mae: 0.6746 - val_loss: 4.1050 - val_mae: 2.0013 - 37ms/epoch - 1ms/step\n",
      "Epoch 4345/5000\n",
      "31/31 - 0s - loss: 23.4353 - mae: 2.1798 - val_loss: 0.1843 - val_mae: 0.3143 - 37ms/epoch - 1ms/step\n",
      "Epoch 4346/5000\n",
      "31/31 - 0s - loss: 1.5237 - mae: 1.0050 - val_loss: 0.7212 - val_mae: 0.7857 - 37ms/epoch - 1ms/step\n",
      "Epoch 4347/5000\n",
      "31/31 - 0s - loss: 19.7910 - mae: 2.3134 - val_loss: 0.5851 - val_mae: 0.6966 - 36ms/epoch - 1ms/step\n",
      "Epoch 4348/5000\n",
      "31/31 - 0s - loss: 1.0570 - mae: 0.6998 - val_loss: 0.2342 - val_mae: 0.3610 - 38ms/epoch - 1ms/step\n",
      "Epoch 4349/5000\n",
      "31/31 - 0s - loss: 9.2435 - mae: 1.7722 - val_loss: 0.5001 - val_mae: 0.6280 - 35ms/epoch - 1ms/step\n",
      "Epoch 4350/5000\n",
      "31/31 - 0s - loss: 1.1011 - mae: 0.7980 - val_loss: 0.4275 - val_mae: 0.5663 - 36ms/epoch - 1ms/step\n",
      "Epoch 4351/5000\n",
      "31/31 - 0s - loss: 22.4751 - mae: 2.1342 - val_loss: 0.1130 - val_mae: 0.2853 - 36ms/epoch - 1ms/step\n",
      "Epoch 4352/5000\n",
      "31/31 - 0s - loss: 1.2773 - mae: 0.8262 - val_loss: 0.6315 - val_mae: 0.7246 - 36ms/epoch - 1ms/step\n",
      "Epoch 4353/5000\n",
      "31/31 - 0s - loss: 3.7370 - mae: 1.1259 - val_loss: 0.7621 - val_mae: 0.8082 - 35ms/epoch - 1ms/step\n",
      "Epoch 4354/5000\n",
      "31/31 - 0s - loss: 8.2804 - mae: 1.9839 - val_loss: 0.1074 - val_mae: 0.2838 - 35ms/epoch - 1ms/step\n",
      "Epoch 4355/5000\n",
      "31/31 - 0s - loss: 19.5852 - mae: 2.4372 - val_loss: 0.4679 - val_mae: 0.6061 - 37ms/epoch - 1ms/step\n",
      "Epoch 4356/5000\n",
      "31/31 - 0s - loss: 2.0827 - mae: 0.8952 - val_loss: 0.4118 - val_mae: 0.5550 - 37ms/epoch - 1ms/step\n",
      "Epoch 4357/5000\n",
      "31/31 - 0s - loss: 1.4026 - mae: 0.6977 - val_loss: 3.4084 - val_mae: 1.8148 - 37ms/epoch - 1ms/step\n",
      "Epoch 4358/5000\n",
      "31/31 - 0s - loss: 12.8992 - mae: 1.8474 - val_loss: 1.9710 - val_mae: 1.3658 - 36ms/epoch - 1ms/step\n",
      "Epoch 4359/5000\n",
      "31/31 - 0s - loss: 0.9646 - mae: 0.8548 - val_loss: 1.1319 - val_mae: 1.0134 - 36ms/epoch - 1ms/step\n",
      "Epoch 4360/5000\n",
      "31/31 - 0s - loss: 8.4633 - mae: 1.8842 - val_loss: 0.1124 - val_mae: 0.2828 - 37ms/epoch - 1ms/step\n",
      "Epoch 4361/5000\n",
      "31/31 - 0s - loss: 13.0331 - mae: 2.0696 - val_loss: 0.1166 - val_mae: 0.2845 - 35ms/epoch - 1ms/step\n",
      "Epoch 4362/5000\n",
      "31/31 - 0s - loss: 0.5389 - mae: 0.5185 - val_loss: 8.0383 - val_mae: 2.8172 - 36ms/epoch - 1ms/step\n",
      "Epoch 4363/5000\n",
      "31/31 - 0s - loss: 15.6906 - mae: 1.8220 - val_loss: 0.1701 - val_mae: 0.3731 - 36ms/epoch - 1ms/step\n",
      "Epoch 4364/5000\n",
      "31/31 - 0s - loss: 2.1135 - mae: 1.1895 - val_loss: 0.1221 - val_mae: 0.2843 - 37ms/epoch - 1ms/step\n",
      "Epoch 4365/5000\n",
      "31/31 - 0s - loss: 10.5723 - mae: 1.9118 - val_loss: 1.6124 - val_mae: 1.2245 - 37ms/epoch - 1ms/step\n",
      "Epoch 4366/5000\n",
      "31/31 - 0s - loss: 3.1688 - mae: 1.2466 - val_loss: 0.5963 - val_mae: 0.6987 - 36ms/epoch - 1ms/step\n",
      "Epoch 4367/5000\n",
      "31/31 - 0s - loss: 3.6032 - mae: 1.2675 - val_loss: 236.4302 - val_mae: 15.3726 - 38ms/epoch - 1ms/step\n",
      "Epoch 4368/5000\n",
      "31/31 - 0s - loss: 10.0798 - mae: 1.6704 - val_loss: 0.1150 - val_mae: 0.2883 - 39ms/epoch - 1ms/step\n",
      "Epoch 4369/5000\n",
      "31/31 - 0s - loss: 17.2653 - mae: 2.4620 - val_loss: 1.7119 - val_mae: 1.2703 - 36ms/epoch - 1ms/step\n",
      "Epoch 4370/5000\n",
      "31/31 - 0s - loss: 1.5676 - mae: 0.8878 - val_loss: 0.3270 - val_mae: 0.4820 - 36ms/epoch - 1ms/step\n",
      "Epoch 4371/5000\n",
      "31/31 - 0s - loss: 9.9674 - mae: 1.6724 - val_loss: 0.3621 - val_mae: 0.5107 - 36ms/epoch - 1ms/step\n",
      "Epoch 4372/5000\n",
      "31/31 - 0s - loss: 0.8169 - mae: 0.7576 - val_loss: 1.5546 - val_mae: 1.2054 - 34ms/epoch - 1ms/step\n",
      "Epoch 4373/5000\n",
      "31/31 - 0s - loss: 19.5463 - mae: 1.8780 - val_loss: 0.1317 - val_mae: 0.2795 - 48ms/epoch - 2ms/step\n",
      "Epoch 4374/5000\n",
      "31/31 - 0s - loss: 0.8199 - mae: 0.7400 - val_loss: 0.5007 - val_mae: 0.6284 - 37ms/epoch - 1ms/step\n",
      "Epoch 4375/5000\n",
      "31/31 - 0s - loss: 20.3975 - mae: 2.4385 - val_loss: 2.0868 - val_mae: 1.4096 - 38ms/epoch - 1ms/step\n",
      "Epoch 4376/5000\n",
      "31/31 - 0s - loss: 0.9162 - mae: 0.6335 - val_loss: 0.1938 - val_mae: 0.3233 - 39ms/epoch - 1ms/step\n",
      "Epoch 4377/5000\n",
      "31/31 - 0s - loss: 5.7219 - mae: 1.4670 - val_loss: 56.5068 - val_mae: 7.5097 - 37ms/epoch - 1ms/step\n",
      "Epoch 4378/5000\n",
      "31/31 - 0s - loss: 4.4508 - mae: 1.3031 - val_loss: 1.1051 - val_mae: 1.0000 - 38ms/epoch - 1ms/step\n",
      "Epoch 4379/5000\n",
      "31/31 - 0s - loss: 9.9095 - mae: 2.0029 - val_loss: 5.5718 - val_mae: 2.3390 - 37ms/epoch - 1ms/step\n",
      "Epoch 4380/5000\n",
      "31/31 - 0s - loss: 1.0998 - mae: 0.8087 - val_loss: 0.7358 - val_mae: 0.7965 - 38ms/epoch - 1ms/step\n",
      "Epoch 4381/5000\n",
      "31/31 - 0s - loss: 14.5351 - mae: 2.1144 - val_loss: 0.2196 - val_mae: 0.3465 - 37ms/epoch - 1ms/step\n",
      "Epoch 4382/5000\n",
      "31/31 - 0s - loss: 1.3832 - mae: 0.9061 - val_loss: 1.7266 - val_mae: 1.2746 - 38ms/epoch - 1ms/step\n",
      "Epoch 4383/5000\n",
      "31/31 - 0s - loss: 8.3407 - mae: 1.8420 - val_loss: 0.2222 - val_mae: 0.3475 - 39ms/epoch - 1ms/step\n",
      "Epoch 4384/5000\n",
      "31/31 - 0s - loss: 1.4451 - mae: 0.9419 - val_loss: 1.0921 - val_mae: 0.9939 - 37ms/epoch - 1ms/step\n",
      "Epoch 4385/5000\n",
      "31/31 - 0s - loss: 25.0205 - mae: 2.1740 - val_loss: 3.4157 - val_mae: 1.8219 - 36ms/epoch - 1ms/step\n",
      "Epoch 4386/5000\n",
      "31/31 - 0s - loss: 1.5620 - mae: 1.0822 - val_loss: 0.1035 - val_mae: 0.2798 - 37ms/epoch - 1ms/step\n",
      "Epoch 4387/5000\n",
      "31/31 - 0s - loss: 18.5739 - mae: 1.8039 - val_loss: 0.2752 - val_mae: 0.4081 - 35ms/epoch - 1ms/step\n",
      "Epoch 4388/5000\n",
      "31/31 - 0s - loss: 1.8226 - mae: 0.9847 - val_loss: 3.2515 - val_mae: 1.7737 - 39ms/epoch - 1ms/step\n",
      "Epoch 4389/5000\n",
      "31/31 - 0s - loss: 4.6141 - mae: 1.4060 - val_loss: 32.4998 - val_mae: 5.6909 - 37ms/epoch - 1ms/step\n",
      "Epoch 4390/5000\n",
      "31/31 - 0s - loss: 3.2641 - mae: 1.3565 - val_loss: 1.3487 - val_mae: 1.1156 - 36ms/epoch - 1ms/step\n",
      "Epoch 4391/5000\n",
      "31/31 - 0s - loss: 18.7760 - mae: 1.9895 - val_loss: 0.1516 - val_mae: 0.2848 - 39ms/epoch - 1ms/step\n",
      "Epoch 4392/5000\n",
      "31/31 - 0s - loss: 2.1037 - mae: 1.2207 - val_loss: 1.3921 - val_mae: 1.1330 - 36ms/epoch - 1ms/step\n",
      "Epoch 4393/5000\n",
      "31/31 - 0s - loss: 25.9819 - mae: 2.3012 - val_loss: 0.5611 - val_mae: 0.6751 - 37ms/epoch - 1ms/step\n",
      "Epoch 4394/5000\n",
      "31/31 - 0s - loss: 1.1479 - mae: 0.7791 - val_loss: 7.5152 - val_mae: 2.7230 - 36ms/epoch - 1ms/step\n",
      "Epoch 4395/5000\n",
      "31/31 - 0s - loss: 0.7956 - mae: 0.7392 - val_loss: 0.1255 - val_mae: 0.2805 - 38ms/epoch - 1ms/step\n",
      "Epoch 4396/5000\n",
      "31/31 - 0s - loss: 17.0558 - mae: 1.8889 - val_loss: 0.1954 - val_mae: 0.3238 - 36ms/epoch - 1ms/step\n",
      "Epoch 4397/5000\n",
      "31/31 - 0s - loss: 2.2977 - mae: 0.8375 - val_loss: 27.8472 - val_mae: 5.2664 - 35ms/epoch - 1ms/step\n",
      "Epoch 4398/5000\n",
      "31/31 - 0s - loss: 11.9058 - mae: 2.0638 - val_loss: 0.5944 - val_mae: 0.6987 - 37ms/epoch - 1ms/step\n",
      "Epoch 4399/5000\n",
      "31/31 - 0s - loss: 4.7669 - mae: 1.5510 - val_loss: 119.3402 - val_mae: 10.9204 - 38ms/epoch - 1ms/step\n",
      "Epoch 4400/5000\n",
      "31/31 - 0s - loss: 12.2368 - mae: 1.6049 - val_loss: 0.1279 - val_mae: 0.2756 - 36ms/epoch - 1ms/step\n",
      "Epoch 4401/5000\n",
      "31/31 - 0s - loss: 0.9407 - mae: 0.6935 - val_loss: 0.1155 - val_mae: 0.2937 - 37ms/epoch - 1ms/step\n",
      "Epoch 4402/5000\n",
      "31/31 - 0s - loss: 13.5792 - mae: 2.1572 - val_loss: 0.1398 - val_mae: 0.3374 - 36ms/epoch - 1ms/step\n",
      "Epoch 4403/5000\n",
      "31/31 - 0s - loss: 2.9317 - mae: 1.3517 - val_loss: 2.3307 - val_mae: 1.4918 - 38ms/epoch - 1ms/step\n",
      "Epoch 4404/5000\n",
      "31/31 - 0s - loss: 15.0400 - mae: 1.9187 - val_loss: 3.7057 - val_mae: 1.8963 - 36ms/epoch - 1ms/step\n",
      "Epoch 4405/5000\n",
      "31/31 - 0s - loss: 7.4621 - mae: 2.0444 - val_loss: 3.2704 - val_mae: 1.7803 - 39ms/epoch - 1ms/step\n",
      "Epoch 4406/5000\n",
      "31/31 - 0s - loss: 0.6503 - mae: 0.6405 - val_loss: 1.2473 - val_mae: 1.0704 - 38ms/epoch - 1ms/step\n",
      "Epoch 4407/5000\n",
      "31/31 - 0s - loss: 27.6896 - mae: 2.1520 - val_loss: 0.1214 - val_mae: 0.2844 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4408/5000\n",
      "31/31 - 0s - loss: 1.6071 - mae: 0.9429 - val_loss: 0.4002 - val_mae: 0.5461 - 35ms/epoch - 1ms/step\n",
      "Epoch 4409/5000\n",
      "31/31 - 0s - loss: 6.1292 - mae: 1.6560 - val_loss: 2.4724 - val_mae: 1.5406 - 36ms/epoch - 1ms/step\n",
      "Epoch 4410/5000\n",
      "31/31 - 0s - loss: 0.4202 - mae: 0.4830 - val_loss: 0.1511 - val_mae: 0.2837 - 38ms/epoch - 1ms/step\n",
      "Epoch 4411/5000\n",
      "31/31 - 0s - loss: 27.7037 - mae: 2.0395 - val_loss: 8.5027 - val_mae: 2.8976 - 37ms/epoch - 1ms/step\n",
      "Epoch 4412/5000\n",
      "31/31 - 0s - loss: 2.5269 - mae: 1.2989 - val_loss: 5.9496 - val_mae: 2.4172 - 33ms/epoch - 1ms/step\n",
      "Epoch 4413/5000\n",
      "31/31 - 0s - loss: 27.9294 - mae: 2.0847 - val_loss: 3.1948 - val_mae: 1.7578 - 34ms/epoch - 1ms/step\n",
      "Epoch 4414/5000\n",
      "31/31 - 0s - loss: 1.4200 - mae: 0.8156 - val_loss: 1.2967 - val_mae: 1.0926 - 36ms/epoch - 1ms/step\n",
      "Epoch 4415/5000\n",
      "31/31 - 0s - loss: 1.1843 - mae: 0.9329 - val_loss: 2.2725 - val_mae: 1.4737 - 36ms/epoch - 1ms/step\n",
      "Epoch 4416/5000\n",
      "31/31 - 0s - loss: 16.8942 - mae: 2.0148 - val_loss: 0.2253 - val_mae: 0.3512 - 36ms/epoch - 1ms/step\n",
      "Epoch 4417/5000\n",
      "31/31 - 0s - loss: 0.5845 - mae: 0.5834 - val_loss: 0.4000 - val_mae: 0.5463 - 37ms/epoch - 1ms/step\n",
      "Epoch 4418/5000\n",
      "31/31 - 0s - loss: 19.1059 - mae: 2.1025 - val_loss: 0.2282 - val_mae: 0.3606 - 36ms/epoch - 1ms/step\n",
      "Epoch 4419/5000\n",
      "31/31 - 0s - loss: 0.5711 - mae: 0.5978 - val_loss: 0.9837 - val_mae: 0.9403 - 37ms/epoch - 1ms/step\n",
      "Epoch 4420/5000\n",
      "31/31 - 0s - loss: 19.8008 - mae: 2.0025 - val_loss: 0.3969 - val_mae: 0.5404 - 36ms/epoch - 1ms/step\n",
      "Epoch 4421/5000\n",
      "31/31 - 0s - loss: 0.6443 - mae: 0.6446 - val_loss: 3.1246 - val_mae: 1.7387 - 35ms/epoch - 1ms/step\n",
      "Epoch 4422/5000\n",
      "31/31 - 0s - loss: 4.7516 - mae: 1.6207 - val_loss: 184.1188 - val_mae: 13.5650 - 33ms/epoch - 1ms/step\n",
      "Epoch 4423/5000\n",
      "31/31 - 0s - loss: 11.3575 - mae: 1.7685 - val_loss: 0.3387 - val_mae: 0.4879 - 36ms/epoch - 1ms/step\n",
      "Epoch 4424/5000\n",
      "31/31 - 0s - loss: 5.3945 - mae: 1.3266 - val_loss: 560.1498 - val_mae: 23.6653 - 37ms/epoch - 1ms/step\n",
      "Epoch 4425/5000\n",
      "31/31 - 0s - loss: 23.2152 - mae: 1.6095 - val_loss: 4.8346 - val_mae: 2.1766 - 37ms/epoch - 1ms/step\n",
      "Epoch 4426/5000\n",
      "31/31 - 0s - loss: 2.0378 - mae: 1.1028 - val_loss: 2.9276 - val_mae: 1.6811 - 35ms/epoch - 1ms/step\n",
      "Epoch 4427/5000\n",
      "31/31 - 0s - loss: 12.5342 - mae: 1.8759 - val_loss: 1.0269 - val_mae: 0.9610 - 34ms/epoch - 1ms/step\n",
      "Epoch 4428/5000\n",
      "31/31 - 0s - loss: 0.5542 - mae: 0.5730 - val_loss: 10.9550 - val_mae: 3.2941 - 37ms/epoch - 1ms/step\n",
      "Epoch 4429/5000\n",
      "31/31 - 0s - loss: 19.3817 - mae: 2.2226 - val_loss: 0.4399 - val_mae: 0.5811 - 37ms/epoch - 1ms/step\n",
      "Epoch 4430/5000\n",
      "31/31 - 0s - loss: 1.4496 - mae: 1.0083 - val_loss: 1.8743 - val_mae: 1.3332 - 36ms/epoch - 1ms/step\n",
      "Epoch 4431/5000\n",
      "31/31 - 0s - loss: 5.2337 - mae: 1.6954 - val_loss: 0.1308 - val_mae: 0.3300 - 37ms/epoch - 1ms/step\n",
      "Epoch 4432/5000\n",
      "31/31 - 0s - loss: 29.0824 - mae: 2.0411 - val_loss: 1.0670 - val_mae: 0.9798 - 36ms/epoch - 1ms/step\n",
      "Epoch 4433/5000\n",
      "31/31 - 0s - loss: 1.3567 - mae: 0.9761 - val_loss: 1.1158 - val_mae: 1.0041 - 37ms/epoch - 1ms/step\n",
      "Epoch 4434/5000\n",
      "31/31 - 0s - loss: 3.1622 - mae: 1.3697 - val_loss: 0.1636 - val_mae: 0.2968 - 37ms/epoch - 1ms/step\n",
      "Epoch 4435/5000\n",
      "31/31 - 0s - loss: 19.2863 - mae: 1.9920 - val_loss: 0.3180 - val_mae: 0.4634 - 35ms/epoch - 1ms/step\n",
      "Epoch 4436/5000\n",
      "31/31 - 0s - loss: 1.1677 - mae: 0.8696 - val_loss: 0.3153 - val_mae: 0.4756 - 37ms/epoch - 1ms/step\n",
      "Epoch 4437/5000\n",
      "31/31 - 0s - loss: 0.6137 - mae: 0.6061 - val_loss: 0.1248 - val_mae: 0.2793 - 36ms/epoch - 1ms/step\n",
      "Epoch 4438/5000\n",
      "31/31 - 0s - loss: 23.4454 - mae: 2.2650 - val_loss: 0.6536 - val_mae: 0.7421 - 37ms/epoch - 1ms/step\n",
      "Epoch 4439/5000\n",
      "31/31 - 0s - loss: 1.4649 - mae: 0.9692 - val_loss: 0.2898 - val_mae: 0.4327 - 36ms/epoch - 1ms/step\n",
      "Epoch 4440/5000\n",
      "31/31 - 0s - loss: 11.5047 - mae: 1.9104 - val_loss: 0.1468 - val_mae: 0.2758 - 38ms/epoch - 1ms/step\n",
      "Epoch 4441/5000\n",
      "31/31 - 0s - loss: 0.9992 - mae: 0.6920 - val_loss: 0.3535 - val_mae: 0.5049 - 37ms/epoch - 1ms/step\n",
      "Epoch 4442/5000\n",
      "31/31 - 0s - loss: 19.7642 - mae: 1.4353 - val_loss: 30.9392 - val_mae: 5.5536 - 37ms/epoch - 1ms/step\n",
      "Epoch 4443/5000\n",
      "31/31 - 0s - loss: 5.4637 - mae: 1.4088 - val_loss: 0.2013 - val_mae: 0.4021 - 35ms/epoch - 1ms/step\n",
      "Epoch 4444/5000\n",
      "31/31 - 0s - loss: 4.3935 - mae: 1.1879 - val_loss: 177.5273 - val_mae: 13.3202 - 39ms/epoch - 1ms/step\n",
      "Epoch 4445/5000\n",
      "31/31 - 0s - loss: 20.6969 - mae: 1.6120 - val_loss: 5.2869 - val_mae: 2.2764 - 34ms/epoch - 1ms/step\n",
      "Epoch 4446/5000\n",
      "31/31 - 0s - loss: 1.4239 - mae: 0.9513 - val_loss: 4.4005 - val_mae: 2.0721 - 36ms/epoch - 1ms/step\n",
      "Epoch 4447/5000\n",
      "31/31 - 0s - loss: 12.8460 - mae: 2.0912 - val_loss: 0.9643 - val_mae: 0.9265 - 37ms/epoch - 1ms/step\n",
      "Epoch 4448/5000\n",
      "31/31 - 0s - loss: 0.9291 - mae: 0.7819 - val_loss: 0.1038 - val_mae: 0.2777 - 37ms/epoch - 1ms/step\n",
      "Epoch 4449/5000\n",
      "31/31 - 0s - loss: 22.6090 - mae: 2.3907 - val_loss: 0.0953 - val_mae: 0.2637 - 36ms/epoch - 1ms/step\n",
      "Epoch 4450/5000\n",
      "31/31 - 0s - loss: 3.9320 - mae: 1.6637 - val_loss: 0.6481 - val_mae: 0.7400 - 36ms/epoch - 1ms/step\n",
      "Epoch 4451/5000\n",
      "31/31 - 0s - loss: 10.2567 - mae: 1.8182 - val_loss: 0.1127 - val_mae: 0.2923 - 36ms/epoch - 1ms/step\n",
      "Epoch 4452/5000\n",
      "31/31 - 0s - loss: 1.8256 - mae: 0.9657 - val_loss: 0.5885 - val_mae: 0.6972 - 36ms/epoch - 1ms/step\n",
      "Epoch 4453/5000\n",
      "31/31 - 0s - loss: 9.2779 - mae: 1.8981 - val_loss: 3.9825 - val_mae: 1.9687 - 36ms/epoch - 1ms/step\n",
      "Epoch 4454/5000\n",
      "31/31 - 0s - loss: 2.5788 - mae: 1.3896 - val_loss: 8.2685 - val_mae: 2.8572 - 38ms/epoch - 1ms/step\n",
      "Epoch 4455/5000\n",
      "31/31 - 0s - loss: 11.6837 - mae: 1.7517 - val_loss: 0.1222 - val_mae: 0.3105 - 38ms/epoch - 1ms/step\n",
      "Epoch 4456/5000\n",
      "31/31 - 0s - loss: 2.4913 - mae: 1.0733 - val_loss: 50.8814 - val_mae: 7.1253 - 36ms/epoch - 1ms/step\n",
      "Epoch 4457/5000\n",
      "31/31 - 0s - loss: 20.5550 - mae: 1.9251 - val_loss: 0.4269 - val_mae: 0.5708 - 35ms/epoch - 1ms/step\n",
      "Epoch 4458/5000\n",
      "31/31 - 0s - loss: 0.4764 - mae: 0.5619 - val_loss: 1.2776 - val_mae: 1.0826 - 35ms/epoch - 1ms/step\n",
      "Epoch 4459/5000\n",
      "31/31 - 0s - loss: 16.9387 - mae: 2.0902 - val_loss: 0.2966 - val_mae: 0.4416 - 36ms/epoch - 1ms/step\n",
      "Epoch 4460/5000\n",
      "31/31 - 0s - loss: 0.9050 - mae: 0.7078 - val_loss: 0.1321 - val_mae: 0.3304 - 36ms/epoch - 1ms/step\n",
      "Epoch 4461/5000\n",
      "31/31 - 0s - loss: 16.9919 - mae: 2.1169 - val_loss: 0.5855 - val_mae: 0.6931 - 35ms/epoch - 1ms/step\n",
      "Epoch 4462/5000\n",
      "31/31 - 0s - loss: 1.2469 - mae: 0.7473 - val_loss: 0.1355 - val_mae: 0.3362 - 36ms/epoch - 1ms/step\n",
      "Epoch 4463/5000\n",
      "31/31 - 0s - loss: 10.5615 - mae: 1.8627 - val_loss: 0.1552 - val_mae: 0.2922 - 39ms/epoch - 1ms/step\n",
      "Epoch 4464/5000\n",
      "31/31 - 0s - loss: 3.0068 - mae: 1.4487 - val_loss: 1.8921 - val_mae: 1.3369 - 38ms/epoch - 1ms/step\n",
      "Epoch 4465/5000\n",
      "31/31 - 0s - loss: 20.6919 - mae: 2.2869 - val_loss: 0.2164 - val_mae: 0.4150 - 35ms/epoch - 1ms/step\n",
      "Epoch 4466/5000\n",
      "31/31 - 0s - loss: 0.8961 - mae: 0.7670 - val_loss: 0.2478 - val_mae: 0.4371 - 38ms/epoch - 1ms/step\n",
      "Epoch 4467/5000\n",
      "31/31 - 0s - loss: 5.5355 - mae: 1.6653 - val_loss: 2.6592 - val_mae: 1.5997 - 36ms/epoch - 1ms/step\n",
      "Epoch 4468/5000\n",
      "31/31 - 0s - loss: 1.8380 - mae: 1.1938 - val_loss: 4.7533 - val_mae: 2.1570 - 40ms/epoch - 1ms/step\n",
      "Epoch 4469/5000\n",
      "31/31 - 0s - loss: 25.4804 - mae: 2.1809 - val_loss: 1.0740 - val_mae: 0.9870 - 36ms/epoch - 1ms/step\n",
      "Epoch 4470/5000\n",
      "31/31 - 0s - loss: 0.9521 - mae: 0.7571 - val_loss: 0.1471 - val_mae: 0.2795 - 36ms/epoch - 1ms/step\n",
      "Epoch 4471/5000\n",
      "31/31 - 0s - loss: 33.5111 - mae: 2.1916 - val_loss: 0.1017 - val_mae: 0.2782 - 51ms/epoch - 2ms/step\n",
      "Epoch 4472/5000\n",
      "31/31 - 0s - loss: 2.5559 - mae: 1.2658 - val_loss: 0.2610 - val_mae: 0.3983 - 39ms/epoch - 1ms/step\n",
      "Epoch 4473/5000\n",
      "31/31 - 0s - loss: 6.6499 - mae: 1.4755 - val_loss: 0.7352 - val_mae: 0.7971 - 36ms/epoch - 1ms/step\n",
      "Epoch 4474/5000\n",
      "31/31 - 0s - loss: 0.5847 - mae: 0.5615 - val_loss: 0.2982 - val_mae: 0.4671 - 37ms/epoch - 1ms/step\n",
      "Epoch 4475/5000\n",
      "31/31 - 0s - loss: 15.0894 - mae: 2.0225 - val_loss: 0.3590 - val_mae: 0.5086 - 38ms/epoch - 1ms/step\n",
      "Epoch 4476/5000\n",
      "31/31 - 0s - loss: 0.5760 - mae: 0.6317 - val_loss: 0.1065 - val_mae: 0.2794 - 36ms/epoch - 1ms/step\n",
      "Epoch 4477/5000\n",
      "31/31 - 0s - loss: 21.1689 - mae: 2.1688 - val_loss: 0.1572 - val_mae: 0.2902 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4478/5000\n",
      "31/31 - 0s - loss: 1.6422 - mae: 1.0414 - val_loss: 0.1416 - val_mae: 0.3422 - 39ms/epoch - 1ms/step\n",
      "Epoch 4479/5000\n",
      "31/31 - 0s - loss: 8.9527 - mae: 1.5311 - val_loss: 1.3114 - val_mae: 1.0957 - 36ms/epoch - 1ms/step\n",
      "Epoch 4480/5000\n",
      "31/31 - 0s - loss: 2.6613 - mae: 1.3498 - val_loss: 0.1159 - val_mae: 0.2929 - 36ms/epoch - 1ms/step\n",
      "Epoch 4481/5000\n",
      "31/31 - 0s - loss: 18.6666 - mae: 2.1485 - val_loss: 1.1061 - val_mae: 0.9993 - 36ms/epoch - 1ms/step\n",
      "Epoch 4482/5000\n",
      "31/31 - 0s - loss: 1.3431 - mae: 0.8681 - val_loss: 0.6882 - val_mae: 0.7665 - 38ms/epoch - 1ms/step\n",
      "Epoch 4483/5000\n",
      "31/31 - 0s - loss: 17.8354 - mae: 2.0535 - val_loss: 0.1064 - val_mae: 0.2914 - 39ms/epoch - 1ms/step\n",
      "Epoch 4484/5000\n",
      "31/31 - 0s - loss: 1.9371 - mae: 1.1485 - val_loss: 0.6182 - val_mae: 0.7209 - 37ms/epoch - 1ms/step\n",
      "Epoch 4485/5000\n",
      "31/31 - 0s - loss: 4.4331 - mae: 1.5697 - val_loss: 0.3816 - val_mae: 0.5300 - 37ms/epoch - 1ms/step\n",
      "Epoch 4486/5000\n",
      "31/31 - 0s - loss: 9.1789 - mae: 1.7033 - val_loss: 0.1214 - val_mae: 0.2756 - 36ms/epoch - 1ms/step\n",
      "Epoch 4487/5000\n",
      "31/31 - 0s - loss: 1.4324 - mae: 0.8101 - val_loss: 2.4612 - val_mae: 1.5347 - 37ms/epoch - 1ms/step\n",
      "Epoch 4488/5000\n",
      "31/31 - 0s - loss: 7.3044 - mae: 1.6217 - val_loss: 0.2864 - val_mae: 0.4288 - 35ms/epoch - 1ms/step\n",
      "Epoch 4489/5000\n",
      "31/31 - 0s - loss: 11.8750 - mae: 1.9004 - val_loss: 0.1332 - val_mae: 0.3290 - 35ms/epoch - 1ms/step\n",
      "Epoch 4490/5000\n",
      "31/31 - 0s - loss: 0.9951 - mae: 0.6500 - val_loss: 0.3397 - val_mae: 0.4827 - 35ms/epoch - 1ms/step\n",
      "Epoch 4491/5000\n",
      "31/31 - 0s - loss: 8.5513 - mae: 1.9187 - val_loss: 0.1886 - val_mae: 0.3213 - 34ms/epoch - 1ms/step\n",
      "Epoch 4492/5000\n",
      "31/31 - 0s - loss: 1.4204 - mae: 0.8092 - val_loss: 19.7722 - val_mae: 4.4344 - 35ms/epoch - 1ms/step\n",
      "Epoch 4493/5000\n",
      "31/31 - 0s - loss: 12.3491 - mae: 2.2726 - val_loss: 0.3036 - val_mae: 0.4707 - 37ms/epoch - 1ms/step\n",
      "Epoch 4494/5000\n",
      "31/31 - 0s - loss: 1.0565 - mae: 0.7380 - val_loss: 1.0409 - val_mae: 0.9691 - 38ms/epoch - 1ms/step\n",
      "Epoch 4495/5000\n",
      "31/31 - 0s - loss: 29.7203 - mae: 2.0997 - val_loss: 0.1167 - val_mae: 0.2713 - 36ms/epoch - 1ms/step\n",
      "Epoch 4496/5000\n",
      "31/31 - 0s - loss: 1.4000 - mae: 0.8528 - val_loss: 0.1053 - val_mae: 0.2776 - 36ms/epoch - 1ms/step\n",
      "Epoch 4497/5000\n",
      "31/31 - 0s - loss: 7.8224 - mae: 1.7735 - val_loss: 0.1160 - val_mae: 0.3050 - 36ms/epoch - 1ms/step\n",
      "Epoch 4498/5000\n",
      "31/31 - 0s - loss: 0.5475 - mae: 0.6186 - val_loss: 3.7464 - val_mae: 1.9092 - 37ms/epoch - 1ms/step\n",
      "Epoch 4499/5000\n",
      "31/31 - 0s - loss: 19.7194 - mae: 2.1873 - val_loss: 0.4696 - val_mae: 0.6054 - 36ms/epoch - 1ms/step\n",
      "Epoch 4500/5000\n",
      "31/31 - 0s - loss: 0.8158 - mae: 0.7450 - val_loss: 2.1145 - val_mae: 1.4196 - 35ms/epoch - 1ms/step\n",
      "Epoch 4501/5000\n",
      "31/31 - 0s - loss: 16.8922 - mae: 2.1805 - val_loss: 6.3051 - val_mae: 2.4897 - 37ms/epoch - 1ms/step\n",
      "Epoch 4502/5000\n",
      "31/31 - 0s - loss: 3.5643 - mae: 1.5890 - val_loss: 0.9891 - val_mae: 0.9389 - 36ms/epoch - 1ms/step\n",
      "Epoch 4503/5000\n",
      "31/31 - 0s - loss: 10.7539 - mae: 1.9386 - val_loss: 0.6809 - val_mae: 0.7598 - 37ms/epoch - 1ms/step\n",
      "Epoch 4504/5000\n",
      "31/31 - 0s - loss: 4.6378 - mae: 1.3049 - val_loss: 3.7412 - val_mae: 1.9063 - 36ms/epoch - 1ms/step\n",
      "Epoch 4505/5000\n",
      "31/31 - 0s - loss: 6.8781 - mae: 1.3432 - val_loss: 0.1305 - val_mae: 0.2857 - 37ms/epoch - 1ms/step\n",
      "Epoch 4506/5000\n",
      "31/31 - 0s - loss: 11.5787 - mae: 1.6135 - val_loss: 37.2011 - val_mae: 6.0909 - 35ms/epoch - 1ms/step\n",
      "Epoch 4507/5000\n",
      "31/31 - 0s - loss: 2.5979 - mae: 1.0798 - val_loss: 9.3907 - val_mae: 3.0466 - 39ms/epoch - 1ms/step\n",
      "Epoch 4508/5000\n",
      "31/31 - 0s - loss: 21.3321 - mae: 2.2958 - val_loss: 0.3044 - val_mae: 0.4494 - 37ms/epoch - 1ms/step\n",
      "Epoch 4509/5000\n",
      "31/31 - 0s - loss: 0.7042 - mae: 0.5473 - val_loss: 0.2449 - val_mae: 0.4343 - 36ms/epoch - 1ms/step\n",
      "Epoch 4510/5000\n",
      "31/31 - 0s - loss: 0.7504 - mae: 0.7270 - val_loss: 1.3848 - val_mae: 1.1335 - 36ms/epoch - 1ms/step\n",
      "Epoch 4511/5000\n",
      "31/31 - 0s - loss: 28.2112 - mae: 2.3227 - val_loss: 0.4131 - val_mae: 0.5520 - 36ms/epoch - 1ms/step\n",
      "Epoch 4512/5000\n",
      "31/31 - 0s - loss: 1.8644 - mae: 1.1434 - val_loss: 0.2336 - val_mae: 0.3622 - 39ms/epoch - 1ms/step\n",
      "Epoch 4513/5000\n",
      "31/31 - 0s - loss: 13.5695 - mae: 1.6260 - val_loss: 0.2828 - val_mae: 0.4586 - 35ms/epoch - 1ms/step\n",
      "Epoch 4514/5000\n",
      "31/31 - 0s - loss: 1.8614 - mae: 1.1809 - val_loss: 1.4755 - val_mae: 1.1726 - 37ms/epoch - 1ms/step\n",
      "Epoch 4515/5000\n",
      "31/31 - 0s - loss: 12.1731 - mae: 2.2167 - val_loss: 0.9815 - val_mae: 0.9395 - 36ms/epoch - 1ms/step\n",
      "Epoch 4516/5000\n",
      "31/31 - 0s - loss: 0.6582 - mae: 0.6035 - val_loss: 6.7118 - val_mae: 2.5719 - 37ms/epoch - 1ms/step\n",
      "Epoch 4517/5000\n",
      "31/31 - 0s - loss: 16.4611 - mae: 2.1253 - val_loss: 0.1304 - val_mae: 0.3272 - 36ms/epoch - 1ms/step\n",
      "Epoch 4518/5000\n",
      "31/31 - 0s - loss: 1.0468 - mae: 0.6882 - val_loss: 0.9840 - val_mae: 0.9347 - 35ms/epoch - 1ms/step\n",
      "Epoch 4519/5000\n",
      "31/31 - 0s - loss: 16.6332 - mae: 1.9849 - val_loss: 76.1805 - val_mae: 8.7227 - 37ms/epoch - 1ms/step\n",
      "Epoch 4520/5000\n",
      "31/31 - 0s - loss: 3.2389 - mae: 1.0379 - val_loss: 1.1090 - val_mae: 1.0051 - 37ms/epoch - 1ms/step\n",
      "Epoch 4521/5000\n",
      "31/31 - 0s - loss: 9.6286 - mae: 1.8717 - val_loss: 7.7531 - val_mae: 2.7672 - 37ms/epoch - 1ms/step\n",
      "Epoch 4522/5000\n",
      "31/31 - 0s - loss: 2.6272 - mae: 1.4034 - val_loss: 0.9899 - val_mae: 0.9439 - 36ms/epoch - 1ms/step\n",
      "Epoch 4523/5000\n",
      "31/31 - 0s - loss: 12.2027 - mae: 1.8715 - val_loss: 0.9212 - val_mae: 0.9085 - 36ms/epoch - 1ms/step\n",
      "Epoch 4524/5000\n",
      "31/31 - 0s - loss: 1.0936 - mae: 0.8583 - val_loss: 1.7220 - val_mae: 1.2741 - 38ms/epoch - 1ms/step\n",
      "Epoch 4525/5000\n",
      "31/31 - 0s - loss: 13.6702 - mae: 1.7949 - val_loss: 0.1363 - val_mae: 0.2803 - 37ms/epoch - 1ms/step\n",
      "Epoch 4526/5000\n",
      "31/31 - 0s - loss: 1.3880 - mae: 1.0061 - val_loss: 0.3768 - val_mae: 0.5244 - 38ms/epoch - 1ms/step\n",
      "Epoch 4527/5000\n",
      "31/31 - 0s - loss: 19.5902 - mae: 2.3332 - val_loss: 0.1962 - val_mae: 0.3346 - 37ms/epoch - 1ms/step\n",
      "Epoch 4528/5000\n",
      "31/31 - 0s - loss: 1.4603 - mae: 0.9940 - val_loss: 0.1952 - val_mae: 0.3967 - 38ms/epoch - 1ms/step\n",
      "Epoch 4529/5000\n",
      "31/31 - 0s - loss: 20.5373 - mae: 2.3508 - val_loss: 0.9703 - val_mae: 0.9336 - 36ms/epoch - 1ms/step\n",
      "Epoch 4530/5000\n",
      "31/31 - 0s - loss: 1.0749 - mae: 0.7394 - val_loss: 0.1431 - val_mae: 0.2733 - 37ms/epoch - 1ms/step\n",
      "Epoch 4531/5000\n",
      "31/31 - 0s - loss: 20.3639 - mae: 2.1063 - val_loss: 25.6811 - val_mae: 5.0590 - 36ms/epoch - 1ms/step\n",
      "Epoch 4532/5000\n",
      "31/31 - 0s - loss: 1.8724 - mae: 0.9554 - val_loss: 7.2543 - val_mae: 2.6758 - 35ms/epoch - 1ms/step\n",
      "Epoch 4533/5000\n",
      "31/31 - 0s - loss: 17.0174 - mae: 2.2991 - val_loss: 0.6294 - val_mae: 0.7275 - 36ms/epoch - 1ms/step\n",
      "Epoch 4534/5000\n",
      "31/31 - 0s - loss: 0.9545 - mae: 0.6975 - val_loss: 0.3175 - val_mae: 0.4783 - 36ms/epoch - 1ms/step\n",
      "Epoch 4535/5000\n",
      "31/31 - 0s - loss: 19.3401 - mae: 2.1448 - val_loss: 0.6505 - val_mae: 0.7436 - 36ms/epoch - 1ms/step\n",
      "Epoch 4536/5000\n",
      "31/31 - 0s - loss: 0.6273 - mae: 0.6233 - val_loss: 1.1283 - val_mae: 1.0139 - 37ms/epoch - 1ms/step\n",
      "Epoch 4537/5000\n",
      "31/31 - 0s - loss: 0.6901 - mae: 0.6603 - val_loss: 0.9378 - val_mae: 0.9156 - 38ms/epoch - 1ms/step\n",
      "Epoch 4538/5000\n",
      "31/31 - 0s - loss: 33.2855 - mae: 2.3413 - val_loss: 0.0994 - val_mae: 0.2738 - 36ms/epoch - 1ms/step\n",
      "Epoch 4539/5000\n",
      "31/31 - 0s - loss: 2.3596 - mae: 1.1071 - val_loss: 0.3764 - val_mae: 0.5264 - 35ms/epoch - 1ms/step\n",
      "Epoch 4540/5000\n",
      "31/31 - 0s - loss: 21.6425 - mae: 2.3364 - val_loss: 0.4182 - val_mae: 0.5644 - 35ms/epoch - 1ms/step\n",
      "Epoch 4541/5000\n",
      "31/31 - 0s - loss: 1.3862 - mae: 0.8281 - val_loss: 0.1754 - val_mae: 0.3078 - 36ms/epoch - 1ms/step\n",
      "Epoch 4542/5000\n",
      "31/31 - 0s - loss: 19.8734 - mae: 2.0033 - val_loss: 2.8032 - val_mae: 1.6437 - 36ms/epoch - 1ms/step\n",
      "Epoch 4543/5000\n",
      "31/31 - 0s - loss: 1.3828 - mae: 0.6542 - val_loss: 0.4935 - val_mae: 0.6248 - 38ms/epoch - 1ms/step\n",
      "Epoch 4544/5000\n",
      "31/31 - 0s - loss: 5.8805 - mae: 1.7599 - val_loss: 3.4458 - val_mae: 1.8289 - 35ms/epoch - 1ms/step\n",
      "Epoch 4545/5000\n",
      "31/31 - 0s - loss: 7.1146 - mae: 1.2829 - val_loss: 45.5408 - val_mae: 6.7416 - 36ms/epoch - 1ms/step\n",
      "Epoch 4546/5000\n",
      "31/31 - 0s - loss: 6.4141 - mae: 1.5638 - val_loss: 0.5824 - val_mae: 0.6949 - 37ms/epoch - 1ms/step\n",
      "Epoch 4547/5000\n",
      "31/31 - 0s - loss: 1.4588 - mae: 0.8557 - val_loss: 270.9557 - val_mae: 16.4579 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4548/5000\n",
      "31/31 - 0s - loss: 21.8659 - mae: 2.3961 - val_loss: 0.2580 - val_mae: 0.3866 - 35ms/epoch - 1ms/step\n",
      "Epoch 4549/5000\n",
      "31/31 - 0s - loss: 10.5100 - mae: 2.0200 - val_loss: 94.0359 - val_mae: 9.6916 - 34ms/epoch - 1ms/step\n",
      "Epoch 4550/5000\n",
      "31/31 - 0s - loss: 3.9197 - mae: 1.0408 - val_loss: 0.1752 - val_mae: 0.3080 - 35ms/epoch - 1ms/step\n",
      "Epoch 4551/5000\n",
      "31/31 - 0s - loss: 19.9600 - mae: 1.9857 - val_loss: 0.4725 - val_mae: 0.6130 - 37ms/epoch - 1ms/step\n",
      "Epoch 4552/5000\n",
      "31/31 - 0s - loss: 1.3860 - mae: 0.8652 - val_loss: 8.6964 - val_mae: 2.9330 - 36ms/epoch - 1ms/step\n",
      "Epoch 4553/5000\n",
      "31/31 - 0s - loss: 4.1727 - mae: 1.5666 - val_loss: 0.3995 - val_mae: 0.5415 - 36ms/epoch - 1ms/step\n",
      "Epoch 4554/5000\n",
      "31/31 - 0s - loss: 0.4086 - mae: 0.4760 - val_loss: 22.6591 - val_mae: 4.7490 - 36ms/epoch - 1ms/step\n",
      "Epoch 4555/5000\n",
      "31/31 - 0s - loss: 24.2377 - mae: 2.4081 - val_loss: 4.7812 - val_mae: 2.1638 - 36ms/epoch - 1ms/step\n",
      "Epoch 4556/5000\n",
      "31/31 - 0s - loss: 0.8996 - mae: 0.6883 - val_loss: 1.5004 - val_mae: 1.1816 - 36ms/epoch - 1ms/step\n",
      "Epoch 4557/5000\n",
      "31/31 - 0s - loss: 27.2753 - mae: 2.5228 - val_loss: 1.6550 - val_mae: 1.2445 - 37ms/epoch - 1ms/step\n",
      "Epoch 4558/5000\n",
      "31/31 - 0s - loss: 1.9522 - mae: 1.0718 - val_loss: 1.6670 - val_mae: 1.2507 - 35ms/epoch - 1ms/step\n",
      "Epoch 4559/5000\n",
      "31/31 - 0s - loss: 17.7778 - mae: 2.2643 - val_loss: 0.8507 - val_mae: 0.8669 - 35ms/epoch - 1ms/step\n",
      "Epoch 4560/5000\n",
      "31/31 - 0s - loss: 0.6351 - mae: 0.5611 - val_loss: 0.1002 - val_mae: 0.2747 - 37ms/epoch - 1ms/step\n",
      "Epoch 4561/5000\n",
      "31/31 - 0s - loss: 0.9088 - mae: 0.8403 - val_loss: 0.6488 - val_mae: 0.7375 - 36ms/epoch - 1ms/step\n",
      "Epoch 4562/5000\n",
      "31/31 - 0s - loss: 18.5993 - mae: 2.2997 - val_loss: 3.1174 - val_mae: 1.7345 - 34ms/epoch - 1ms/step\n",
      "Epoch 4563/5000\n",
      "31/31 - 0s - loss: 7.5635 - mae: 2.0478 - val_loss: 20.3038 - val_mae: 4.4945 - 35ms/epoch - 1ms/step\n",
      "Epoch 4564/5000\n",
      "31/31 - 0s - loss: 1.2517 - mae: 0.6630 - val_loss: 0.1063 - val_mae: 0.2837 - 34ms/epoch - 1ms/step\n",
      "Epoch 4565/5000\n",
      "31/31 - 0s - loss: 17.3974 - mae: 1.9895 - val_loss: 1.4394 - val_mae: 1.1594 - 38ms/epoch - 1ms/step\n",
      "Epoch 4566/5000\n",
      "31/31 - 0s - loss: 2.1264 - mae: 0.9293 - val_loss: 1.7883 - val_mae: 1.2987 - 38ms/epoch - 1ms/step\n",
      "Epoch 4567/5000\n",
      "31/31 - 0s - loss: 8.1249 - mae: 1.7681 - val_loss: 1.2623 - val_mae: 1.0735 - 39ms/epoch - 1ms/step\n",
      "Epoch 4568/5000\n",
      "31/31 - 0s - loss: 1.1643 - mae: 0.8159 - val_loss: 0.8174 - val_mae: 0.8434 - 38ms/epoch - 1ms/step\n",
      "Epoch 4569/5000\n",
      "31/31 - 0s - loss: 20.1388 - mae: 2.2044 - val_loss: 2.4268 - val_mae: 1.5271 - 36ms/epoch - 1ms/step\n",
      "Epoch 4570/5000\n",
      "31/31 - 0s - loss: 2.2291 - mae: 1.3202 - val_loss: 0.2662 - val_mae: 0.4077 - 37ms/epoch - 1ms/step\n",
      "Epoch 4571/5000\n",
      "31/31 - 0s - loss: 6.7036 - mae: 1.7507 - val_loss: 0.8908 - val_mae: 0.8872 - 36ms/epoch - 1ms/step\n",
      "Epoch 4572/5000\n",
      "31/31 - 0s - loss: 3.6689 - mae: 1.2293 - val_loss: 1.8469 - val_mae: 1.3181 - 36ms/epoch - 1ms/step\n",
      "Epoch 4573/5000\n",
      "31/31 - 0s - loss: 2.7468 - mae: 1.3035 - val_loss: 0.1091 - val_mae: 0.2841 - 36ms/epoch - 1ms/step\n",
      "Epoch 4574/5000\n",
      "31/31 - 0s - loss: 14.5036 - mae: 1.9790 - val_loss: 0.8550 - val_mae: 0.8681 - 34ms/epoch - 1ms/step\n",
      "Epoch 4575/5000\n",
      "31/31 - 0s - loss: 0.4956 - mae: 0.5111 - val_loss: 0.4014 - val_mae: 0.5455 - 35ms/epoch - 1ms/step\n",
      "Epoch 4576/5000\n",
      "31/31 - 0s - loss: 11.5568 - mae: 1.8877 - val_loss: 0.1341 - val_mae: 0.2722 - 38ms/epoch - 1ms/step\n",
      "Epoch 4577/5000\n",
      "31/31 - 0s - loss: 1.4316 - mae: 0.9221 - val_loss: 1.2103 - val_mae: 1.0535 - 37ms/epoch - 1ms/step\n",
      "Epoch 4578/5000\n",
      "31/31 - 0s - loss: 15.7219 - mae: 2.0608 - val_loss: 0.1952 - val_mae: 0.3257 - 45ms/epoch - 1ms/step\n",
      "Epoch 4579/5000\n",
      "31/31 - 0s - loss: 1.3073 - mae: 0.8976 - val_loss: 0.9045 - val_mae: 0.8960 - 37ms/epoch - 1ms/step\n",
      "Epoch 4580/5000\n",
      "31/31 - 0s - loss: 11.9132 - mae: 1.8865 - val_loss: 1.6805 - val_mae: 1.2533 - 35ms/epoch - 1ms/step\n",
      "Epoch 4581/5000\n",
      "31/31 - 0s - loss: 2.2289 - mae: 1.0435 - val_loss: 0.1161 - val_mae: 0.2872 - 37ms/epoch - 1ms/step\n",
      "Epoch 4582/5000\n",
      "31/31 - 0s - loss: 10.8319 - mae: 2.0074 - val_loss: 0.1048 - val_mae: 0.2824 - 38ms/epoch - 1ms/step\n",
      "Epoch 4583/5000\n",
      "31/31 - 0s - loss: 0.7448 - mae: 0.7819 - val_loss: 0.8224 - val_mae: 0.8492 - 36ms/epoch - 1ms/step\n",
      "Epoch 4584/5000\n",
      "31/31 - 0s - loss: 21.1889 - mae: 1.9861 - val_loss: 0.1067 - val_mae: 0.2813 - 38ms/epoch - 1ms/step\n",
      "Epoch 4585/5000\n",
      "31/31 - 0s - loss: 1.1866 - mae: 0.9222 - val_loss: 0.1026 - val_mae: 0.2777 - 36ms/epoch - 1ms/step\n",
      "Epoch 4586/5000\n",
      "31/31 - 0s - loss: 36.8070 - mae: 2.1722 - val_loss: 1.0980 - val_mae: 1.0023 - 34ms/epoch - 1ms/step\n",
      "Epoch 4587/5000\n",
      "31/31 - 0s - loss: 2.0377 - mae: 1.1730 - val_loss: 0.1749 - val_mae: 0.3790 - 35ms/epoch - 1ms/step\n",
      "Epoch 4588/5000\n",
      "31/31 - 0s - loss: 10.5306 - mae: 2.1131 - val_loss: 0.1727 - val_mae: 0.3049 - 36ms/epoch - 1ms/step\n",
      "Epoch 4589/5000\n",
      "31/31 - 0s - loss: 0.3217 - mae: 0.4974 - val_loss: 0.1220 - val_mae: 0.3142 - 37ms/epoch - 1ms/step\n",
      "Epoch 4590/5000\n",
      "31/31 - 0s - loss: 11.2235 - mae: 2.1568 - val_loss: 12.9892 - val_mae: 3.5887 - 38ms/epoch - 1ms/step\n",
      "Epoch 4591/5000\n",
      "31/31 - 0s - loss: 3.0151 - mae: 1.3575 - val_loss: 0.3629 - val_mae: 0.5032 - 36ms/epoch - 1ms/step\n",
      "Epoch 4592/5000\n",
      "31/31 - 0s - loss: 17.6115 - mae: 1.7020 - val_loss: 6.8034 - val_mae: 2.5893 - 36ms/epoch - 1ms/step\n",
      "Epoch 4593/5000\n",
      "31/31 - 0s - loss: 1.1165 - mae: 0.7263 - val_loss: 0.6908 - val_mae: 0.7669 - 36ms/epoch - 1ms/step\n",
      "Epoch 4594/5000\n",
      "31/31 - 0s - loss: 12.1563 - mae: 2.0293 - val_loss: 2.5177 - val_mae: 1.5514 - 37ms/epoch - 1ms/step\n",
      "Epoch 4595/5000\n",
      "31/31 - 0s - loss: 2.0552 - mae: 1.2578 - val_loss: 19.8693 - val_mae: 4.4461 - 36ms/epoch - 1ms/step\n",
      "Epoch 4596/5000\n",
      "31/31 - 0s - loss: 17.8927 - mae: 2.3267 - val_loss: 1.5428 - val_mae: 1.1998 - 35ms/epoch - 1ms/step\n",
      "Epoch 4597/5000\n",
      "31/31 - 0s - loss: 1.1460 - mae: 0.7405 - val_loss: 0.1080 - val_mae: 0.2800 - 36ms/epoch - 1ms/step\n",
      "Epoch 4598/5000\n",
      "31/31 - 0s - loss: 16.3713 - mae: 2.1635 - val_loss: 1.1618 - val_mae: 1.0329 - 35ms/epoch - 1ms/step\n",
      "Epoch 4599/5000\n",
      "31/31 - 0s - loss: 1.8310 - mae: 1.0971 - val_loss: 4.5341 - val_mae: 2.1059 - 36ms/epoch - 1ms/step\n",
      "Epoch 4600/5000\n",
      "31/31 - 0s - loss: 8.1979 - mae: 1.8219 - val_loss: 1.5406 - val_mae: 1.1996 - 35ms/epoch - 1ms/step\n",
      "Epoch 4601/5000\n",
      "31/31 - 0s - loss: 18.0528 - mae: 2.2120 - val_loss: 1.8734 - val_mae: 1.3326 - 37ms/epoch - 1ms/step\n",
      "Epoch 4602/5000\n",
      "31/31 - 0s - loss: 1.0678 - mae: 0.6898 - val_loss: 0.9883 - val_mae: 0.9435 - 36ms/epoch - 1ms/step\n",
      "Epoch 4603/5000\n",
      "31/31 - 0s - loss: 0.9011 - mae: 0.7412 - val_loss: 4.9412 - val_mae: 2.1998 - 38ms/epoch - 1ms/step\n",
      "Epoch 4604/5000\n",
      "31/31 - 0s - loss: 13.5272 - mae: 2.2626 - val_loss: 0.9835 - val_mae: 0.9365 - 35ms/epoch - 1ms/step\n",
      "Epoch 4605/5000\n",
      "31/31 - 0s - loss: 14.3276 - mae: 2.5021 - val_loss: 0.6882 - val_mae: 0.7668 - 35ms/epoch - 1ms/step\n",
      "Epoch 4606/5000\n",
      "31/31 - 0s - loss: 0.9713 - mae: 0.6871 - val_loss: 0.1179 - val_mae: 0.2807 - 36ms/epoch - 1ms/step\n",
      "Epoch 4607/5000\n",
      "31/31 - 0s - loss: 17.0563 - mae: 1.9753 - val_loss: 2.0014 - val_mae: 1.3804 - 37ms/epoch - 1ms/step\n",
      "Epoch 4608/5000\n",
      "31/31 - 0s - loss: 1.8845 - mae: 1.1200 - val_loss: 4.3906 - val_mae: 2.0719 - 35ms/epoch - 1ms/step\n",
      "Epoch 4609/5000\n",
      "31/31 - 0s - loss: 1.5891 - mae: 1.0101 - val_loss: 0.7975 - val_mae: 0.8336 - 35ms/epoch - 1ms/step\n",
      "Epoch 4610/5000\n",
      "31/31 - 0s - loss: 25.3237 - mae: 2.2709 - val_loss: 0.5107 - val_mae: 0.6428 - 36ms/epoch - 1ms/step\n",
      "Epoch 4611/5000\n",
      "31/31 - 0s - loss: 2.2502 - mae: 1.0378 - val_loss: 0.3569 - val_mae: 0.5030 - 37ms/epoch - 1ms/step\n",
      "Epoch 4612/5000\n",
      "31/31 - 0s - loss: 14.9222 - mae: 1.9807 - val_loss: 2.2744 - val_mae: 1.4747 - 36ms/epoch - 1ms/step\n",
      "Epoch 4613/5000\n",
      "31/31 - 0s - loss: 1.6303 - mae: 0.9589 - val_loss: 0.9775 - val_mae: 0.9342 - 36ms/epoch - 1ms/step\n",
      "Epoch 4614/5000\n",
      "31/31 - 0s - loss: 1.2734 - mae: 0.8393 - val_loss: 7.5980 - val_mae: 2.7385 - 37ms/epoch - 1ms/step\n",
      "Epoch 4615/5000\n",
      "31/31 - 0s - loss: 23.9772 - mae: 2.2721 - val_loss: 4.2137 - val_mae: 2.0284 - 36ms/epoch - 1ms/step\n",
      "Epoch 4616/5000\n",
      "31/31 - 0s - loss: 1.2251 - mae: 0.8583 - val_loss: 0.1939 - val_mae: 0.3242 - 39ms/epoch - 1ms/step\n",
      "Epoch 4617/5000\n",
      "31/31 - 0s - loss: 13.4253 - mae: 1.8811 - val_loss: 2.4504 - val_mae: 1.5335 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4618/5000\n",
      "31/31 - 0s - loss: 0.7096 - mae: 0.5607 - val_loss: 0.1139 - val_mae: 0.2803 - 36ms/epoch - 1ms/step\n",
      "Epoch 4619/5000\n",
      "31/31 - 0s - loss: 22.1090 - mae: 2.0340 - val_loss: 0.3589 - val_mae: 0.5086 - 37ms/epoch - 1ms/step\n",
      "Epoch 4620/5000\n",
      "31/31 - 0s - loss: 1.6874 - mae: 1.0137 - val_loss: 0.4171 - val_mae: 0.5620 - 39ms/epoch - 1ms/step\n",
      "Epoch 4621/5000\n",
      "31/31 - 0s - loss: 10.9109 - mae: 1.3074 - val_loss: 404.7233 - val_mae: 20.1154 - 37ms/epoch - 1ms/step\n",
      "Epoch 4622/5000\n",
      "31/31 - 0s - loss: 15.5012 - mae: 1.6722 - val_loss: 0.2923 - val_mae: 0.4349 - 35ms/epoch - 1ms/step\n",
      "Epoch 4623/5000\n",
      "31/31 - 0s - loss: 0.9811 - mae: 0.6911 - val_loss: 64.3975 - val_mae: 8.0187 - 37ms/epoch - 1ms/step\n",
      "Epoch 4624/5000\n",
      "31/31 - 0s - loss: 5.8861 - mae: 1.6733 - val_loss: 0.1104 - val_mae: 0.2862 - 38ms/epoch - 1ms/step\n",
      "Epoch 4625/5000\n",
      "31/31 - 0s - loss: 17.4531 - mae: 2.0151 - val_loss: 1.6287 - val_mae: 1.2352 - 37ms/epoch - 1ms/step\n",
      "Epoch 4626/5000\n",
      "31/31 - 0s - loss: 2.3959 - mae: 1.1648 - val_loss: 0.2210 - val_mae: 0.4177 - 37ms/epoch - 1ms/step\n",
      "Epoch 4627/5000\n",
      "31/31 - 0s - loss: 5.9698 - mae: 1.6749 - val_loss: 1.1376 - val_mae: 1.0188 - 37ms/epoch - 1ms/step\n",
      "Epoch 4628/5000\n",
      "31/31 - 0s - loss: 10.7976 - mae: 1.8865 - val_loss: 0.1151 - val_mae: 0.2916 - 35ms/epoch - 1ms/step\n",
      "Epoch 4629/5000\n",
      "31/31 - 0s - loss: 1.6579 - mae: 0.8947 - val_loss: 0.1044 - val_mae: 0.2796 - 36ms/epoch - 1ms/step\n",
      "Epoch 4630/5000\n",
      "31/31 - 0s - loss: 13.1619 - mae: 2.2742 - val_loss: 0.0980 - val_mae: 0.2710 - 35ms/epoch - 1ms/step\n",
      "Epoch 4631/5000\n",
      "31/31 - 0s - loss: 0.9419 - mae: 0.8460 - val_loss: 0.1065 - val_mae: 0.2724 - 35ms/epoch - 1ms/step\n",
      "Epoch 4632/5000\n",
      "31/31 - 0s - loss: 22.3116 - mae: 2.3735 - val_loss: 0.2687 - val_mae: 0.4081 - 37ms/epoch - 1ms/step\n",
      "Epoch 4633/5000\n",
      "31/31 - 0s - loss: 1.1533 - mae: 0.8666 - val_loss: 0.2045 - val_mae: 0.4052 - 37ms/epoch - 1ms/step\n",
      "Epoch 4634/5000\n",
      "31/31 - 0s - loss: 15.6817 - mae: 1.5623 - val_loss: 110.6630 - val_mae: 10.5151 - 37ms/epoch - 1ms/step\n",
      "Epoch 4635/5000\n",
      "31/31 - 0s - loss: 6.0192 - mae: 1.4654 - val_loss: 1.1785 - val_mae: 1.0356 - 35ms/epoch - 1ms/step\n",
      "Epoch 4636/5000\n",
      "31/31 - 0s - loss: 1.7121 - mae: 1.1686 - val_loss: 3.3971 - val_mae: 1.8136 - 38ms/epoch - 1ms/step\n",
      "Epoch 4637/5000\n",
      "31/31 - 0s - loss: 19.0588 - mae: 2.2438 - val_loss: 1.4281 - val_mae: 1.1537 - 37ms/epoch - 1ms/step\n",
      "Epoch 4638/5000\n",
      "31/31 - 0s - loss: 1.2030 - mae: 0.9118 - val_loss: 0.1009 - val_mae: 0.2753 - 38ms/epoch - 1ms/step\n",
      "Epoch 4639/5000\n",
      "31/31 - 0s - loss: 21.4343 - mae: 1.8600 - val_loss: 1.6310 - val_mae: 1.2385 - 37ms/epoch - 1ms/step\n",
      "Epoch 4640/5000\n",
      "31/31 - 0s - loss: 1.8009 - mae: 1.0013 - val_loss: 0.7728 - val_mae: 0.8204 - 40ms/epoch - 1ms/step\n",
      "Epoch 4641/5000\n",
      "31/31 - 0s - loss: 19.2422 - mae: 2.2037 - val_loss: 0.5818 - val_mae: 0.6957 - 37ms/epoch - 1ms/step\n",
      "Epoch 4642/5000\n",
      "31/31 - 0s - loss: 0.7721 - mae: 0.7394 - val_loss: 0.6046 - val_mae: 0.7111 - 35ms/epoch - 1ms/step\n",
      "Epoch 4643/5000\n",
      "31/31 - 0s - loss: 24.7857 - mae: 2.3434 - val_loss: 0.3602 - val_mae: 0.5115 - 36ms/epoch - 1ms/step\n",
      "Epoch 4644/5000\n",
      "31/31 - 0s - loss: 1.5469 - mae: 0.8274 - val_loss: 2.3584 - val_mae: 1.5035 - 36ms/epoch - 1ms/step\n",
      "Epoch 4645/5000\n",
      "31/31 - 0s - loss: 1.8725 - mae: 0.9984 - val_loss: 50.7948 - val_mae: 7.1204 - 36ms/epoch - 1ms/step\n",
      "Epoch 4646/5000\n",
      "31/31 - 0s - loss: 12.2246 - mae: 2.3935 - val_loss: 1.3926 - val_mae: 1.1386 - 36ms/epoch - 1ms/step\n",
      "Epoch 4647/5000\n",
      "31/31 - 0s - loss: 4.4978 - mae: 1.6153 - val_loss: 0.1193 - val_mae: 0.3110 - 38ms/epoch - 1ms/step\n",
      "Epoch 4648/5000\n",
      "31/31 - 0s - loss: 0.5910 - mae: 0.6098 - val_loss: 62.9534 - val_mae: 7.9282 - 36ms/epoch - 1ms/step\n",
      "Epoch 4649/5000\n",
      "31/31 - 0s - loss: 9.9137 - mae: 1.8506 - val_loss: 0.6556 - val_mae: 0.7435 - 35ms/epoch - 1ms/step\n",
      "Epoch 4650/5000\n",
      "31/31 - 0s - loss: 0.9172 - mae: 0.6596 - val_loss: 0.6595 - val_mae: 0.7567 - 37ms/epoch - 1ms/step\n",
      "Epoch 4651/5000\n",
      "31/31 - 0s - loss: 15.1000 - mae: 1.8833 - val_loss: 1.2619 - val_mae: 1.0778 - 38ms/epoch - 1ms/step\n",
      "Epoch 4652/5000\n",
      "31/31 - 0s - loss: 8.5048 - mae: 1.7532 - val_loss: 72.2130 - val_mae: 8.4925 - 36ms/epoch - 1ms/step\n",
      "Epoch 4653/5000\n",
      "31/31 - 0s - loss: 9.0447 - mae: 1.4674 - val_loss: 0.1785 - val_mae: 0.3096 - 36ms/epoch - 1ms/step\n",
      "Epoch 4654/5000\n",
      "31/31 - 0s - loss: 0.7610 - mae: 0.7603 - val_loss: 2.3966 - val_mae: 1.5159 - 39ms/epoch - 1ms/step\n",
      "Epoch 4655/5000\n",
      "31/31 - 0s - loss: 25.5140 - mae: 2.2700 - val_loss: 4.1533 - val_mae: 2.0136 - 38ms/epoch - 1ms/step\n",
      "Epoch 4656/5000\n",
      "31/31 - 0s - loss: 1.0511 - mae: 0.8288 - val_loss: 18.2984 - val_mae: 4.2651 - 36ms/epoch - 1ms/step\n",
      "Epoch 4657/5000\n",
      "31/31 - 0s - loss: 10.4123 - mae: 2.1194 - val_loss: 0.1012 - val_mae: 0.2753 - 36ms/epoch - 1ms/step\n",
      "Epoch 4658/5000\n",
      "31/31 - 0s - loss: 10.2978 - mae: 2.0511 - val_loss: 6.0417 - val_mae: 2.4381 - 36ms/epoch - 1ms/step\n",
      "Epoch 4659/5000\n",
      "31/31 - 0s - loss: 2.2225 - mae: 1.1704 - val_loss: 0.2128 - val_mae: 0.3374 - 37ms/epoch - 1ms/step\n",
      "Epoch 4660/5000\n",
      "31/31 - 0s - loss: 11.7860 - mae: 2.2904 - val_loss: 2.7252 - val_mae: 1.6184 - 35ms/epoch - 1ms/step\n",
      "Epoch 4661/5000\n",
      "31/31 - 0s - loss: 3.8160 - mae: 1.4131 - val_loss: 0.8419 - val_mae: 0.8648 - 37ms/epoch - 1ms/step\n",
      "Epoch 4662/5000\n",
      "31/31 - 0s - loss: 0.7807 - mae: 0.6856 - val_loss: 0.1208 - val_mae: 0.2727 - 36ms/epoch - 1ms/step\n",
      "Epoch 4663/5000\n",
      "31/31 - 0s - loss: 21.5546 - mae: 2.0575 - val_loss: 0.5324 - val_mae: 0.6491 - 36ms/epoch - 1ms/step\n",
      "Epoch 4664/5000\n",
      "31/31 - 0s - loss: 4.3968 - mae: 1.8025 - val_loss: 5.1384 - val_mae: 2.2442 - 36ms/epoch - 1ms/step\n",
      "Epoch 4665/5000\n",
      "31/31 - 0s - loss: 4.2905 - mae: 1.2031 - val_loss: 40.7778 - val_mae: 6.3782 - 35ms/epoch - 1ms/step\n",
      "Epoch 4666/5000\n",
      "31/31 - 0s - loss: 14.1031 - mae: 1.9870 - val_loss: 1.3517 - val_mae: 1.1184 - 37ms/epoch - 1ms/step\n",
      "Epoch 4667/5000\n",
      "31/31 - 0s - loss: 6.0060 - mae: 2.0867 - val_loss: 0.1977 - val_mae: 0.4003 - 36ms/epoch - 1ms/step\n",
      "Epoch 4668/5000\n",
      "31/31 - 0s - loss: 0.8111 - mae: 0.6952 - val_loss: 3.1002 - val_mae: 1.7309 - 35ms/epoch - 1ms/step\n",
      "Epoch 4669/5000\n",
      "31/31 - 0s - loss: 19.4751 - mae: 2.2096 - val_loss: 1.3990 - val_mae: 1.1409 - 34ms/epoch - 1ms/step\n",
      "Epoch 4670/5000\n",
      "31/31 - 0s - loss: 0.9541 - mae: 0.7606 - val_loss: 2.0675 - val_mae: 1.4030 - 35ms/epoch - 1ms/step\n",
      "Epoch 4671/5000\n",
      "31/31 - 0s - loss: 11.9443 - mae: 1.8775 - val_loss: 5.5726 - val_mae: 2.3370 - 37ms/epoch - 1ms/step\n",
      "Epoch 4672/5000\n",
      "31/31 - 0s - loss: 2.5237 - mae: 1.2401 - val_loss: 1.9525 - val_mae: 1.3587 - 37ms/epoch - 1ms/step\n",
      "Epoch 4673/5000\n",
      "31/31 - 0s - loss: 11.5470 - mae: 1.8496 - val_loss: 0.2735 - val_mae: 0.4174 - 35ms/epoch - 1ms/step\n",
      "Epoch 4674/5000\n",
      "31/31 - 0s - loss: 0.9432 - mae: 0.6228 - val_loss: 1.9110 - val_mae: 1.3449 - 35ms/epoch - 1ms/step\n",
      "Epoch 4675/5000\n",
      "31/31 - 0s - loss: 18.7861 - mae: 1.9953 - val_loss: 6.5929 - val_mae: 2.5464 - 35ms/epoch - 1ms/step\n",
      "Epoch 4676/5000\n",
      "31/31 - 0s - loss: 1.6949 - mae: 1.0657 - val_loss: 0.1779 - val_mae: 0.3825 - 36ms/epoch - 1ms/step\n",
      "Epoch 4677/5000\n",
      "31/31 - 0s - loss: 14.2768 - mae: 2.3476 - val_loss: 6.9595 - val_mae: 2.6198 - 37ms/epoch - 1ms/step\n",
      "Epoch 4678/5000\n",
      "31/31 - 0s - loss: 1.5316 - mae: 1.0983 - val_loss: 1.6145 - val_mae: 1.2287 - 44ms/epoch - 1ms/step\n",
      "Epoch 4679/5000\n",
      "31/31 - 0s - loss: 16.4364 - mae: 2.1231 - val_loss: 0.2160 - val_mae: 0.3403 - 38ms/epoch - 1ms/step\n",
      "Epoch 4680/5000\n",
      "31/31 - 0s - loss: 1.0135 - mae: 0.6530 - val_loss: 0.1273 - val_mae: 0.3216 - 37ms/epoch - 1ms/step\n",
      "Epoch 4681/5000\n",
      "31/31 - 0s - loss: 17.0778 - mae: 1.9517 - val_loss: 2.3558 - val_mae: 1.4984 - 37ms/epoch - 1ms/step\n",
      "Epoch 4682/5000\n",
      "31/31 - 0s - loss: 1.2890 - mae: 0.7688 - val_loss: 1.5482 - val_mae: 1.1998 - 37ms/epoch - 1ms/step\n",
      "Epoch 4683/5000\n",
      "31/31 - 0s - loss: 1.2661 - mae: 0.9131 - val_loss: 3.2133 - val_mae: 1.7633 - 38ms/epoch - 1ms/step\n",
      "Epoch 4684/5000\n",
      "31/31 - 0s - loss: 24.8135 - mae: 2.4040 - val_loss: 0.2830 - val_mae: 0.4180 - 37ms/epoch - 1ms/step\n",
      "Epoch 4685/5000\n",
      "31/31 - 0s - loss: 1.5637 - mae: 0.8949 - val_loss: 0.7966 - val_mae: 0.8296 - 35ms/epoch - 1ms/step\n",
      "Epoch 4686/5000\n",
      "31/31 - 0s - loss: 13.0773 - mae: 2.0059 - val_loss: 1.1841 - val_mae: 1.0402 - 37ms/epoch - 1ms/step\n",
      "Epoch 4687/5000\n",
      "31/31 - 0s - loss: 1.5077 - mae: 1.1173 - val_loss: 6.2527 - val_mae: 2.4794 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4688/5000\n",
      "31/31 - 0s - loss: 12.5434 - mae: 2.1827 - val_loss: 1.7221 - val_mae: 1.2715 - 35ms/epoch - 1ms/step\n",
      "Epoch 4689/5000\n",
      "31/31 - 0s - loss: 9.8885 - mae: 1.6913 - val_loss: 22.8634 - val_mae: 4.7713 - 37ms/epoch - 1ms/step\n",
      "Epoch 4690/5000\n",
      "31/31 - 0s - loss: 5.3471 - mae: 1.1587 - val_loss: 14.3293 - val_mae: 3.7724 - 36ms/epoch - 1ms/step\n",
      "Epoch 4691/5000\n",
      "31/31 - 0s - loss: 10.7623 - mae: 1.5179 - val_loss: 92.1690 - val_mae: 9.5955 - 37ms/epoch - 1ms/step\n",
      "Epoch 4692/5000\n",
      "31/31 - 0s - loss: 5.4623 - mae: 1.2658 - val_loss: 2.3740 - val_mae: 1.5080 - 36ms/epoch - 1ms/step\n",
      "Epoch 4693/5000\n",
      "31/31 - 0s - loss: 0.8715 - mae: 0.7961 - val_loss: 1.5028 - val_mae: 1.1846 - 36ms/epoch - 1ms/step\n",
      "Epoch 4694/5000\n",
      "31/31 - 0s - loss: 24.3910 - mae: 2.1867 - val_loss: 2.5627 - val_mae: 1.5687 - 36ms/epoch - 1ms/step\n",
      "Epoch 4695/5000\n",
      "31/31 - 0s - loss: 1.5319 - mae: 0.9021 - val_loss: 0.5539 - val_mae: 0.6712 - 36ms/epoch - 1ms/step\n",
      "Epoch 4696/5000\n",
      "31/31 - 0s - loss: 16.9214 - mae: 1.5305 - val_loss: 473.6262 - val_mae: 21.7605 - 35ms/epoch - 1ms/step\n",
      "Epoch 4697/5000\n",
      "31/31 - 0s - loss: 19.3642 - mae: 1.8890 - val_loss: 1.2173 - val_mae: 1.0587 - 36ms/epoch - 1ms/step\n",
      "Epoch 4698/5000\n",
      "31/31 - 0s - loss: 1.4023 - mae: 0.9688 - val_loss: 2.3286 - val_mae: 1.4937 - 35ms/epoch - 1ms/step\n",
      "Epoch 4699/5000\n",
      "31/31 - 0s - loss: 17.8209 - mae: 2.0413 - val_loss: 0.3938 - val_mae: 0.5387 - 36ms/epoch - 1ms/step\n",
      "Epoch 4700/5000\n",
      "31/31 - 0s - loss: 0.4771 - mae: 0.4650 - val_loss: 0.7857 - val_mae: 0.8264 - 36ms/epoch - 1ms/step\n",
      "Epoch 4701/5000\n",
      "31/31 - 0s - loss: 12.5421 - mae: 2.2467 - val_loss: 0.1168 - val_mae: 0.2771 - 36ms/epoch - 1ms/step\n",
      "Epoch 4702/5000\n",
      "31/31 - 0s - loss: 1.2647 - mae: 0.8826 - val_loss: 0.3245 - val_mae: 0.4703 - 37ms/epoch - 1ms/step\n",
      "Epoch 4703/5000\n",
      "31/31 - 0s - loss: 21.4226 - mae: 1.8882 - val_loss: 0.3688 - val_mae: 0.5098 - 37ms/epoch - 1ms/step\n",
      "Epoch 4704/5000\n",
      "31/31 - 0s - loss: 1.3318 - mae: 0.9235 - val_loss: 4.8720 - val_mae: 2.1835 - 37ms/epoch - 1ms/step\n",
      "Epoch 4705/5000\n",
      "31/31 - 0s - loss: 1.8244 - mae: 1.0664 - val_loss: 98.5731 - val_mae: 9.9233 - 34ms/epoch - 1ms/step\n",
      "Epoch 4706/5000\n",
      "31/31 - 0s - loss: 18.3610 - mae: 1.9808 - val_loss: 0.4415 - val_mae: 0.5832 - 36ms/epoch - 1ms/step\n",
      "Epoch 4707/5000\n",
      "31/31 - 0s - loss: 1.1108 - mae: 0.8366 - val_loss: 1.9392 - val_mae: 1.3564 - 35ms/epoch - 1ms/step\n",
      "Epoch 4708/5000\n",
      "31/31 - 0s - loss: 25.0547 - mae: 2.1455 - val_loss: 2.8898 - val_mae: 1.6719 - 36ms/epoch - 1ms/step\n",
      "Epoch 4709/5000\n",
      "31/31 - 0s - loss: 0.9895 - mae: 0.7280 - val_loss: 0.9806 - val_mae: 0.9393 - 37ms/epoch - 1ms/step\n",
      "Epoch 4710/5000\n",
      "31/31 - 0s - loss: 22.4010 - mae: 2.2744 - val_loss: 0.3109 - val_mae: 0.4603 - 38ms/epoch - 1ms/step\n",
      "Epoch 4711/5000\n",
      "31/31 - 0s - loss: 0.9143 - mae: 0.7673 - val_loss: 4.4250 - val_mae: 2.0804 - 37ms/epoch - 1ms/step\n",
      "Epoch 4712/5000\n",
      "31/31 - 0s - loss: 29.8850 - mae: 2.3439 - val_loss: 0.2002 - val_mae: 0.4008 - 38ms/epoch - 1ms/step\n",
      "Epoch 4713/5000\n",
      "31/31 - 0s - loss: 2.0655 - mae: 1.0217 - val_loss: 0.1056 - val_mae: 0.2837 - 40ms/epoch - 1ms/step\n",
      "Epoch 4714/5000\n",
      "31/31 - 0s - loss: 2.1161 - mae: 1.1097 - val_loss: 0.6825 - val_mae: 0.7627 - 40ms/epoch - 1ms/step\n",
      "Epoch 4715/5000\n",
      "31/31 - 0s - loss: 13.0603 - mae: 1.8679 - val_loss: 0.1847 - val_mae: 0.3190 - 39ms/epoch - 1ms/step\n",
      "Epoch 4716/5000\n",
      "31/31 - 0s - loss: 2.4733 - mae: 1.3658 - val_loss: 8.2956 - val_mae: 2.8619 - 38ms/epoch - 1ms/step\n",
      "Epoch 4717/5000\n",
      "31/31 - 0s - loss: 16.1533 - mae: 2.2531 - val_loss: 1.5285 - val_mae: 1.1939 - 40ms/epoch - 1ms/step\n",
      "Epoch 4718/5000\n",
      "31/31 - 0s - loss: 1.0522 - mae: 0.7850 - val_loss: 1.7192 - val_mae: 1.2725 - 41ms/epoch - 1ms/step\n",
      "Epoch 4719/5000\n",
      "31/31 - 0s - loss: 29.3509 - mae: 2.1466 - val_loss: 0.9757 - val_mae: 0.9389 - 44ms/epoch - 1ms/step\n",
      "Epoch 4720/5000\n",
      "31/31 - 0s - loss: 1.8844 - mae: 0.8832 - val_loss: 0.2622 - val_mae: 0.4044 - 43ms/epoch - 1ms/step\n",
      "Epoch 4721/5000\n",
      "31/31 - 0s - loss: 7.7313 - mae: 1.5695 - val_loss: 0.5273 - val_mae: 0.6525 - 43ms/epoch - 1ms/step\n",
      "Epoch 4722/5000\n",
      "31/31 - 0s - loss: 1.3497 - mae: 0.9334 - val_loss: 0.3796 - val_mae: 0.5289 - 44ms/epoch - 1ms/step\n",
      "Epoch 4723/5000\n",
      "31/31 - 0s - loss: 19.1069 - mae: 1.9052 - val_loss: 0.3368 - val_mae: 0.4833 - 43ms/epoch - 1ms/step\n",
      "Epoch 4724/5000\n",
      "31/31 - 0s - loss: 1.2307 - mae: 0.8340 - val_loss: 1.7222 - val_mae: 1.2715 - 45ms/epoch - 1ms/step\n",
      "Epoch 4725/5000\n",
      "31/31 - 0s - loss: 5.4335 - mae: 1.5186 - val_loss: 0.8009 - val_mae: 0.8354 - 43ms/epoch - 1ms/step\n",
      "Epoch 4726/5000\n",
      "31/31 - 0s - loss: 17.3493 - mae: 2.2246 - val_loss: 1.6717 - val_mae: 1.2561 - 54ms/epoch - 2ms/step\n",
      "Epoch 4727/5000\n",
      "31/31 - 0s - loss: 1.7640 - mae: 1.0682 - val_loss: 8.8607 - val_mae: 2.9598 - 42ms/epoch - 1ms/step\n",
      "Epoch 4728/5000\n",
      "31/31 - 0s - loss: 22.6830 - mae: 2.1799 - val_loss: 0.3038 - val_mae: 0.4535 - 42ms/epoch - 1ms/step\n",
      "Epoch 4729/5000\n",
      "31/31 - 0s - loss: 0.8142 - mae: 0.6450 - val_loss: 0.2241 - val_mae: 0.4191 - 41ms/epoch - 1ms/step\n",
      "Epoch 4730/5000\n",
      "31/31 - 0s - loss: 0.7418 - mae: 0.7013 - val_loss: 23.1188 - val_mae: 4.7985 - 42ms/epoch - 1ms/step\n",
      "Epoch 4731/5000\n",
      "31/31 - 0s - loss: 10.1061 - mae: 1.8974 - val_loss: 0.1199 - val_mae: 0.2851 - 42ms/epoch - 1ms/step\n",
      "Epoch 4732/5000\n",
      "31/31 - 0s - loss: 1.5172 - mae: 0.9182 - val_loss: 4.2182 - val_mae: 2.0296 - 44ms/epoch - 1ms/step\n",
      "Epoch 4733/5000\n",
      "31/31 - 0s - loss: 18.1456 - mae: 1.8810 - val_loss: 0.1009 - val_mae: 0.2748 - 46ms/epoch - 1ms/step\n",
      "Epoch 4734/5000\n",
      "31/31 - 0s - loss: 1.0422 - mae: 0.7903 - val_loss: 2.1463 - val_mae: 1.4311 - 46ms/epoch - 1ms/step\n",
      "Epoch 4735/5000\n",
      "31/31 - 0s - loss: 17.6795 - mae: 2.0386 - val_loss: 0.4439 - val_mae: 0.5842 - 46ms/epoch - 1ms/step\n",
      "Epoch 4736/5000\n",
      "31/31 - 0s - loss: 0.7050 - mae: 0.7210 - val_loss: 0.1700 - val_mae: 0.3025 - 48ms/epoch - 2ms/step\n",
      "Epoch 4737/5000\n",
      "31/31 - 0s - loss: 19.3168 - mae: 1.9497 - val_loss: 0.2762 - val_mae: 0.4119 - 42ms/epoch - 1ms/step\n",
      "Epoch 4738/5000\n",
      "31/31 - 0s - loss: 1.3945 - mae: 0.8646 - val_loss: 2.8858 - val_mae: 1.6688 - 46ms/epoch - 1ms/step\n",
      "Epoch 4739/5000\n",
      "31/31 - 0s - loss: 1.0119 - mae: 0.8625 - val_loss: 0.4272 - val_mae: 0.5708 - 45ms/epoch - 1ms/step\n",
      "Epoch 4740/5000\n",
      "31/31 - 0s - loss: 25.7352 - mae: 2.1191 - val_loss: 3.5789 - val_mae: 1.8666 - 41ms/epoch - 1ms/step\n",
      "Epoch 4741/5000\n",
      "31/31 - 0s - loss: 1.9293 - mae: 1.0712 - val_loss: 0.1886 - val_mae: 0.3209 - 40ms/epoch - 1ms/step\n",
      "Epoch 4742/5000\n",
      "31/31 - 0s - loss: 10.6679 - mae: 1.3040 - val_loss: 128.5908 - val_mae: 11.3358 - 41ms/epoch - 1ms/step\n",
      "Epoch 4743/5000\n",
      "31/31 - 0s - loss: 5.3645 - mae: 1.2047 - val_loss: 0.2137 - val_mae: 0.3412 - 36ms/epoch - 1ms/step\n",
      "Epoch 4744/5000\n",
      "31/31 - 0s - loss: 1.5742 - mae: 0.9172 - val_loss: 0.8886 - val_mae: 0.8926 - 38ms/epoch - 1ms/step\n",
      "Epoch 4745/5000\n",
      "31/31 - 0s - loss: 21.2051 - mae: 2.0761 - val_loss: 0.1987 - val_mae: 0.3295 - 37ms/epoch - 1ms/step\n",
      "Epoch 4746/5000\n",
      "31/31 - 0s - loss: 1.2729 - mae: 0.9726 - val_loss: 0.1855 - val_mae: 0.3169 - 36ms/epoch - 1ms/step\n",
      "Epoch 4747/5000\n",
      "31/31 - 0s - loss: 14.4410 - mae: 1.9763 - val_loss: 0.4681 - val_mae: 0.6114 - 39ms/epoch - 1ms/step\n",
      "Epoch 4748/5000\n",
      "31/31 - 0s - loss: 1.7426 - mae: 1.0148 - val_loss: 2.8078 - val_mae: 1.6443 - 37ms/epoch - 1ms/step\n",
      "Epoch 4749/5000\n",
      "31/31 - 0s - loss: 18.0875 - mae: 2.2563 - val_loss: 7.0536 - val_mae: 2.6376 - 37ms/epoch - 1ms/step\n",
      "Epoch 4750/5000\n",
      "31/31 - 0s - loss: 0.9369 - mae: 0.8496 - val_loss: 0.6726 - val_mae: 0.7577 - 37ms/epoch - 1ms/step\n",
      "Epoch 4751/5000\n",
      "31/31 - 0s - loss: 14.4600 - mae: 2.5755 - val_loss: 0.3278 - val_mae: 0.4825 - 36ms/epoch - 1ms/step\n",
      "Epoch 4752/5000\n",
      "31/31 - 0s - loss: 1.5280 - mae: 0.9791 - val_loss: 4.4933 - val_mae: 2.0962 - 41ms/epoch - 1ms/step\n",
      "Epoch 4753/5000\n",
      "31/31 - 0s - loss: 5.3503 - mae: 1.4335 - val_loss: 0.1078 - val_mae: 0.2880 - 37ms/epoch - 1ms/step\n",
      "Epoch 4754/5000\n",
      "31/31 - 0s - loss: 16.1674 - mae: 1.6940 - val_loss: 2.2684 - val_mae: 1.4708 - 37ms/epoch - 1ms/step\n",
      "Epoch 4755/5000\n",
      "31/31 - 0s - loss: 1.6808 - mae: 1.0576 - val_loss: 0.4115 - val_mae: 0.5553 - 37ms/epoch - 1ms/step\n",
      "Epoch 4756/5000\n",
      "31/31 - 0s - loss: 1.0274 - mae: 0.7231 - val_loss: 3.4194 - val_mae: 1.8224 - 36ms/epoch - 1ms/step\n",
      "Epoch 4757/5000\n",
      "31/31 - 0s - loss: 29.4583 - mae: 2.0418 - val_loss: 26.0072 - val_mae: 5.0901 - 35ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4758/5000\n",
      "31/31 - 0s - loss: 2.3682 - mae: 1.1685 - val_loss: 27.8268 - val_mae: 5.2647 - 38ms/epoch - 1ms/step\n",
      "Epoch 4759/5000\n",
      "31/31 - 0s - loss: 3.8581 - mae: 1.4199 - val_loss: 0.6094 - val_mae: 0.7120 - 37ms/epoch - 1ms/step\n",
      "Epoch 4760/5000\n",
      "31/31 - 0s - loss: 19.1236 - mae: 2.1820 - val_loss: 0.3022 - val_mae: 0.4492 - 37ms/epoch - 1ms/step\n",
      "Epoch 4761/5000\n",
      "31/31 - 0s - loss: 0.9394 - mae: 0.7087 - val_loss: 2.2121 - val_mae: 1.4528 - 34ms/epoch - 1ms/step\n",
      "Epoch 4762/5000\n",
      "31/31 - 0s - loss: 2.2809 - mae: 0.8830 - val_loss: 142.0149 - val_mae: 11.9125 - 36ms/epoch - 1ms/step\n",
      "Epoch 4763/5000\n",
      "31/31 - 0s - loss: 24.0288 - mae: 2.2318 - val_loss: 1.8740 - val_mae: 1.3329 - 35ms/epoch - 1ms/step\n",
      "Epoch 4764/5000\n",
      "31/31 - 0s - loss: 1.1593 - mae: 0.7184 - val_loss: 4.3280 - val_mae: 2.0566 - 35ms/epoch - 1ms/step\n",
      "Epoch 4765/5000\n",
      "31/31 - 0s - loss: 16.3792 - mae: 2.0546 - val_loss: 4.4353 - val_mae: 2.0810 - 38ms/epoch - 1ms/step\n",
      "Epoch 4766/5000\n",
      "31/31 - 0s - loss: 2.0614 - mae: 1.2979 - val_loss: 0.2670 - val_mae: 0.4485 - 39ms/epoch - 1ms/step\n",
      "Epoch 4767/5000\n",
      "31/31 - 0s - loss: 12.4221 - mae: 1.9106 - val_loss: 0.2965 - val_mae: 0.4423 - 35ms/epoch - 1ms/step\n",
      "Epoch 4768/5000\n",
      "31/31 - 0s - loss: 0.8583 - mae: 0.7438 - val_loss: 1.9363 - val_mae: 1.3551 - 37ms/epoch - 1ms/step\n",
      "Epoch 4769/5000\n",
      "31/31 - 0s - loss: 6.8917 - mae: 1.9266 - val_loss: 0.9009 - val_mae: 0.8918 - 36ms/epoch - 1ms/step\n",
      "Epoch 4770/5000\n",
      "31/31 - 0s - loss: 16.6123 - mae: 2.1090 - val_loss: 0.9255 - val_mae: 0.9095 - 37ms/epoch - 1ms/step\n",
      "Epoch 4771/5000\n",
      "31/31 - 0s - loss: 1.5134 - mae: 0.8999 - val_loss: 2.8761 - val_mae: 1.6668 - 35ms/epoch - 1ms/step\n",
      "Epoch 4772/5000\n",
      "31/31 - 0s - loss: 18.0773 - mae: 2.3023 - val_loss: 0.2525 - val_mae: 0.3949 - 34ms/epoch - 1ms/step\n",
      "Epoch 4773/5000\n",
      "31/31 - 0s - loss: 1.1409 - mae: 0.7487 - val_loss: 0.1727 - val_mae: 0.3037 - 37ms/epoch - 1ms/step\n",
      "Epoch 4774/5000\n",
      "31/31 - 0s - loss: 6.3132 - mae: 1.5579 - val_loss: 163.1918 - val_mae: 12.7710 - 38ms/epoch - 1ms/step\n",
      "Epoch 4775/5000\n",
      "31/31 - 0s - loss: 8.9094 - mae: 1.6036 - val_loss: 1.9654 - val_mae: 1.3645 - 35ms/epoch - 1ms/step\n",
      "Epoch 4776/5000\n",
      "31/31 - 0s - loss: 15.6902 - mae: 2.1668 - val_loss: 34.2009 - val_mae: 5.8389 - 34ms/epoch - 1ms/step\n",
      "Epoch 4777/5000\n",
      "31/31 - 0s - loss: 1.8142 - mae: 0.8695 - val_loss: 5.3159 - val_mae: 2.2837 - 38ms/epoch - 1ms/step\n",
      "Epoch 4778/5000\n",
      "31/31 - 0s - loss: 1.2789 - mae: 0.9385 - val_loss: 0.4857 - val_mae: 0.6213 - 36ms/epoch - 1ms/step\n",
      "Epoch 4779/5000\n",
      "31/31 - 0s - loss: 21.9109 - mae: 2.0471 - val_loss: 4.3901 - val_mae: 2.0711 - 35ms/epoch - 1ms/step\n",
      "Epoch 4780/5000\n",
      "31/31 - 0s - loss: 1.6515 - mae: 0.9743 - val_loss: 0.2996 - val_mae: 0.4455 - 35ms/epoch - 1ms/step\n",
      "Epoch 4781/5000\n",
      "31/31 - 0s - loss: 23.9345 - mae: 2.2412 - val_loss: 0.2796 - val_mae: 0.4564 - 36ms/epoch - 1ms/step\n",
      "Epoch 4782/5000\n",
      "31/31 - 0s - loss: 1.1711 - mae: 0.9633 - val_loss: 0.3061 - val_mae: 0.4717 - 36ms/epoch - 1ms/step\n",
      "Epoch 4783/5000\n",
      "31/31 - 0s - loss: 2.0999 - mae: 0.9537 - val_loss: 220.1933 - val_mae: 14.8360 - 37ms/epoch - 1ms/step\n",
      "Epoch 4784/5000\n",
      "31/31 - 0s - loss: 15.1222 - mae: 2.0122 - val_loss: 0.1318 - val_mae: 0.3288 - 37ms/epoch - 1ms/step\n",
      "Epoch 4785/5000\n",
      "31/31 - 0s - loss: 0.5464 - mae: 0.5572 - val_loss: 0.1157 - val_mae: 0.3033 - 35ms/epoch - 1ms/step\n",
      "Epoch 4786/5000\n",
      "31/31 - 0s - loss: 25.6007 - mae: 2.2304 - val_loss: 0.8574 - val_mae: 0.8723 - 47ms/epoch - 2ms/step\n",
      "Epoch 4787/5000\n",
      "31/31 - 0s - loss: 1.2910 - mae: 0.8958 - val_loss: 0.5267 - val_mae: 0.6528 - 36ms/epoch - 1ms/step\n",
      "Epoch 4788/5000\n",
      "31/31 - 0s - loss: 21.4865 - mae: 2.1567 - val_loss: 0.4047 - val_mae: 0.5500 - 37ms/epoch - 1ms/step\n",
      "Epoch 4789/5000\n",
      "31/31 - 0s - loss: 1.2059 - mae: 0.8052 - val_loss: 0.5553 - val_mae: 0.6727 - 39ms/epoch - 1ms/step\n",
      "Epoch 4790/5000\n",
      "31/31 - 0s - loss: 0.9127 - mae: 0.7361 - val_loss: 8.7547 - val_mae: 2.9415 - 36ms/epoch - 1ms/step\n",
      "Epoch 4791/5000\n",
      "31/31 - 0s - loss: 22.8932 - mae: 2.1908 - val_loss: 5.0814 - val_mae: 2.2314 - 35ms/epoch - 1ms/step\n",
      "Epoch 4792/5000\n",
      "31/31 - 0s - loss: 1.1815 - mae: 0.8019 - val_loss: 0.2301 - val_mae: 0.3623 - 37ms/epoch - 1ms/step\n",
      "Epoch 4793/5000\n",
      "31/31 - 0s - loss: 13.7595 - mae: 2.1764 - val_loss: 3.1767 - val_mae: 1.7545 - 36ms/epoch - 1ms/step\n",
      "Epoch 4794/5000\n",
      "31/31 - 0s - loss: 3.1425 - mae: 1.5782 - val_loss: 2.4990 - val_mae: 1.5487 - 36ms/epoch - 1ms/step\n",
      "Epoch 4795/5000\n",
      "31/31 - 0s - loss: 27.7203 - mae: 2.2943 - val_loss: 0.1090 - val_mae: 0.2855 - 36ms/epoch - 1ms/step\n",
      "Epoch 4796/5000\n",
      "31/31 - 0s - loss: 1.1759 - mae: 0.8579 - val_loss: 0.3083 - val_mae: 0.4728 - 38ms/epoch - 1ms/step\n",
      "Epoch 4797/5000\n",
      "31/31 - 0s - loss: 27.3914 - mae: 2.2565 - val_loss: 0.2245 - val_mae: 0.3536 - 38ms/epoch - 1ms/step\n",
      "Epoch 4798/5000\n",
      "31/31 - 0s - loss: 1.1071 - mae: 0.8109 - val_loss: 0.1592 - val_mae: 0.3651 - 35ms/epoch - 1ms/step\n",
      "Epoch 4799/5000\n",
      "31/31 - 0s - loss: 12.0034 - mae: 1.6994 - val_loss: 23.0562 - val_mae: 4.7899 - 37ms/epoch - 1ms/step\n",
      "Epoch 4800/5000\n",
      "31/31 - 0s - loss: 2.3338 - mae: 1.1701 - val_loss: 0.3208 - val_mae: 0.4632 - 37ms/epoch - 1ms/step\n",
      "Epoch 4801/5000\n",
      "31/31 - 0s - loss: 8.5061 - mae: 2.0285 - val_loss: 0.1578 - val_mae: 0.2910 - 35ms/epoch - 1ms/step\n",
      "Epoch 4802/5000\n",
      "31/31 - 0s - loss: 0.3684 - mae: 0.4530 - val_loss: 2.4652 - val_mae: 1.5371 - 37ms/epoch - 1ms/step\n",
      "Epoch 4803/5000\n",
      "31/31 - 0s - loss: 11.3046 - mae: 1.6823 - val_loss: 1.0130 - val_mae: 0.9539 - 38ms/epoch - 1ms/step\n",
      "Epoch 4804/5000\n",
      "31/31 - 0s - loss: 1.0431 - mae: 0.7821 - val_loss: 0.5289 - val_mae: 0.6498 - 38ms/epoch - 1ms/step\n",
      "Epoch 4805/5000\n",
      "31/31 - 0s - loss: 18.6737 - mae: 2.0930 - val_loss: 2.9304 - val_mae: 1.6830 - 37ms/epoch - 1ms/step\n",
      "Epoch 4806/5000\n",
      "31/31 - 0s - loss: 1.1916 - mae: 0.8645 - val_loss: 0.1117 - val_mae: 0.2741 - 38ms/epoch - 1ms/step\n",
      "Epoch 4807/5000\n",
      "31/31 - 0s - loss: 30.8750 - mae: 2.1864 - val_loss: 0.2167 - val_mae: 0.3494 - 34ms/epoch - 1ms/step\n",
      "Epoch 4808/5000\n",
      "31/31 - 0s - loss: 1.7209 - mae: 1.1505 - val_loss: 3.5972 - val_mae: 1.8704 - 35ms/epoch - 1ms/step\n",
      "Epoch 4809/5000\n",
      "31/31 - 0s - loss: 9.2326 - mae: 1.8421 - val_loss: 0.1185 - val_mae: 0.2836 - 37ms/epoch - 1ms/step\n",
      "Epoch 4810/5000\n",
      "31/31 - 0s - loss: 0.6637 - mae: 0.6437 - val_loss: 0.1050 - val_mae: 0.2812 - 37ms/epoch - 1ms/step\n",
      "Epoch 4811/5000\n",
      "31/31 - 0s - loss: 7.6441 - mae: 1.5805 - val_loss: 0.7749 - val_mae: 0.8182 - 37ms/epoch - 1ms/step\n",
      "Epoch 4812/5000\n",
      "31/31 - 0s - loss: 13.3015 - mae: 2.1094 - val_loss: 0.1481 - val_mae: 0.2920 - 35ms/epoch - 1ms/step\n",
      "Epoch 4813/5000\n",
      "31/31 - 0s - loss: 1.6090 - mae: 1.0401 - val_loss: 3.1081 - val_mae: 1.7324 - 36ms/epoch - 1ms/step\n",
      "Epoch 4814/5000\n",
      "31/31 - 0s - loss: 11.6939 - mae: 1.5754 - val_loss: 235.6745 - val_mae: 15.3483 - 36ms/epoch - 1ms/step\n",
      "Epoch 4815/5000\n",
      "31/31 - 0s - loss: 10.3366 - mae: 1.3523 - val_loss: 0.3372 - val_mae: 0.4878 - 36ms/epoch - 1ms/step\n",
      "Epoch 4816/5000\n",
      "31/31 - 0s - loss: 1.2153 - mae: 0.8949 - val_loss: 0.7993 - val_mae: 0.8361 - 37ms/epoch - 1ms/step\n",
      "Epoch 4817/5000\n",
      "31/31 - 0s - loss: 21.5448 - mae: 2.1632 - val_loss: 1.1397 - val_mae: 1.0177 - 37ms/epoch - 1ms/step\n",
      "Epoch 4818/5000\n",
      "31/31 - 0s - loss: 3.3141 - mae: 1.2621 - val_loss: 12.5232 - val_mae: 3.5245 - 36ms/epoch - 1ms/step\n",
      "Epoch 4819/5000\n",
      "31/31 - 0s - loss: 1.3678 - mae: 0.7131 - val_loss: 0.6925 - val_mae: 0.7674 - 36ms/epoch - 1ms/step\n",
      "Epoch 4820/5000\n",
      "31/31 - 0s - loss: 26.0816 - mae: 2.0105 - val_loss: 0.1163 - val_mae: 0.3044 - 34ms/epoch - 1ms/step\n",
      "Epoch 4821/5000\n",
      "31/31 - 0s - loss: 1.8788 - mae: 0.9440 - val_loss: 0.1034 - val_mae: 0.2770 - 38ms/epoch - 1ms/step\n",
      "Epoch 4822/5000\n",
      "31/31 - 0s - loss: 14.6567 - mae: 1.9238 - val_loss: 1.2957 - val_mae: 1.0920 - 38ms/epoch - 1ms/step\n",
      "Epoch 4823/5000\n",
      "31/31 - 0s - loss: 0.4657 - mae: 0.5532 - val_loss: 3.0977 - val_mae: 1.7313 - 40ms/epoch - 1ms/step\n",
      "Epoch 4824/5000\n",
      "31/31 - 0s - loss: 2.0191 - mae: 0.8543 - val_loss: 30.4247 - val_mae: 5.5070 - 37ms/epoch - 1ms/step\n",
      "Epoch 4825/5000\n",
      "31/31 - 0s - loss: 17.5431 - mae: 2.5912 - val_loss: 5.6391 - val_mae: 2.3534 - 37ms/epoch - 1ms/step\n",
      "Epoch 4826/5000\n",
      "31/31 - 0s - loss: 11.8026 - mae: 2.5360 - val_loss: 0.4647 - val_mae: 0.6014 - 36ms/epoch - 1ms/step\n",
      "Epoch 4827/5000\n",
      "31/31 - 0s - loss: 0.3337 - mae: 0.4481 - val_loss: 1.4269 - val_mae: 1.1514 - 34ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4828/5000\n",
      "31/31 - 0s - loss: 5.8732 - mae: 1.8117 - val_loss: 0.1614 - val_mae: 0.2951 - 37ms/epoch - 1ms/step\n",
      "Epoch 4829/5000\n",
      "31/31 - 0s - loss: 9.8891 - mae: 1.8708 - val_loss: 0.6523 - val_mae: 0.7328 - 37ms/epoch - 1ms/step\n",
      "Epoch 4830/5000\n",
      "31/31 - 0s - loss: 2.3139 - mae: 1.1444 - val_loss: 1.6175 - val_mae: 1.2293 - 38ms/epoch - 1ms/step\n",
      "Epoch 4831/5000\n",
      "31/31 - 0s - loss: 17.3950 - mae: 2.1374 - val_loss: 0.1285 - val_mae: 0.2896 - 37ms/epoch - 1ms/step\n",
      "Epoch 4832/5000\n",
      "31/31 - 0s - loss: 1.0350 - mae: 0.8530 - val_loss: 0.9337 - val_mae: 0.9106 - 36ms/epoch - 1ms/step\n",
      "Epoch 4833/5000\n",
      "31/31 - 0s - loss: 18.9282 - mae: 2.0325 - val_loss: 0.2791 - val_mae: 0.4572 - 36ms/epoch - 1ms/step\n",
      "Epoch 4834/5000\n",
      "31/31 - 0s - loss: 1.2095 - mae: 0.8412 - val_loss: 7.9824 - val_mae: 2.8059 - 37ms/epoch - 1ms/step\n",
      "Epoch 4835/5000\n",
      "31/31 - 0s - loss: 11.8543 - mae: 2.0045 - val_loss: 4.6283 - val_mae: 2.1289 - 35ms/epoch - 1ms/step\n",
      "Epoch 4836/5000\n",
      "31/31 - 0s - loss: 1.3315 - mae: 0.9336 - val_loss: 0.4682 - val_mae: 0.6078 - 35ms/epoch - 1ms/step\n",
      "Epoch 4837/5000\n",
      "31/31 - 0s - loss: 23.0860 - mae: 2.0229 - val_loss: 0.9145 - val_mae: 0.9058 - 35ms/epoch - 1ms/step\n",
      "Epoch 4838/5000\n",
      "31/31 - 0s - loss: 0.9924 - mae: 0.6573 - val_loss: 0.1254 - val_mae: 0.2749 - 37ms/epoch - 1ms/step\n",
      "Epoch 4839/5000\n",
      "31/31 - 0s - loss: 22.0077 - mae: 1.8807 - val_loss: 46.8274 - val_mae: 6.8357 - 35ms/epoch - 1ms/step\n",
      "Epoch 4840/5000\n",
      "31/31 - 0s - loss: 2.9164 - mae: 1.0000 - val_loss: 2.2635 - val_mae: 1.4712 - 36ms/epoch - 1ms/step\n",
      "Epoch 4841/5000\n",
      "31/31 - 0s - loss: 1.7985 - mae: 0.8454 - val_loss: 6.1602 - val_mae: 2.4611 - 36ms/epoch - 1ms/step\n",
      "Epoch 4842/5000\n",
      "31/31 - 0s - loss: 12.6634 - mae: 2.1943 - val_loss: 0.1795 - val_mae: 0.3162 - 36ms/epoch - 1ms/step\n",
      "Epoch 4843/5000\n",
      "31/31 - 0s - loss: 1.4113 - mae: 0.9509 - val_loss: 0.1141 - val_mae: 0.2807 - 34ms/epoch - 1ms/step\n",
      "Epoch 4844/5000\n",
      "31/31 - 0s - loss: 23.4576 - mae: 2.2047 - val_loss: 1.8692 - val_mae: 1.3310 - 35ms/epoch - 1ms/step\n",
      "Epoch 4845/5000\n",
      "31/31 - 0s - loss: 1.8059 - mae: 0.9788 - val_loss: 0.4821 - val_mae: 0.6168 - 36ms/epoch - 1ms/step\n",
      "Epoch 4846/5000\n",
      "31/31 - 0s - loss: 17.0618 - mae: 2.0158 - val_loss: 0.2102 - val_mae: 0.4094 - 36ms/epoch - 1ms/step\n",
      "Epoch 4847/5000\n",
      "31/31 - 0s - loss: 1.1222 - mae: 0.8517 - val_loss: 0.1528 - val_mae: 0.2886 - 37ms/epoch - 1ms/step\n",
      "Epoch 4848/5000\n",
      "31/31 - 0s - loss: 9.1565 - mae: 2.1046 - val_loss: 38.6917 - val_mae: 6.2109 - 34ms/epoch - 1ms/step\n",
      "Epoch 4849/5000\n",
      "31/31 - 0s - loss: 3.3555 - mae: 1.4160 - val_loss: 2.7811 - val_mae: 1.6344 - 36ms/epoch - 1ms/step\n",
      "Epoch 4850/5000\n",
      "31/31 - 0s - loss: 15.8285 - mae: 2.3231 - val_loss: 1.5927 - val_mae: 1.2210 - 38ms/epoch - 1ms/step\n",
      "Epoch 4851/5000\n",
      "31/31 - 0s - loss: 1.2228 - mae: 0.9401 - val_loss: 0.4452 - val_mae: 0.5850 - 37ms/epoch - 1ms/step\n",
      "Epoch 4852/5000\n",
      "31/31 - 0s - loss: 1.3920 - mae: 0.6639 - val_loss: 48.9673 - val_mae: 6.9904 - 34ms/epoch - 1ms/step\n",
      "Epoch 4853/5000\n",
      "31/31 - 0s - loss: 24.8662 - mae: 1.8983 - val_loss: 1.3983 - val_mae: 1.1389 - 35ms/epoch - 1ms/step\n",
      "Epoch 4854/5000\n",
      "31/31 - 0s - loss: 5.1221 - mae: 1.6740 - val_loss: 0.1393 - val_mae: 0.3381 - 40ms/epoch - 1ms/step\n",
      "Epoch 4855/5000\n",
      "31/31 - 0s - loss: 0.4822 - mae: 0.5630 - val_loss: 0.2274 - val_mae: 0.3559 - 37ms/epoch - 1ms/step\n",
      "Epoch 4856/5000\n",
      "31/31 - 0s - loss: 18.2169 - mae: 2.2408 - val_loss: 0.5390 - val_mae: 0.6598 - 35ms/epoch - 1ms/step\n",
      "Epoch 4857/5000\n",
      "31/31 - 0s - loss: 1.2321 - mae: 0.9021 - val_loss: 0.1655 - val_mae: 0.2974 - 39ms/epoch - 1ms/step\n",
      "Epoch 4858/5000\n",
      "31/31 - 0s - loss: 16.3904 - mae: 2.0199 - val_loss: 2.3906 - val_mae: 1.5114 - 35ms/epoch - 1ms/step\n",
      "Epoch 4859/5000\n",
      "31/31 - 0s - loss: 1.3359 - mae: 0.8439 - val_loss: 0.3001 - val_mae: 0.4413 - 38ms/epoch - 1ms/step\n",
      "Epoch 4860/5000\n",
      "31/31 - 0s - loss: 15.9119 - mae: 1.8894 - val_loss: 0.5314 - val_mae: 0.6534 - 35ms/epoch - 1ms/step\n",
      "Epoch 4861/5000\n",
      "31/31 - 0s - loss: 1.0332 - mae: 0.8276 - val_loss: 0.3852 - val_mae: 0.5299 - 35ms/epoch - 1ms/step\n",
      "Epoch 4862/5000\n",
      "31/31 - 0s - loss: 27.2886 - mae: 2.1145 - val_loss: 0.4911 - val_mae: 0.6215 - 35ms/epoch - 1ms/step\n",
      "Epoch 4863/5000\n",
      "31/31 - 0s - loss: 1.2393 - mae: 0.9148 - val_loss: 2.8675 - val_mae: 1.6632 - 36ms/epoch - 1ms/step\n",
      "Epoch 4864/5000\n",
      "31/31 - 0s - loss: 1.0122 - mae: 0.8260 - val_loss: 4.4384 - val_mae: 2.0840 - 38ms/epoch - 1ms/step\n",
      "Epoch 4865/5000\n",
      "31/31 - 0s - loss: 15.7403 - mae: 1.8992 - val_loss: 0.1653 - val_mae: 0.2991 - 36ms/epoch - 1ms/step\n",
      "Epoch 4866/5000\n",
      "31/31 - 0s - loss: 0.7781 - mae: 0.7541 - val_loss: 0.8686 - val_mae: 0.8760 - 38ms/epoch - 1ms/step\n",
      "Epoch 4867/5000\n",
      "31/31 - 0s - loss: 20.1854 - mae: 2.0684 - val_loss: 0.7645 - val_mae: 0.8112 - 37ms/epoch - 1ms/step\n",
      "Epoch 4868/5000\n",
      "31/31 - 0s - loss: 0.9685 - mae: 0.8295 - val_loss: 1.2575 - val_mae: 1.0717 - 33ms/epoch - 1ms/step\n",
      "Epoch 4869/5000\n",
      "31/31 - 0s - loss: 16.1554 - mae: 2.1254 - val_loss: 2.3638 - val_mae: 1.5038 - 36ms/epoch - 1ms/step\n",
      "Epoch 4870/5000\n",
      "31/31 - 0s - loss: 1.0161 - mae: 0.7768 - val_loss: 10.7831 - val_mae: 3.2689 - 36ms/epoch - 1ms/step\n",
      "Epoch 4871/5000\n",
      "31/31 - 0s - loss: 9.7855 - mae: 2.2196 - val_loss: 0.1237 - val_mae: 0.2760 - 37ms/epoch - 1ms/step\n",
      "Epoch 4872/5000\n",
      "31/31 - 0s - loss: 2.6649 - mae: 1.1192 - val_loss: 115.8205 - val_mae: 10.7574 - 35ms/epoch - 1ms/step\n",
      "Epoch 4873/5000\n",
      "31/31 - 0s - loss: 8.4123 - mae: 1.6449 - val_loss: 6.7420 - val_mae: 2.5779 - 36ms/epoch - 1ms/step\n",
      "Epoch 4874/5000\n",
      "31/31 - 0s - loss: 18.8138 - mae: 2.1552 - val_loss: 0.1093 - val_mae: 0.2850 - 35ms/epoch - 1ms/step\n",
      "Epoch 4875/5000\n",
      "31/31 - 0s - loss: 0.7670 - mae: 0.6051 - val_loss: 0.1362 - val_mae: 0.3365 - 35ms/epoch - 1ms/step\n",
      "Epoch 4876/5000\n",
      "31/31 - 0s - loss: 8.6490 - mae: 1.7877 - val_loss: 39.1379 - val_mae: 6.2484 - 37ms/epoch - 1ms/step\n",
      "Epoch 4877/5000\n",
      "31/31 - 0s - loss: 2.2842 - mae: 0.9761 - val_loss: 0.6803 - val_mae: 0.7608 - 36ms/epoch - 1ms/step\n",
      "Epoch 4878/5000\n",
      "31/31 - 0s - loss: 9.7500 - mae: 1.9307 - val_loss: 2.5691 - val_mae: 1.5720 - 35ms/epoch - 1ms/step\n",
      "Epoch 4879/5000\n",
      "31/31 - 0s - loss: 1.2828 - mae: 0.8618 - val_loss: 0.1283 - val_mae: 0.3258 - 36ms/epoch - 1ms/step\n",
      "Epoch 4880/5000\n",
      "31/31 - 0s - loss: 19.2457 - mae: 2.1874 - val_loss: 0.2128 - val_mae: 0.3410 - 36ms/epoch - 1ms/step\n",
      "Epoch 4881/5000\n",
      "31/31 - 0s - loss: 1.1647 - mae: 0.9187 - val_loss: 0.1555 - val_mae: 0.2879 - 37ms/epoch - 1ms/step\n",
      "Epoch 4882/5000\n",
      "31/31 - 0s - loss: 17.7661 - mae: 1.9831 - val_loss: 0.1195 - val_mae: 0.3036 - 34ms/epoch - 1ms/step\n",
      "Epoch 4883/5000\n",
      "31/31 - 0s - loss: 0.8381 - mae: 0.7583 - val_loss: 0.4151 - val_mae: 0.5580 - 36ms/epoch - 1ms/step\n",
      "Epoch 4884/5000\n",
      "31/31 - 0s - loss: 15.2322 - mae: 2.0474 - val_loss: 12.9798 - val_mae: 3.5877 - 35ms/epoch - 1ms/step\n",
      "Epoch 4885/5000\n",
      "31/31 - 0s - loss: 1.6379 - mae: 0.8888 - val_loss: 4.9921 - val_mae: 2.2120 - 36ms/epoch - 1ms/step\n",
      "Epoch 4886/5000\n",
      "31/31 - 0s - loss: 10.3662 - mae: 2.0114 - val_loss: 0.8428 - val_mae: 0.8620 - 48ms/epoch - 2ms/step\n",
      "Epoch 4887/5000\n",
      "31/31 - 0s - loss: 0.4558 - mae: 0.5733 - val_loss: 0.3516 - val_mae: 0.4986 - 37ms/epoch - 1ms/step\n",
      "Epoch 4888/5000\n",
      "31/31 - 0s - loss: 10.3054 - mae: 1.9544 - val_loss: 0.1192 - val_mae: 0.2875 - 36ms/epoch - 1ms/step\n",
      "Epoch 4889/5000\n",
      "31/31 - 0s - loss: 1.9629 - mae: 1.1192 - val_loss: 0.4084 - val_mae: 0.5483 - 35ms/epoch - 1ms/step\n",
      "Epoch 4890/5000\n",
      "31/31 - 0s - loss: 29.9729 - mae: 2.5051 - val_loss: 2.3238 - val_mae: 1.4919 - 38ms/epoch - 1ms/step\n",
      "Epoch 4891/5000\n",
      "31/31 - 0s - loss: 2.5468 - mae: 1.3101 - val_loss: 0.9362 - val_mae: 0.9119 - 37ms/epoch - 1ms/step\n",
      "Epoch 4892/5000\n",
      "31/31 - 0s - loss: 9.3688 - mae: 1.3320 - val_loss: 48.8511 - val_mae: 6.9825 - 35ms/epoch - 1ms/step\n",
      "Epoch 4893/5000\n",
      "31/31 - 0s - loss: 3.7276 - mae: 1.0625 - val_loss: 0.2986 - val_mae: 0.4674 - 36ms/epoch - 1ms/step\n",
      "Epoch 4894/5000\n",
      "31/31 - 0s - loss: 13.5477 - mae: 2.0292 - val_loss: 1.6623 - val_mae: 1.2527 - 36ms/epoch - 1ms/step\n",
      "Epoch 4895/5000\n",
      "31/31 - 0s - loss: 2.6895 - mae: 1.3927 - val_loss: 0.5976 - val_mae: 0.7069 - 37ms/epoch - 1ms/step\n",
      "Epoch 4896/5000\n",
      "31/31 - 0s - loss: 9.5768 - mae: 2.1346 - val_loss: 0.3805 - val_mae: 0.5259 - 36ms/epoch - 1ms/step\n",
      "Epoch 4897/5000\n",
      "31/31 - 0s - loss: 0.8805 - mae: 0.7047 - val_loss: 0.2606 - val_mae: 0.3989 - 36ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4898/5000\n",
      "31/31 - 0s - loss: 23.5782 - mae: 2.0107 - val_loss: 0.1303 - val_mae: 0.3286 - 36ms/epoch - 1ms/step\n",
      "Epoch 4899/5000\n",
      "31/31 - 0s - loss: 1.6375 - mae: 0.8083 - val_loss: 2.5361 - val_mae: 1.5609 - 37ms/epoch - 1ms/step\n",
      "Epoch 4900/5000\n",
      "31/31 - 0s - loss: 1.5118 - mae: 0.9151 - val_loss: 312.6139 - val_mae: 17.6781 - 37ms/epoch - 1ms/step\n",
      "Epoch 4901/5000\n",
      "31/31 - 0s - loss: 18.5368 - mae: 2.3725 - val_loss: 6.6421 - val_mae: 2.5563 - 38ms/epoch - 1ms/step\n",
      "Epoch 4902/5000\n",
      "31/31 - 0s - loss: 4.3783 - mae: 1.6135 - val_loss: 41.7550 - val_mae: 6.4548 - 35ms/epoch - 1ms/step\n",
      "Epoch 4903/5000\n",
      "31/31 - 0s - loss: 8.8661 - mae: 1.4897 - val_loss: 0.1598 - val_mae: 0.2935 - 35ms/epoch - 1ms/step\n",
      "Epoch 4904/5000\n",
      "31/31 - 0s - loss: 20.3003 - mae: 2.2831 - val_loss: 4.8218 - val_mae: 2.1718 - 36ms/epoch - 1ms/step\n",
      "Epoch 4905/5000\n",
      "31/31 - 0s - loss: 0.9982 - mae: 0.8176 - val_loss: 0.9152 - val_mae: 0.9014 - 36ms/epoch - 1ms/step\n",
      "Epoch 4906/5000\n",
      "31/31 - 0s - loss: 0.6079 - mae: 0.5767 - val_loss: 0.4672 - val_mae: 0.6034 - 36ms/epoch - 1ms/step\n",
      "Epoch 4907/5000\n",
      "31/31 - 0s - loss: 14.4862 - mae: 2.1336 - val_loss: 0.1160 - val_mae: 0.2925 - 37ms/epoch - 1ms/step\n",
      "Epoch 4908/5000\n",
      "31/31 - 0s - loss: 2.3482 - mae: 1.0899 - val_loss: 0.1366 - val_mae: 0.3376 - 36ms/epoch - 1ms/step\n",
      "Epoch 4909/5000\n",
      "31/31 - 0s - loss: 29.4894 - mae: 2.2854 - val_loss: 0.5937 - val_mae: 0.6992 - 36ms/epoch - 1ms/step\n",
      "Epoch 4910/5000\n",
      "31/31 - 0s - loss: 3.9469 - mae: 0.9766 - val_loss: 6.4969 - val_mae: 2.5296 - 35ms/epoch - 1ms/step\n",
      "Epoch 4911/5000\n",
      "31/31 - 0s - loss: 0.5367 - mae: 0.5163 - val_loss: 0.3306 - val_mae: 0.4840 - 37ms/epoch - 1ms/step\n",
      "Epoch 4912/5000\n",
      "31/31 - 0s - loss: 7.6463 - mae: 1.5833 - val_loss: 2.3281 - val_mae: 1.4917 - 36ms/epoch - 1ms/step\n",
      "Epoch 4913/5000\n",
      "31/31 - 0s - loss: 2.6860 - mae: 1.3516 - val_loss: 0.8835 - val_mae: 0.8842 - 34ms/epoch - 1ms/step\n",
      "Epoch 4914/5000\n",
      "31/31 - 0s - loss: 7.4965 - mae: 1.4093 - val_loss: 5.2955 - val_mae: 2.2781 - 36ms/epoch - 1ms/step\n",
      "Epoch 4915/5000\n",
      "31/31 - 0s - loss: 1.5496 - mae: 1.0974 - val_loss: 1.0088 - val_mae: 0.9505 - 37ms/epoch - 1ms/step\n",
      "Epoch 4916/5000\n",
      "31/31 - 0s - loss: 10.3328 - mae: 1.8683 - val_loss: 0.6362 - val_mae: 0.7278 - 36ms/epoch - 1ms/step\n",
      "Epoch 4917/5000\n",
      "31/31 - 0s - loss: 1.1668 - mae: 0.7013 - val_loss: 34.6106 - val_mae: 5.8752 - 34ms/epoch - 1ms/step\n",
      "Epoch 4918/5000\n",
      "31/31 - 0s - loss: 5.1155 - mae: 1.4668 - val_loss: 0.4796 - val_mae: 0.6151 - 40ms/epoch - 1ms/step\n",
      "Epoch 4919/5000\n",
      "31/31 - 0s - loss: 28.8280 - mae: 1.9961 - val_loss: 20.6615 - val_mae: 4.5347 - 39ms/epoch - 1ms/step\n",
      "Epoch 4920/5000\n",
      "31/31 - 0s - loss: 2.0232 - mae: 0.9840 - val_loss: 0.0994 - val_mae: 0.2727 - 36ms/epoch - 1ms/step\n",
      "Epoch 4921/5000\n",
      "31/31 - 0s - loss: 3.0223 - mae: 1.3219 - val_loss: 48.6363 - val_mae: 6.9671 - 36ms/epoch - 1ms/step\n",
      "Epoch 4922/5000\n",
      "31/31 - 0s - loss: 3.1949 - mae: 1.0510 - val_loss: 0.3774 - val_mae: 0.5257 - 36ms/epoch - 1ms/step\n",
      "Epoch 4923/5000\n",
      "31/31 - 0s - loss: 24.5943 - mae: 2.1187 - val_loss: 0.8991 - val_mae: 0.8963 - 37ms/epoch - 1ms/step\n",
      "Epoch 4924/5000\n",
      "31/31 - 0s - loss: 1.7934 - mae: 0.9433 - val_loss: 0.3363 - val_mae: 0.4881 - 36ms/epoch - 1ms/step\n",
      "Epoch 4925/5000\n",
      "31/31 - 0s - loss: 9.9011 - mae: 1.8820 - val_loss: 1.5812 - val_mae: 1.2152 - 36ms/epoch - 1ms/step\n",
      "Epoch 4926/5000\n",
      "31/31 - 0s - loss: 2.0321 - mae: 1.0972 - val_loss: 0.4148 - val_mae: 0.5565 - 38ms/epoch - 1ms/step\n",
      "Epoch 4927/5000\n",
      "31/31 - 0s - loss: 16.3483 - mae: 2.3103 - val_loss: 0.4542 - val_mae: 0.5989 - 36ms/epoch - 1ms/step\n",
      "Epoch 4928/5000\n",
      "31/31 - 0s - loss: 1.5834 - mae: 0.9800 - val_loss: 0.1655 - val_mae: 0.2973 - 34ms/epoch - 1ms/step\n",
      "Epoch 4929/5000\n",
      "31/31 - 0s - loss: 12.8534 - mae: 1.6899 - val_loss: 0.6323 - val_mae: 0.7326 - 36ms/epoch - 1ms/step\n",
      "Epoch 4930/5000\n",
      "31/31 - 0s - loss: 1.0478 - mae: 0.6833 - val_loss: 0.1187 - val_mae: 0.2785 - 35ms/epoch - 1ms/step\n",
      "Epoch 4931/5000\n",
      "31/31 - 0s - loss: 15.5084 - mae: 1.7623 - val_loss: 0.6474 - val_mae: 0.7357 - 35ms/epoch - 1ms/step\n",
      "Epoch 4932/5000\n",
      "31/31 - 0s - loss: 1.1600 - mae: 0.6980 - val_loss: 0.4771 - val_mae: 0.6134 - 37ms/epoch - 1ms/step\n",
      "Epoch 4933/5000\n",
      "31/31 - 0s - loss: 13.2682 - mae: 2.0160 - val_loss: 0.2634 - val_mae: 0.4475 - 34ms/epoch - 1ms/step\n",
      "Epoch 4934/5000\n",
      "31/31 - 0s - loss: 2.4599 - mae: 1.3033 - val_loss: 4.6838 - val_mae: 2.1404 - 36ms/epoch - 1ms/step\n",
      "Epoch 4935/5000\n",
      "31/31 - 0s - loss: 18.3634 - mae: 2.1999 - val_loss: 3.0506 - val_mae: 1.7175 - 36ms/epoch - 1ms/step\n",
      "Epoch 4936/5000\n",
      "31/31 - 0s - loss: 1.4081 - mae: 1.0484 - val_loss: 0.6962 - val_mae: 0.7689 - 38ms/epoch - 1ms/step\n",
      "Epoch 4937/5000\n",
      "31/31 - 0s - loss: 9.0321 - mae: 1.8579 - val_loss: 1.4595 - val_mae: 1.1649 - 37ms/epoch - 1ms/step\n",
      "Epoch 4938/5000\n",
      "31/31 - 0s - loss: 2.2851 - mae: 1.0546 - val_loss: 44.8407 - val_mae: 6.6886 - 36ms/epoch - 1ms/step\n",
      "Epoch 4939/5000\n",
      "31/31 - 0s - loss: 9.2255 - mae: 2.0386 - val_loss: 1.0246 - val_mae: 0.9582 - 36ms/epoch - 1ms/step\n",
      "Epoch 4940/5000\n",
      "31/31 - 0s - loss: 13.7218 - mae: 2.1592 - val_loss: 0.1659 - val_mae: 0.2967 - 36ms/epoch - 1ms/step\n",
      "Epoch 4941/5000\n",
      "31/31 - 0s - loss: 1.0193 - mae: 0.7545 - val_loss: 0.5916 - val_mae: 0.7004 - 37ms/epoch - 1ms/step\n",
      "Epoch 4942/5000\n",
      "31/31 - 0s - loss: 22.0529 - mae: 2.0535 - val_loss: 0.2217 - val_mae: 0.3466 - 37ms/epoch - 1ms/step\n",
      "Epoch 4943/5000\n",
      "31/31 - 0s - loss: 1.2089 - mae: 0.8396 - val_loss: 2.0435 - val_mae: 1.3933 - 36ms/epoch - 1ms/step\n",
      "Epoch 4944/5000\n",
      "31/31 - 0s - loss: 0.8844 - mae: 0.7754 - val_loss: 0.1060 - val_mae: 0.2760 - 37ms/epoch - 1ms/step\n",
      "Epoch 4945/5000\n",
      "31/31 - 0s - loss: 20.2051 - mae: 1.9573 - val_loss: 5.6622 - val_mae: 2.3576 - 35ms/epoch - 1ms/step\n",
      "Epoch 4946/5000\n",
      "31/31 - 0s - loss: 2.1548 - mae: 1.1638 - val_loss: 2.1142 - val_mae: 1.4178 - 36ms/epoch - 1ms/step\n",
      "Epoch 4947/5000\n",
      "31/31 - 0s - loss: 19.1484 - mae: 2.1948 - val_loss: 1.3597 - val_mae: 1.1212 - 37ms/epoch - 1ms/step\n",
      "Epoch 4948/5000\n",
      "31/31 - 0s - loss: 1.4486 - mae: 0.8687 - val_loss: 0.9284 - val_mae: 0.9099 - 36ms/epoch - 1ms/step\n",
      "Epoch 4949/5000\n",
      "31/31 - 0s - loss: 13.4179 - mae: 1.8729 - val_loss: 0.6556 - val_mae: 0.7417 - 35ms/epoch - 1ms/step\n",
      "Epoch 4950/5000\n",
      "31/31 - 0s - loss: 1.6154 - mae: 1.0267 - val_loss: 2.4980 - val_mae: 1.5479 - 36ms/epoch - 1ms/step\n",
      "Epoch 4951/5000\n",
      "31/31 - 0s - loss: 25.5289 - mae: 2.3266 - val_loss: 0.6456 - val_mae: 0.7359 - 35ms/epoch - 1ms/step\n",
      "Epoch 4952/5000\n",
      "31/31 - 0s - loss: 1.3225 - mae: 0.7675 - val_loss: 0.2080 - val_mae: 0.3383 - 35ms/epoch - 1ms/step\n",
      "Epoch 4953/5000\n",
      "31/31 - 0s - loss: 0.7753 - mae: 0.7842 - val_loss: 6.5714 - val_mae: 2.5435 - 37ms/epoch - 1ms/step\n",
      "Epoch 4954/5000\n",
      "31/31 - 0s - loss: 17.0203 - mae: 2.2512 - val_loss: 0.1334 - val_mae: 0.3355 - 35ms/epoch - 1ms/step\n",
      "Epoch 4955/5000\n",
      "31/31 - 0s - loss: 0.9700 - mae: 0.8053 - val_loss: 6.5485 - val_mae: 2.5398 - 38ms/epoch - 1ms/step\n",
      "Epoch 4956/5000\n",
      "31/31 - 0s - loss: 19.4266 - mae: 2.0203 - val_loss: 0.8393 - val_mae: 0.8582 - 35ms/epoch - 1ms/step\n",
      "Epoch 4957/5000\n",
      "31/31 - 0s - loss: 1.1007 - mae: 0.7265 - val_loss: 0.8589 - val_mae: 0.8699 - 36ms/epoch - 1ms/step\n",
      "Epoch 4958/5000\n",
      "31/31 - 0s - loss: 16.8344 - mae: 1.9293 - val_loss: 0.1477 - val_mae: 0.2809 - 40ms/epoch - 1ms/step\n",
      "Epoch 4959/5000\n",
      "31/31 - 0s - loss: 0.9901 - mae: 0.7196 - val_loss: 0.1074 - val_mae: 0.2793 - 35ms/epoch - 1ms/step\n",
      "Epoch 4960/5000\n",
      "31/31 - 0s - loss: 10.4260 - mae: 1.9944 - val_loss: 2.8650 - val_mae: 1.6629 - 36ms/epoch - 1ms/step\n",
      "Epoch 4961/5000\n",
      "31/31 - 0s - loss: 1.2425 - mae: 0.7619 - val_loss: 2.5888 - val_mae: 1.5777 - 35ms/epoch - 1ms/step\n",
      "Epoch 4962/5000\n",
      "31/31 - 0s - loss: 17.5455 - mae: 2.1432 - val_loss: 0.1704 - val_mae: 0.3014 - 36ms/epoch - 1ms/step\n",
      "Epoch 4963/5000\n",
      "31/31 - 0s - loss: 0.9689 - mae: 0.6850 - val_loss: 3.8771 - val_mae: 1.9437 - 37ms/epoch - 1ms/step\n",
      "Epoch 4964/5000\n",
      "31/31 - 0s - loss: 0.5240 - mae: 0.5473 - val_loss: 1.4695 - val_mae: 1.1682 - 35ms/epoch - 1ms/step\n",
      "Epoch 4965/5000\n",
      "31/31 - 0s - loss: 25.8050 - mae: 2.3262 - val_loss: 3.3819 - val_mae: 1.8110 - 37ms/epoch - 1ms/step\n",
      "Epoch 4966/5000\n",
      "31/31 - 0s - loss: 4.5852 - mae: 1.5696 - val_loss: 67.1825 - val_mae: 8.1903 - 37ms/epoch - 1ms/step\n",
      "Epoch 4967/5000\n",
      "31/31 - 0s - loss: 7.3496 - mae: 1.2276 - val_loss: 0.1234 - val_mae: 0.2796 - 37ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4968/5000\n",
      "31/31 - 0s - loss: 17.4756 - mae: 1.7827 - val_loss: 70.0996 - val_mae: 8.3661 - 38ms/epoch - 1ms/step\n",
      "Epoch 4969/5000\n",
      "31/31 - 0s - loss: 4.0899 - mae: 1.2229 - val_loss: 0.3105 - val_mae: 0.4530 - 36ms/epoch - 1ms/step\n",
      "Epoch 4970/5000\n",
      "31/31 - 0s - loss: 15.0763 - mae: 2.3720 - val_loss: 1.9887 - val_mae: 1.3752 - 35ms/epoch - 1ms/step\n",
      "Epoch 4971/5000\n",
      "31/31 - 0s - loss: 0.5972 - mae: 0.6416 - val_loss: 3.2993 - val_mae: 1.7891 - 36ms/epoch - 1ms/step\n",
      "Epoch 4972/5000\n",
      "31/31 - 0s - loss: 13.1810 - mae: 2.1059 - val_loss: 0.1439 - val_mae: 0.2790 - 35ms/epoch - 1ms/step\n",
      "Epoch 4973/5000\n",
      "31/31 - 0s - loss: 0.7469 - mae: 0.7494 - val_loss: 1.2589 - val_mae: 1.0761 - 35ms/epoch - 1ms/step\n",
      "Epoch 4974/5000\n",
      "31/31 - 0s - loss: 6.9631 - mae: 1.6729 - val_loss: 0.4616 - val_mae: 0.5928 - 36ms/epoch - 1ms/step\n",
      "Epoch 4975/5000\n",
      "31/31 - 0s - loss: 3.7814 - mae: 1.4243 - val_loss: 12.3821 - val_mae: 3.5029 - 35ms/epoch - 1ms/step\n",
      "Epoch 4976/5000\n",
      "31/31 - 0s - loss: 8.2527 - mae: 2.0325 - val_loss: 2.7651 - val_mae: 1.6301 - 39ms/epoch - 1ms/step\n",
      "Epoch 4977/5000\n",
      "31/31 - 0s - loss: 17.1689 - mae: 2.0286 - val_loss: 1.6210 - val_mae: 1.2326 - 37ms/epoch - 1ms/step\n",
      "Epoch 4978/5000\n",
      "31/31 - 0s - loss: 1.0791 - mae: 0.8472 - val_loss: 0.1073 - val_mae: 0.2851 - 36ms/epoch - 1ms/step\n",
      "Epoch 4979/5000\n",
      "31/31 - 0s - loss: 15.7037 - mae: 1.9314 - val_loss: 0.1368 - val_mae: 0.2760 - 35ms/epoch - 1ms/step\n",
      "Epoch 4980/5000\n",
      "31/31 - 0s - loss: 3.1169 - mae: 1.3850 - val_loss: 1.4505 - val_mae: 1.1620 - 35ms/epoch - 1ms/step\n",
      "Epoch 4981/5000\n",
      "31/31 - 0s - loss: 7.8699 - mae: 1.6547 - val_loss: 1.3060 - val_mae: 1.0978 - 37ms/epoch - 1ms/step\n",
      "Epoch 4982/5000\n",
      "31/31 - 0s - loss: 0.6672 - mae: 0.7080 - val_loss: 2.5527 - val_mae: 1.5655 - 37ms/epoch - 1ms/step\n",
      "Epoch 4983/5000\n",
      "31/31 - 0s - loss: 16.7220 - mae: 2.0260 - val_loss: 0.4134 - val_mae: 0.5591 - 34ms/epoch - 1ms/step\n",
      "Epoch 4984/5000\n",
      "31/31 - 0s - loss: 0.6836 - mae: 0.6609 - val_loss: 0.3071 - val_mae: 0.4523 - 35ms/epoch - 1ms/step\n",
      "Epoch 4985/5000\n",
      "31/31 - 0s - loss: 13.9849 - mae: 1.7846 - val_loss: 0.7687 - val_mae: 0.8165 - 38ms/epoch - 1ms/step\n",
      "Epoch 4986/5000\n",
      "31/31 - 0s - loss: 0.7848 - mae: 0.6581 - val_loss: 1.0317 - val_mae: 0.9640 - 36ms/epoch - 1ms/step\n",
      "Epoch 4987/5000\n",
      "31/31 - 0s - loss: 9.5944 - mae: 1.8146 - val_loss: 0.9399 - val_mae: 0.9173 - 36ms/epoch - 1ms/step\n",
      "Epoch 4988/5000\n",
      "31/31 - 0s - loss: 1.8167 - mae: 1.0862 - val_loss: 3.3342 - val_mae: 1.7995 - 35ms/epoch - 1ms/step\n",
      "Epoch 4989/5000\n",
      "31/31 - 0s - loss: 20.5233 - mae: 2.0026 - val_loss: 0.4126 - val_mae: 0.5570 - 36ms/epoch - 1ms/step\n",
      "Epoch 4990/5000\n",
      "31/31 - 0s - loss: 1.1563 - mae: 0.7859 - val_loss: 0.2811 - val_mae: 0.4568 - 36ms/epoch - 1ms/step\n",
      "Epoch 4991/5000\n",
      "31/31 - 0s - loss: 29.3950 - mae: 2.1313 - val_loss: 0.3425 - val_mae: 0.4944 - 36ms/epoch - 1ms/step\n",
      "Epoch 4992/5000\n",
      "31/31 - 0s - loss: 1.4170 - mae: 1.0000 - val_loss: 3.3230 - val_mae: 1.7961 - 43ms/epoch - 1ms/step\n",
      "Epoch 4993/5000\n",
      "31/31 - 0s - loss: 3.2117 - mae: 1.2645 - val_loss: 26.0487 - val_mae: 5.0936 - 37ms/epoch - 1ms/step\n",
      "Epoch 4994/5000\n",
      "31/31 - 0s - loss: 6.6330 - mae: 1.3275 - val_loss: 0.6705 - val_mae: 0.7554 - 37ms/epoch - 1ms/step\n",
      "Epoch 4995/5000\n",
      "31/31 - 0s - loss: 20.1290 - mae: 2.0637 - val_loss: 0.4438 - val_mae: 0.5802 - 36ms/epoch - 1ms/step\n",
      "Epoch 4996/5000\n",
      "31/31 - 0s - loss: 1.2528 - mae: 0.7710 - val_loss: 0.4147 - val_mae: 0.5560 - 36ms/epoch - 1ms/step\n",
      "Epoch 4997/5000\n",
      "31/31 - 0s - loss: 1.2406 - mae: 0.9001 - val_loss: 3.2334 - val_mae: 1.7694 - 36ms/epoch - 1ms/step\n",
      "Epoch 4998/5000\n",
      "31/31 - 0s - loss: 9.2181 - mae: 1.9942 - val_loss: 0.2582 - val_mae: 0.3970 - 35ms/epoch - 1ms/step\n",
      "Epoch 4999/5000\n",
      "31/31 - 0s - loss: 0.9372 - mae: 0.7741 - val_loss: 0.1024 - val_mae: 0.2777 - 36ms/epoch - 1ms/step\n",
      "Epoch 5000/5000\n",
      "31/31 - 0s - loss: 10.1887 - mae: 2.0505 - val_loss: 0.1266 - val_mae: 0.3204 - 38ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "inputs = Input(shape=(51))\n",
    "hidden_layer_1 = Dense(128, activation='linear')(inputs) #linear работает лучше для данной сети, чем elu\n",
    "outputs = Dense(1)(hidden_layer_1)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=5000,\n",
    "                    batch_size = 1,\n",
    "                    validation_split=0.1, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f013ca26f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 - 0s - loss: 1.6331 - mae: 1.1174 - 55ms/epoch - 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_mse: 1.63, test_mae: 1.12'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "test_mse, test_mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "\n",
    "print \n",
    "(f'test_mse: {round(test_mse, 2)}, test_mae: {round(test_mae,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.array(model.predict(X_test))\n",
    "y_train_pred = np.array(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f013caa3d30>]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(y_train))\n",
    "plt.plot(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f00c5701b20>]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(y_test))\n",
    "plt.plot(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим рекуррентную сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого преобразуем данные, на вход будем подавать вектора ['women_median', women_average', 'men_median', 'men_average'] по каждому из 10 предшествующих этому году лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec = np.array(df[['women_median1years_back', 'women_average1years_back',\n",
    "       'men_median1years_back', 'men_average1years_back', \n",
    "       'women_median2years_back', 'women_average2years_back',\n",
    "       'men_median2years_back', 'men_average2years_back', \n",
    "       'women_median3years_back', 'women_average3years_back',\n",
    "       'men_median3years_back', 'men_average3years_back', \n",
    "       'women_median4years_back', 'women_average4years_back',\n",
    "       'men_median4years_back', 'men_average4years_back', \n",
    "       'women_median5years_back', 'women_average5years_back',\n",
    "       'men_median5years_back', 'men_average5years_back', \n",
    "       'women_median6years_back', 'women_average6years_back',\n",
    "       'men_median6years_back', 'men_average6years_back', \n",
    "       'women_median7years_back', 'women_average7years_back',\n",
    "       'men_median7years_back', 'men_average7years_back', \n",
    "       'women_median8years_back', 'women_average8years_back',\n",
    "       'men_median8years_back', 'men_average8years_back', \n",
    "       'women_median9years_back', 'women_average9years_back',\n",
    "       'men_median9years_back', 'men_average9years_back', \n",
    "       'women_median10years_back', 'women_average10years_back',\n",
    "       'men_median10years_back', 'men_average10years_back']][x_len:])\n",
    "\n",
    "df_rec_scaled = scaler.fit_transform(df_rec)\n",
    "\n",
    "\n",
    "df_rec_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.42342342, 0.04069176, 0.02575758,\n",
       "       0.        , 0.42117117, 0.01831129, 0.01698113, 0.        ,\n",
       "       0.93675889, 0.04563758, 0.03470716, 0.02191465, 1.        ,\n",
       "       0.12589413, 0.01094092, 0.        , 1.        , 0.10873147,\n",
       "       0.        , 0.        , 0.87318841, 0.08862876, 0.02466368,\n",
       "       0.02607562, 0.78985507, 0.09962406, 0.        , 0.        ,\n",
       "       0.93115942, 0.05252525, 0.        , 0.        , 0.79347826,\n",
       "       0.05656566, 0.04690832, 0.03911343, 0.90217391, 0.15353535])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec_scaled = df_rec_scaled.reshape(40, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.42342342, 0.04069176],\n",
       "       [0.02575758, 0.        , 0.42117117, 0.01831129],\n",
       "       [0.01698113, 0.        , 0.93675889, 0.04563758],\n",
       "       [0.03470716, 0.02191465, 1.        , 0.12589413],\n",
       "       [0.01094092, 0.        , 1.        , 0.10873147],\n",
       "       [0.        , 0.        , 0.87318841, 0.08862876],\n",
       "       [0.02466368, 0.02607562, 0.78985507, 0.09962406],\n",
       "       [0.        , 0.        , 0.93115942, 0.05252525],\n",
       "       [0.        , 0.        , 0.79347826, 0.05656566],\n",
       "       [0.04690832, 0.03911343, 0.90217391, 0.15353535]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 10, 4)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_rec_scaled[:35]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10, 4)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_rec_scaled[35:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 128)               68096     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68225 (266.50 KB)\n",
      "Trainable params: 68225 (266.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10, 4)))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 10, 4)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qe-A1Y9OVGz3",
    "outputId": "d64b10c5-ab27-4168-9420-8989271c77b4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "2/2 [==============================] - 1s 243ms/step - loss: 318.4706 - mae: 17.7997 - val_loss: 417.2475 - val_mae: 20.4141\n",
      "Epoch 2/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 312.1010 - mae: 17.6237 - val_loss: 403.8221 - val_mae: 20.0828\n",
      "Epoch 3/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 305.2982 - mae: 17.4334 - val_loss: 387.8065 - val_mae: 19.6802\n",
      "Epoch 4/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 297.1122 - mae: 17.2021 - val_loss: 367.3531 - val_mae: 19.1539\n",
      "Epoch 5/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 287.2383 - mae: 16.9169 - val_loss: 340.2964 - val_mae: 18.4347\n",
      "Epoch 6/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 273.5698 - mae: 16.5140 - val_loss: 304.9711 - val_mae: 17.4510\n",
      "Epoch 7/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 254.2030 - mae: 15.9240 - val_loss: 262.0032 - val_mae: 16.1739\n",
      "Epoch 8/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 227.4707 - mae: 15.0678 - val_loss: 217.5292 - val_mae: 14.7353\n",
      "Epoch 9/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 191.9122 - mae: 13.8372 - val_loss: 180.2525 - val_mae: 13.4100\n",
      "Epoch 10/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 150.9427 - mae: 12.2734 - val_loss: 151.8852 - val_mae: 12.3055\n",
      "Epoch 11/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 112.3190 - mae: 10.5794 - val_loss: 128.9079 - val_mae: 11.3325\n",
      "Epoch 12/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 82.4559 - mae: 9.0413 - val_loss: 108.3778 - val_mae: 10.3867\n",
      "Epoch 13/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 61.6872 - mae: 7.7852 - val_loss: 89.8960 - val_mae: 9.4549\n",
      "Epoch 14/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 46.1527 - mae: 6.6906 - val_loss: 74.1106 - val_mae: 8.5793\n",
      "Epoch 15/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 34.3354 - mae: 5.7346 - val_loss: 61.2880 - val_mae: 7.7961\n",
      "Epoch 16/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 25.6098 - mae: 4.9067 - val_loss: 51.1739 - val_mae: 7.1177\n",
      "Epoch 17/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 19.2981 - mae: 4.2019 - val_loss: 43.4096 - val_mae: 6.5495\n",
      "Epoch 18/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 14.7045 - mae: 3.6163 - val_loss: 37.3530 - val_mae: 6.0695\n",
      "Epoch 19/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 11.4178 - mae: 3.1232 - val_loss: 32.4769 - val_mae: 5.6535\n",
      "Epoch 20/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.9664 - mae: 2.6986 - val_loss: 28.4872 - val_mae: 5.2889\n",
      "Epoch 21/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.1253 - mae: 2.3329 - val_loss: 25.1859 - val_mae: 4.9670\n",
      "Epoch 22/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.7182 - mae: 2.0367 - val_loss: 22.4281 - val_mae: 4.6812\n",
      "Epoch 23/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.6464 - mae: 1.8016 - val_loss: 20.0953 - val_mae: 4.4250\n",
      "Epoch 24/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.8322 - mae: 1.6098 - val_loss: 18.1047 - val_mae: 4.1940\n",
      "Epoch 25/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.2230 - mae: 1.4657 - val_loss: 16.4142 - val_mae: 3.9874\n",
      "Epoch 26/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.7534 - mae: 1.3672 - val_loss: 14.9816 - val_mae: 3.8035\n",
      "Epoch 27/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4237 - mae: 1.3250 - val_loss: 13.7751 - val_mae: 3.6415\n",
      "Epoch 28/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1680 - mae: 1.2902 - val_loss: 12.7572 - val_mae: 3.4989\n",
      "Epoch 29/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9888 - mae: 1.2665 - val_loss: 11.8603 - val_mae: 3.3683\n",
      "Epoch 30/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8754 - mae: 1.2517 - val_loss: 11.0680 - val_mae: 3.2486\n",
      "Epoch 31/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7973 - mae: 1.2349 - val_loss: 10.3915 - val_mae: 3.1427\n",
      "Epoch 32/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7485 - mae: 1.2201 - val_loss: 9.8179 - val_mae: 3.0501\n",
      "Epoch 33/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7335 - mae: 1.2094 - val_loss: 9.3546 - val_mae: 2.9732\n",
      "Epoch 34/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7204 - mae: 1.2007 - val_loss: 8.9895 - val_mae: 2.9111\n",
      "Epoch 35/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7194 - mae: 1.1975 - val_loss: 8.6622 - val_mae: 2.8544\n",
      "Epoch 36/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7317 - mae: 1.1959 - val_loss: 8.3589 - val_mae: 2.8007\n",
      "Epoch 37/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7497 - mae: 1.1960 - val_loss: 8.1057 - val_mae: 2.7551\n",
      "Epoch 38/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7679 - mae: 1.1973 - val_loss: 7.9158 - val_mae: 2.7205\n",
      "Epoch 39/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7869 - mae: 1.1989 - val_loss: 7.8151 - val_mae: 2.7019\n",
      "Epoch 40/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7936 - mae: 1.1986 - val_loss: 7.8182 - val_mae: 2.7025\n",
      "Epoch 41/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7910 - mae: 1.1979 - val_loss: 7.9134 - val_mae: 2.7200\n",
      "Epoch 42/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7856 - mae: 1.1990 - val_loss: 8.0321 - val_mae: 2.7418\n",
      "Epoch 43/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7732 - mae: 1.1974 - val_loss: 8.1211 - val_mae: 2.7580\n",
      "Epoch 44/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7650 - mae: 1.1965 - val_loss: 8.2311 - val_mae: 2.7778\n",
      "Epoch 45/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7585 - mae: 1.1958 - val_loss: 8.3583 - val_mae: 2.8006\n",
      "Epoch 46/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7502 - mae: 1.1965 - val_loss: 8.4740 - val_mae: 2.8212\n",
      "Epoch 47/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7415 - mae: 1.1966 - val_loss: 8.6184 - val_mae: 2.8467\n",
      "Epoch 48/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7400 - mae: 1.1995 - val_loss: 8.7609 - val_mae: 2.8716\n",
      "Epoch 49/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7330 - mae: 1.1991 - val_loss: 8.8364 - val_mae: 2.8847\n",
      "Epoch 50/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7292 - mae: 1.1991 - val_loss: 8.8962 - val_mae: 2.8951\n",
      "Epoch 51/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7284 - mae: 1.1996 - val_loss: 8.9536 - val_mae: 2.9049\n",
      "Epoch 52/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7274 - mae: 1.2001 - val_loss: 8.9610 - val_mae: 2.9062\n",
      "Epoch 53/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7264 - mae: 1.1997 - val_loss: 8.9337 - val_mae: 2.9015\n",
      "Epoch 54/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7272 - mae: 1.1997 - val_loss: 8.9278 - val_mae: 2.9005\n",
      "Epoch 55/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7271 - mae: 1.1996 - val_loss: 8.9488 - val_mae: 2.9041\n",
      "Epoch 56/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7266 - mae: 1.1996 - val_loss: 8.9760 - val_mae: 2.9088\n",
      "Epoch 57/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7258 - mae: 1.1998 - val_loss: 9.0212 - val_mae: 2.9166\n",
      "Epoch 58/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7253 - mae: 1.2002 - val_loss: 9.0777 - val_mae: 2.9262\n",
      "Epoch 59/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7252 - mae: 1.2007 - val_loss: 9.0881 - val_mae: 2.9280\n",
      "Epoch 60/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7249 - mae: 1.2006 - val_loss: 9.1039 - val_mae: 2.9307\n",
      "Epoch 61/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7243 - mae: 1.2006 - val_loss: 9.1547 - val_mae: 2.9394\n",
      "Epoch 62/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7232 - mae: 1.2006 - val_loss: 9.1924 - val_mae: 2.9458\n",
      "Epoch 63/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7228 - mae: 1.2007 - val_loss: 9.2408 - val_mae: 2.9540\n",
      "Epoch 64/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7237 - mae: 1.2015 - val_loss: 9.2584 - val_mae: 2.9570\n",
      "Epoch 65/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7231 - mae: 1.2013 - val_loss: 9.2690 - val_mae: 2.9587\n",
      "Epoch 66/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7221 - mae: 1.2011 - val_loss: 9.3393 - val_mae: 2.9706\n",
      "Epoch 67/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7211 - mae: 1.2009 - val_loss: 9.4613 - val_mae: 2.9911\n",
      "Epoch 68/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7231 - mae: 1.2035 - val_loss: 9.5988 - val_mae: 3.0140\n",
      "Epoch 69/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7242 - mae: 1.2049 - val_loss: 9.7201 - val_mae: 3.0340\n",
      "Epoch 70/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7274 - mae: 1.2071 - val_loss: 9.8203 - val_mae: 3.0505\n",
      "Epoch 71/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7292 - mae: 1.2082 - val_loss: 9.9008 - val_mae: 3.0636\n",
      "Epoch 72/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7321 - mae: 1.2104 - val_loss: 9.9678 - val_mae: 3.0746\n",
      "Epoch 73/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7341 - mae: 1.2118 - val_loss: 10.0136 - val_mae: 3.0820\n",
      "Epoch 74/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7357 - mae: 1.2127 - val_loss: 10.0556 - val_mae: 3.0888\n",
      "Epoch 75/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7385 - mae: 1.2141 - val_loss: 10.0368 - val_mae: 3.0858\n",
      "Epoch 76/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7369 - mae: 1.2135 - val_loss: 9.9598 - val_mae: 3.0733\n",
      "Epoch 77/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7340 - mae: 1.2114 - val_loss: 9.9014 - val_mae: 3.0637\n",
      "Epoch 78/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7323 - mae: 1.2103 - val_loss: 9.8734 - val_mae: 3.0592\n",
      "Epoch 79/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7309 - mae: 1.2095 - val_loss: 9.8297 - val_mae: 3.0520\n",
      "Epoch 80/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7299 - mae: 1.2087 - val_loss: 9.7548 - val_mae: 3.0397\n",
      "Epoch 81/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7270 - mae: 1.2071 - val_loss: 9.6655 - val_mae: 3.0250\n",
      "Epoch 82/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7261 - mae: 1.2062 - val_loss: 9.5657 - val_mae: 3.0085\n",
      "Epoch 83/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7238 - mae: 1.2044 - val_loss: 9.4879 - val_mae: 2.9955\n",
      "Epoch 84/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7232 - mae: 1.2036 - val_loss: 9.4284 - val_mae: 2.9856\n",
      "Epoch 85/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7235 - mae: 1.2029 - val_loss: 9.4414 - val_mae: 2.9877\n",
      "Epoch 86/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7218 - mae: 1.2026 - val_loss: 9.5321 - val_mae: 3.0029\n",
      "Epoch 87/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7235 - mae: 1.2043 - val_loss: 9.6270 - val_mae: 3.0186\n",
      "Epoch 88/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7259 - mae: 1.2059 - val_loss: 9.6590 - val_mae: 3.0239\n",
      "Epoch 89/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7254 - mae: 1.2059 - val_loss: 9.6445 - val_mae: 3.0215\n",
      "Epoch 90/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7250 - mae: 1.2056 - val_loss: 9.6209 - val_mae: 3.0176\n",
      "Epoch 91/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7243 - mae: 1.2052 - val_loss: 9.5686 - val_mae: 3.0089\n",
      "Epoch 92/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7227 - mae: 1.2041 - val_loss: 9.4625 - val_mae: 2.9913\n",
      "Epoch 93/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7210 - mae: 1.2026 - val_loss: 9.3002 - val_mae: 2.9640\n",
      "Epoch 94/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7208 - mae: 1.2006 - val_loss: 9.1283 - val_mae: 2.9349\n",
      "Epoch 95/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7224 - mae: 1.1998 - val_loss: 8.9769 - val_mae: 2.9090\n",
      "Epoch 96/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7235 - mae: 1.1991 - val_loss: 8.8325 - val_mae: 2.8840\n",
      "Epoch 97/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7281 - mae: 1.1983 - val_loss: 8.6952 - val_mae: 2.8601\n",
      "Epoch 98/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7332 - mae: 1.1983 - val_loss: 8.6080 - val_mae: 2.8449\n",
      "Epoch 99/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7364 - mae: 1.1977 - val_loss: 8.5848 - val_mae: 2.8408\n",
      "Epoch 100/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7369 - mae: 1.1975 - val_loss: 8.5970 - val_mae: 2.8429\n",
      "Epoch 101/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7363 - mae: 1.1974 - val_loss: 8.6175 - val_mae: 2.8465\n",
      "Epoch 102/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7356 - mae: 1.1976 - val_loss: 8.6342 - val_mae: 2.8495\n",
      "Epoch 103/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7346 - mae: 1.1976 - val_loss: 8.6658 - val_mae: 2.8550\n",
      "Epoch 104/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7330 - mae: 1.1976 - val_loss: 8.7395 - val_mae: 2.8679\n",
      "Epoch 105/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7324 - mae: 1.1989 - val_loss: 8.7784 - val_mae: 2.8747\n",
      "Epoch 106/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7293 - mae: 1.1983 - val_loss: 8.7404 - val_mae: 2.8680\n",
      "Epoch 107/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7305 - mae: 1.1980 - val_loss: 8.6855 - val_mae: 2.8585\n",
      "Epoch 108/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7319 - mae: 1.1976 - val_loss: 8.6008 - val_mae: 2.8436\n",
      "Epoch 109/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7372 - mae: 1.1977 - val_loss: 8.5203 - val_mae: 2.8294\n",
      "Epoch 110/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7391 - mae: 1.1969 - val_loss: 8.4574 - val_mae: 2.8183\n",
      "Epoch 111/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7415 - mae: 1.1959 - val_loss: 8.3480 - val_mae: 2.7988\n",
      "Epoch 112/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7498 - mae: 1.1963 - val_loss: 8.2820 - val_mae: 2.7870\n",
      "Epoch 113/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7523 - mae: 1.1957 - val_loss: 8.3120 - val_mae: 2.7924\n",
      "Epoch 114/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7516 - mae: 1.1964 - val_loss: 8.3480 - val_mae: 2.7988\n",
      "Epoch 115/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7483 - mae: 1.1960 - val_loss: 8.4157 - val_mae: 2.8109\n",
      "Epoch 116/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7433 - mae: 1.1959 - val_loss: 8.5714 - val_mae: 2.8384\n",
      "Epoch 117/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7357 - mae: 1.1966 - val_loss: 8.7374 - val_mae: 2.8675\n",
      "Epoch 118/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7296 - mae: 1.1975 - val_loss: 8.8981 - val_mae: 2.8954\n",
      "Epoch 119/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7254 - mae: 1.1990 - val_loss: 9.0372 - val_mae: 2.9193\n",
      "Epoch 120/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7208 - mae: 1.1985 - val_loss: 9.1939 - val_mae: 2.9460\n",
      "Epoch 121/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7190 - mae: 1.1996 - val_loss: 9.3980 - val_mae: 2.9805\n",
      "Epoch 122/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7227 - mae: 1.2022 - val_loss: 9.5656 - val_mae: 3.0085\n",
      "Epoch 123/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7221 - mae: 1.2038 - val_loss: 9.6739 - val_mae: 3.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7250 - mae: 1.2058 - val_loss: 9.7393 - val_mae: 3.0372\n",
      "Epoch 125/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7257 - mae: 1.2065 - val_loss: 9.7486 - val_mae: 3.0387\n",
      "Epoch 126/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7257 - mae: 1.2066 - val_loss: 9.7095 - val_mae: 3.0323\n",
      "Epoch 127/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7242 - mae: 1.2059 - val_loss: 9.6138 - val_mae: 3.0165\n",
      "Epoch 128/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7226 - mae: 1.2049 - val_loss: 9.4954 - val_mae: 2.9968\n",
      "Epoch 129/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7217 - mae: 1.2026 - val_loss: 9.4050 - val_mae: 2.9817\n",
      "Epoch 130/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7199 - mae: 1.2015 - val_loss: 9.3349 - val_mae: 2.9699\n",
      "Epoch 131/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7195 - mae: 1.2004 - val_loss: 9.2498 - val_mae: 2.9555\n",
      "Epoch 132/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7194 - mae: 1.1999 - val_loss: 9.1566 - val_mae: 2.9397\n",
      "Epoch 133/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7199 - mae: 1.1998 - val_loss: 9.0643 - val_mae: 2.9240\n",
      "Epoch 134/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7213 - mae: 1.1993 - val_loss: 8.9951 - val_mae: 2.9121\n",
      "Epoch 135/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7226 - mae: 1.1989 - val_loss: 8.9963 - val_mae: 2.9123\n",
      "Epoch 136/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7224 - mae: 1.1989 - val_loss: 9.0196 - val_mae: 2.9163\n",
      "Epoch 137/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7215 - mae: 1.1988 - val_loss: 9.0491 - val_mae: 2.9214\n",
      "Epoch 138/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7206 - mae: 1.1987 - val_loss: 9.1246 - val_mae: 2.9343\n",
      "Epoch 139/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7210 - mae: 1.1999 - val_loss: 9.1546 - val_mae: 2.9394\n",
      "Epoch 140/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7198 - mae: 1.1994 - val_loss: 9.1737 - val_mae: 2.9426\n",
      "Epoch 141/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7193 - mae: 1.1996 - val_loss: 9.2300 - val_mae: 2.9522\n",
      "Epoch 142/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7192 - mae: 1.1998 - val_loss: 9.2456 - val_mae: 2.9548\n",
      "Epoch 143/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7186 - mae: 1.1997 - val_loss: 9.2112 - val_mae: 2.9490\n",
      "Epoch 144/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7192 - mae: 1.1996 - val_loss: 9.1980 - val_mae: 2.9468\n",
      "Epoch 145/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7182 - mae: 1.1993 - val_loss: 9.2853 - val_mae: 2.9615\n",
      "Epoch 146/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7187 - mae: 1.2001 - val_loss: 9.4092 - val_mae: 2.9824\n",
      "Epoch 147/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7200 - mae: 1.2019 - val_loss: 9.4455 - val_mae: 2.9885\n",
      "Epoch 148/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7185 - mae: 1.2016 - val_loss: 9.3814 - val_mae: 2.9777\n",
      "Epoch 149/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7211 - mae: 1.2015 - val_loss: 9.3730 - val_mae: 2.9763\n",
      "Epoch 150/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7176 - mae: 1.2003 - val_loss: 9.4689 - val_mae: 2.9924\n",
      "Epoch 151/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7208 - mae: 1.2026 - val_loss: 9.4826 - val_mae: 2.9947\n",
      "Epoch 152/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7172 - mae: 1.2016 - val_loss: 9.3371 - val_mae: 2.9703\n",
      "Epoch 153/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7163 - mae: 1.2002 - val_loss: 9.1232 - val_mae: 2.9340\n",
      "Epoch 154/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7177 - mae: 1.1991 - val_loss: 8.9375 - val_mae: 2.9022\n",
      "Epoch 155/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7199 - mae: 1.1972 - val_loss: 8.7856 - val_mae: 2.8759\n",
      "Epoch 156/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7250 - mae: 1.1971 - val_loss: 8.6863 - val_mae: 2.8586\n",
      "Epoch 157/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7272 - mae: 1.1961 - val_loss: 8.6515 - val_mae: 2.8525\n",
      "Epoch 158/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7282 - mae: 1.1960 - val_loss: 8.6135 - val_mae: 2.8459\n",
      "Epoch 159/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7306 - mae: 1.1963 - val_loss: 8.6163 - val_mae: 2.8464\n",
      "Epoch 160/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7297 - mae: 1.1959 - val_loss: 8.6719 - val_mae: 2.8561\n",
      "Epoch 161/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7270 - mae: 1.1961 - val_loss: 8.6985 - val_mae: 2.8608\n",
      "Epoch 162/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7256 - mae: 1.1961 - val_loss: 8.7372 - val_mae: 2.8675\n",
      "Epoch 163/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7252 - mae: 1.1967 - val_loss: 8.7497 - val_mae: 2.8697\n",
      "Epoch 164/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7232 - mae: 1.1960 - val_loss: 8.6694 - val_mae: 2.8557\n",
      "Epoch 165/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7268 - mae: 1.1960 - val_loss: 8.5834 - val_mae: 2.8406\n",
      "Epoch 166/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7296 - mae: 1.1953 - val_loss: 8.5784 - val_mae: 2.8397\n",
      "Epoch 167/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7301 - mae: 1.1955 - val_loss: 8.5654 - val_mae: 2.8374\n",
      "Epoch 168/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7302 - mae: 1.1951 - val_loss: 8.5475 - val_mae: 2.8343\n",
      "Epoch 169/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7296 - mae: 1.1947 - val_loss: 8.6278 - val_mae: 2.8484\n",
      "Epoch 170/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7268 - mae: 1.1955 - val_loss: 8.7395 - val_mae: 2.8679\n",
      "Epoch 171/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7229 - mae: 1.1959 - val_loss: 8.8134 - val_mae: 2.8808\n",
      "Epoch 172/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7197 - mae: 1.1959 - val_loss: 8.8893 - val_mae: 2.8939\n",
      "Epoch 173/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7186 - mae: 1.1966 - val_loss: 8.9682 - val_mae: 2.9075\n",
      "Epoch 174/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7166 - mae: 1.1969 - val_loss: 9.0002 - val_mae: 2.9130\n",
      "Epoch 175/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7157 - mae: 1.1969 - val_loss: 8.9907 - val_mae: 2.9114\n",
      "Epoch 176/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7155 - mae: 1.1967 - val_loss: 8.9793 - val_mae: 2.9094\n",
      "Epoch 177/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7152 - mae: 1.1965 - val_loss: 8.9880 - val_mae: 2.9109\n",
      "Epoch 178/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7149 - mae: 1.1964 - val_loss: 8.9641 - val_mae: 2.9068\n",
      "Epoch 179/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7144 - mae: 1.1959 - val_loss: 8.8878 - val_mae: 2.8937\n",
      "Epoch 180/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7152 - mae: 1.1955 - val_loss: 8.7689 - val_mae: 2.8730\n",
      "Epoch 181/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7183 - mae: 1.1948 - val_loss: 8.6281 - val_mae: 2.8484\n",
      "Epoch 182/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7232 - mae: 1.1941 - val_loss: 8.4902 - val_mae: 2.8241\n",
      "Epoch 183/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7315 - mae: 1.1941 - val_loss: 8.4153 - val_mae: 2.8108\n",
      "Epoch 184/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7336 - mae: 1.1933 - val_loss: 8.4275 - val_mae: 2.8130\n",
      "Epoch 185/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7330 - mae: 1.1936 - val_loss: 8.4272 - val_mae: 2.8130\n",
      "Epoch 186/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7318 - mae: 1.1930 - val_loss: 8.4020 - val_mae: 2.8085\n",
      "Epoch 187/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7326 - mae: 1.1928 - val_loss: 8.4462 - val_mae: 2.8163\n",
      "Epoch 188/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7273 - mae: 1.1920 - val_loss: 8.6344 - val_mae: 2.8495\n",
      "Epoch 189/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7200 - mae: 1.1930 - val_loss: 8.9117 - val_mae: 2.8978\n",
      "Epoch 190/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7105 - mae: 1.1936 - val_loss: 9.2155 - val_mae: 2.9497\n",
      "Epoch 191/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7158 - mae: 1.1983 - val_loss: 9.4763 - val_mae: 2.9936\n",
      "Epoch 192/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7152 - mae: 1.2010 - val_loss: 9.6120 - val_mae: 3.0161\n",
      "Epoch 193/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7170 - mae: 1.2029 - val_loss: 9.6832 - val_mae: 3.0279\n",
      "Epoch 194/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7188 - mae: 1.2038 - val_loss: 9.6659 - val_mae: 3.0251\n",
      "Epoch 195/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7176 - mae: 1.2034 - val_loss: 9.6018 - val_mae: 3.0145\n",
      "Epoch 196/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7149 - mae: 1.2019 - val_loss: 9.5493 - val_mae: 3.0058\n",
      "Epoch 197/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7136 - mae: 1.2011 - val_loss: 9.5129 - val_mae: 2.9997\n",
      "Epoch 198/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7115 - mae: 1.2001 - val_loss: 9.5084 - val_mae: 2.9990\n",
      "Epoch 199/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7106 - mae: 1.1998 - val_loss: 9.5185 - val_mae: 3.0007\n",
      "Epoch 200/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7098 - mae: 1.1996 - val_loss: 9.5563 - val_mae: 3.0069\n",
      "Epoch 201/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7097 - mae: 1.2000 - val_loss: 9.6158 - val_mae: 3.0168\n",
      "Epoch 202/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7098 - mae: 1.2007 - val_loss: 9.7414 - val_mae: 3.0376\n",
      "Epoch 203/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7137 - mae: 1.2029 - val_loss: 9.8907 - val_mae: 3.0621\n",
      "Epoch 204/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7175 - mae: 1.2060 - val_loss: 10.0009 - val_mae: 3.0800\n",
      "Epoch 205/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7220 - mae: 1.2085 - val_loss: 10.0731 - val_mae: 3.0917\n",
      "Epoch 206/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7251 - mae: 1.2101 - val_loss: 10.0217 - val_mae: 3.0834\n",
      "Epoch 207/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7241 - mae: 1.2096 - val_loss: 9.9478 - val_mae: 3.0714\n",
      "Epoch 208/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7188 - mae: 1.2068 - val_loss: 10.0066 - val_mae: 3.0809\n",
      "Epoch 209/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7205 - mae: 1.2082 - val_loss: 10.1058 - val_mae: 3.0970\n",
      "Epoch 210/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7249 - mae: 1.2103 - val_loss: 10.1365 - val_mae: 3.1020\n",
      "Epoch 211/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7254 - mae: 1.2107 - val_loss: 10.0843 - val_mae: 3.0935\n",
      "Epoch 212/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7233 - mae: 1.2096 - val_loss: 10.0211 - val_mae: 3.0833\n",
      "Epoch 213/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7192 - mae: 1.2077 - val_loss: 9.9364 - val_mae: 3.0695\n",
      "Epoch 214/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7160 - mae: 1.2060 - val_loss: 9.8123 - val_mae: 3.0492\n",
      "Epoch 215/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7098 - mae: 1.2020 - val_loss: 9.6552 - val_mae: 3.0234\n",
      "Epoch 216/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7038 - mae: 1.1983 - val_loss: 9.4057 - val_mae: 2.9818\n",
      "Epoch 217/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7060 - mae: 1.1969 - val_loss: 9.1949 - val_mae: 2.9463\n",
      "Epoch 218/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7020 - mae: 1.1941 - val_loss: 9.1019 - val_mae: 2.9304\n",
      "Epoch 219/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7004 - mae: 1.1928 - val_loss: 9.0285 - val_mae: 2.9179\n",
      "Epoch 220/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7003 - mae: 1.1923 - val_loss: 8.9858 - val_mae: 2.9106\n",
      "Epoch 221/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6984 - mae: 1.1913 - val_loss: 9.0464 - val_mae: 2.9209\n",
      "Epoch 222/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6958 - mae: 1.1907 - val_loss: 9.2190 - val_mae: 2.9503\n",
      "Epoch 223/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6992 - mae: 1.1934 - val_loss: 9.3905 - val_mae: 2.9792\n",
      "Epoch 224/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7011 - mae: 1.1957 - val_loss: 9.4546 - val_mae: 2.9899\n",
      "Epoch 225/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7016 - mae: 1.1964 - val_loss: 9.4690 - val_mae: 2.9923\n",
      "Epoch 226/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7008 - mae: 1.1964 - val_loss: 9.4082 - val_mae: 2.9822\n",
      "Epoch 227/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6977 - mae: 1.1949 - val_loss: 9.3073 - val_mae: 2.9652\n",
      "Epoch 228/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6933 - mae: 1.1923 - val_loss: 9.2084 - val_mae: 2.9485\n",
      "Epoch 229/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6902 - mae: 1.1900 - val_loss: 9.0221 - val_mae: 2.9168\n",
      "Epoch 230/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6896 - mae: 1.1886 - val_loss: 8.7351 - val_mae: 2.8672\n",
      "Epoch 231/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7069 - mae: 1.1908 - val_loss: 8.4819 - val_mae: 2.8227\n",
      "Epoch 232/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7151 - mae: 1.1892 - val_loss: 8.3252 - val_mae: 2.7948\n",
      "Epoch 233/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7240 - mae: 1.1885 - val_loss: 8.2080 - val_mae: 2.7737\n",
      "Epoch 234/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7292 - mae: 1.1875 - val_loss: 8.1630 - val_mae: 2.7656\n",
      "Epoch 235/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7272 - mae: 1.1861 - val_loss: 8.1930 - val_mae: 2.7710\n",
      "Epoch 236/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7186 - mae: 1.1845 - val_loss: 8.3143 - val_mae: 2.7928\n",
      "Epoch 237/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7111 - mae: 1.1861 - val_loss: 8.4477 - val_mae: 2.8166\n",
      "Epoch 238/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7026 - mae: 1.1856 - val_loss: 8.5065 - val_mae: 2.8270\n",
      "Epoch 239/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7003 - mae: 1.1859 - val_loss: 8.6100 - val_mae: 2.8452\n",
      "Epoch 240/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6987 - mae: 1.1872 - val_loss: 8.7374 - val_mae: 2.8675\n",
      "Epoch 241/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6949 - mae: 1.1879 - val_loss: 8.7937 - val_mae: 2.8773\n",
      "Epoch 242/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6931 - mae: 1.1880 - val_loss: 8.7269 - val_mae: 2.8657\n",
      "Epoch 243/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6900 - mae: 1.1858 - val_loss: 8.5703 - val_mae: 2.8383\n",
      "Epoch 244/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6923 - mae: 1.1846 - val_loss: 8.4764 - val_mae: 2.8217\n",
      "Epoch 245/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6946 - mae: 1.1835 - val_loss: 8.4853 - val_mae: 2.8233\n",
      "Epoch 246/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6924 - mae: 1.1829 - val_loss: 8.6512 - val_mae: 2.8525\n",
      "Epoch 247/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6913 - mae: 1.1860 - val_loss: 8.8369 - val_mae: 2.8849\n",
      "Epoch 248/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6804 - mae: 1.1842 - val_loss: 8.9311 - val_mae: 2.9012\n",
      "Epoch 249/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6803 - mae: 1.1856 - val_loss: 8.9650 - val_mae: 2.9070\n",
      "Epoch 250/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6769 - mae: 1.1843 - val_loss: 8.9059 - val_mae: 2.8968\n",
      "Epoch 251/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6761 - mae: 1.1836 - val_loss: 8.8231 - val_mae: 2.8825\n",
      "Epoch 252/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6797 - mae: 1.1839 - val_loss: 8.8509 - val_mae: 2.8873\n",
      "Epoch 253/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6731 - mae: 1.1814 - val_loss: 9.0689 - val_mae: 2.9248\n",
      "Epoch 254/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6750 - mae: 1.1846 - val_loss: 9.2490 - val_mae: 2.9554\n",
      "Epoch 255/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6732 - mae: 1.1855 - val_loss: 9.2521 - val_mae: 2.9560\n",
      "Epoch 256/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6702 - mae: 1.1847 - val_loss: 9.1390 - val_mae: 2.9368\n",
      "Epoch 257/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6667 - mae: 1.1822 - val_loss: 8.9611 - val_mae: 2.9063\n",
      "Epoch 258/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6670 - mae: 1.1812 - val_loss: 8.7524 - val_mae: 2.8702\n",
      "Epoch 259/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6735 - mae: 1.1809 - val_loss: 8.5477 - val_mae: 2.8343\n",
      "Epoch 260/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6843 - mae: 1.1809 - val_loss: 8.3916 - val_mae: 2.8067\n",
      "Epoch 261/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6917 - mae: 1.1810 - val_loss: 8.3234 - val_mae: 2.7945\n",
      "Epoch 262/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6901 - mae: 1.1791 - val_loss: 8.3825 - val_mae: 2.8051\n",
      "Epoch 263/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6818 - mae: 1.1787 - val_loss: 8.4800 - val_mae: 2.8224\n",
      "Epoch 264/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6706 - mae: 1.1766 - val_loss: 8.5061 - val_mae: 2.8270\n",
      "Epoch 265/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6693 - mae: 1.1767 - val_loss: 8.3928 - val_mae: 2.8069\n",
      "Epoch 266/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6745 - mae: 1.1759 - val_loss: 8.2629 - val_mae: 2.7836\n",
      "Epoch 267/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6753 - mae: 1.1741 - val_loss: 8.3907 - val_mae: 2.8065\n",
      "Epoch 268/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6677 - mae: 1.1753 - val_loss: 8.6709 - val_mae: 2.8559\n",
      "Epoch 269/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6613 - mae: 1.1775 - val_loss: 8.9111 - val_mae: 2.8976\n",
      "Epoch 270/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6590 - mae: 1.1784 - val_loss: 9.0997 - val_mae: 2.9300\n",
      "Epoch 271/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6583 - mae: 1.1795 - val_loss: 9.2115 - val_mae: 2.9491\n",
      "Epoch 272/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6537 - mae: 1.1794 - val_loss: 9.2492 - val_mae: 2.9555\n",
      "Epoch 273/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6478 - mae: 1.1777 - val_loss: 9.2779 - val_mae: 2.9604\n",
      "Epoch 274/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6445 - mae: 1.1768 - val_loss: 9.2583 - val_mae: 2.9571\n",
      "Epoch 275/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6424 - mae: 1.1759 - val_loss: 9.1607 - val_mae: 2.9405\n",
      "Epoch 276/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6451 - mae: 1.1754 - val_loss: 9.0325 - val_mae: 2.9186\n",
      "Epoch 277/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6477 - mae: 1.1753 - val_loss: 8.8790 - val_mae: 2.8922\n",
      "Epoch 278/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6510 - mae: 1.1746 - val_loss: 8.7491 - val_mae: 2.8697\n",
      "Epoch 279/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6471 - mae: 1.1728 - val_loss: 8.6348 - val_mae: 2.8497\n",
      "Epoch 280/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6421 - mae: 1.1703 - val_loss: 8.5741 - val_mae: 2.8390\n",
      "Epoch 281/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6341 - mae: 1.1670 - val_loss: 8.5404 - val_mae: 2.8331\n",
      "Epoch 282/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6282 - mae: 1.1646 - val_loss: 8.3712 - val_mae: 2.8031\n",
      "Epoch 283/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6302 - mae: 1.1628 - val_loss: 8.1644 - val_mae: 2.7660\n",
      "Epoch 284/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6426 - mae: 1.1628 - val_loss: 8.1287 - val_mae: 2.7595\n",
      "Epoch 285/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6352 - mae: 1.1604 - val_loss: 8.3128 - val_mae: 2.7927\n",
      "Epoch 286/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6274 - mae: 1.1615 - val_loss: 8.5138 - val_mae: 2.8284\n",
      "Epoch 287/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6289 - mae: 1.1650 - val_loss: 8.4898 - val_mae: 2.8242\n",
      "Epoch 288/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6123 - mae: 1.1592 - val_loss: 8.3328 - val_mae: 2.7963\n",
      "Epoch 289/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6115 - mae: 1.1565 - val_loss: 8.2923 - val_mae: 2.7890\n",
      "Epoch 290/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6240 - mae: 1.1590 - val_loss: 8.2976 - val_mae: 2.7899\n",
      "Epoch 291/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6292 - mae: 1.1607 - val_loss: 8.2994 - val_mae: 2.7903\n",
      "Epoch 292/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6247 - mae: 1.1593 - val_loss: 8.3399 - val_mae: 2.7975\n",
      "Epoch 293/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6096 - mae: 1.1562 - val_loss: 8.3739 - val_mae: 2.8037\n",
      "Epoch 294/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5889 - mae: 1.1498 - val_loss: 8.5659 - val_mae: 2.8378\n",
      "Epoch 295/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5723 - mae: 1.1468 - val_loss: 9.5425 - val_mae: 3.0045\n",
      "Epoch 296/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6536 - mae: 1.1823 - val_loss: 10.0805 - val_mae: 3.0926\n",
      "Epoch 297/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6813 - mae: 1.1947 - val_loss: 9.6009 - val_mae: 3.0146\n",
      "Epoch 298/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6069 - mae: 1.1682 - val_loss: 9.2427 - val_mae: 2.9546\n",
      "Epoch 299/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5696 - mae: 1.1509 - val_loss: 9.2532 - val_mae: 2.9563\n",
      "Epoch 300/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5882 - mae: 1.1580 - val_loss: 9.3281 - val_mae: 2.9689\n",
      "Epoch 301/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6019 - mae: 1.1633 - val_loss: 9.3295 - val_mae: 2.9691\n",
      "Epoch 302/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6041 - mae: 1.1641 - val_loss: 9.2917 - val_mae: 2.9628\n",
      "Epoch 303/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5969 - mae: 1.1614 - val_loss: 9.1967 - val_mae: 2.9467\n",
      "Epoch 304/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5858 - mae: 1.1568 - val_loss: 9.1109 - val_mae: 2.9322\n",
      "Epoch 305/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5713 - mae: 1.1514 - val_loss: 9.0839 - val_mae: 2.9276\n",
      "Epoch 306/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5595 - mae: 1.1473 - val_loss: 9.0072 - val_mae: 2.9145\n",
      "Epoch 307/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5515 - mae: 1.1444 - val_loss: 8.8975 - val_mae: 2.8957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5452 - mae: 1.1412 - val_loss: 8.7789 - val_mae: 2.8752\n",
      "Epoch 309/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5384 - mae: 1.1378 - val_loss: 8.5214 - val_mae: 2.8300\n",
      "Epoch 310/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5331 - mae: 1.1335 - val_loss: 8.1815 - val_mae: 2.7693\n",
      "Epoch 311/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5382 - mae: 1.1312 - val_loss: 7.9804 - val_mae: 2.7327\n",
      "Epoch 312/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5346 - mae: 1.1269 - val_loss: 7.9442 - val_mae: 2.7261\n",
      "Epoch 313/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5226 - mae: 1.1223 - val_loss: 7.9887 - val_mae: 2.7343\n",
      "Epoch 314/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5061 - mae: 1.1183 - val_loss: 8.1131 - val_mae: 2.7571\n",
      "Epoch 315/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4899 - mae: 1.1163 - val_loss: 8.4237 - val_mae: 2.8131\n",
      "Epoch 316/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4997 - mae: 1.1219 - val_loss: 8.6003 - val_mae: 2.8444\n",
      "Epoch 317/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4822 - mae: 1.1180 - val_loss: 8.6663 - val_mae: 2.8558\n",
      "Epoch 318/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4488 - mae: 1.1054 - val_loss: 8.8155 - val_mae: 2.8816\n",
      "Epoch 319/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4217 - mae: 1.0954 - val_loss: 8.8696 - val_mae: 2.8908\n",
      "Epoch 320/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4187 - mae: 1.0948 - val_loss: 8.8475 - val_mae: 2.8870\n",
      "Epoch 321/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4043 - mae: 1.0895 - val_loss: 8.8172 - val_mae: 2.8819\n",
      "Epoch 322/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3361 - mae: 1.0611 - val_loss: 8.9728 - val_mae: 2.9096\n",
      "Epoch 323/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4047 - mae: 1.0895 - val_loss: 8.8963 - val_mae: 2.8956\n",
      "Epoch 324/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2753 - mae: 1.0316 - val_loss: 8.9810 - val_mae: 2.9101\n",
      "Epoch 325/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2498 - mae: 1.0189 - val_loss: 9.0151 - val_mae: 2.9159\n",
      "Epoch 326/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2269 - mae: 1.0070 - val_loss: 8.9221 - val_mae: 2.8999\n",
      "Epoch 327/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1950 - mae: 0.9919 - val_loss: 8.6606 - val_mae: 2.8545\n",
      "Epoch 328/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1698 - mae: 0.9825 - val_loss: 8.3448 - val_mae: 2.7986\n",
      "Epoch 329/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1328 - mae: 0.9675 - val_loss: 8.0326 - val_mae: 2.7423\n",
      "Epoch 330/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0987 - mae: 0.9488 - val_loss: 7.6606 - val_mae: 2.6736\n",
      "Epoch 331/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0795 - mae: 0.9393 - val_loss: 7.2865 - val_mae: 2.6026\n",
      "Epoch 332/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1112 - mae: 0.9608 - val_loss: 6.9508 - val_mae: 2.5373\n",
      "Epoch 333/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1699 - mae: 0.9831 - val_loss: 6.7100 - val_mae: 2.4894\n",
      "Epoch 334/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0986 - mae: 0.9381 - val_loss: 6.6763 - val_mae: 2.4836\n",
      "Epoch 335/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2635 - mae: 1.0245 - val_loss: 6.5409 - val_mae: 2.4552\n",
      "Epoch 336/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0596 - mae: 0.9175 - val_loss: 6.4536 - val_mae: 2.4373\n",
      "Epoch 337/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2266 - mae: 0.9930 - val_loss: 6.4754 - val_mae: 2.4418\n",
      "Epoch 338/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1984 - mae: 0.9841 - val_loss: 6.5490 - val_mae: 2.4569\n",
      "Epoch 339/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0412 - mae: 0.9178 - val_loss: 6.6093 - val_mae: 2.4693\n",
      "Epoch 340/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0633 - mae: 0.9278 - val_loss: 6.6694 - val_mae: 2.4819\n",
      "Epoch 341/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1529 - mae: 0.9802 - val_loss: 6.7197 - val_mae: 2.4915\n",
      "Epoch 342/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9613 - mae: 0.8766 - val_loss: 6.9248 - val_mae: 2.5323\n",
      "Epoch 343/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9446 - mae: 0.8755 - val_loss: 7.1770 - val_mae: 2.5817\n",
      "Epoch 344/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9144 - mae: 0.8544 - val_loss: 7.4384 - val_mae: 2.6319\n",
      "Epoch 345/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9341 - mae: 0.8703 - val_loss: 7.6259 - val_mae: 2.6673\n",
      "Epoch 346/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9792 - mae: 0.9000 - val_loss: 7.6769 - val_mae: 2.6768\n",
      "Epoch 347/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8989 - mae: 0.8445 - val_loss: 7.6936 - val_mae: 2.6799\n",
      "Epoch 348/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8827 - mae: 0.8329 - val_loss: 7.6438 - val_mae: 2.6706\n",
      "Epoch 349/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8703 - mae: 0.8250 - val_loss: 7.5537 - val_mae: 2.6537\n",
      "Epoch 350/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8671 - mae: 0.8304 - val_loss: 7.4791 - val_mae: 2.6396\n",
      "Epoch 351/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8425 - mae: 0.8113 - val_loss: 7.4694 - val_mae: 2.6378\n",
      "Epoch 352/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8312 - mae: 0.8048 - val_loss: 7.4348 - val_mae: 2.6312\n",
      "Epoch 353/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8193 - mae: 0.7981 - val_loss: 7.3533 - val_mae: 2.6157\n",
      "Epoch 354/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8056 - mae: 0.7907 - val_loss: 7.2888 - val_mae: 2.6033\n",
      "Epoch 355/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7919 - mae: 0.7828 - val_loss: 7.2117 - val_mae: 2.5885\n",
      "Epoch 356/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7795 - mae: 0.7775 - val_loss: 7.0997 - val_mae: 2.5668\n",
      "Epoch 357/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7684 - mae: 0.7759 - val_loss: 6.9815 - val_mae: 2.5437\n",
      "Epoch 358/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7505 - mae: 0.7634 - val_loss: 6.8424 - val_mae: 2.5162\n",
      "Epoch 359/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7327 - mae: 0.7487 - val_loss: 6.7330 - val_mae: 2.4944\n",
      "Epoch 360/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7212 - mae: 0.7435 - val_loss: 6.6756 - val_mae: 2.4829\n",
      "Epoch 361/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7247 - mae: 0.7550 - val_loss: 6.5598 - val_mae: 2.4594\n",
      "Epoch 362/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6947 - mae: 0.7277 - val_loss: 6.3399 - val_mae: 2.4142\n",
      "Epoch 363/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7231 - mae: 0.7593 - val_loss: 6.1101 - val_mae: 2.3661\n",
      "Epoch 364/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7685 - mae: 0.7830 - val_loss: 5.9212 - val_mae: 2.3259\n",
      "Epoch 365/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7501 - mae: 0.7660 - val_loss: 5.7854 - val_mae: 2.2965\n",
      "Epoch 366/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6727 - mae: 0.7075 - val_loss: 5.7084 - val_mae: 2.2798\n",
      "Epoch 367/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6918 - mae: 0.7321 - val_loss: 5.6999 - val_mae: 2.2780\n",
      "Epoch 368/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7306 - mae: 0.7576 - val_loss: 5.7770 - val_mae: 2.2949\n",
      "Epoch 369/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6531 - mae: 0.7103 - val_loss: 5.8420 - val_mae: 2.3091\n",
      "Epoch 370/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6110 - mae: 0.6714 - val_loss: 5.8621 - val_mae: 2.3134\n",
      "Epoch 371/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6623 - mae: 0.7192 - val_loss: 5.9736 - val_mae: 2.3374\n",
      "Epoch 372/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5953 - mae: 0.6753 - val_loss: 6.0616 - val_mae: 2.3563\n",
      "Epoch 373/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6633 - mae: 0.7214 - val_loss: 6.0360 - val_mae: 2.3508\n",
      "Epoch 374/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6876 - mae: 0.7315 - val_loss: 6.0407 - val_mae: 2.3517\n",
      "Epoch 375/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5773 - mae: 0.6658 - val_loss: 6.0237 - val_mae: 2.3481\n",
      "Epoch 376/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5417 - mae: 0.6293 - val_loss: 6.0406 - val_mae: 2.3517\n",
      "Epoch 377/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5697 - mae: 0.6621 - val_loss: 6.1165 - val_mae: 2.3678\n",
      "Epoch 378/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5229 - mae: 0.6159 - val_loss: 6.1431 - val_mae: 2.3736\n",
      "Epoch 379/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5420 - mae: 0.6345 - val_loss: 6.1718 - val_mae: 2.3797\n",
      "Epoch 380/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5479 - mae: 0.6383 - val_loss: 6.1075 - val_mae: 2.3660\n",
      "Epoch 381/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4933 - mae: 0.5889 - val_loss: 5.9602 - val_mae: 2.3346\n",
      "Epoch 382/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5048 - mae: 0.6136 - val_loss: 5.8632 - val_mae: 2.3137\n",
      "Epoch 383/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4834 - mae: 0.5958 - val_loss: 5.8131 - val_mae: 2.3029\n",
      "Epoch 384/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4513 - mae: 0.5604 - val_loss: 5.7287 - val_mae: 2.2845\n",
      "Epoch 385/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4363 - mae: 0.5394 - val_loss: 5.5793 - val_mae: 2.2516\n",
      "Epoch 386/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4350 - mae: 0.5476 - val_loss: 5.4918 - val_mae: 2.2322\n",
      "Epoch 387/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4225 - mae: 0.5393 - val_loss: 5.4573 - val_mae: 2.2245\n",
      "Epoch 388/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3994 - mae: 0.5128 - val_loss: 5.3835 - val_mae: 2.2078\n",
      "Epoch 389/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3783 - mae: 0.4979 - val_loss: 5.2747 - val_mae: 2.1829\n",
      "Epoch 390/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3718 - mae: 0.4971 - val_loss: 5.1244 - val_mae: 2.1481\n",
      "Epoch 391/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3675 - mae: 0.4978 - val_loss: 5.0181 - val_mae: 2.1233\n",
      "Epoch 392/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3351 - mae: 0.4679 - val_loss: 5.0504 - val_mae: 2.1318\n",
      "Epoch 393/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3296 - mae: 0.4486 - val_loss: 4.9046 - val_mae: 2.0965\n",
      "Epoch 394/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2967 - mae: 0.4178 - val_loss: 4.8251 - val_mae: 2.0773\n",
      "Epoch 395/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2872 - mae: 0.4168 - val_loss: 4.7551 - val_mae: 2.0604\n",
      "Epoch 396/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2693 - mae: 0.3972 - val_loss: 4.6718 - val_mae: 2.0401\n",
      "Epoch 397/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2547 - mae: 0.3769 - val_loss: 4.5719 - val_mae: 2.0155\n",
      "Epoch 398/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2419 - mae: 0.3679 - val_loss: 4.4335 - val_mae: 1.9809\n",
      "Epoch 399/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2317 - mae: 0.3528 - val_loss: 4.3214 - val_mae: 1.9525\n",
      "Epoch 400/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2328 - mae: 0.3572 - val_loss: 4.2131 - val_mae: 1.9244\n",
      "Epoch 401/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2147 - mae: 0.3316 - val_loss: 4.1152 - val_mae: 1.8987\n",
      "Epoch 402/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2071 - mae: 0.3306 - val_loss: 4.0614 - val_mae: 1.8845\n",
      "Epoch 403/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1994 - mae: 0.3208 - val_loss: 4.0430 - val_mae: 1.8796\n",
      "Epoch 404/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1921 - mae: 0.3108 - val_loss: 4.0536 - val_mae: 1.8825\n",
      "Epoch 405/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1868 - mae: 0.3070 - val_loss: 4.0318 - val_mae: 1.8767\n",
      "Epoch 406/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1786 - mae: 0.3009 - val_loss: 3.9829 - val_mae: 1.8636\n",
      "Epoch 407/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1732 - mae: 0.2967 - val_loss: 3.9495 - val_mae: 1.8547\n",
      "Epoch 408/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1692 - mae: 0.2925 - val_loss: 3.8909 - val_mae: 1.8388\n",
      "Epoch 409/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1661 - mae: 0.2894 - val_loss: 3.8438 - val_mae: 1.8260\n",
      "Epoch 410/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1622 - mae: 0.2860 - val_loss: 3.8465 - val_mae: 1.8267\n",
      "Epoch 411/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1594 - mae: 0.2878 - val_loss: 3.8560 - val_mae: 1.8293\n",
      "Epoch 412/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1542 - mae: 0.2855 - val_loss: 3.8439 - val_mae: 1.8260\n",
      "Epoch 413/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1509 - mae: 0.2871 - val_loss: 3.7858 - val_mae: 1.8100\n",
      "Epoch 414/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1493 - mae: 0.2862 - val_loss: 3.7255 - val_mae: 1.7933\n",
      "Epoch 415/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1435 - mae: 0.2755 - val_loss: 3.7006 - val_mae: 1.7864\n",
      "Epoch 416/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1405 - mae: 0.2696 - val_loss: 3.6664 - val_mae: 1.7768\n",
      "Epoch 417/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1357 - mae: 0.2644 - val_loss: 3.6059 - val_mae: 1.7597\n",
      "Epoch 418/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1473 - mae: 0.2826 - val_loss: 3.5471 - val_mae: 1.7429\n",
      "Epoch 419/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1500 - mae: 0.2851 - val_loss: 3.5172 - val_mae: 1.7343\n",
      "Epoch 420/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1861 - mae: 0.3255 - val_loss: 3.4793 - val_mae: 1.7233\n",
      "Epoch 421/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1373 - mae: 0.2764 - val_loss: 3.4201 - val_mae: 1.7060\n",
      "Epoch 422/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1778 - mae: 0.3219 - val_loss: 3.3896 - val_mae: 1.6970\n",
      "Epoch 423/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2118 - mae: 0.3541 - val_loss: 3.3932 - val_mae: 1.6982\n",
      "Epoch 424/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1547 - mae: 0.2993 - val_loss: 3.4380 - val_mae: 1.7114\n",
      "Epoch 425/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1431 - mae: 0.2886 - val_loss: 3.4789 - val_mae: 1.7234\n",
      "Epoch 426/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1720 - mae: 0.3315 - val_loss: 3.4864 - val_mae: 1.7255\n",
      "Epoch 427/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1279 - mae: 0.2785 - val_loss: 3.4852 - val_mae: 1.7251\n",
      "Epoch 428/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1341 - mae: 0.2876 - val_loss: 3.4505 - val_mae: 1.7150\n",
      "Epoch 429/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1485 - mae: 0.2953 - val_loss: 3.4333 - val_mae: 1.7100\n",
      "Epoch 430/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1662 - mae: 0.3296 - val_loss: 3.5025 - val_mae: 1.7302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1118 - mae: 0.2496 - val_loss: 3.5921 - val_mae: 1.7560\n",
      "Epoch 432/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2013 - mae: 0.3725 - val_loss: 3.5965 - val_mae: 1.7573\n",
      "Epoch 433/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1832 - mae: 0.3514 - val_loss: 3.5182 - val_mae: 1.7348\n",
      "Epoch 434/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1493 - mae: 0.3148 - val_loss: 3.4677 - val_mae: 1.7202\n",
      "Epoch 435/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1411 - mae: 0.3106 - val_loss: 3.4292 - val_mae: 1.7093\n",
      "Epoch 436/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2512 - mae: 0.4084 - val_loss: 3.2548 - val_mae: 1.6571\n",
      "Epoch 437/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1638 - mae: 0.3241 - val_loss: 3.1269 - val_mae: 1.6178\n",
      "Epoch 438/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6744 - mae: 0.5805 - val_loss: 3.1545 - val_mae: 1.6264\n",
      "Epoch 439/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9349 - mae: 0.7235 - val_loss: 3.3823 - val_mae: 1.6952\n",
      "Epoch 440/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6208 - mae: 0.6037 - val_loss: 5.4904 - val_mae: 2.2376\n",
      "Epoch 441/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5570 - mae: 0.6386 - val_loss: 6.7461 - val_mae: 2.4980\n",
      "Epoch 442/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5597 - mae: 0.6480 - val_loss: 6.7312 - val_mae: 2.4949\n",
      "Epoch 443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5100 - mae: 0.6206 - val_loss: 6.4538 - val_mae: 2.4387\n",
      "Epoch 444/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4356 - mae: 0.5607 - val_loss: 6.0010 - val_mae: 2.3439\n",
      "Epoch 445/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4547 - mae: 0.6062 - val_loss: 5.3796 - val_mae: 2.2073\n",
      "Epoch 446/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3998 - mae: 0.5486 - val_loss: 4.7386 - val_mae: 2.0568\n",
      "Epoch 447/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2481 - mae: 0.3871 - val_loss: 4.2868 - val_mae: 1.9437\n",
      "Epoch 448/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3176 - mae: 0.4465 - val_loss: 4.0566 - val_mae: 1.8834\n",
      "Epoch 449/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4003 - mae: 0.4916 - val_loss: 3.9194 - val_mae: 1.8466\n",
      "Epoch 450/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3844 - mae: 0.4814 - val_loss: 3.8717 - val_mae: 1.8337\n",
      "Epoch 451/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2822 - mae: 0.4129 - val_loss: 3.8927 - val_mae: 1.8394\n",
      "Epoch 452/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2201 - mae: 0.3381 - val_loss: 3.9096 - val_mae: 1.8441\n",
      "Epoch 453/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2634 - mae: 0.3924 - val_loss: 3.9042 - val_mae: 1.8427\n",
      "Epoch 454/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2987 - mae: 0.4176 - val_loss: 3.8859 - val_mae: 1.8377\n",
      "Epoch 455/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2437 - mae: 0.3741 - val_loss: 3.8443 - val_mae: 1.8263\n",
      "Epoch 456/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2070 - mae: 0.3313 - val_loss: 3.8337 - val_mae: 1.8234\n",
      "Epoch 457/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2861 - mae: 0.4119 - val_loss: 3.9156 - val_mae: 1.8458\n",
      "Epoch 458/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3326 - mae: 0.4394 - val_loss: 4.0590 - val_mae: 1.8843\n",
      "Epoch 459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2647 - mae: 0.3935 - val_loss: 4.2006 - val_mae: 1.9216\n",
      "Epoch 460/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1850 - mae: 0.3294 - val_loss: 4.2796 - val_mae: 1.9421\n",
      "Epoch 461/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2034 - mae: 0.3561 - val_loss: 4.2486 - val_mae: 1.9342\n",
      "Epoch 462/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2200 - mae: 0.3756 - val_loss: 4.0915 - val_mae: 1.8931\n",
      "Epoch 463/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1842 - mae: 0.3227 - val_loss: 3.9124 - val_mae: 1.8451\n",
      "Epoch 464/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1730 - mae: 0.3074 - val_loss: 3.8147 - val_mae: 1.8184\n",
      "Epoch 465/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1773 - mae: 0.3098 - val_loss: 3.8065 - val_mae: 1.8162\n",
      "Epoch 466/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1741 - mae: 0.3082 - val_loss: 3.8170 - val_mae: 1.8191\n",
      "Epoch 467/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1650 - mae: 0.3023 - val_loss: 3.8610 - val_mae: 1.8312\n",
      "Epoch 468/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1605 - mae: 0.3027 - val_loss: 3.9256 - val_mae: 1.8488\n",
      "Epoch 469/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1605 - mae: 0.3034 - val_loss: 3.9390 - val_mae: 1.8525\n",
      "Epoch 470/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1603 - mae: 0.3085 - val_loss: 3.9195 - val_mae: 1.8472\n",
      "Epoch 471/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1573 - mae: 0.3055 - val_loss: 3.8780 - val_mae: 1.8359\n",
      "Epoch 472/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1571 - mae: 0.3092 - val_loss: 3.8308 - val_mae: 1.8231\n",
      "Epoch 473/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1606 - mae: 0.3089 - val_loss: 3.7684 - val_mae: 1.8059\n",
      "Epoch 474/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2208 - mae: 0.3714 - val_loss: 3.6339 - val_mae: 1.7682\n",
      "Epoch 475/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1839 - mae: 0.3252 - val_loss: 3.4814 - val_mae: 1.7244\n",
      "Epoch 476/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1514 - mae: 0.2833 - val_loss: 3.3757 - val_mae: 1.6934\n",
      "Epoch 477/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1923 - mae: 0.3274 - val_loss: 3.3660 - val_mae: 1.6906\n",
      "Epoch 478/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2084 - mae: 0.3447 - val_loss: 3.4491 - val_mae: 1.7150\n",
      "Epoch 479/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1717 - mae: 0.3083 - val_loss: 3.5451 - val_mae: 1.7429\n",
      "Epoch 480/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1432 - mae: 0.2830 - val_loss: 3.6194 - val_mae: 1.7641\n",
      "Epoch 481/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1537 - mae: 0.2946 - val_loss: 3.6414 - val_mae: 1.7704\n",
      "Epoch 482/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1859 - mae: 0.3392 - val_loss: 3.5703 - val_mae: 1.7502\n",
      "Epoch 483/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1422 - mae: 0.2875 - val_loss: 3.4635 - val_mae: 1.7193\n",
      "Epoch 484/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2257 - mae: 0.3555 - val_loss: 3.4685 - val_mae: 1.7208\n",
      "Epoch 485/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1827 - mae: 0.3261 - val_loss: 3.5640 - val_mae: 1.7484\n",
      "Epoch 486/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1480 - mae: 0.2973 - val_loss: 3.6374 - val_mae: 1.7694\n",
      "Epoch 487/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2515 - mae: 0.4011 - val_loss: 3.5905 - val_mae: 1.7561\n",
      "Epoch 488/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2704 - mae: 0.4104 - val_loss: 3.4340 - val_mae: 1.7108\n",
      "Epoch 489/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1369 - mae: 0.2815 - val_loss: 3.2944 - val_mae: 1.6694\n",
      "Epoch 490/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3205 - mae: 0.4097 - val_loss: 3.2313 - val_mae: 1.6504\n",
      "Epoch 491/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5349 - mae: 0.5134 - val_loss: 3.2717 - val_mae: 1.6626\n",
      "Epoch 492/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5964 - mae: 0.5446 - val_loss: 3.4680 - val_mae: 1.7207\n",
      "Epoch 493/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3973 - mae: 0.4477 - val_loss: 3.7660 - val_mae: 1.8054\n",
      "Epoch 494/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1501 - mae: 0.3202 - val_loss: 3.9471 - val_mae: 1.8551\n",
      "Epoch 495/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3379 - mae: 0.4777 - val_loss: 3.8827 - val_mae: 1.8377\n",
      "Epoch 496/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4207 - mae: 0.5156 - val_loss: 3.6351 - val_mae: 1.7689\n",
      "Epoch 497/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2370 - mae: 0.3855 - val_loss: 3.3657 - val_mae: 1.6908\n",
      "Epoch 498/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1447 - mae: 0.2949 - val_loss: 3.1550 - val_mae: 1.6272\n",
      "Epoch 499/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1557 - mae: 0.3002 - val_loss: 3.0321 - val_mae: 1.5889\n",
      "Epoch 500/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2093 - mae: 0.3500 - val_loss: 3.0194 - val_mae: 1.5849\n",
      "Epoch 501/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1948 - mae: 0.3368 - val_loss: 3.1347 - val_mae: 1.6209\n",
      "Epoch 502/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1457 - mae: 0.2886 - val_loss: 3.3178 - val_mae: 1.6766\n",
      "Epoch 503/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1654 - mae: 0.3158 - val_loss: 3.4781 - val_mae: 1.7239\n",
      "Epoch 504/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2349 - mae: 0.3834 - val_loss: 3.5214 - val_mae: 1.7364\n",
      "Epoch 505/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1780 - mae: 0.3318 - val_loss: 3.4341 - val_mae: 1.7110\n",
      "Epoch 506/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1447 - mae: 0.3006 - val_loss: 3.3758 - val_mae: 1.6938\n",
      "Epoch 507/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1673 - mae: 0.3200 - val_loss: 3.3664 - val_mae: 1.6910\n",
      "Epoch 508/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1540 - mae: 0.3039 - val_loss: 3.3827 - val_mae: 1.6958\n",
      "Epoch 509/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1402 - mae: 0.2923 - val_loss: 3.4099 - val_mae: 1.7039\n",
      "Epoch 510/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1395 - mae: 0.2937 - val_loss: 3.4175 - val_mae: 1.7061\n",
      "Epoch 511/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1481 - mae: 0.3041 - val_loss: 3.4205 - val_mae: 1.7070\n",
      "Epoch 512/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1531 - mae: 0.3054 - val_loss: 3.3925 - val_mae: 1.6988\n",
      "Epoch 513/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1491 - mae: 0.3025 - val_loss: 3.3285 - val_mae: 1.6798\n",
      "Epoch 514/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1411 - mae: 0.2954 - val_loss: 3.2948 - val_mae: 1.6697\n",
      "Epoch 515/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1344 - mae: 0.2850 - val_loss: 3.2487 - val_mae: 1.6558\n",
      "Epoch 516/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1485 - mae: 0.2928 - val_loss: 3.1927 - val_mae: 1.6387\n",
      "Epoch 517/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2140 - mae: 0.3561 - val_loss: 3.2553 - val_mae: 1.6578\n",
      "Epoch 518/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2330 - mae: 0.3668 - val_loss: 3.4521 - val_mae: 1.7162\n",
      "Epoch 519/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1667 - mae: 0.3270 - val_loss: 3.6482 - val_mae: 1.7726\n",
      "Epoch 520/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1452 - mae: 0.3173 - val_loss: 3.7587 - val_mae: 1.8035\n",
      "Epoch 521/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1710 - mae: 0.3472 - val_loss: 3.7367 - val_mae: 1.7974\n",
      "Epoch 522/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1574 - mae: 0.3316 - val_loss: 3.5985 - val_mae: 1.7585\n",
      "Epoch 523/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1415 - mae: 0.3060 - val_loss: 3.4878 - val_mae: 1.7267\n",
      "Epoch 524/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1418 - mae: 0.2971 - val_loss: 3.3828 - val_mae: 1.6959\n",
      "Epoch 525/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1449 - mae: 0.2999 - val_loss: 3.2585 - val_mae: 1.6588\n",
      "Epoch 526/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1458 - mae: 0.2970 - val_loss: 3.1476 - val_mae: 1.6250\n",
      "Epoch 527/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1482 - mae: 0.2951 - val_loss: 3.0676 - val_mae: 1.6001\n",
      "Epoch 528/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1482 - mae: 0.2934 - val_loss: 3.0379 - val_mae: 1.5908\n",
      "Epoch 529/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1418 - mae: 0.2863 - val_loss: 3.0489 - val_mae: 1.5943\n",
      "Epoch 530/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1370 - mae: 0.2815 - val_loss: 3.0499 - val_mae: 1.5946\n",
      "Epoch 531/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1377 - mae: 0.2831 - val_loss: 3.0538 - val_mae: 1.5958\n",
      "Epoch 532/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1391 - mae: 0.2848 - val_loss: 3.0904 - val_mae: 1.6073\n",
      "Epoch 533/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1337 - mae: 0.2805 - val_loss: 3.1372 - val_mae: 1.6218\n",
      "Epoch 534/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1332 - mae: 0.2833 - val_loss: 3.1924 - val_mae: 1.6387\n",
      "Epoch 535/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1374 - mae: 0.2906 - val_loss: 3.2404 - val_mae: 1.6534\n",
      "Epoch 536/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1352 - mae: 0.2904 - val_loss: 3.2707 - val_mae: 1.6625\n",
      "Epoch 537/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1281 - mae: 0.2845 - val_loss: 3.3025 - val_mae: 1.6721\n",
      "Epoch 538/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1244 - mae: 0.2792 - val_loss: 3.3161 - val_mae: 1.6762\n",
      "Epoch 539/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1499 - mae: 0.3109 - val_loss: 3.2432 - val_mae: 1.6543\n",
      "Epoch 540/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1772 - mae: 0.3401 - val_loss: 3.1065 - val_mae: 1.6123\n",
      "Epoch 541/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1573 - mae: 0.3106 - val_loss: 2.9490 - val_mae: 1.5626\n",
      "Epoch 542/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1360 - mae: 0.2737 - val_loss: 2.8000 - val_mae: 1.5140\n",
      "Epoch 543/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1586 - mae: 0.3026 - val_loss: 2.7075 - val_mae: 1.4831\n",
      "Epoch 544/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1931 - mae: 0.3347 - val_loss: 2.7045 - val_mae: 1.4821\n",
      "Epoch 545/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1920 - mae: 0.3336 - val_loss: 2.7918 - val_mae: 1.5113\n",
      "Epoch 546/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1493 - mae: 0.2836 - val_loss: 2.9205 - val_mae: 1.5535\n",
      "Epoch 547/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1766 - mae: 0.3296 - val_loss: 3.0200 - val_mae: 1.5853\n",
      "Epoch 548/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2498 - mae: 0.3872 - val_loss: 3.0269 - val_mae: 1.5874\n",
      "Epoch 549/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2007 - mae: 0.3501 - val_loss: 2.9506 - val_mae: 1.5631\n",
      "Epoch 550/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1346 - mae: 0.2743 - val_loss: 2.8945 - val_mae: 1.5450\n",
      "Epoch 551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1622 - mae: 0.3089 - val_loss: 2.9287 - val_mae: 1.5560\n",
      "Epoch 552/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2140 - mae: 0.3591 - val_loss: 3.0644 - val_mae: 1.5991\n",
      "Epoch 553/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1613 - mae: 0.3154 - val_loss: 3.3077 - val_mae: 1.6736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1303 - mae: 0.2827 - val_loss: 3.5392 - val_mae: 1.7415\n",
      "Epoch 555/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1458 - mae: 0.3098 - val_loss: 3.6405 - val_mae: 1.7704\n",
      "Epoch 556/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1428 - mae: 0.3127 - val_loss: 3.6276 - val_mae: 1.7667\n",
      "Epoch 557/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1280 - mae: 0.2932 - val_loss: 3.5364 - val_mae: 1.7407\n",
      "Epoch 558/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1216 - mae: 0.2805 - val_loss: 3.4454 - val_mae: 1.7143\n",
      "Epoch 559/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1368 - mae: 0.2951 - val_loss: 3.4285 - val_mae: 1.7093\n",
      "Epoch 560/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1210 - mae: 0.2769 - val_loss: 3.4916 - val_mae: 1.7278\n",
      "Epoch 561/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1207 - mae: 0.2746 - val_loss: 3.5494 - val_mae: 1.7445\n",
      "Epoch 562/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1528 - mae: 0.3223 - val_loss: 3.5180 - val_mae: 1.7354\n",
      "Epoch 563/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1497 - mae: 0.3187 - val_loss: 3.4376 - val_mae: 1.7121\n",
      "Epoch 564/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1206 - mae: 0.2697 - val_loss: 3.3551 - val_mae: 1.6878\n",
      "Epoch 565/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1095 - mae: 0.2542 - val_loss: 3.2876 - val_mae: 1.6676\n",
      "Epoch 566/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1125 - mae: 0.2652 - val_loss: 3.2931 - val_mae: 1.6692\n",
      "Epoch 567/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1162 - mae: 0.2711 - val_loss: 3.3359 - val_mae: 1.6820\n",
      "Epoch 568/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1092 - mae: 0.2635 - val_loss: 3.3479 - val_mae: 1.6857\n",
      "Epoch 569/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1052 - mae: 0.2499 - val_loss: 3.3352 - val_mae: 1.6819\n",
      "Epoch 570/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1105 - mae: 0.2570 - val_loss: 3.3275 - val_mae: 1.6796\n",
      "Epoch 571/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1178 - mae: 0.2712 - val_loss: 3.2832 - val_mae: 1.6664\n",
      "Epoch 572/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1109 - mae: 0.2624 - val_loss: 3.1827 - val_mae: 1.6359\n",
      "Epoch 573/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1033 - mae: 0.2462 - val_loss: 3.0997 - val_mae: 1.6103\n",
      "Epoch 574/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1201 - mae: 0.2709 - val_loss: 3.1140 - val_mae: 1.6147\n",
      "Epoch 575/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1301 - mae: 0.2821 - val_loss: 3.2230 - val_mae: 1.6482\n",
      "Epoch 576/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1160 - mae: 0.2708 - val_loss: 3.3605 - val_mae: 1.6895\n",
      "Epoch 577/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1028 - mae: 0.2603 - val_loss: 3.4378 - val_mae: 1.7123\n",
      "Epoch 578/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1008 - mae: 0.2556 - val_loss: 3.4841 - val_mae: 1.7258\n",
      "Epoch 579/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1040 - mae: 0.2582 - val_loss: 3.4727 - val_mae: 1.7225\n",
      "Epoch 580/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1025 - mae: 0.2539 - val_loss: 3.3961 - val_mae: 1.7001\n",
      "Epoch 581/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0988 - mae: 0.2487 - val_loss: 3.3907 - val_mae: 1.6985\n",
      "Epoch 582/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0976 - mae: 0.2495 - val_loss: 3.3946 - val_mae: 1.6997\n",
      "Epoch 583/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0970 - mae: 0.2512 - val_loss: 3.3516 - val_mae: 1.6870\n",
      "Epoch 584/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0964 - mae: 0.2538 - val_loss: 3.3856 - val_mae: 1.6970\n",
      "Epoch 585/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0988 - mae: 0.2568 - val_loss: 3.4391 - val_mae: 1.7128\n",
      "Epoch 586/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1014 - mae: 0.2632 - val_loss: 3.4299 - val_mae: 1.7101\n",
      "Epoch 587/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1028 - mae: 0.2677 - val_loss: 3.3994 - val_mae: 1.7011\n",
      "Epoch 588/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1062 - mae: 0.2730 - val_loss: 3.3756 - val_mae: 1.6941\n",
      "Epoch 589/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1044 - mae: 0.2715 - val_loss: 3.3488 - val_mae: 1.6862\n",
      "Epoch 590/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0988 - mae: 0.2648 - val_loss: 3.3048 - val_mae: 1.6731\n",
      "Epoch 591/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0942 - mae: 0.2576 - val_loss: 3.2713 - val_mae: 1.6631\n",
      "Epoch 592/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0908 - mae: 0.2506 - val_loss: 3.2406 - val_mae: 1.6538\n",
      "Epoch 593/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0889 - mae: 0.2438 - val_loss: 3.1925 - val_mae: 1.6392\n",
      "Epoch 594/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0888 - mae: 0.2395 - val_loss: 3.1628 - val_mae: 1.6301\n",
      "Epoch 595/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0881 - mae: 0.2357 - val_loss: 3.1923 - val_mae: 1.6392\n",
      "Epoch 596/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0921 - mae: 0.2427 - val_loss: 3.2146 - val_mae: 1.6460\n",
      "Epoch 597/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0901 - mae: 0.2398 - val_loss: 3.1717 - val_mae: 1.6329\n",
      "Epoch 598/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0895 - mae: 0.2490 - val_loss: 3.1647 - val_mae: 1.6307\n",
      "Epoch 599/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0869 - mae: 0.2479 - val_loss: 3.2501 - val_mae: 1.6568\n",
      "Epoch 600/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0880 - mae: 0.2478 - val_loss: 3.3313 - val_mae: 1.6811\n",
      "Epoch 601/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0947 - mae: 0.2509 - val_loss: 3.3625 - val_mae: 1.6904\n",
      "Epoch 602/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1008 - mae: 0.2576 - val_loss: 3.3066 - val_mae: 1.6738\n",
      "Epoch 603/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0946 - mae: 0.2549 - val_loss: 3.2040 - val_mae: 1.6428\n",
      "Epoch 604/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0877 - mae: 0.2507 - val_loss: 3.1426 - val_mae: 1.6240\n",
      "Epoch 605/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0870 - mae: 0.2494 - val_loss: 3.1358 - val_mae: 1.6219\n",
      "Epoch 606/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0857 - mae: 0.2453 - val_loss: 3.1179 - val_mae: 1.6164\n",
      "Epoch 607/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0859 - mae: 0.2374 - val_loss: 3.0088 - val_mae: 1.5823\n",
      "Epoch 608/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0832 - mae: 0.2335 - val_loss: 2.8663 - val_mae: 1.5365\n",
      "Epoch 609/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0870 - mae: 0.2356 - val_loss: 2.7683 - val_mae: 1.5042\n",
      "Epoch 610/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0944 - mae: 0.2429 - val_loss: 2.7575 - val_mae: 1.5006\n",
      "Epoch 611/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0931 - mae: 0.2383 - val_loss: 2.7879 - val_mae: 1.5107\n",
      "Epoch 612/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0884 - mae: 0.2333 - val_loss: 2.8405 - val_mae: 1.5281\n",
      "Epoch 613/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0855 - mae: 0.2329 - val_loss: 2.9251 - val_mae: 1.5556\n",
      "Epoch 614/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0829 - mae: 0.2332 - val_loss: 3.0161 - val_mae: 1.5846\n",
      "Epoch 615/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0867 - mae: 0.2419 - val_loss: 3.0650 - val_mae: 1.6000\n",
      "Epoch 616/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0840 - mae: 0.2361 - val_loss: 3.0208 - val_mae: 1.5861\n",
      "Epoch 617/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0829 - mae: 0.2382 - val_loss: 2.9977 - val_mae: 1.5787\n",
      "Epoch 618/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0840 - mae: 0.2375 - val_loss: 3.0588 - val_mae: 1.5980\n",
      "Epoch 619/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0828 - mae: 0.2397 - val_loss: 3.1105 - val_mae: 1.6142\n",
      "Epoch 620/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0818 - mae: 0.2394 - val_loss: 3.1676 - val_mae: 1.6318\n",
      "Epoch 621/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0816 - mae: 0.2398 - val_loss: 3.2537 - val_mae: 1.6580\n",
      "Epoch 622/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0901 - mae: 0.2428 - val_loss: 3.2752 - val_mae: 1.6645\n",
      "Epoch 623/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0974 - mae: 0.2522 - val_loss: 3.2389 - val_mae: 1.6535\n",
      "Epoch 624/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0911 - mae: 0.2462 - val_loss: 3.1593 - val_mae: 1.6293\n",
      "Epoch 625/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0836 - mae: 0.2481 - val_loss: 3.0636 - val_mae: 1.5995\n",
      "Epoch 626/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0860 - mae: 0.2480 - val_loss: 3.0356 - val_mae: 1.5907\n",
      "Epoch 627/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0816 - mae: 0.2409 - val_loss: 3.0573 - val_mae: 1.5976\n",
      "Epoch 628/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0792 - mae: 0.2351 - val_loss: 3.0530 - val_mae: 1.5963\n",
      "Epoch 629/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0809 - mae: 0.2326 - val_loss: 3.0204 - val_mae: 1.5861\n",
      "Epoch 630/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0813 - mae: 0.2326 - val_loss: 2.9498 - val_mae: 1.5636\n",
      "Epoch 631/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0801 - mae: 0.2231 - val_loss: 2.8720 - val_mae: 1.5385\n",
      "Epoch 632/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0900 - mae: 0.2395 - val_loss: 2.8635 - val_mae: 1.5357\n",
      "Epoch 633/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0921 - mae: 0.2451 - val_loss: 2.9560 - val_mae: 1.5656\n",
      "Epoch 634/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0834 - mae: 0.2320 - val_loss: 3.0672 - val_mae: 1.6008\n",
      "Epoch 635/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0786 - mae: 0.2316 - val_loss: 3.1107 - val_mae: 1.6143\n",
      "Epoch 636/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0785 - mae: 0.2338 - val_loss: 3.1167 - val_mae: 1.6162\n",
      "Epoch 637/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0791 - mae: 0.2367 - val_loss: 3.1079 - val_mae: 1.6135\n",
      "Epoch 638/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0799 - mae: 0.2412 - val_loss: 3.1029 - val_mae: 1.6119\n",
      "Epoch 639/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0814 - mae: 0.2463 - val_loss: 3.0849 - val_mae: 1.6063\n",
      "Epoch 640/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0826 - mae: 0.2479 - val_loss: 3.0292 - val_mae: 1.5889\n",
      "Epoch 641/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0820 - mae: 0.2465 - val_loss: 2.9855 - val_mae: 1.5751\n",
      "Epoch 642/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0818 - mae: 0.2425 - val_loss: 2.9301 - val_mae: 1.5573\n",
      "Epoch 643/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0825 - mae: 0.2403 - val_loss: 2.8658 - val_mae: 1.5365\n",
      "Epoch 644/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0801 - mae: 0.2368 - val_loss: 2.8234 - val_mae: 1.5227\n",
      "Epoch 645/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0778 - mae: 0.2335 - val_loss: 2.7598 - val_mae: 1.5016\n",
      "Epoch 646/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0788 - mae: 0.2348 - val_loss: 2.7153 - val_mae: 1.4867\n",
      "Epoch 647/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0788 - mae: 0.2328 - val_loss: 2.7465 - val_mae: 1.4972\n",
      "Epoch 648/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0783 - mae: 0.2320 - val_loss: 2.8023 - val_mae: 1.5158\n",
      "Epoch 649/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0796 - mae: 0.2344 - val_loss: 2.8474 - val_mae: 1.5307\n",
      "Epoch 650/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0800 - mae: 0.2358 - val_loss: 2.8859 - val_mae: 1.5432\n",
      "Epoch 651/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0790 - mae: 0.2322 - val_loss: 2.9611 - val_mae: 1.5674\n",
      "Epoch 652/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0787 - mae: 0.2313 - val_loss: 3.0046 - val_mae: 1.5812\n",
      "Epoch 653/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0764 - mae: 0.2242 - val_loss: 2.9939 - val_mae: 1.5778\n",
      "Epoch 654/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0782 - mae: 0.2274 - val_loss: 3.0576 - val_mae: 1.5979\n",
      "Epoch 655/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0783 - mae: 0.2284 - val_loss: 3.1435 - val_mae: 1.6246\n",
      "Epoch 656/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0770 - mae: 0.2274 - val_loss: 3.2113 - val_mae: 1.6454\n",
      "Epoch 657/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0804 - mae: 0.2338 - val_loss: 3.2360 - val_mae: 1.6529\n",
      "Epoch 658/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0865 - mae: 0.2388 - val_loss: 3.1322 - val_mae: 1.6212\n",
      "Epoch 659/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0814 - mae: 0.2350 - val_loss: 2.9887 - val_mae: 1.5762\n",
      "Epoch 660/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0757 - mae: 0.2304 - val_loss: 2.9035 - val_mae: 1.5489\n",
      "Epoch 661/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0741 - mae: 0.2280 - val_loss: 2.8495 - val_mae: 1.5313\n",
      "Epoch 662/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0751 - mae: 0.2301 - val_loss: 2.8441 - val_mae: 1.5295\n",
      "Epoch 663/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0760 - mae: 0.2310 - val_loss: 2.8617 - val_mae: 1.5353\n",
      "Epoch 664/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0784 - mae: 0.2327 - val_loss: 2.8223 - val_mae: 1.5224\n",
      "Epoch 665/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0769 - mae: 0.2343 - val_loss: 2.7701 - val_mae: 1.5051\n",
      "Epoch 666/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0759 - mae: 0.2354 - val_loss: 2.7472 - val_mae: 1.4974\n",
      "Epoch 667/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0758 - mae: 0.2356 - val_loss: 2.7309 - val_mae: 1.4920\n",
      "Epoch 668/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0762 - mae: 0.2361 - val_loss: 2.7303 - val_mae: 1.4918\n",
      "Epoch 669/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0758 - mae: 0.2355 - val_loss: 2.7697 - val_mae: 1.5050\n",
      "Epoch 670/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0758 - mae: 0.2351 - val_loss: 2.7704 - val_mae: 1.5052\n",
      "Epoch 671/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0740 - mae: 0.2322 - val_loss: 2.7188 - val_mae: 1.4879\n",
      "Epoch 672/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0782 - mae: 0.2340 - val_loss: 2.6901 - val_mae: 1.4782\n",
      "Epoch 673/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0823 - mae: 0.2365 - val_loss: 2.7440 - val_mae: 1.4964\n",
      "Epoch 674/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0745 - mae: 0.2281 - val_loss: 2.8603 - val_mae: 1.5349\n",
      "Epoch 675/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0767 - mae: 0.2292 - val_loss: 2.9579 - val_mae: 1.5665\n",
      "Epoch 676/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0861 - mae: 0.2470 - val_loss: 3.0153 - val_mae: 1.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0856 - mae: 0.2443 - val_loss: 3.0470 - val_mae: 1.5947\n",
      "Epoch 678/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0790 - mae: 0.2309 - val_loss: 3.0063 - val_mae: 1.5818\n",
      "Epoch 679/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0729 - mae: 0.2285 - val_loss: 2.9436 - val_mae: 1.5618\n",
      "Epoch 680/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0741 - mae: 0.2277 - val_loss: 2.9391 - val_mae: 1.5603\n",
      "Epoch 681/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0782 - mae: 0.2319 - val_loss: 2.9557 - val_mae: 1.5656\n",
      "Epoch 682/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0786 - mae: 0.2324 - val_loss: 2.9996 - val_mae: 1.5796\n",
      "Epoch 683/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0757 - mae: 0.2306 - val_loss: 3.0482 - val_mae: 1.5950\n",
      "Epoch 684/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0734 - mae: 0.2296 - val_loss: 3.0594 - val_mae: 1.5985\n",
      "Epoch 685/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0731 - mae: 0.2304 - val_loss: 3.0684 - val_mae: 1.6014\n",
      "Epoch 686/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0736 - mae: 0.2320 - val_loss: 3.0588 - val_mae: 1.5984\n",
      "Epoch 687/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0721 - mae: 0.2279 - val_loss: 2.9858 - val_mae: 1.5753\n",
      "Epoch 688/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0718 - mae: 0.2240 - val_loss: 2.9046 - val_mae: 1.5493\n",
      "Epoch 689/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0745 - mae: 0.2258 - val_loss: 2.8635 - val_mae: 1.5360\n",
      "Epoch 690/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0752 - mae: 0.2267 - val_loss: 2.8499 - val_mae: 1.5315\n",
      "Epoch 691/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0737 - mae: 0.2244 - val_loss: 2.8483 - val_mae: 1.5310\n",
      "Epoch 692/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0709 - mae: 0.2220 - val_loss: 2.8426 - val_mae: 1.5292\n",
      "Epoch 693/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0702 - mae: 0.2217 - val_loss: 2.8288 - val_mae: 1.5247\n",
      "Epoch 694/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2239 - val_loss: 2.8053 - val_mae: 1.5170\n",
      "Epoch 695/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0712 - mae: 0.2248 - val_loss: 2.7990 - val_mae: 1.5149\n",
      "Epoch 696/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0702 - mae: 0.2249 - val_loss: 2.8023 - val_mae: 1.5159\n",
      "Epoch 697/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0710 - mae: 0.2255 - val_loss: 2.8492 - val_mae: 1.5314\n",
      "Epoch 698/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0699 - mae: 0.2222 - val_loss: 2.9315 - val_mae: 1.5581\n",
      "Epoch 699/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0723 - mae: 0.2241 - val_loss: 2.9546 - val_mae: 1.5656\n",
      "Epoch 700/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0744 - mae: 0.2268 - val_loss: 2.9692 - val_mae: 1.5703\n",
      "Epoch 701/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0746 - mae: 0.2264 - val_loss: 2.9751 - val_mae: 1.5721\n",
      "Epoch 702/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0727 - mae: 0.2225 - val_loss: 2.9652 - val_mae: 1.5689\n",
      "Epoch 703/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0699 - mae: 0.2198 - val_loss: 2.9635 - val_mae: 1.5684\n",
      "Epoch 704/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0687 - mae: 0.2169 - val_loss: 2.9533 - val_mae: 1.5651\n",
      "Epoch 705/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0702 - mae: 0.2183 - val_loss: 2.9462 - val_mae: 1.5628\n",
      "Epoch 706/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0738 - mae: 0.2236 - val_loss: 3.0108 - val_mae: 1.5834\n",
      "Epoch 707/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0705 - mae: 0.2179 - val_loss: 3.1235 - val_mae: 1.6188\n",
      "Epoch 708/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0751 - mae: 0.2240 - val_loss: 3.1453 - val_mae: 1.6255\n",
      "Epoch 709/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0766 - mae: 0.2252 - val_loss: 3.1025 - val_mae: 1.6122\n",
      "Epoch 710/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0727 - mae: 0.2191 - val_loss: 3.0500 - val_mae: 1.5958\n",
      "Epoch 711/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0704 - mae: 0.2169 - val_loss: 3.0023 - val_mae: 1.5807\n",
      "Epoch 712/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0691 - mae: 0.2147 - val_loss: 3.0295 - val_mae: 1.5893\n",
      "Epoch 713/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0691 - mae: 0.2158 - val_loss: 3.0881 - val_mae: 1.6077\n",
      "Epoch 714/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0756 - mae: 0.2248 - val_loss: 3.0748 - val_mae: 1.6036\n",
      "Epoch 715/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0727 - mae: 0.2215 - val_loss: 2.9435 - val_mae: 1.5620\n",
      "Epoch 716/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0692 - mae: 0.2158 - val_loss: 2.8123 - val_mae: 1.5192\n",
      "Epoch 717/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0833 - mae: 0.2376 - val_loss: 2.7803 - val_mae: 1.5086\n",
      "Epoch 718/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0905 - mae: 0.2499 - val_loss: 2.8207 - val_mae: 1.5220\n",
      "Epoch 719/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0801 - mae: 0.2306 - val_loss: 2.9153 - val_mae: 1.5529\n",
      "Epoch 720/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0696 - mae: 0.2126 - val_loss: 2.9863 - val_mae: 1.5757\n",
      "Epoch 721/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0697 - mae: 0.2142 - val_loss: 2.9782 - val_mae: 1.5732\n",
      "Epoch 722/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0707 - mae: 0.2182 - val_loss: 2.8991 - val_mae: 1.5477\n",
      "Epoch 723/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0678 - mae: 0.2156 - val_loss: 2.7919 - val_mae: 1.5126\n",
      "Epoch 724/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0675 - mae: 0.2158 - val_loss: 2.6983 - val_mae: 1.4812\n",
      "Epoch 725/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0730 - mae: 0.2246 - val_loss: 2.6551 - val_mae: 1.4665\n",
      "Epoch 726/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0770 - mae: 0.2315 - val_loss: 2.6592 - val_mae: 1.4679\n",
      "Epoch 727/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0752 - mae: 0.2290 - val_loss: 2.6958 - val_mae: 1.4803\n",
      "Epoch 728/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0695 - mae: 0.2228 - val_loss: 2.7858 - val_mae: 1.5105\n",
      "Epoch 729/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0699 - mae: 0.2226 - val_loss: 2.8717 - val_mae: 1.5388\n",
      "Epoch 730/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0851 - mae: 0.2452 - val_loss: 2.8669 - val_mae: 1.5373\n",
      "Epoch 731/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0884 - mae: 0.2486 - val_loss: 2.7957 - val_mae: 1.5138\n",
      "Epoch 732/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0756 - mae: 0.2311 - val_loss: 2.7162 - val_mae: 1.4872\n",
      "Epoch 733/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0703 - mae: 0.2292 - val_loss: 2.6635 - val_mae: 1.4693\n",
      "Epoch 734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0769 - mae: 0.2326 - val_loss: 2.6890 - val_mae: 1.4780\n",
      "Epoch 735/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0783 - mae: 0.2352 - val_loss: 2.7724 - val_mae: 1.5060\n",
      "Epoch 736/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0717 - mae: 0.2248 - val_loss: 2.8552 - val_mae: 1.5333\n",
      "Epoch 737/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0677 - mae: 0.2204 - val_loss: 2.8634 - val_mae: 1.5360\n",
      "Epoch 738/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0677 - mae: 0.2169 - val_loss: 2.8466 - val_mae: 1.5305\n",
      "Epoch 739/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0715 - mae: 0.2226 - val_loss: 2.8574 - val_mae: 1.5341\n",
      "Epoch 740/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0718 - mae: 0.2219 - val_loss: 2.9078 - val_mae: 1.5505\n",
      "Epoch 741/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0677 - mae: 0.2129 - val_loss: 2.9989 - val_mae: 1.5797\n",
      "Epoch 742/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0667 - mae: 0.2088 - val_loss: 3.0362 - val_mae: 1.5915\n",
      "Epoch 743/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2091 - val_loss: 2.9965 - val_mae: 1.5790\n",
      "Epoch 744/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0655 - mae: 0.2026 - val_loss: 2.8911 - val_mae: 1.5452\n",
      "Epoch 745/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0727 - mae: 0.2211 - val_loss: 2.8230 - val_mae: 1.5229\n",
      "Epoch 746/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0778 - mae: 0.2292 - val_loss: 2.8766 - val_mae: 1.5405\n",
      "Epoch 747/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0684 - mae: 0.2117 - val_loss: 2.9850 - val_mae: 1.5755\n",
      "Epoch 748/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0679 - mae: 0.2119 - val_loss: 3.0593 - val_mae: 1.5989\n",
      "Epoch 749/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0772 - mae: 0.2277 - val_loss: 3.0839 - val_mae: 1.6066\n",
      "Epoch 750/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0808 - mae: 0.2333 - val_loss: 2.9867 - val_mae: 1.5759\n",
      "Epoch 751/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0642 - mae: 0.2062 - val_loss: 2.7977 - val_mae: 1.5145\n",
      "Epoch 752/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0814 - mae: 0.2370 - val_loss: 2.6814 - val_mae: 1.4754\n",
      "Epoch 753/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1181 - mae: 0.2928 - val_loss: 2.6963 - val_mae: 1.4805\n",
      "Epoch 754/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1108 - mae: 0.2818 - val_loss: 2.8549 - val_mae: 1.5333\n",
      "Epoch 755/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0744 - mae: 0.2217 - val_loss: 3.0852 - val_mae: 1.6069\n",
      "Epoch 756/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0688 - mae: 0.2122 - val_loss: 3.2553 - val_mae: 1.6591\n",
      "Epoch 757/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0901 - mae: 0.2423 - val_loss: 3.2561 - val_mae: 1.6594\n",
      "Epoch 758/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0861 - mae: 0.2355 - val_loss: 3.1695 - val_mae: 1.6329\n",
      "Epoch 759/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0697 - mae: 0.2103 - val_loss: 3.0499 - val_mae: 1.5957\n",
      "Epoch 760/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0677 - mae: 0.2116 - val_loss: 2.9224 - val_mae: 1.5551\n",
      "Epoch 761/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0748 - mae: 0.2252 - val_loss: 2.8952 - val_mae: 1.5464\n",
      "Epoch 762/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0732 - mae: 0.2211 - val_loss: 2.9390 - val_mae: 1.5605\n",
      "Epoch 763/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0664 - mae: 0.2125 - val_loss: 2.9605 - val_mae: 1.5674\n",
      "Epoch 764/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0644 - mae: 0.2122 - val_loss: 2.9064 - val_mae: 1.5500\n",
      "Epoch 765/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0648 - mae: 0.2154 - val_loss: 2.8323 - val_mae: 1.5260\n",
      "Epoch 766/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0662 - mae: 0.2158 - val_loss: 2.7573 - val_mae: 1.5011\n",
      "Epoch 767/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0715 - mae: 0.2251 - val_loss: 2.6845 - val_mae: 1.4767\n",
      "Epoch 768/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0734 - mae: 0.2274 - val_loss: 2.6357 - val_mae: 1.4600\n",
      "Epoch 769/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0722 - mae: 0.2247 - val_loss: 2.5993 - val_mae: 1.4475\n",
      "Epoch 770/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0698 - mae: 0.2203 - val_loss: 2.5694 - val_mae: 1.4371\n",
      "Epoch 771/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0697 - mae: 0.2180 - val_loss: 2.5770 - val_mae: 1.4397\n",
      "Epoch 772/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0687 - mae: 0.2156 - val_loss: 2.6577 - val_mae: 1.4675\n",
      "Epoch 773/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.2149 - val_loss: 2.7685 - val_mae: 1.5049\n",
      "Epoch 774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0695 - mae: 0.2197 - val_loss: 2.8228 - val_mae: 1.5229\n",
      "Epoch 775/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0684 - mae: 0.2177 - val_loss: 2.8245 - val_mae: 1.5234\n",
      "Epoch 776/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0645 - mae: 0.2118 - val_loss: 2.8439 - val_mae: 1.5298\n",
      "Epoch 777/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.2074 - val_loss: 2.9000 - val_mae: 1.5480\n",
      "Epoch 778/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0631 - mae: 0.2061 - val_loss: 2.9499 - val_mae: 1.5641\n",
      "Epoch 779/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0632 - mae: 0.2057 - val_loss: 2.9708 - val_mae: 1.5708\n",
      "Epoch 780/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0633 - mae: 0.2050 - val_loss: 2.9701 - val_mae: 1.5705\n",
      "Epoch 781/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0639 - mae: 0.2055 - val_loss: 2.9902 - val_mae: 1.5770\n",
      "Epoch 782/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0636 - mae: 0.2014 - val_loss: 3.0235 - val_mae: 1.5876\n",
      "Epoch 783/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0651 - mae: 0.2042 - val_loss: 2.9867 - val_mae: 1.5759\n",
      "Epoch 784/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2024 - val_loss: 2.8894 - val_mae: 1.5447\n",
      "Epoch 785/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0634 - mae: 0.2006 - val_loss: 2.8026 - val_mae: 1.5163\n",
      "Epoch 786/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0644 - mae: 0.2045 - val_loss: 2.7718 - val_mae: 1.5061\n",
      "Epoch 787/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0646 - mae: 0.2044 - val_loss: 2.7571 - val_mae: 1.5012\n",
      "Epoch 788/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0642 - mae: 0.2033 - val_loss: 2.7293 - val_mae: 1.4919\n",
      "Epoch 789/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2035 - val_loss: 2.7283 - val_mae: 1.4915\n",
      "Epoch 790/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0641 - mae: 0.2047 - val_loss: 2.7584 - val_mae: 1.5016\n",
      "Epoch 791/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0640 - mae: 0.2052 - val_loss: 2.8112 - val_mae: 1.5192\n",
      "Epoch 792/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0655 - mae: 0.2082 - val_loss: 2.8551 - val_mae: 1.5336\n",
      "Epoch 793/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0650 - mae: 0.2069 - val_loss: 2.8499 - val_mae: 1.5318\n",
      "Epoch 794/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0619 - mae: 0.2018 - val_loss: 2.7983 - val_mae: 1.5148\n",
      "Epoch 795/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0658 - mae: 0.2115 - val_loss: 2.7198 - val_mae: 1.4886\n",
      "Epoch 796/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0817 - mae: 0.2414 - val_loss: 2.7199 - val_mae: 1.4886\n",
      "Epoch 797/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0797 - mae: 0.2378 - val_loss: 2.8434 - val_mae: 1.5297\n",
      "Epoch 798/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0619 - mae: 0.1985 - val_loss: 3.0228 - val_mae: 1.5876\n",
      "Epoch 799/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0759 - mae: 0.2245 - val_loss: 3.1701 - val_mae: 1.6336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1178 - mae: 0.2873 - val_loss: 3.1198 - val_mae: 1.6180\n",
      "Epoch 801/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0910 - mae: 0.2505 - val_loss: 2.8699 - val_mae: 1.5384\n",
      "Epoch 802/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.1981 - val_loss: 2.6094 - val_mae: 1.4510\n",
      "Epoch 803/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1284 - mae: 0.3067 - val_loss: 2.4618 - val_mae: 1.3990\n",
      "Epoch 804/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2031 - mae: 0.3901 - val_loss: 2.4933 - val_mae: 1.4102\n",
      "Epoch 805/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1880 - mae: 0.3768 - val_loss: 2.7138 - val_mae: 1.4865\n",
      "Epoch 806/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1058 - mae: 0.2787 - val_loss: 3.0102 - val_mae: 1.5834\n",
      "Epoch 807/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0637 - mae: 0.1975 - val_loss: 3.2380 - val_mae: 1.6540\n",
      "Epoch 808/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0964 - mae: 0.2571 - val_loss: 3.3160 - val_mae: 1.6774\n",
      "Epoch 809/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1214 - mae: 0.2905 - val_loss: 3.2233 - val_mae: 1.6495\n",
      "Epoch 810/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0987 - mae: 0.2587 - val_loss: 3.0407 - val_mae: 1.5930\n",
      "Epoch 811/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0698 - mae: 0.2119 - val_loss: 2.8777 - val_mae: 1.5408\n",
      "Epoch 812/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.2034 - val_loss: 2.8045 - val_mae: 1.5168\n",
      "Epoch 813/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0676 - mae: 0.2161 - val_loss: 2.8058 - val_mae: 1.5172\n",
      "Epoch 814/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0658 - mae: 0.2135 - val_loss: 2.8686 - val_mae: 1.5378\n",
      "Epoch 815/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0626 - mae: 0.2063 - val_loss: 2.9266 - val_mae: 1.5566\n",
      "Epoch 816/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0622 - mae: 0.2056 - val_loss: 2.9274 - val_mae: 1.5569\n",
      "Epoch 817/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0629 - mae: 0.2079 - val_loss: 2.9581 - val_mae: 1.5667\n",
      "Epoch 818/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.2105 - val_loss: 2.9850 - val_mae: 1.5753\n",
      "Epoch 819/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.2118 - val_loss: 2.9457 - val_mae: 1.5627\n",
      "Epoch 820/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0638 - mae: 0.2091 - val_loss: 2.8613 - val_mae: 1.5355\n",
      "Epoch 821/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0619 - mae: 0.2072 - val_loss: 2.7632 - val_mae: 1.5031\n",
      "Epoch 822/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0651 - mae: 0.2152 - val_loss: 2.7409 - val_mae: 1.4956\n",
      "Epoch 823/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0665 - mae: 0.2161 - val_loss: 2.7807 - val_mae: 1.5089\n",
      "Epoch 824/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0634 - mae: 0.2106 - val_loss: 2.8540 - val_mae: 1.5331\n",
      "Epoch 825/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0613 - mae: 0.2049 - val_loss: 2.9295 - val_mae: 1.5576\n",
      "Epoch 826/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0621 - mae: 0.2034 - val_loss: 2.9584 - val_mae: 1.5668\n",
      "Epoch 827/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0609 - mae: 0.2000 - val_loss: 2.9175 - val_mae: 1.5537\n",
      "Epoch 828/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2100 - val_loss: 2.8707 - val_mae: 1.5385\n",
      "Epoch 829/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0745 - mae: 0.2292 - val_loss: 2.9463 - val_mae: 1.5629\n",
      "Epoch 830/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0683 - mae: 0.2165 - val_loss: 3.1026 - val_mae: 1.6122\n",
      "Epoch 831/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0647 - mae: 0.2007 - val_loss: 3.1832 - val_mae: 1.6371\n",
      "Epoch 832/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0679 - mae: 0.2026 - val_loss: 3.1753 - val_mae: 1.6347\n",
      "Epoch 833/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2006 - val_loss: 3.0812 - val_mae: 1.6056\n",
      "Epoch 834/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0641 - mae: 0.2015 - val_loss: 2.9741 - val_mae: 1.5718\n",
      "Epoch 835/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0631 - mae: 0.2064 - val_loss: 2.9427 - val_mae: 1.5618\n",
      "Epoch 836/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.2058 - val_loss: 2.9513 - val_mae: 1.5646\n",
      "Epoch 837/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.2013 - val_loss: 2.9777 - val_mae: 1.5730\n",
      "Epoch 838/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0632 - mae: 0.2032 - val_loss: 2.9673 - val_mae: 1.5697\n",
      "Epoch 839/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.2058 - val_loss: 2.9418 - val_mae: 1.5615\n",
      "Epoch 840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0619 - mae: 0.2014 - val_loss: 2.8934 - val_mae: 1.5459\n",
      "Epoch 841/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0602 - mae: 0.1987 - val_loss: 2.8016 - val_mae: 1.5159\n",
      "Epoch 842/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0634 - mae: 0.2082 - val_loss: 2.7400 - val_mae: 1.4953\n",
      "Epoch 843/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0692 - mae: 0.2220 - val_loss: 2.7235 - val_mae: 1.4898\n",
      "Epoch 844/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0689 - mae: 0.2220 - val_loss: 2.7858 - val_mae: 1.5106\n",
      "Epoch 845/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0610 - mae: 0.2038 - val_loss: 2.9199 - val_mae: 1.5545\n",
      "Epoch 846/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0641 - mae: 0.2044 - val_loss: 3.0059 - val_mae: 1.5820\n",
      "Epoch 847/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0749 - mae: 0.2209 - val_loss: 3.0218 - val_mae: 1.5870\n",
      "Epoch 848/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0772 - mae: 0.2252 - val_loss: 3.0028 - val_mae: 1.5810\n",
      "Epoch 849/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0714 - mae: 0.2144 - val_loss: 2.9656 - val_mae: 1.5691\n",
      "Epoch 850/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2062 - val_loss: 2.9207 - val_mae: 1.5547\n",
      "Epoch 851/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0599 - mae: 0.2007 - val_loss: 2.8024 - val_mae: 1.5161\n",
      "Epoch 852/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.2130 - val_loss: 2.6888 - val_mae: 1.4780\n",
      "Epoch 853/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0812 - mae: 0.2425 - val_loss: 2.6844 - val_mae: 1.4765\n",
      "Epoch 854/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0789 - mae: 0.2387 - val_loss: 2.7996 - val_mae: 1.5151\n",
      "Epoch 855/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.2116 - val_loss: 2.9528 - val_mae: 1.5651\n",
      "Epoch 856/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.2038 - val_loss: 3.0639 - val_mae: 1.6003\n",
      "Epoch 857/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0770 - mae: 0.2226 - val_loss: 3.0675 - val_mae: 1.6014\n",
      "Epoch 858/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0703 - mae: 0.2093 - val_loss: 2.9267 - val_mae: 1.5567\n",
      "Epoch 859/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.1964 - val_loss: 2.7613 - val_mae: 1.5024\n",
      "Epoch 860/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0771 - mae: 0.2377 - val_loss: 2.6569 - val_mae: 1.4672\n",
      "Epoch 861/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1027 - mae: 0.2771 - val_loss: 2.6380 - val_mae: 1.4607\n",
      "Epoch 862/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0967 - mae: 0.2688 - val_loss: 2.7640 - val_mae: 1.5034\n",
      "Epoch 863/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0651 - mae: 0.2137 - val_loss: 2.9604 - val_mae: 1.5676\n",
      "Epoch 864/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2129 - val_loss: 3.0207 - val_mae: 1.5868\n",
      "Epoch 865/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0926 - mae: 0.2533 - val_loss: 2.9205 - val_mae: 1.5548\n",
      "Epoch 866/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0786 - mae: 0.2284 - val_loss: 2.7678 - val_mae: 1.5047\n",
      "Epoch 867/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0615 - mae: 0.2072 - val_loss: 2.6488 - val_mae: 1.4645\n",
      "Epoch 868/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0684 - mae: 0.2203 - val_loss: 2.6389 - val_mae: 1.4611\n",
      "Epoch 869/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0728 - mae: 0.2291 - val_loss: 2.7391 - val_mae: 1.4951\n",
      "Epoch 870/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0649 - mae: 0.2168 - val_loss: 2.8652 - val_mae: 1.5368\n",
      "Epoch 871/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0611 - mae: 0.2043 - val_loss: 2.9476 - val_mae: 1.5634\n",
      "Epoch 872/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0629 - mae: 0.2072 - val_loss: 2.9604 - val_mae: 1.5675\n",
      "Epoch 873/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.2070 - val_loss: 2.8906 - val_mae: 1.5450\n",
      "Epoch 874/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0605 - mae: 0.2043 - val_loss: 2.7970 - val_mae: 1.5143\n",
      "Epoch 875/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2206 - val_loss: 2.7592 - val_mae: 1.5018\n",
      "Epoch 876/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0738 - mae: 0.2308 - val_loss: 2.7759 - val_mae: 1.5073\n",
      "Epoch 877/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0693 - mae: 0.2232 - val_loss: 2.8386 - val_mae: 1.5281\n",
      "Epoch 878/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0605 - mae: 0.2056 - val_loss: 2.9472 - val_mae: 1.5633\n",
      "Epoch 879/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0636 - mae: 0.2039 - val_loss: 3.0215 - val_mae: 1.5870\n",
      "Epoch 880/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0740 - mae: 0.2172 - val_loss: 2.9779 - val_mae: 1.5732\n",
      "Epoch 881/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0699 - mae: 0.2114 - val_loss: 2.8735 - val_mae: 1.5396\n",
      "Epoch 882/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0601 - mae: 0.1976 - val_loss: 2.7362 - val_mae: 1.4942\n",
      "Epoch 883/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0611 - mae: 0.2046 - val_loss: 2.6233 - val_mae: 1.4558\n",
      "Epoch 884/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0688 - mae: 0.2210 - val_loss: 2.5793 - val_mae: 1.4406\n",
      "Epoch 885/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0706 - mae: 0.2233 - val_loss: 2.5989 - val_mae: 1.4475\n",
      "Epoch 886/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2047 - val_loss: 2.6902 - val_mae: 1.4788\n",
      "Epoch 887/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0651 - mae: 0.2070 - val_loss: 2.7371 - val_mae: 1.4947\n",
      "Epoch 888/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0690 - mae: 0.2127 - val_loss: 2.7572 - val_mae: 1.5014\n",
      "Epoch 889/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0687 - mae: 0.2119 - val_loss: 2.7537 - val_mae: 1.5002\n",
      "Epoch 890/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0643 - mae: 0.2029 - val_loss: 2.7102 - val_mae: 1.4855\n",
      "Epoch 891/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0608 - mae: 0.1991 - val_loss: 2.7099 - val_mae: 1.4854\n",
      "Epoch 892/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0622 - mae: 0.2048 - val_loss: 2.7297 - val_mae: 1.4920\n",
      "Epoch 893/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0630 - mae: 0.2085 - val_loss: 2.8028 - val_mae: 1.5163\n",
      "Epoch 894/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.2019 - val_loss: 2.9083 - val_mae: 1.5508\n",
      "Epoch 895/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - mae: 0.1971 - val_loss: 3.0006 - val_mae: 1.5804\n",
      "Epoch 896/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0605 - mae: 0.1941 - val_loss: 3.0461 - val_mae: 1.5947\n",
      "Epoch 897/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0611 - mae: 0.1934 - val_loss: 3.0410 - val_mae: 1.5931\n",
      "Epoch 898/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0608 - mae: 0.1949 - val_loss: 3.0088 - val_mae: 1.5829\n",
      "Epoch 899/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0620 - mae: 0.2001 - val_loss: 2.9839 - val_mae: 1.5750\n",
      "Epoch 900/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.2067 - val_loss: 2.9700 - val_mae: 1.5706\n",
      "Epoch 901/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0637 - mae: 0.2079 - val_loss: 2.9899 - val_mae: 1.5769\n",
      "Epoch 902/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0617 - mae: 0.2002 - val_loss: 3.0241 - val_mae: 1.5878\n",
      "Epoch 903/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0598 - mae: 0.1930 - val_loss: 3.0704 - val_mae: 1.6024\n",
      "Epoch 904/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.1959 - val_loss: 3.1394 - val_mae: 1.6238\n",
      "Epoch 905/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0794 - mae: 0.2247 - val_loss: 3.1359 - val_mae: 1.6228\n",
      "Epoch 906/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0814 - mae: 0.2292 - val_loss: 2.9922 - val_mae: 1.5777\n",
      "Epoch 907/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0633 - mae: 0.2006 - val_loss: 2.8179 - val_mae: 1.5213\n",
      "Epoch 908/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.2094 - val_loss: 2.7396 - val_mae: 1.4953\n",
      "Epoch 909/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0704 - mae: 0.2265 - val_loss: 2.7477 - val_mae: 1.4980\n",
      "Epoch 910/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0661 - mae: 0.2174 - val_loss: 2.8223 - val_mae: 1.5228\n",
      "Epoch 911/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.1993 - val_loss: 2.9076 - val_mae: 1.5506\n",
      "Epoch 912/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0610 - mae: 0.1977 - val_loss: 2.9311 - val_mae: 1.5582\n",
      "Epoch 913/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.1985 - val_loss: 2.8824 - val_mae: 1.5424\n",
      "Epoch 914/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0599 - mae: 0.1978 - val_loss: 2.8245 - val_mae: 1.5235\n",
      "Epoch 915/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0589 - mae: 0.1992 - val_loss: 2.7990 - val_mae: 1.5150\n",
      "Epoch 916/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0604 - mae: 0.2035 - val_loss: 2.8024 - val_mae: 1.5161\n",
      "Epoch 917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2032 - val_loss: 2.8439 - val_mae: 1.5298\n",
      "Epoch 918/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0587 - mae: 0.1989 - val_loss: 2.8953 - val_mae: 1.5466\n",
      "Epoch 919/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - mae: 0.1971 - val_loss: 2.9012 - val_mae: 1.5485\n",
      "Epoch 920/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0599 - mae: 0.1977 - val_loss: 2.8786 - val_mae: 1.5411\n",
      "Epoch 921/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0600 - mae: 0.1984 - val_loss: 2.8135 - val_mae: 1.5198\n",
      "Epoch 922/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0597 - mae: 0.2040 - val_loss: 2.7412 - val_mae: 1.4958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0608 - mae: 0.2055 - val_loss: 2.7721 - val_mae: 1.5061\n",
      "Epoch 924/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0591 - mae: 0.2010 - val_loss: 2.8464 - val_mae: 1.5307\n",
      "Epoch 925/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.1990 - val_loss: 2.8608 - val_mae: 1.5354\n",
      "Epoch 926/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0598 - mae: 0.1979 - val_loss: 2.8623 - val_mae: 1.5358\n",
      "Epoch 927/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0584 - mae: 0.1978 - val_loss: 2.8607 - val_mae: 1.5353\n",
      "Epoch 928/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0603 - mae: 0.2038 - val_loss: 2.8445 - val_mae: 1.5300\n",
      "Epoch 929/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0635 - mae: 0.2124 - val_loss: 2.9077 - val_mae: 1.5506\n",
      "Epoch 930/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0619 - mae: 0.2047 - val_loss: 2.9559 - val_mae: 1.5661\n",
      "Epoch 931/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0590 - mae: 0.1946 - val_loss: 2.9306 - val_mae: 1.5580\n",
      "Epoch 932/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0603 - mae: 0.1991 - val_loss: 2.9579 - val_mae: 1.5667\n",
      "Epoch 933/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0602 - mae: 0.1971 - val_loss: 2.9886 - val_mae: 1.5766\n",
      "Epoch 934/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0595 - mae: 0.1926 - val_loss: 2.9405 - val_mae: 1.5612\n",
      "Epoch 935/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0589 - mae: 0.1935 - val_loss: 2.8777 - val_mae: 1.5409\n",
      "Epoch 936/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1954 - val_loss: 2.8196 - val_mae: 1.5219\n",
      "Epoch 937/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0591 - mae: 0.1976 - val_loss: 2.7838 - val_mae: 1.5101\n",
      "Epoch 938/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0593 - mae: 0.1998 - val_loss: 2.8043 - val_mae: 1.5169\n",
      "Epoch 939/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0585 - mae: 0.1963 - val_loss: 2.8423 - val_mae: 1.5294\n",
      "Epoch 940/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0590 - mae: 0.1960 - val_loss: 2.8514 - val_mae: 1.5324\n",
      "Epoch 941/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0596 - mae: 0.1966 - val_loss: 2.8525 - val_mae: 1.5327\n",
      "Epoch 942/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.1964 - val_loss: 2.8613 - val_mae: 1.5355\n",
      "Epoch 943/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1962 - val_loss: 2.8968 - val_mae: 1.5471\n",
      "Epoch 944/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0602 - mae: 0.1969 - val_loss: 2.9139 - val_mae: 1.5526\n",
      "Epoch 945/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0612 - mae: 0.1976 - val_loss: 2.9054 - val_mae: 1.5499\n",
      "Epoch 946/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0601 - mae: 0.1962 - val_loss: 2.9193 - val_mae: 1.5544\n",
      "Epoch 947/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1943 - val_loss: 2.9047 - val_mae: 1.5496\n",
      "Epoch 948/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1968 - val_loss: 2.8757 - val_mae: 1.5402\n",
      "Epoch 949/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0642 - mae: 0.2146 - val_loss: 2.9155 - val_mae: 1.5530\n",
      "Epoch 950/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0662 - mae: 0.2186 - val_loss: 3.0260 - val_mae: 1.5883\n",
      "Epoch 951/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0626 - mae: 0.2065 - val_loss: 3.1298 - val_mae: 1.6207\n",
      "Epoch 952/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0623 - mae: 0.1955 - val_loss: 3.1313 - val_mae: 1.6211\n",
      "Epoch 953/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0619 - mae: 0.1946 - val_loss: 3.0659 - val_mae: 1.6008\n",
      "Epoch 954/5000\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0619 - mae: 0.2022 - val_loss: 2.9960 - val_mae: 1.5788\n",
      "Epoch 955/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0639 - mae: 0.2112 - val_loss: 2.9617 - val_mae: 1.5679\n",
      "Epoch 956/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0633 - mae: 0.2106 - val_loss: 2.9946 - val_mae: 1.5784\n",
      "Epoch 957/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.1998 - val_loss: 3.0311 - val_mae: 1.5899\n",
      "Epoch 958/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.1947 - val_loss: 3.0385 - val_mae: 1.5923\n",
      "Epoch 959/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0612 - mae: 0.1951 - val_loss: 3.0145 - val_mae: 1.5847\n",
      "Epoch 960/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0613 - mae: 0.1967 - val_loss: 2.9313 - val_mae: 1.5582\n",
      "Epoch 961/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0604 - mae: 0.2007 - val_loss: 2.8849 - val_mae: 1.5432\n",
      "Epoch 962/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1989 - val_loss: 2.9000 - val_mae: 1.5481\n",
      "Epoch 963/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1980 - val_loss: 2.9194 - val_mae: 1.5544\n",
      "Epoch 964/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0618 - mae: 0.2007 - val_loss: 2.9193 - val_mae: 1.5544\n",
      "Epoch 965/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0612 - mae: 0.1995 - val_loss: 2.8454 - val_mae: 1.5303\n",
      "Epoch 966/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.2004 - val_loss: 2.7898 - val_mae: 1.5120\n",
      "Epoch 967/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.2006 - val_loss: 2.7975 - val_mae: 1.5146\n",
      "Epoch 968/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.1975 - val_loss: 2.8218 - val_mae: 1.5227\n",
      "Epoch 969/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0591 - mae: 0.1953 - val_loss: 2.8113 - val_mae: 1.5193\n",
      "Epoch 970/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1946 - val_loss: 2.7739 - val_mae: 1.5069\n",
      "Epoch 971/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0581 - mae: 0.1953 - val_loss: 2.7486 - val_mae: 1.4984\n",
      "Epoch 972/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0589 - mae: 0.1979 - val_loss: 2.7231 - val_mae: 1.4899\n",
      "Epoch 973/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0597 - mae: 0.1998 - val_loss: 2.7228 - val_mae: 1.4898\n",
      "Epoch 974/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - mae: 0.1977 - val_loss: 2.7722 - val_mae: 1.5064\n",
      "Epoch 975/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0591 - mae: 0.1932 - val_loss: 2.8282 - val_mae: 1.5249\n",
      "Epoch 976/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0597 - mae: 0.1927 - val_loss: 2.8373 - val_mae: 1.5278\n",
      "Epoch 977/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0595 - mae: 0.1937 - val_loss: 2.8724 - val_mae: 1.5393\n",
      "Epoch 978/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0593 - mae: 0.1923 - val_loss: 2.9627 - val_mae: 1.5684\n",
      "Epoch 979/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.1999 - val_loss: 2.9846 - val_mae: 1.5754\n",
      "Epoch 980/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.1974 - val_loss: 2.8809 - val_mae: 1.5419\n",
      "Epoch 981/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0583 - mae: 0.1933 - val_loss: 2.7832 - val_mae: 1.5098\n",
      "Epoch 982/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - mae: 0.2042 - val_loss: 2.7268 - val_mae: 1.4909\n",
      "Epoch 983/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0644 - mae: 0.2186 - val_loss: 2.6855 - val_mae: 1.4770\n",
      "Epoch 984/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0665 - mae: 0.2216 - val_loss: 2.6981 - val_mae: 1.4813\n",
      "Epoch 985/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0613 - mae: 0.2079 - val_loss: 2.7494 - val_mae: 1.4986\n",
      "Epoch 986/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0592 - mae: 0.2002 - val_loss: 2.7893 - val_mae: 1.5119\n",
      "Epoch 987/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0633 - mae: 0.2037 - val_loss: 2.8169 - val_mae: 1.5211\n",
      "Epoch 988/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2139 - val_loss: 2.8407 - val_mae: 1.5289\n",
      "Epoch 989/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0699 - mae: 0.2162 - val_loss: 2.7986 - val_mae: 1.5150\n",
      "Epoch 990/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0599 - mae: 0.1989 - val_loss: 2.6950 - val_mae: 1.4802\n",
      "Epoch 991/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0641 - mae: 0.2156 - val_loss: 2.6827 - val_mae: 1.4760\n",
      "Epoch 992/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0680 - mae: 0.2249 - val_loss: 2.7718 - val_mae: 1.5060\n",
      "Epoch 993/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0613 - mae: 0.2109 - val_loss: 2.8462 - val_mae: 1.5306\n",
      "Epoch 994/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0582 - mae: 0.1976 - val_loss: 2.8895 - val_mae: 1.5447\n",
      "Epoch 995/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0573 - mae: 0.1942 - val_loss: 2.9107 - val_mae: 1.5515\n",
      "Epoch 996/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0575 - mae: 0.1941 - val_loss: 2.9261 - val_mae: 1.5565\n",
      "Epoch 997/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0577 - mae: 0.1948 - val_loss: 2.9504 - val_mae: 1.5643\n",
      "Epoch 998/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0575 - mae: 0.1906 - val_loss: 3.0274 - val_mae: 1.5888\n",
      "Epoch 999/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0637 - mae: 0.1956 - val_loss: 3.0750 - val_mae: 1.6038\n",
      "Epoch 1000/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0683 - mae: 0.2020 - val_loss: 3.0314 - val_mae: 1.5901\n",
      "Epoch 1001/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0627 - mae: 0.1932 - val_loss: 2.9852 - val_mae: 1.5754\n",
      "Epoch 1002/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1920 - val_loss: 2.9679 - val_mae: 1.5699\n",
      "Epoch 1003/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.1934 - val_loss: 2.9784 - val_mae: 1.5732\n",
      "Epoch 1004/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1969 - val_loss: 3.0215 - val_mae: 1.5869\n",
      "Epoch 1005/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.1936 - val_loss: 3.0609 - val_mae: 1.5993\n",
      "Epoch 1006/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0591 - mae: 0.1915 - val_loss: 3.0405 - val_mae: 1.5928\n",
      "Epoch 1007/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0585 - mae: 0.1937 - val_loss: 2.9669 - val_mae: 1.5695\n",
      "Epoch 1008/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0599 - mae: 0.2047 - val_loss: 2.9187 - val_mae: 1.5540\n",
      "Epoch 1009/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0597 - mae: 0.2056 - val_loss: 2.9153 - val_mae: 1.5529\n",
      "Epoch 1010/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1978 - val_loss: 2.9097 - val_mae: 1.5512\n",
      "Epoch 1011/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1961 - val_loss: 2.8605 - val_mae: 1.5352\n",
      "Epoch 1012/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.1949 - val_loss: 2.7810 - val_mae: 1.5091\n",
      "Epoch 1013/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2002 - val_loss: 2.7381 - val_mae: 1.4948\n",
      "Epoch 1014/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.2017 - val_loss: 2.7837 - val_mae: 1.5100\n",
      "Epoch 1015/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0575 - mae: 0.1935 - val_loss: 2.9001 - val_mae: 1.5482\n",
      "Epoch 1016/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0700 - mae: 0.2144 - val_loss: 2.9045 - val_mae: 1.5497\n",
      "Epoch 1017/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0687 - mae: 0.2127 - val_loss: 2.7953 - val_mae: 1.5139\n",
      "Epoch 1018/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.1984 - val_loss: 2.7469 - val_mae: 1.4977\n",
      "Epoch 1019/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.2036 - val_loss: 2.7802 - val_mae: 1.5088\n",
      "Epoch 1020/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0583 - mae: 0.1998 - val_loss: 2.8058 - val_mae: 1.5173\n",
      "Epoch 1021/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1960 - val_loss: 2.7427 - val_mae: 1.4963\n",
      "Epoch 1022/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0601 - mae: 0.2069 - val_loss: 2.6923 - val_mae: 1.4794\n",
      "Epoch 1023/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0641 - mae: 0.2176 - val_loss: 2.7358 - val_mae: 1.4941\n",
      "Epoch 1024/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.2076 - val_loss: 2.7843 - val_mae: 1.5103\n",
      "Epoch 1025/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0572 - mae: 0.1934 - val_loss: 2.8012 - val_mae: 1.5159\n",
      "Epoch 1026/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1934 - val_loss: 2.8255 - val_mae: 1.5239\n",
      "Epoch 1027/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0583 - mae: 0.1928 - val_loss: 2.8378 - val_mae: 1.5279\n",
      "Epoch 1028/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0567 - mae: 0.1929 - val_loss: 2.7905 - val_mae: 1.5122\n",
      "Epoch 1029/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0593 - mae: 0.2072 - val_loss: 2.7383 - val_mae: 1.4948\n",
      "Epoch 1030/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2237 - val_loss: 2.7617 - val_mae: 1.5026\n",
      "Epoch 1031/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0660 - mae: 0.2225 - val_loss: 2.8624 - val_mae: 1.5358\n",
      "Epoch 1032/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0599 - mae: 0.2058 - val_loss: 2.9516 - val_mae: 1.5647\n",
      "Epoch 1033/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0576 - mae: 0.1928 - val_loss: 2.9284 - val_mae: 1.5573\n",
      "Epoch 1034/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1931 - val_loss: 2.8421 - val_mae: 1.5292\n",
      "Epoch 1035/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0572 - mae: 0.1975 - val_loss: 2.7312 - val_mae: 1.4924\n",
      "Epoch 1036/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0627 - mae: 0.2149 - val_loss: 2.6265 - val_mae: 1.4568\n",
      "Epoch 1037/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0784 - mae: 0.2408 - val_loss: 2.6446 - val_mae: 1.4631\n",
      "Epoch 1038/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0720 - mae: 0.2315 - val_loss: 2.7790 - val_mae: 1.5085\n",
      "Epoch 1039/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0565 - mae: 0.1962 - val_loss: 2.9559 - val_mae: 1.5662\n",
      "Epoch 1040/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0640 - mae: 0.1988 - val_loss: 3.0993 - val_mae: 1.6115\n",
      "Epoch 1041/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0821 - mae: 0.2330 - val_loss: 3.0960 - val_mae: 1.6104\n",
      "Epoch 1042/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0747 - mae: 0.2172 - val_loss: 2.9563 - val_mae: 1.5662\n",
      "Epoch 1043/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1938 - val_loss: 2.8166 - val_mae: 1.5208\n",
      "Epoch 1044/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.2112 - val_loss: 2.7780 - val_mae: 1.5080\n",
      "Epoch 1045/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0645 - mae: 0.2183 - val_loss: 2.8221 - val_mae: 1.5226\n",
      "Epoch 1046/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.2052 - val_loss: 2.9127 - val_mae: 1.5521\n",
      "Epoch 1047/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0562 - mae: 0.1905 - val_loss: 3.0322 - val_mae: 1.5903\n",
      "Epoch 1048/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.1975 - val_loss: 3.0943 - val_mae: 1.6097\n",
      "Epoch 1049/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0703 - mae: 0.2073 - val_loss: 3.0408 - val_mae: 1.5930\n",
      "Epoch 1050/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0626 - mae: 0.1973 - val_loss: 2.9790 - val_mae: 1.5733\n",
      "Epoch 1051/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1925 - val_loss: 2.9512 - val_mae: 1.5644\n",
      "Epoch 1052/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1992 - val_loss: 2.9371 - val_mae: 1.5599\n",
      "Epoch 1053/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0589 - mae: 0.2038 - val_loss: 2.9183 - val_mae: 1.5538\n",
      "Epoch 1054/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0591 - mae: 0.2051 - val_loss: 2.8571 - val_mae: 1.5340\n",
      "Epoch 1055/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.2193 - val_loss: 2.8094 - val_mae: 1.5183\n",
      "Epoch 1056/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0717 - mae: 0.2310 - val_loss: 2.8060 - val_mae: 1.5171\n",
      "Epoch 1057/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0701 - mae: 0.2290 - val_loss: 2.8689 - val_mae: 1.5378\n",
      "Epoch 1058/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.2123 - val_loss: 2.9787 - val_mae: 1.5732\n",
      "Epoch 1059/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mae: 0.1928 - val_loss: 3.0384 - val_mae: 1.5922\n",
      "Epoch 1060/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0628 - mae: 0.1969 - val_loss: 3.0111 - val_mae: 1.5835\n",
      "Epoch 1061/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0610 - mae: 0.1954 - val_loss: 2.9283 - val_mae: 1.5571\n",
      "Epoch 1062/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0566 - mae: 0.1924 - val_loss: 2.8355 - val_mae: 1.5269\n",
      "Epoch 1063/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0585 - mae: 0.2040 - val_loss: 2.7437 - val_mae: 1.4965\n",
      "Epoch 1064/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0692 - mae: 0.2278 - val_loss: 2.6889 - val_mae: 1.4780\n",
      "Epoch 1065/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0772 - mae: 0.2390 - val_loss: 2.7847 - val_mae: 1.5102\n",
      "Epoch 1066/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0594 - mae: 0.2086 - val_loss: 2.9592 - val_mae: 1.5671\n",
      "Epoch 1067/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0693 - mae: 0.2106 - val_loss: 3.0364 - val_mae: 1.5917\n",
      "Epoch 1068/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0886 - mae: 0.2463 - val_loss: 2.9595 - val_mae: 1.5673\n",
      "Epoch 1069/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0743 - mae: 0.2193 - val_loss: 2.7802 - val_mae: 1.5088\n",
      "Epoch 1070/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0555 - mae: 0.1917 - val_loss: 2.6139 - val_mae: 1.4525\n",
      "Epoch 1071/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0743 - mae: 0.2339 - val_loss: 2.5626 - val_mae: 1.4346\n",
      "Epoch 1072/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0853 - mae: 0.2506 - val_loss: 2.7150 - val_mae: 1.4869\n",
      "Epoch 1073/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0598 - mae: 0.2052 - val_loss: 2.9651 - val_mae: 1.5690\n",
      "Epoch 1074/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0662 - mae: 0.2072 - val_loss: 3.1206 - val_mae: 1.6179\n",
      "Epoch 1075/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0882 - mae: 0.2442 - val_loss: 3.0702 - val_mae: 1.6022\n",
      "Epoch 1076/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0727 - mae: 0.2162 - val_loss: 2.8913 - val_mae: 1.5452\n",
      "Epoch 1077/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0582 - mae: 0.1962 - val_loss: 2.7676 - val_mae: 1.5045\n",
      "Epoch 1078/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0654 - mae: 0.2204 - val_loss: 2.7566 - val_mae: 1.5008\n",
      "Epoch 1079/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0715 - mae: 0.2306 - val_loss: 2.7884 - val_mae: 1.5114\n",
      "Epoch 1080/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0690 - mae: 0.2257 - val_loss: 2.8590 - val_mae: 1.5346\n",
      "Epoch 1081/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0609 - mae: 0.2102 - val_loss: 2.9578 - val_mae: 1.5665\n",
      "Epoch 1082/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1910 - val_loss: 3.0396 - val_mae: 1.5925\n",
      "Epoch 1083/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0614 - mae: 0.1923 - val_loss: 3.0359 - val_mae: 1.5914\n",
      "Epoch 1084/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.1970 - val_loss: 2.9605 - val_mae: 1.5675\n",
      "Epoch 1085/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0601 - mae: 0.1924 - val_loss: 2.8768 - val_mae: 1.5405\n",
      "Epoch 1086/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.1925 - val_loss: 2.8568 - val_mae: 1.5340\n",
      "Epoch 1087/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mae: 0.1934 - val_loss: 2.8600 - val_mae: 1.5350\n",
      "Epoch 1088/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.1939 - val_loss: 2.8382 - val_mae: 1.5279\n",
      "Epoch 1089/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1932 - val_loss: 2.7987 - val_mae: 1.5149\n",
      "Epoch 1090/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0583 - mae: 0.1966 - val_loss: 2.7865 - val_mae: 1.5108\n",
      "Epoch 1091/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0578 - mae: 0.1971 - val_loss: 2.8060 - val_mae: 1.5173\n",
      "Epoch 1092/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1960 - val_loss: 2.8069 - val_mae: 1.5176\n",
      "Epoch 1093/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1950 - val_loss: 2.8454 - val_mae: 1.5302\n",
      "Epoch 1094/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mae: 0.1938 - val_loss: 2.8610 - val_mae: 1.5354\n",
      "Epoch 1095/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0581 - mae: 0.1931 - val_loss: 2.8259 - val_mae: 1.5239\n",
      "Epoch 1096/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0571 - mae: 0.1933 - val_loss: 2.7987 - val_mae: 1.5149\n",
      "Epoch 1097/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0567 - mae: 0.1957 - val_loss: 2.7831 - val_mae: 1.5097\n",
      "Epoch 1098/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.2018 - val_loss: 2.7848 - val_mae: 1.5103\n",
      "Epoch 1099/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0595 - mae: 0.2070 - val_loss: 2.8582 - val_mae: 1.5344\n",
      "Epoch 1100/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mae: 0.1987 - val_loss: 2.9499 - val_mae: 1.5641\n",
      "Epoch 1101/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0570 - mae: 0.1910 - val_loss: 3.0078 - val_mae: 1.5826\n",
      "Epoch 1102/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0578 - mae: 0.1898 - val_loss: 3.0439 - val_mae: 1.5939\n",
      "Epoch 1103/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0585 - mae: 0.1895 - val_loss: 3.0393 - val_mae: 1.5924\n",
      "Epoch 1104/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.1919 - val_loss: 2.9965 - val_mae: 1.5789\n",
      "Epoch 1105/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0607 - mae: 0.2067 - val_loss: 2.9991 - val_mae: 1.5797\n",
      "Epoch 1106/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0625 - mae: 0.2105 - val_loss: 3.0397 - val_mae: 1.5925\n",
      "Epoch 1107/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2047 - val_loss: 3.0940 - val_mae: 1.6095\n",
      "Epoch 1108/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1916 - val_loss: 3.2106 - val_mae: 1.6454\n",
      "Epoch 1109/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0707 - mae: 0.2047 - val_loss: 3.1952 - val_mae: 1.6407\n",
      "Epoch 1110/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0681 - mae: 0.2028 - val_loss: 2.9725 - val_mae: 1.5712\n",
      "Epoch 1111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.2041 - val_loss: 2.8167 - val_mae: 1.5207\n",
      "Epoch 1112/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0667 - mae: 0.2222 - val_loss: 2.8159 - val_mae: 1.5205\n",
      "Epoch 1113/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0621 - mae: 0.2148 - val_loss: 2.8922 - val_mae: 1.5455\n",
      "Epoch 1114/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0567 - mae: 0.1941 - val_loss: 2.9700 - val_mae: 1.5706\n",
      "Epoch 1115/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.1902 - val_loss: 2.9733 - val_mae: 1.5717\n",
      "Epoch 1116/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0607 - mae: 0.1919 - val_loss: 2.9080 - val_mae: 1.5507\n",
      "Epoch 1117/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1908 - val_loss: 2.8732 - val_mae: 1.5394\n",
      "Epoch 1118/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0574 - mae: 0.1895 - val_loss: 2.8319 - val_mae: 1.5259\n",
      "Epoch 1119/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1917 - val_loss: 2.7493 - val_mae: 1.4985\n",
      "Epoch 1120/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0597 - mae: 0.2070 - val_loss: 2.6988 - val_mae: 1.4815\n",
      "Epoch 1121/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0670 - mae: 0.2226 - val_loss: 2.6635 - val_mae: 1.4695\n",
      "Epoch 1122/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0746 - mae: 0.2351 - val_loss: 2.6352 - val_mae: 1.4598\n",
      "Epoch 1123/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0802 - mae: 0.2425 - val_loss: 2.7426 - val_mae: 1.4962\n",
      "Epoch 1124/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.2069 - val_loss: 3.0274 - val_mae: 1.5888\n",
      "Epoch 1125/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0745 - mae: 0.2185 - val_loss: 3.2160 - val_mae: 1.6472\n",
      "Epoch 1126/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1110 - mae: 0.2768 - val_loss: 3.1769 - val_mae: 1.6353\n",
      "Epoch 1127/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0908 - mae: 0.2433 - val_loss: 3.0027 - val_mae: 1.5809\n",
      "Epoch 1128/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0589 - mae: 0.1922 - val_loss: 2.7977 - val_mae: 1.5145\n",
      "Epoch 1129/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0671 - mae: 0.2251 - val_loss: 2.7252 - val_mae: 1.4903\n",
      "Epoch 1130/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0750 - mae: 0.2357 - val_loss: 2.8222 - val_mae: 1.5226\n",
      "Epoch 1131/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0604 - mae: 0.2096 - val_loss: 2.9638 - val_mae: 1.5685\n",
      "Epoch 1132/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1906 - val_loss: 3.0996 - val_mae: 1.6113\n",
      "Epoch 1133/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0731 - mae: 0.2123 - val_loss: 3.1857 - val_mae: 1.6379\n",
      "Epoch 1134/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0920 - mae: 0.2472 - val_loss: 3.0933 - val_mae: 1.6094\n",
      "Epoch 1135/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0737 - mae: 0.2156 - val_loss: 2.9101 - val_mae: 1.5513\n",
      "Epoch 1136/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1973 - val_loss: 2.8161 - val_mae: 1.5206\n",
      "Epoch 1137/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0587 - mae: 0.2049 - val_loss: 2.7434 - val_mae: 1.4965\n",
      "Epoch 1138/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.2139 - val_loss: 2.6819 - val_mae: 1.4757\n",
      "Epoch 1139/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.2173 - val_loss: 2.7337 - val_mae: 1.4932\n",
      "Epoch 1140/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0569 - mae: 0.1995 - val_loss: 2.8553 - val_mae: 1.5336\n",
      "Epoch 1141/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0612 - mae: 0.1972 - val_loss: 2.9020 - val_mae: 1.5488\n",
      "Epoch 1142/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0708 - mae: 0.2142 - val_loss: 2.8482 - val_mae: 1.5313\n",
      "Epoch 1143/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - mae: 0.2035 - val_loss: 2.7746 - val_mae: 1.5070\n",
      "Epoch 1144/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0586 - mae: 0.1903 - val_loss: 2.6894 - val_mae: 1.4784\n",
      "Epoch 1145/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.2024 - val_loss: 2.6572 - val_mae: 1.4674\n",
      "Epoch 1146/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0610 - mae: 0.2067 - val_loss: 2.7019 - val_mae: 1.4826\n",
      "Epoch 1147/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1966 - val_loss: 2.7839 - val_mae: 1.5102\n",
      "Epoch 1148/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0600 - mae: 0.1904 - val_loss: 2.8330 - val_mae: 1.5264\n",
      "Epoch 1149/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0627 - mae: 0.1970 - val_loss: 2.8267 - val_mae: 1.5243\n",
      "Epoch 1150/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0600 - mae: 0.1934 - val_loss: 2.8466 - val_mae: 1.5308\n",
      "Epoch 1151/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0591 - mae: 0.1907 - val_loss: 2.8534 - val_mae: 1.5330\n",
      "Epoch 1152/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - mae: 0.1912 - val_loss: 2.8096 - val_mae: 1.5186\n",
      "Epoch 1153/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1896 - val_loss: 2.7673 - val_mae: 1.5046\n",
      "Epoch 1154/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0563 - mae: 0.1925 - val_loss: 2.7141 - val_mae: 1.4867\n",
      "Epoch 1155/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0610 - mae: 0.2098 - val_loss: 2.6942 - val_mae: 1.4800\n",
      "Epoch 1156/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0652 - mae: 0.2186 - val_loss: 2.7883 - val_mae: 1.5115\n",
      "Epoch 1157/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.1987 - val_loss: 2.9457 - val_mae: 1.5628\n",
      "Epoch 1158/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0588 - mae: 0.1877 - val_loss: 3.0987 - val_mae: 1.6112\n",
      "Epoch 1159/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0772 - mae: 0.2225 - val_loss: 3.1369 - val_mae: 1.6230\n",
      "Epoch 1160/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0754 - mae: 0.2186 - val_loss: 2.9918 - val_mae: 1.5775\n",
      "Epoch 1161/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0584 - mae: 0.1880 - val_loss: 2.8152 - val_mae: 1.5203\n",
      "Epoch 1162/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0703 - mae: 0.2259 - val_loss: 2.7705 - val_mae: 1.5055\n",
      "Epoch 1163/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0770 - mae: 0.2385 - val_loss: 2.8383 - val_mae: 1.5280\n",
      "Epoch 1164/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0638 - mae: 0.2097 - val_loss: 2.9513 - val_mae: 1.5647\n",
      "Epoch 1165/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1886 - val_loss: 3.0459 - val_mae: 1.5948\n",
      "Epoch 1166/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.1998 - val_loss: 3.0295 - val_mae: 1.5896\n",
      "Epoch 1167/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0674 - mae: 0.2041 - val_loss: 2.8719 - val_mae: 1.5391\n",
      "Epoch 1168/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0596 - mae: 0.1944 - val_loss: 2.7144 - val_mae: 1.4870\n",
      "Epoch 1169/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.2047 - val_loss: 2.7167 - val_mae: 1.4878\n",
      "Epoch 1170/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0594 - mae: 0.2012 - val_loss: 2.8531 - val_mae: 1.5330\n",
      "Epoch 1171/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.1931 - val_loss: 2.9285 - val_mae: 1.5575\n",
      "Epoch 1172/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0625 - mae: 0.1927 - val_loss: 2.9436 - val_mae: 1.5623\n",
      "Epoch 1173/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.1900 - val_loss: 3.0393 - val_mae: 1.5926\n",
      "Epoch 1174/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.1900 - val_loss: 3.1186 - val_mae: 1.6173\n",
      "Epoch 1175/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.1910 - val_loss: 3.0793 - val_mae: 1.6050\n",
      "Epoch 1176/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0603 - mae: 0.1925 - val_loss: 3.0057 - val_mae: 1.5819\n",
      "Epoch 1177/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0605 - mae: 0.2004 - val_loss: 3.0101 - val_mae: 1.5832\n",
      "Epoch 1178/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1971 - val_loss: 3.0731 - val_mae: 1.6030\n",
      "Epoch 1179/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1893 - val_loss: 3.1227 - val_mae: 1.6185\n",
      "Epoch 1180/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0639 - mae: 0.1912 - val_loss: 3.0581 - val_mae: 1.5983\n",
      "Epoch 1181/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.1870 - val_loss: 2.9374 - val_mae: 1.5600\n",
      "Epoch 1182/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0580 - mae: 0.2001 - val_loss: 2.8764 - val_mae: 1.5402\n",
      "Epoch 1183/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0623 - mae: 0.2119 - val_loss: 2.8137 - val_mae: 1.5197\n",
      "Epoch 1184/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0686 - mae: 0.2246 - val_loss: 2.7807 - val_mae: 1.5088\n",
      "Epoch 1185/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0691 - mae: 0.2267 - val_loss: 2.8568 - val_mae: 1.5339\n",
      "Epoch 1186/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0590 - mae: 0.2046 - val_loss: 2.9448 - val_mae: 1.5624\n",
      "Epoch 1187/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0577 - mae: 0.1891 - val_loss: 2.9226 - val_mae: 1.5553\n",
      "Epoch 1188/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1895 - val_loss: 2.8840 - val_mae: 1.5428\n",
      "Epoch 1189/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0563 - mae: 0.1906 - val_loss: 2.8811 - val_mae: 1.5418\n",
      "Epoch 1190/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1945 - val_loss: 2.9141 - val_mae: 1.5525\n",
      "Epoch 1191/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0558 - mae: 0.1899 - val_loss: 3.0178 - val_mae: 1.5856\n",
      "Epoch 1192/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0631 - mae: 0.1960 - val_loss: 3.0485 - val_mae: 1.5953\n",
      "Epoch 1193/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0626 - mae: 0.1945 - val_loss: 2.9306 - val_mae: 1.5577\n",
      "Epoch 1194/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2006 - val_loss: 2.8283 - val_mae: 1.5244\n",
      "Epoch 1195/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0686 - mae: 0.2252 - val_loss: 2.8480 - val_mae: 1.5309\n",
      "Epoch 1196/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0712 - mae: 0.2286 - val_loss: 2.8989 - val_mae: 1.5474\n",
      "Epoch 1197/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0654 - mae: 0.2208 - val_loss: 2.9599 - val_mae: 1.5671\n",
      "Epoch 1198/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0580 - mae: 0.2022 - val_loss: 3.0894 - val_mae: 1.6080\n",
      "Epoch 1199/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.1896 - val_loss: 3.1518 - val_mae: 1.6274\n",
      "Epoch 1200/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0648 - mae: 0.1935 - val_loss: 3.0042 - val_mae: 1.5813\n",
      "Epoch 1201/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0564 - mae: 0.1887 - val_loss: 2.8057 - val_mae: 1.5171\n",
      "Epoch 1202/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0655 - mae: 0.2187 - val_loss: 2.6945 - val_mae: 1.4799\n",
      "Epoch 1203/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0753 - mae: 0.2372 - val_loss: 2.7194 - val_mae: 1.4883\n",
      "Epoch 1204/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0626 - mae: 0.2114 - val_loss: 2.8637 - val_mae: 1.5362\n",
      "Epoch 1205/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1904 - val_loss: 3.0018 - val_mae: 1.5807\n",
      "Epoch 1206/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0724 - mae: 0.2164 - val_loss: 3.0020 - val_mae: 1.5807\n",
      "Epoch 1207/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0689 - mae: 0.2100 - val_loss: 2.8523 - val_mae: 1.5325\n",
      "Epoch 1208/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.1918 - val_loss: 2.7106 - val_mae: 1.4854\n",
      "Epoch 1209/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2178 - val_loss: 2.6450 - val_mae: 1.4631\n",
      "Epoch 1210/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0776 - mae: 0.2409 - val_loss: 2.6868 - val_mae: 1.4773\n",
      "Epoch 1211/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0684 - mae: 0.2235 - val_loss: 2.8393 - val_mae: 1.5282\n",
      "Epoch 1212/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1964 - val_loss: 2.9412 - val_mae: 1.5613\n",
      "Epoch 1213/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0623 - mae: 0.1930 - val_loss: 2.8867 - val_mae: 1.5437\n",
      "Epoch 1214/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1862 - val_loss: 2.7191 - val_mae: 1.4883\n",
      "Epoch 1215/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0623 - mae: 0.2093 - val_loss: 2.5899 - val_mae: 1.4441\n",
      "Epoch 1216/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0812 - mae: 0.2458 - val_loss: 2.6077 - val_mae: 1.4503\n",
      "Epoch 1217/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0788 - mae: 0.2410 - val_loss: 2.7649 - val_mae: 1.5037\n",
      "Epoch 1218/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0598 - mae: 0.2023 - val_loss: 2.9761 - val_mae: 1.5725\n",
      "Epoch 1219/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0641 - mae: 0.1970 - val_loss: 3.0812 - val_mae: 1.6057\n",
      "Epoch 1220/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0729 - mae: 0.2133 - val_loss: 3.0344 - val_mae: 1.5909\n",
      "Epoch 1221/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0635 - mae: 0.1940 - val_loss: 2.9354 - val_mae: 1.5594\n",
      "Epoch 1222/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1932 - val_loss: 2.8260 - val_mae: 1.5238\n",
      "Epoch 1223/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0666 - mae: 0.2192 - val_loss: 2.7614 - val_mae: 1.5024\n",
      "Epoch 1224/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0751 - mae: 0.2367 - val_loss: 2.8559 - val_mae: 1.5335\n",
      "Epoch 1225/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0594 - mae: 0.2014 - val_loss: 3.0962 - val_mae: 1.6102\n",
      "Epoch 1226/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0649 - mae: 0.1933 - val_loss: 3.2701 - val_mae: 1.6634\n",
      "Epoch 1227/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0886 - mae: 0.2393 - val_loss: 3.3099 - val_mae: 1.6753\n",
      "Epoch 1228/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0908 - mae: 0.2438 - val_loss: 3.2187 - val_mae: 1.6477\n",
      "Epoch 1229/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0701 - mae: 0.2047 - val_loss: 3.0381 - val_mae: 1.5918\n",
      "Epoch 1230/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0570 - mae: 0.1959 - val_loss: 2.8893 - val_mae: 1.5442\n",
      "Epoch 1231/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0662 - mae: 0.2204 - val_loss: 2.7889 - val_mae: 1.5113\n",
      "Epoch 1232/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0762 - mae: 0.2380 - val_loss: 2.7913 - val_mae: 1.5121\n",
      "Epoch 1233/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0699 - mae: 0.2279 - val_loss: 2.8664 - val_mae: 1.5368\n",
      "Epoch 1234/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0576 - mae: 0.2020 - val_loss: 2.9790 - val_mae: 1.5732\n",
      "Epoch 1235/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0564 - mae: 0.1877 - val_loss: 3.1109 - val_mae: 1.6146\n",
      "Epoch 1236/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0681 - mae: 0.2027 - val_loss: 3.1147 - val_mae: 1.6158\n",
      "Epoch 1237/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0646 - mae: 0.1996 - val_loss: 3.0159 - val_mae: 1.5848\n",
      "Epoch 1238/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0565 - mae: 0.1907 - val_loss: 2.9245 - val_mae: 1.5556\n",
      "Epoch 1239/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0606 - mae: 0.2074 - val_loss: 2.8792 - val_mae: 1.5410\n",
      "Epoch 1240/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0644 - mae: 0.2154 - val_loss: 2.8638 - val_mae: 1.5360\n",
      "Epoch 1241/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.2130 - val_loss: 2.8168 - val_mae: 1.5206\n",
      "Epoch 1242/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0634 - mae: 0.2141 - val_loss: 2.8284 - val_mae: 1.5245\n",
      "Epoch 1243/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0595 - mae: 0.2056 - val_loss: 2.9283 - val_mae: 1.5570\n",
      "Epoch 1244/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0573 - mae: 0.1932 - val_loss: 2.9992 - val_mae: 1.5796\n",
      "Epoch 1245/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0613 - mae: 0.1913 - val_loss: 2.9609 - val_mae: 1.5675\n",
      "Epoch 1246/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0600 - mae: 0.1892 - val_loss: 2.8940 - val_mae: 1.5460\n",
      "Epoch 1247/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1902 - val_loss: 2.8566 - val_mae: 1.5338\n",
      "Epoch 1248/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0567 - mae: 0.1915 - val_loss: 2.8699 - val_mae: 1.5381\n",
      "Epoch 1249/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.1904 - val_loss: 2.8733 - val_mae: 1.5392\n",
      "Epoch 1250/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0562 - mae: 0.1914 - val_loss: 2.8235 - val_mae: 1.5229\n",
      "Epoch 1251/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0575 - mae: 0.2008 - val_loss: 2.7901 - val_mae: 1.5119\n",
      "Epoch 1252/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0605 - mae: 0.2090 - val_loss: 2.7276 - val_mae: 1.4910\n",
      "Epoch 1253/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0664 - mae: 0.2215 - val_loss: 2.6962 - val_mae: 1.4804\n",
      "Epoch 1254/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - mae: 0.2222 - val_loss: 2.8007 - val_mae: 1.5154\n",
      "Epoch 1255/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1977 - val_loss: 2.9151 - val_mae: 1.5528\n",
      "Epoch 1256/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0625 - mae: 0.1990 - val_loss: 2.9031 - val_mae: 1.5489\n",
      "Epoch 1257/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.1955 - val_loss: 2.8245 - val_mae: 1.5233\n",
      "Epoch 1258/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0559 - mae: 0.1926 - val_loss: 2.7519 - val_mae: 1.4992\n",
      "Epoch 1259/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.2051 - val_loss: 2.6794 - val_mae: 1.4747\n",
      "Epoch 1260/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2243 - val_loss: 2.6881 - val_mae: 1.4777\n",
      "Epoch 1261/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0645 - mae: 0.2165 - val_loss: 2.8149 - val_mae: 1.5201\n",
      "Epoch 1262/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0560 - mae: 0.1932 - val_loss: 2.9561 - val_mae: 1.5660\n",
      "Epoch 1263/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0631 - mae: 0.1984 - val_loss: 2.9833 - val_mae: 1.5747\n",
      "Epoch 1264/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0651 - mae: 0.2003 - val_loss: 2.8831 - val_mae: 1.5425\n",
      "Epoch 1265/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0582 - mae: 0.1903 - val_loss: 2.7976 - val_mae: 1.5145\n",
      "Epoch 1266/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0565 - mae: 0.1956 - val_loss: 2.7702 - val_mae: 1.5054\n",
      "Epoch 1267/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0589 - mae: 0.2038 - val_loss: 2.7964 - val_mae: 1.5141\n",
      "Epoch 1268/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0566 - mae: 0.1955 - val_loss: 2.8889 - val_mae: 1.5444\n",
      "Epoch 1269/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0586 - mae: 0.1894 - val_loss: 2.9258 - val_mae: 1.5564\n",
      "Epoch 1270/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0610 - mae: 0.1918 - val_loss: 2.8253 - val_mae: 1.5237\n",
      "Epoch 1271/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0576 - mae: 0.1937 - val_loss: 2.7121 - val_mae: 1.4860\n",
      "Epoch 1272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1987 - val_loss: 2.6743 - val_mae: 1.4732\n",
      "Epoch 1273/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.2008 - val_loss: 2.6661 - val_mae: 1.4704\n",
      "Epoch 1274/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0588 - mae: 0.1997 - val_loss: 2.6843 - val_mae: 1.4766\n",
      "Epoch 1275/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0579 - mae: 0.1957 - val_loss: 2.7336 - val_mae: 1.4933\n",
      "Epoch 1276/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0585 - mae: 0.1924 - val_loss: 2.7673 - val_mae: 1.5046\n",
      "Epoch 1277/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0601 - mae: 0.1910 - val_loss: 2.7442 - val_mae: 1.4969\n",
      "Epoch 1278/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1918 - val_loss: 2.6873 - val_mae: 1.4777\n",
      "Epoch 1279/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0582 - mae: 0.1937 - val_loss: 2.6234 - val_mae: 1.4559\n",
      "Epoch 1280/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0616 - mae: 0.2039 - val_loss: 2.6243 - val_mae: 1.4562\n",
      "Epoch 1281/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0609 - mae: 0.2037 - val_loss: 2.7105 - val_mae: 1.4856\n",
      "Epoch 1282/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0573 - mae: 0.1918 - val_loss: 2.8364 - val_mae: 1.5275\n",
      "Epoch 1283/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0626 - mae: 0.1966 - val_loss: 2.9782 - val_mae: 1.5733\n",
      "Epoch 1284/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0804 - mae: 0.2319 - val_loss: 3.0416 - val_mae: 1.5934\n",
      "Epoch 1285/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0857 - mae: 0.2430 - val_loss: 2.8986 - val_mae: 1.5476\n",
      "Epoch 1286/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1932 - val_loss: 2.6739 - val_mae: 1.4730\n",
      "Epoch 1287/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0744 - mae: 0.2338 - val_loss: 2.5884 - val_mae: 1.4436\n",
      "Epoch 1288/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1012 - mae: 0.2760 - val_loss: 2.6666 - val_mae: 1.4705\n",
      "Epoch 1289/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0862 - mae: 0.2521 - val_loss: 2.8355 - val_mae: 1.5270\n",
      "Epoch 1290/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0582 - mae: 0.2013 - val_loss: 3.0422 - val_mae: 1.5935\n",
      "Epoch 1291/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0647 - mae: 0.1975 - val_loss: 3.1727 - val_mae: 1.6340\n",
      "Epoch 1292/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0832 - mae: 0.2330 - val_loss: 3.1047 - val_mae: 1.6130\n",
      "Epoch 1293/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0726 - mae: 0.2127 - val_loss: 2.9292 - val_mae: 1.5575\n",
      "Epoch 1294/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1921 - val_loss: 2.7942 - val_mae: 1.5135\n",
      "Epoch 1295/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0572 - mae: 0.1965 - val_loss: 2.7786 - val_mae: 1.5084\n",
      "Epoch 1296/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0568 - mae: 0.1937 - val_loss: 2.8165 - val_mae: 1.5210\n",
      "Epoch 1297/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1886 - val_loss: 2.8806 - val_mae: 1.5420\n",
      "Epoch 1298/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0608 - mae: 0.1911 - val_loss: 2.9035 - val_mae: 1.5494\n",
      "Epoch 1299/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0622 - mae: 0.1936 - val_loss: 2.8499 - val_mae: 1.5319\n",
      "Epoch 1300/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0573 - mae: 0.1867 - val_loss: 2.7313 - val_mae: 1.4926\n",
      "Epoch 1301/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1990 - val_loss: 2.5956 - val_mae: 1.4463\n",
      "Epoch 1302/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0715 - mae: 0.2282 - val_loss: 2.5876 - val_mae: 1.4435\n",
      "Epoch 1303/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2193 - val_loss: 2.6950 - val_mae: 1.4803\n",
      "Epoch 1304/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0553 - mae: 0.1922 - val_loss: 2.8866 - val_mae: 1.5439\n",
      "Epoch 1305/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0695 - mae: 0.2095 - val_loss: 3.0301 - val_mae: 1.5897\n",
      "Epoch 1306/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0906 - mae: 0.2493 - val_loss: 3.0064 - val_mae: 1.5822\n",
      "Epoch 1307/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0771 - mae: 0.2248 - val_loss: 2.9024 - val_mae: 1.5489\n",
      "Epoch 1308/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0589 - mae: 0.1949 - val_loss: 2.8234 - val_mae: 1.5230\n",
      "Epoch 1309/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2000 - val_loss: 2.8519 - val_mae: 1.5324\n",
      "Epoch 1310/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1971 - val_loss: 2.9111 - val_mae: 1.5517\n",
      "Epoch 1311/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0564 - mae: 0.1898 - val_loss: 2.9179 - val_mae: 1.5539\n",
      "Epoch 1312/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0566 - mae: 0.1886 - val_loss: 2.9277 - val_mae: 1.5571\n",
      "Epoch 1313/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0564 - mae: 0.1875 - val_loss: 2.8846 - val_mae: 1.5431\n",
      "Epoch 1314/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0586 - mae: 0.1998 - val_loss: 2.8209 - val_mae: 1.5223\n",
      "Epoch 1315/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0638 - mae: 0.2122 - val_loss: 2.8534 - val_mae: 1.5330\n",
      "Epoch 1316/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.2072 - val_loss: 2.9258 - val_mae: 1.5565\n",
      "Epoch 1317/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0587 - mae: 0.1950 - val_loss: 2.9744 - val_mae: 1.5721\n",
      "Epoch 1318/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0581 - mae: 0.1896 - val_loss: 3.0130 - val_mae: 1.5844\n",
      "Epoch 1319/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0593 - mae: 0.1882 - val_loss: 3.0497 - val_mae: 1.5960\n",
      "Epoch 1320/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0617 - mae: 0.1892 - val_loss: 3.0721 - val_mae: 1.6029\n",
      "Epoch 1321/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.1913 - val_loss: 3.0460 - val_mae: 1.5948\n",
      "Epoch 1322/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0616 - mae: 0.1887 - val_loss: 3.0263 - val_mae: 1.5885\n",
      "Epoch 1323/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0591 - mae: 0.1869 - val_loss: 3.0008 - val_mae: 1.5804\n",
      "Epoch 1324/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0581 - mae: 0.1895 - val_loss: 2.9796 - val_mae: 1.5735\n",
      "Epoch 1325/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1916 - val_loss: 2.9944 - val_mae: 1.5782\n",
      "Epoch 1326/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1907 - val_loss: 2.9916 - val_mae: 1.5773\n",
      "Epoch 1327/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0565 - mae: 0.1902 - val_loss: 2.9971 - val_mae: 1.5790\n",
      "Epoch 1328/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1898 - val_loss: 3.0199 - val_mae: 1.5862\n",
      "Epoch 1329/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.1918 - val_loss: 3.0681 - val_mae: 1.6014\n",
      "Epoch 1330/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0633 - mae: 0.1982 - val_loss: 3.0249 - val_mae: 1.5878\n",
      "Epoch 1331/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0564 - mae: 0.1906 - val_loss: 2.8176 - val_mae: 1.5209\n",
      "Epoch 1332/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0669 - mae: 0.2255 - val_loss: 2.6824 - val_mae: 1.4756\n",
      "Epoch 1333/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0940 - mae: 0.2618 - val_loss: 2.7124 - val_mae: 1.4858\n",
      "Epoch 1334/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0866 - mae: 0.2508 - val_loss: 2.8853 - val_mae: 1.5430\n",
      "Epoch 1335/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0621 - mae: 0.2115 - val_loss: 3.1275 - val_mae: 1.6198\n",
      "Epoch 1336/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2011 - val_loss: 3.2063 - val_mae: 1.6440\n",
      "Epoch 1337/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0682 - mae: 0.2045 - val_loss: 3.1909 - val_mae: 1.6392\n",
      "Epoch 1338/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0628 - mae: 0.1965 - val_loss: 3.1619 - val_mae: 1.6303\n",
      "Epoch 1339/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.1970 - val_loss: 3.1152 - val_mae: 1.6159\n",
      "Epoch 1340/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0613 - mae: 0.2028 - val_loss: 3.1622 - val_mae: 1.6304\n",
      "Epoch 1341/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.1990 - val_loss: 3.2558 - val_mae: 1.6589\n",
      "Epoch 1342/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.1962 - val_loss: 3.2942 - val_mae: 1.6704\n",
      "Epoch 1343/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0653 - mae: 0.1973 - val_loss: 3.2417 - val_mae: 1.6546\n",
      "Epoch 1344/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0633 - mae: 0.1971 - val_loss: 3.1667 - val_mae: 1.6317\n",
      "Epoch 1345/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0616 - mae: 0.1997 - val_loss: 3.1518 - val_mae: 1.6272\n",
      "Epoch 1346/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0599 - mae: 0.1941 - val_loss: 3.1116 - val_mae: 1.6148\n",
      "Epoch 1347/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0600 - mae: 0.1935 - val_loss: 2.9448 - val_mae: 1.5623\n",
      "Epoch 1348/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1983 - val_loss: 2.7781 - val_mae: 1.5079\n",
      "Epoch 1349/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.2088 - val_loss: 2.6829 - val_mae: 1.4760\n",
      "Epoch 1350/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0647 - mae: 0.2194 - val_loss: 2.6597 - val_mae: 1.4681\n",
      "Epoch 1351/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0631 - mae: 0.2157 - val_loss: 2.7420 - val_mae: 1.4960\n",
      "Epoch 1352/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0554 - mae: 0.1941 - val_loss: 2.8973 - val_mae: 1.5471\n",
      "Epoch 1353/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0629 - mae: 0.1986 - val_loss: 3.0150 - val_mae: 1.5848\n",
      "Epoch 1354/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0761 - mae: 0.2235 - val_loss: 2.9698 - val_mae: 1.5705\n",
      "Epoch 1355/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2018 - val_loss: 2.7557 - val_mae: 1.5006\n",
      "Epoch 1356/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0581 - mae: 0.2043 - val_loss: 2.5397 - val_mae: 1.4266\n",
      "Epoch 1357/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0920 - mae: 0.2614 - val_loss: 2.4905 - val_mae: 1.4092\n",
      "Epoch 1358/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1002 - mae: 0.2722 - val_loss: 2.5817 - val_mae: 1.4413\n",
      "Epoch 1359/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0721 - mae: 0.2278 - val_loss: 2.7422 - val_mae: 1.4961\n",
      "Epoch 1360/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.1951 - val_loss: 2.8511 - val_mae: 1.5322\n",
      "Epoch 1361/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0606 - mae: 0.1955 - val_loss: 2.9157 - val_mae: 1.5532\n",
      "Epoch 1362/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2036 - val_loss: 2.9864 - val_mae: 1.5758\n",
      "Epoch 1363/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0687 - mae: 0.2081 - val_loss: 3.0513 - val_mae: 1.5963\n",
      "Epoch 1364/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0680 - mae: 0.2044 - val_loss: 3.0756 - val_mae: 1.6039\n",
      "Epoch 1365/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0622 - mae: 0.1917 - val_loss: 2.9789 - val_mae: 1.5733\n",
      "Epoch 1366/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0583 - mae: 0.1971 - val_loss: 2.8850 - val_mae: 1.5431\n",
      "Epoch 1367/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0644 - mae: 0.2143 - val_loss: 2.8988 - val_mae: 1.5476\n",
      "Epoch 1368/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0625 - mae: 0.2095 - val_loss: 2.9916 - val_mae: 1.5774\n",
      "Epoch 1369/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.1893 - val_loss: 3.1176 - val_mae: 1.6170\n",
      "Epoch 1370/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0647 - mae: 0.1934 - val_loss: 3.1142 - val_mae: 1.6159\n",
      "Epoch 1371/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.1979 - val_loss: 2.9677 - val_mae: 1.5698\n",
      "Epoch 1372/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.1865 - val_loss: 2.7835 - val_mae: 1.5099\n",
      "Epoch 1373/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.2000 - val_loss: 2.6414 - val_mae: 1.4619\n",
      "Epoch 1374/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0650 - mae: 0.2172 - val_loss: 2.5900 - val_mae: 1.4442\n",
      "Epoch 1375/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0658 - mae: 0.2174 - val_loss: 2.5972 - val_mae: 1.4467\n",
      "Epoch 1376/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.2075 - val_loss: 2.6664 - val_mae: 1.4705\n",
      "Epoch 1377/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0569 - mae: 0.1932 - val_loss: 2.7653 - val_mae: 1.5039\n",
      "Epoch 1378/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0629 - mae: 0.2013 - val_loss: 2.8085 - val_mae: 1.5182\n",
      "Epoch 1379/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0682 - mae: 0.2116 - val_loss: 2.7624 - val_mae: 1.5029\n",
      "Epoch 1380/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0628 - mae: 0.2032 - val_loss: 2.7031 - val_mae: 1.4829\n",
      "Epoch 1381/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0582 - mae: 0.1953 - val_loss: 2.6317 - val_mae: 1.4586\n",
      "Epoch 1382/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0581 - mae: 0.1981 - val_loss: 2.5264 - val_mae: 1.4219\n",
      "Epoch 1383/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0664 - mae: 0.2164 - val_loss: 2.4944 - val_mae: 1.4105\n",
      "Epoch 1384/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0688 - mae: 0.2203 - val_loss: 2.5820 - val_mae: 1.4413\n",
      "Epoch 1385/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0608 - mae: 0.2030 - val_loss: 2.6915 - val_mae: 1.4789\n",
      "Epoch 1386/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0625 - mae: 0.2065 - val_loss: 2.7327 - val_mae: 1.4928\n",
      "Epoch 1387/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0647 - mae: 0.2104 - val_loss: 2.6347 - val_mae: 1.4595\n",
      "Epoch 1388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.2020 - val_loss: 2.4952 - val_mae: 1.4107\n",
      "Epoch 1389/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0807 - mae: 0.2376 - val_loss: 2.5315 - val_mae: 1.4236\n",
      "Epoch 1390/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0774 - mae: 0.2341 - val_loss: 2.7572 - val_mae: 1.5009\n",
      "Epoch 1391/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0577 - mae: 0.2010 - val_loss: 2.9829 - val_mae: 1.5745\n",
      "Epoch 1392/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0701 - mae: 0.2130 - val_loss: 3.0825 - val_mae: 1.6059\n",
      "Epoch 1393/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0798 - mae: 0.2284 - val_loss: 3.0183 - val_mae: 1.5857\n",
      "Epoch 1394/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0618 - mae: 0.1967 - val_loss: 2.8908 - val_mae: 1.5448\n",
      "Epoch 1395/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2075 - val_loss: 2.9135 - val_mae: 1.5521\n",
      "Epoch 1396/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0611 - mae: 0.2088 - val_loss: 3.0657 - val_mae: 1.6005\n",
      "Epoch 1397/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1932 - val_loss: 3.1966 - val_mae: 1.6410\n",
      "Epoch 1398/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0636 - mae: 0.1918 - val_loss: 3.1975 - val_mae: 1.6413\n",
      "Epoch 1399/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0620 - mae: 0.1889 - val_loss: 3.0351 - val_mae: 1.5909\n",
      "Epoch 1400/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0578 - mae: 0.1970 - val_loss: 2.8121 - val_mae: 1.5191\n",
      "Epoch 1401/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0797 - mae: 0.2428 - val_loss: 2.7534 - val_mae: 1.4996\n",
      "Epoch 1402/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0756 - mae: 0.2375 - val_loss: 2.8859 - val_mae: 1.5434\n",
      "Epoch 1403/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0547 - mae: 0.1886 - val_loss: 3.0751 - val_mae: 1.6037\n",
      "Epoch 1404/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0788 - mae: 0.2275 - val_loss: 3.1885 - val_mae: 1.6388\n",
      "Epoch 1405/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1131 - mae: 0.2819 - val_loss: 3.0746 - val_mae: 1.6036\n",
      "Epoch 1406/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0897 - mae: 0.2440 - val_loss: 2.8461 - val_mae: 1.5305\n",
      "Epoch 1407/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0557 - mae: 0.1871 - val_loss: 2.6467 - val_mae: 1.4636\n",
      "Epoch 1408/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0693 - mae: 0.2266 - val_loss: 2.5804 - val_mae: 1.4407\n",
      "Epoch 1409/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0783 - mae: 0.2397 - val_loss: 2.7253 - val_mae: 1.4903\n",
      "Epoch 1410/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0549 - mae: 0.1951 - val_loss: 2.9806 - val_mae: 1.5739\n",
      "Epoch 1411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0764 - mae: 0.2282 - val_loss: 3.1091 - val_mae: 1.6143\n",
      "Epoch 1412/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1027 - mae: 0.2684 - val_loss: 2.9592 - val_mae: 1.5671\n",
      "Epoch 1413/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0699 - mae: 0.2105 - val_loss: 2.6834 - val_mae: 1.4762\n",
      "Epoch 1414/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0573 - mae: 0.2004 - val_loss: 2.4641 - val_mae: 1.3997\n",
      "Epoch 1415/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0894 - mae: 0.2539 - val_loss: 2.4171 - val_mae: 1.3828\n",
      "Epoch 1416/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0943 - mae: 0.2586 - val_loss: 2.5287 - val_mae: 1.4227\n",
      "Epoch 1417/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2178 - val_loss: 2.6833 - val_mae: 1.4762\n",
      "Epoch 1418/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0597 - mae: 0.1932 - val_loss: 2.8127 - val_mae: 1.5196\n",
      "Epoch 1419/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0696 - mae: 0.2131 - val_loss: 2.8508 - val_mae: 1.5321\n",
      "Epoch 1420/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0647 - mae: 0.2033 - val_loss: 2.7152 - val_mae: 1.4870\n",
      "Epoch 1421/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.2032 - val_loss: 2.6281 - val_mae: 1.4573\n",
      "Epoch 1422/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0683 - mae: 0.2225 - val_loss: 2.7669 - val_mae: 1.5043\n",
      "Epoch 1423/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0590 - mae: 0.1995 - val_loss: 2.9212 - val_mae: 1.5549\n",
      "Epoch 1424/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.1883 - val_loss: 2.9983 - val_mae: 1.5795\n",
      "Epoch 1425/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.1954 - val_loss: 3.0679 - val_mae: 1.6014\n",
      "Epoch 1426/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0690 - mae: 0.2065 - val_loss: 3.0110 - val_mae: 1.5835\n",
      "Epoch 1427/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.1902 - val_loss: 2.8501 - val_mae: 1.5317\n",
      "Epoch 1428/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0581 - mae: 0.2011 - val_loss: 2.7808 - val_mae: 1.5088\n",
      "Epoch 1429/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2146 - val_loss: 2.8431 - val_mae: 1.5294\n",
      "Epoch 1430/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.2025 - val_loss: 2.9980 - val_mae: 1.5794\n",
      "Epoch 1431/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0577 - mae: 0.1859 - val_loss: 3.1152 - val_mae: 1.6161\n",
      "Epoch 1432/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0632 - mae: 0.1916 - val_loss: 3.1404 - val_mae: 1.6239\n",
      "Epoch 1433/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.1904 - val_loss: 3.0460 - val_mae: 1.5945\n",
      "Epoch 1434/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mae: 0.1878 - val_loss: 2.9039 - val_mae: 1.5491\n",
      "Epoch 1435/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0611 - mae: 0.2085 - val_loss: 2.8853 - val_mae: 1.5431\n",
      "Epoch 1436/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0634 - mae: 0.2135 - val_loss: 2.9594 - val_mae: 1.5669\n",
      "Epoch 1437/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0594 - mae: 0.2041 - val_loss: 3.0963 - val_mae: 1.6101\n",
      "Epoch 1438/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0577 - mae: 0.1894 - val_loss: 3.2637 - val_mae: 1.6613\n",
      "Epoch 1439/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0670 - mae: 0.1969 - val_loss: 3.2961 - val_mae: 1.6710\n",
      "Epoch 1440/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0664 - mae: 0.1949 - val_loss: 3.1587 - val_mae: 1.6293\n",
      "Epoch 1441/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0584 - mae: 0.1904 - val_loss: 2.9665 - val_mae: 1.5691\n",
      "Epoch 1442/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0690 - mae: 0.2243 - val_loss: 2.8700 - val_mae: 1.5379\n",
      "Epoch 1443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0765 - mae: 0.2367 - val_loss: 2.8914 - val_mae: 1.5450\n",
      "Epoch 1444/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2207 - val_loss: 2.8949 - val_mae: 1.5462\n",
      "Epoch 1445/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.2077 - val_loss: 2.8860 - val_mae: 1.5433\n",
      "Epoch 1446/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0573 - mae: 0.1975 - val_loss: 2.8862 - val_mae: 1.5434\n",
      "Epoch 1447/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0556 - mae: 0.1900 - val_loss: 2.8911 - val_mae: 1.5451\n",
      "Epoch 1448/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0568 - mae: 0.1889 - val_loss: 2.8575 - val_mae: 1.5342\n",
      "Epoch 1449/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0570 - mae: 0.1882 - val_loss: 2.7772 - val_mae: 1.5078\n",
      "Epoch 1450/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0564 - mae: 0.1914 - val_loss: 2.7247 - val_mae: 1.4902\n",
      "Epoch 1451/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1930 - val_loss: 2.7107 - val_mae: 1.4856\n",
      "Epoch 1452/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0576 - mae: 0.1919 - val_loss: 2.7729 - val_mae: 1.5064\n",
      "Epoch 1453/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0618 - mae: 0.1946 - val_loss: 2.8372 - val_mae: 1.5277\n",
      "Epoch 1454/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0691 - mae: 0.2125 - val_loss: 2.8909 - val_mae: 1.5451\n",
      "Epoch 1455/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0728 - mae: 0.2202 - val_loss: 2.9413 - val_mae: 1.5613\n",
      "Epoch 1456/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0683 - mae: 0.2113 - val_loss: 2.8543 - val_mae: 1.5331\n",
      "Epoch 1457/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1902 - val_loss: 2.7340 - val_mae: 1.4931\n",
      "Epoch 1458/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2222 - val_loss: 2.7300 - val_mae: 1.4917\n",
      "Epoch 1459/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0747 - mae: 0.2357 - val_loss: 2.8901 - val_mae: 1.5446\n",
      "Epoch 1460/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.2136 - val_loss: 3.0987 - val_mae: 1.6108\n",
      "Epoch 1461/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1891 - val_loss: 3.2191 - val_mae: 1.6478\n",
      "Epoch 1462/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0617 - mae: 0.1888 - val_loss: 3.2566 - val_mae: 1.6591\n",
      "Epoch 1463/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0630 - mae: 0.1900 - val_loss: 3.1959 - val_mae: 1.6406\n",
      "Epoch 1464/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0596 - mae: 0.1894 - val_loss: 3.0894 - val_mae: 1.6077\n",
      "Epoch 1465/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0620 - mae: 0.2081 - val_loss: 3.0765 - val_mae: 1.6037\n",
      "Epoch 1466/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0611 - mae: 0.2066 - val_loss: 3.1410 - val_mae: 1.6238\n",
      "Epoch 1467/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1914 - val_loss: 3.1988 - val_mae: 1.6415\n",
      "Epoch 1468/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0612 - mae: 0.1885 - val_loss: 3.2159 - val_mae: 1.6468\n",
      "Epoch 1469/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0664 - mae: 0.1968 - val_loss: 3.1234 - val_mae: 1.6184\n",
      "Epoch 1470/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0624 - mae: 0.1949 - val_loss: 3.0034 - val_mae: 1.5808\n",
      "Epoch 1471/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0560 - mae: 0.1878 - val_loss: 2.8921 - val_mae: 1.5451\n",
      "Epoch 1472/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0559 - mae: 0.1953 - val_loss: 2.8025 - val_mae: 1.5158\n",
      "Epoch 1473/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0581 - mae: 0.2044 - val_loss: 2.8005 - val_mae: 1.5151\n",
      "Epoch 1474/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2043 - val_loss: 2.8542 - val_mae: 1.5328\n",
      "Epoch 1475/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0550 - mae: 0.1942 - val_loss: 2.9700 - val_mae: 1.5702\n",
      "Epoch 1476/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0601 - mae: 0.1934 - val_loss: 3.0625 - val_mae: 1.5994\n",
      "Epoch 1477/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.2033 - val_loss: 3.1212 - val_mae: 1.6177\n",
      "Epoch 1478/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1970 - val_loss: 3.0928 - val_mae: 1.6088\n",
      "Epoch 1479/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0572 - mae: 0.1862 - val_loss: 2.9381 - val_mae: 1.5598\n",
      "Epoch 1480/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0603 - mae: 0.2088 - val_loss: 2.8562 - val_mae: 1.5332\n",
      "Epoch 1481/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0742 - mae: 0.2352 - val_loss: 2.9624 - val_mae: 1.5676\n",
      "Epoch 1482/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0621 - mae: 0.2082 - val_loss: 3.1582 - val_mae: 1.6290\n",
      "Epoch 1483/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0600 - mae: 0.1866 - val_loss: 3.2450 - val_mae: 1.6555\n",
      "Epoch 1484/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0731 - mae: 0.2107 - val_loss: 3.2070 - val_mae: 1.6440\n",
      "Epoch 1485/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0709 - mae: 0.2057 - val_loss: 3.0928 - val_mae: 1.6088\n",
      "Epoch 1486/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.1861 - val_loss: 2.9459 - val_mae: 1.5624\n",
      "Epoch 1487/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0577 - mae: 0.1987 - val_loss: 2.8397 - val_mae: 1.5280\n",
      "Epoch 1488/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0619 - mae: 0.2097 - val_loss: 2.8148 - val_mae: 1.5198\n",
      "Epoch 1489/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0601 - mae: 0.2062 - val_loss: 2.8443 - val_mae: 1.5295\n",
      "Epoch 1490/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0559 - mae: 0.1947 - val_loss: 2.9375 - val_mae: 1.5598\n",
      "Epoch 1491/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0612 - mae: 0.1941 - val_loss: 3.0472 - val_mae: 1.5947\n",
      "Epoch 1492/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0784 - mae: 0.2274 - val_loss: 3.1090 - val_mae: 1.6140\n",
      "Epoch 1493/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0840 - mae: 0.2362 - val_loss: 2.9813 - val_mae: 1.5738\n",
      "Epoch 1494/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0577 - mae: 0.1865 - val_loss: 2.7331 - val_mae: 1.4926\n",
      "Epoch 1495/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0741 - mae: 0.2353 - val_loss: 2.6331 - val_mae: 1.4586\n",
      "Epoch 1496/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1003 - mae: 0.2759 - val_loss: 2.7433 - val_mae: 1.4960\n",
      "Epoch 1497/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0735 - mae: 0.2330 - val_loss: 2.9938 - val_mae: 1.5777\n",
      "Epoch 1498/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.1908 - val_loss: 3.1809 - val_mae: 1.6361\n",
      "Epoch 1499/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0764 - mae: 0.2196 - val_loss: 3.1438 - val_mae: 1.6247\n",
      "Epoch 1500/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0726 - mae: 0.2150 - val_loss: 2.9536 - val_mae: 1.5649\n",
      "Epoch 1501/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0589 - mae: 0.1902 - val_loss: 2.8044 - val_mae: 1.5164\n",
      "Epoch 1502/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0569 - mae: 0.1991 - val_loss: 2.8109 - val_mae: 1.5186\n",
      "Epoch 1503/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0556 - mae: 0.1951 - val_loss: 2.9456 - val_mae: 1.5624\n",
      "Epoch 1504/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0582 - mae: 0.1904 - val_loss: 3.0985 - val_mae: 1.6107\n",
      "Epoch 1505/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0714 - mae: 0.2121 - val_loss: 3.0822 - val_mae: 1.6056\n",
      "Epoch 1506/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.1989 - val_loss: 2.9078 - val_mae: 1.5501\n",
      "Epoch 1507/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0553 - mae: 0.1909 - val_loss: 2.7273 - val_mae: 1.4907\n",
      "Epoch 1508/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2188 - val_loss: 2.6575 - val_mae: 1.4670\n",
      "Epoch 1509/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0728 - mae: 0.2325 - val_loss: 2.6832 - val_mae: 1.4758\n",
      "Epoch 1510/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0648 - mae: 0.2160 - val_loss: 2.7694 - val_mae: 1.5048\n",
      "Epoch 1511/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1955 - val_loss: 2.8500 - val_mae: 1.5314\n",
      "Epoch 1512/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0596 - mae: 0.1937 - val_loss: 2.7868 - val_mae: 1.5106\n",
      "Epoch 1513/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0559 - mae: 0.1896 - val_loss: 2.6607 - val_mae: 1.4681\n",
      "Epoch 1514/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0643 - mae: 0.2153 - val_loss: 2.6216 - val_mae: 1.4547\n",
      "Epoch 1515/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0785 - mae: 0.2400 - val_loss: 2.7099 - val_mae: 1.4848\n",
      "Epoch 1516/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0701 - mae: 0.2293 - val_loss: 2.8735 - val_mae: 1.5389\n",
      "Epoch 1517/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.2021 - val_loss: 2.9813 - val_mae: 1.5736\n",
      "Epoch 1518/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1939 - val_loss: 3.0322 - val_mae: 1.5897\n",
      "Epoch 1519/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1932 - val_loss: 3.0516 - val_mae: 1.5958\n",
      "Epoch 1520/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0574 - mae: 0.1933 - val_loss: 2.9955 - val_mae: 1.5781\n",
      "Epoch 1521/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0558 - mae: 0.1939 - val_loss: 2.9042 - val_mae: 1.5489\n",
      "Epoch 1522/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0576 - mae: 0.2012 - val_loss: 2.8872 - val_mae: 1.5433\n",
      "Epoch 1523/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.2061 - val_loss: 2.9406 - val_mae: 1.5606\n",
      "Epoch 1524/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0571 - mae: 0.2004 - val_loss: 2.9454 - val_mae: 1.5621\n",
      "Epoch 1525/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0568 - mae: 0.1995 - val_loss: 2.9228 - val_mae: 1.5548\n",
      "Epoch 1526/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2031 - val_loss: 2.9054 - val_mae: 1.5492\n",
      "Epoch 1527/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.2063 - val_loss: 2.9488 - val_mae: 1.5632\n",
      "Epoch 1528/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0559 - mae: 0.1968 - val_loss: 3.0701 - val_mae: 1.6016\n",
      "Epoch 1529/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0596 - mae: 0.1930 - val_loss: 3.0730 - val_mae: 1.6026\n",
      "Epoch 1530/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.2000 - val_loss: 2.9843 - val_mae: 1.5746\n",
      "Epoch 1531/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.1962 - val_loss: 2.9742 - val_mae: 1.5714\n",
      "Epoch 1532/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0575 - mae: 0.1926 - val_loss: 2.9915 - val_mae: 1.5769\n",
      "Epoch 1533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0575 - mae: 0.1923 - val_loss: 2.9157 - val_mae: 1.5526\n",
      "Epoch 1534/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0560 - mae: 0.1946 - val_loss: 2.8522 - val_mae: 1.5319\n",
      "Epoch 1535/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.2040 - val_loss: 2.8796 - val_mae: 1.5409\n",
      "Epoch 1536/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.2047 - val_loss: 2.9314 - val_mae: 1.5576\n",
      "Epoch 1537/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0565 - mae: 0.1996 - val_loss: 3.0005 - val_mae: 1.5797\n",
      "Epoch 1538/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1948 - val_loss: 3.0260 - val_mae: 1.5877\n",
      "Epoch 1539/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0556 - mae: 0.1926 - val_loss: 3.0014 - val_mae: 1.5799\n",
      "Epoch 1540/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0561 - mae: 0.1966 - val_loss: 3.0148 - val_mae: 1.5842\n",
      "Epoch 1541/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0565 - mae: 0.1967 - val_loss: 3.0054 - val_mae: 1.5812\n",
      "Epoch 1542/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0557 - mae: 0.1950 - val_loss: 2.9268 - val_mae: 1.5561\n",
      "Epoch 1543/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0570 - mae: 0.2000 - val_loss: 2.9119 - val_mae: 1.5514\n",
      "Epoch 1544/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0564 - mae: 0.1952 - val_loss: 2.9282 - val_mae: 1.5567\n",
      "Epoch 1545/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0566 - mae: 0.1891 - val_loss: 2.8841 - val_mae: 1.5425\n",
      "Epoch 1546/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0568 - mae: 0.1895 - val_loss: 2.8265 - val_mae: 1.5237\n",
      "Epoch 1547/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0567 - mae: 0.1926 - val_loss: 2.8037 - val_mae: 1.5162\n",
      "Epoch 1548/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0563 - mae: 0.1918 - val_loss: 2.8360 - val_mae: 1.5268\n",
      "Epoch 1549/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0580 - mae: 0.1910 - val_loss: 2.7999 - val_mae: 1.5150\n",
      "Epoch 1550/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0569 - mae: 0.1909 - val_loss: 2.7074 - val_mae: 1.4841\n",
      "Epoch 1551/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0594 - mae: 0.2026 - val_loss: 2.7176 - val_mae: 1.4875\n",
      "Epoch 1552/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.2002 - val_loss: 2.7332 - val_mae: 1.4928\n",
      "Epoch 1553/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0576 - mae: 0.1945 - val_loss: 2.6750 - val_mae: 1.4732\n",
      "Epoch 1554/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0591 - mae: 0.1976 - val_loss: 2.6690 - val_mae: 1.4712\n",
      "Epoch 1555/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.1966 - val_loss: 2.7414 - val_mae: 1.4957\n",
      "Epoch 1556/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.1930 - val_loss: 2.7942 - val_mae: 1.5132\n",
      "Epoch 1557/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0595 - mae: 0.1918 - val_loss: 2.7601 - val_mae: 1.5019\n",
      "Epoch 1558/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1912 - val_loss: 2.7155 - val_mae: 1.4869\n",
      "Epoch 1559/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2035 - val_loss: 2.7216 - val_mae: 1.4889\n",
      "Epoch 1560/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2048 - val_loss: 2.8072 - val_mae: 1.5175\n",
      "Epoch 1561/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1932 - val_loss: 2.9159 - val_mae: 1.5529\n",
      "Epoch 1562/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0587 - mae: 0.1901 - val_loss: 2.8867 - val_mae: 1.5435\n",
      "Epoch 1563/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1908 - val_loss: 2.7718 - val_mae: 1.5057\n",
      "Epoch 1564/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.2047 - val_loss: 2.7122 - val_mae: 1.4857\n",
      "Epoch 1565/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - mae: 0.2160 - val_loss: 2.7831 - val_mae: 1.5094\n",
      "Epoch 1566/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0556 - mae: 0.1971 - val_loss: 2.9668 - val_mae: 1.5693\n",
      "Epoch 1567/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2040 - val_loss: 3.0028 - val_mae: 1.5808\n",
      "Epoch 1568/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0689 - mae: 0.2108 - val_loss: 2.8771 - val_mae: 1.5404\n",
      "Epoch 1569/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0555 - mae: 0.1909 - val_loss: 2.7424 - val_mae: 1.4959\n",
      "Epoch 1570/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0613 - mae: 0.2092 - val_loss: 2.7174 - val_mae: 1.4875\n",
      "Epoch 1571/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0644 - mae: 0.2184 - val_loss: 2.8100 - val_mae: 1.5184\n",
      "Epoch 1572/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0569 - mae: 0.2000 - val_loss: 2.8675 - val_mae: 1.5373\n",
      "Epoch 1573/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0551 - mae: 0.1903 - val_loss: 2.8679 - val_mae: 1.5374\n",
      "Epoch 1574/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0551 - mae: 0.1890 - val_loss: 2.8511 - val_mae: 1.5319\n",
      "Epoch 1575/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1898 - val_loss: 2.8272 - val_mae: 1.5242\n",
      "Epoch 1576/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0556 - mae: 0.1928 - val_loss: 2.7948 - val_mae: 1.5135\n",
      "Epoch 1577/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1960 - val_loss: 2.7993 - val_mae: 1.5150\n",
      "Epoch 1578/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0562 - mae: 0.1948 - val_loss: 2.8546 - val_mae: 1.5332\n",
      "Epoch 1579/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0567 - mae: 0.1912 - val_loss: 2.8353 - val_mae: 1.5268\n",
      "Epoch 1580/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0563 - mae: 0.1940 - val_loss: 2.7772 - val_mae: 1.5076\n",
      "Epoch 1581/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.2034 - val_loss: 2.8399 - val_mae: 1.5283\n",
      "Epoch 1582/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0565 - mae: 0.1970 - val_loss: 2.9911 - val_mae: 1.5770\n",
      "Epoch 1583/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1862 - val_loss: 3.1278 - val_mae: 1.6199\n",
      "Epoch 1584/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0660 - mae: 0.1982 - val_loss: 3.1649 - val_mae: 1.6313\n",
      "Epoch 1585/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0675 - mae: 0.1993 - val_loss: 3.1131 - val_mae: 1.6152\n",
      "Epoch 1586/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1873 - val_loss: 3.0106 - val_mae: 1.5831\n",
      "Epoch 1587/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1982 - val_loss: 2.9834 - val_mae: 1.5744\n",
      "Epoch 1588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0619 - mae: 0.2095 - val_loss: 3.0088 - val_mae: 1.5824\n",
      "Epoch 1589/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0619 - mae: 0.2102 - val_loss: 3.0254 - val_mae: 1.5877\n",
      "Epoch 1590/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0601 - mae: 0.2039 - val_loss: 3.0546 - val_mae: 1.5969\n",
      "Epoch 1591/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0571 - mae: 0.1948 - val_loss: 3.0133 - val_mae: 1.5839\n",
      "Epoch 1592/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1936 - val_loss: 2.9542 - val_mae: 1.5651\n",
      "Epoch 1593/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0553 - mae: 0.1930 - val_loss: 2.9324 - val_mae: 1.5582\n",
      "Epoch 1594/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0551 - mae: 0.1917 - val_loss: 2.8948 - val_mae: 1.5461\n",
      "Epoch 1595/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1923 - val_loss: 2.8535 - val_mae: 1.5327\n",
      "Epoch 1596/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1916 - val_loss: 2.8608 - val_mae: 1.5351\n",
      "Epoch 1597/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1940 - val_loss: 2.8645 - val_mae: 1.5363\n",
      "Epoch 1598/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0588 - mae: 0.1952 - val_loss: 2.8464 - val_mae: 1.5304\n",
      "Epoch 1599/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0582 - mae: 0.1944 - val_loss: 2.7994 - val_mae: 1.5149\n",
      "Epoch 1600/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1933 - val_loss: 2.7120 - val_mae: 1.4858\n",
      "Epoch 1601/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1946 - val_loss: 2.6120 - val_mae: 1.4517\n",
      "Epoch 1602/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.2069 - val_loss: 2.6044 - val_mae: 1.4491\n",
      "Epoch 1603/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.2019 - val_loss: 2.6918 - val_mae: 1.4790\n",
      "Epoch 1604/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0588 - mae: 0.1955 - val_loss: 2.7687 - val_mae: 1.5049\n",
      "Epoch 1605/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0654 - mae: 0.2080 - val_loss: 2.7146 - val_mae: 1.4867\n",
      "Epoch 1606/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0601 - mae: 0.1998 - val_loss: 2.6048 - val_mae: 1.4492\n",
      "Epoch 1607/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.2083 - val_loss: 2.6478 - val_mae: 1.4639\n",
      "Epoch 1608/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0598 - mae: 0.2066 - val_loss: 2.8223 - val_mae: 1.5224\n",
      "Epoch 1609/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0566 - mae: 0.1953 - val_loss: 2.9778 - val_mae: 1.5728\n",
      "Epoch 1610/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.1953 - val_loss: 2.9772 - val_mae: 1.5725\n",
      "Epoch 1611/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1932 - val_loss: 2.9136 - val_mae: 1.5521\n",
      "Epoch 1612/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1936 - val_loss: 2.8725 - val_mae: 1.5388\n",
      "Epoch 1613/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1974 - val_loss: 2.8952 - val_mae: 1.5462\n",
      "Epoch 1614/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1975 - val_loss: 2.9218 - val_mae: 1.5547\n",
      "Epoch 1615/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0564 - mae: 0.1973 - val_loss: 2.8821 - val_mae: 1.5419\n",
      "Epoch 1616/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0601 - mae: 0.2082 - val_loss: 2.8943 - val_mae: 1.5458\n",
      "Epoch 1617/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0593 - mae: 0.2062 - val_loss: 2.9950 - val_mae: 1.5781\n",
      "Epoch 1618/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1950 - val_loss: 3.0245 - val_mae: 1.5875\n",
      "Epoch 1619/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1886 - val_loss: 2.9392 - val_mae: 1.5603\n",
      "Epoch 1620/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1997 - val_loss: 2.8920 - val_mae: 1.5451\n",
      "Epoch 1621/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0574 - mae: 0.1999 - val_loss: 2.9358 - val_mae: 1.5593\n",
      "Epoch 1622/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0559 - mae: 0.1890 - val_loss: 2.9782 - val_mae: 1.5729\n",
      "Epoch 1623/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0568 - mae: 0.1874 - val_loss: 2.9913 - val_mae: 1.5771\n",
      "Epoch 1624/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0569 - mae: 0.1870 - val_loss: 2.9787 - val_mae: 1.5730\n",
      "Epoch 1625/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0556 - mae: 0.1861 - val_loss: 2.8997 - val_mae: 1.5476\n",
      "Epoch 1626/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.1974 - val_loss: 2.8506 - val_mae: 1.5316\n",
      "Epoch 1627/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0617 - mae: 0.2099 - val_loss: 2.9517 - val_mae: 1.5643\n",
      "Epoch 1628/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1932 - val_loss: 3.1493 - val_mae: 1.6264\n",
      "Epoch 1629/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0618 - mae: 0.1914 - val_loss: 3.2926 - val_mae: 1.6699\n",
      "Epoch 1630/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0798 - mae: 0.2225 - val_loss: 3.2533 - val_mae: 1.6580\n",
      "Epoch 1631/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0723 - mae: 0.2068 - val_loss: 3.0820 - val_mae: 1.6054\n",
      "Epoch 1632/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0588 - mae: 0.1930 - val_loss: 2.9856 - val_mae: 1.5750\n",
      "Epoch 1633/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0573 - mae: 0.1988 - val_loss: 3.0197 - val_mae: 1.5858\n",
      "Epoch 1634/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1945 - val_loss: 3.0751 - val_mae: 1.6032\n",
      "Epoch 1635/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1874 - val_loss: 3.0827 - val_mae: 1.6056\n",
      "Epoch 1636/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0579 - mae: 0.1879 - val_loss: 2.9950 - val_mae: 1.5781\n",
      "Epoch 1637/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1881 - val_loss: 2.9209 - val_mae: 1.5544\n",
      "Epoch 1638/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1895 - val_loss: 2.9625 - val_mae: 1.5677\n",
      "Epoch 1639/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1874 - val_loss: 3.0648 - val_mae: 1.6000\n",
      "Epoch 1640/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0628 - mae: 0.1974 - val_loss: 3.1221 - val_mae: 1.6179\n",
      "Epoch 1641/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0694 - mae: 0.2086 - val_loss: 3.0103 - val_mae: 1.5828\n",
      "Epoch 1642/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0596 - mae: 0.1961 - val_loss: 2.8687 - val_mae: 1.5373\n",
      "Epoch 1643/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0567 - mae: 0.2004 - val_loss: 2.8994 - val_mae: 1.5473\n",
      "Epoch 1644/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0566 - mae: 0.1979 - val_loss: 2.9561 - val_mae: 1.5655\n",
      "Epoch 1645/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0551 - mae: 0.1931 - val_loss: 2.9451 - val_mae: 1.5620\n",
      "Epoch 1646/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0556 - mae: 0.1964 - val_loss: 2.9849 - val_mae: 1.5747\n",
      "Epoch 1647/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0555 - mae: 0.1964 - val_loss: 3.0684 - val_mae: 1.6010\n",
      "Epoch 1648/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0571 - mae: 0.1964 - val_loss: 3.1948 - val_mae: 1.6400\n",
      "Epoch 1649/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0636 - mae: 0.1995 - val_loss: 3.2787 - val_mae: 1.6654\n",
      "Epoch 1650/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0645 - mae: 0.1974 - val_loss: 3.1639 - val_mae: 1.6305\n",
      "Epoch 1651/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0580 - mae: 0.2007 - val_loss: 2.9486 - val_mae: 1.5629\n",
      "Epoch 1652/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0750 - mae: 0.2331 - val_loss: 2.8131 - val_mae: 1.5189\n",
      "Epoch 1653/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0843 - mae: 0.2494 - val_loss: 2.8996 - val_mae: 1.5473\n",
      "Epoch 1654/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0597 - mae: 0.2060 - val_loss: 3.0777 - val_mae: 1.6040\n",
      "Epoch 1655/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0677 - mae: 0.2078 - val_loss: 3.0177 - val_mae: 1.5852\n",
      "Epoch 1656/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0617 - mae: 0.1993 - val_loss: 2.8266 - val_mae: 1.5236\n",
      "Epoch 1657/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.2026 - val_loss: 2.7659 - val_mae: 1.5035\n",
      "Epoch 1658/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0630 - mae: 0.2137 - val_loss: 2.8613 - val_mae: 1.5350\n",
      "Epoch 1659/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0549 - mae: 0.1932 - val_loss: 3.0356 - val_mae: 1.5909\n",
      "Epoch 1660/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0651 - mae: 0.1986 - val_loss: 3.0319 - val_mae: 1.5898\n",
      "Epoch 1661/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0618 - mae: 0.1940 - val_loss: 2.8051 - val_mae: 1.5166\n",
      "Epoch 1662/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0596 - mae: 0.2034 - val_loss: 2.6807 - val_mae: 1.4749\n",
      "Epoch 1663/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0679 - mae: 0.2228 - val_loss: 2.7264 - val_mae: 1.4903\n",
      "Epoch 1664/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0612 - mae: 0.2103 - val_loss: 2.8516 - val_mae: 1.5318\n",
      "Epoch 1665/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0548 - mae: 0.1914 - val_loss: 3.0276 - val_mae: 1.5883\n",
      "Epoch 1666/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0628 - mae: 0.1989 - val_loss: 3.0686 - val_mae: 1.6012\n",
      "Epoch 1667/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0614 - mae: 0.1952 - val_loss: 2.9965 - val_mae: 1.5784\n",
      "Epoch 1668/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0558 - mae: 0.1909 - val_loss: 2.9890 - val_mae: 1.5759\n",
      "Epoch 1669/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0563 - mae: 0.1972 - val_loss: 3.0273 - val_mae: 1.5880\n",
      "Epoch 1670/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0567 - mae: 0.1979 - val_loss: 2.9971 - val_mae: 1.5784\n",
      "Epoch 1671/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0597 - mae: 0.2080 - val_loss: 2.9197 - val_mae: 1.5537\n",
      "Epoch 1672/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0661 - mae: 0.2207 - val_loss: 2.9165 - val_mae: 1.5527\n",
      "Epoch 1673/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0631 - mae: 0.2152 - val_loss: 2.9967 - val_mae: 1.5783\n",
      "Epoch 1674/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0576 - mae: 0.2026 - val_loss: 3.0298 - val_mae: 1.5888\n",
      "Epoch 1675/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0567 - mae: 0.1992 - val_loss: 3.0620 - val_mae: 1.5989\n",
      "Epoch 1676/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0576 - mae: 0.1972 - val_loss: 3.0494 - val_mae: 1.5950\n",
      "Epoch 1677/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0577 - mae: 0.1973 - val_loss: 2.9376 - val_mae: 1.5596\n",
      "Epoch 1678/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0558 - mae: 0.1962 - val_loss: 2.8912 - val_mae: 1.5446\n",
      "Epoch 1679/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0553 - mae: 0.1954 - val_loss: 2.8538 - val_mae: 1.5324\n",
      "Epoch 1680/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0552 - mae: 0.1954 - val_loss: 2.7790 - val_mae: 1.5078\n",
      "Epoch 1681/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0570 - mae: 0.2011 - val_loss: 2.7702 - val_mae: 1.5049\n",
      "Epoch 1682/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0572 - mae: 0.1990 - val_loss: 2.7870 - val_mae: 1.5105\n",
      "Epoch 1683/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0560 - mae: 0.1947 - val_loss: 2.8004 - val_mae: 1.5149\n",
      "Epoch 1684/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0555 - mae: 0.1949 - val_loss: 2.8520 - val_mae: 1.5319\n",
      "Epoch 1685/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0550 - mae: 0.1927 - val_loss: 2.8703 - val_mae: 1.5378\n",
      "Epoch 1686/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0552 - mae: 0.1949 - val_loss: 2.8658 - val_mae: 1.5363\n",
      "Epoch 1687/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0566 - mae: 0.1999 - val_loss: 2.9162 - val_mae: 1.5527\n",
      "Epoch 1688/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0549 - mae: 0.1935 - val_loss: 3.0281 - val_mae: 1.5884\n",
      "Epoch 1689/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0569 - mae: 0.1892 - val_loss: 3.0624 - val_mae: 1.5992\n",
      "Epoch 1690/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0583 - mae: 0.1892 - val_loss: 2.9260 - val_mae: 1.5559\n",
      "Epoch 1691/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0560 - mae: 0.1946 - val_loss: 2.7962 - val_mae: 1.5135\n",
      "Epoch 1692/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0587 - mae: 0.2034 - val_loss: 2.7861 - val_mae: 1.5102\n",
      "Epoch 1693/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0567 - mae: 0.1964 - val_loss: 2.8121 - val_mae: 1.5189\n",
      "Epoch 1694/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0560 - mae: 0.1896 - val_loss: 2.8133 - val_mae: 1.5193\n",
      "Epoch 1695/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1911 - val_loss: 2.7962 - val_mae: 1.5136\n",
      "Epoch 1696/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1924 - val_loss: 2.7854 - val_mae: 1.5100\n",
      "Epoch 1697/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0579 - mae: 0.1931 - val_loss: 2.7737 - val_mae: 1.5061\n",
      "Epoch 1698/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1924 - val_loss: 2.7214 - val_mae: 1.4886\n",
      "Epoch 1699/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1979 - val_loss: 2.6548 - val_mae: 1.4659\n",
      "Epoch 1700/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0667 - mae: 0.2196 - val_loss: 2.7627 - val_mae: 1.5024\n",
      "Epoch 1701/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.2006 - val_loss: 3.0152 - val_mae: 1.5843\n",
      "Epoch 1702/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0676 - mae: 0.2102 - val_loss: 3.1479 - val_mae: 1.6257\n",
      "Epoch 1703/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0784 - mae: 0.2234 - val_loss: 3.1130 - val_mae: 1.6149\n",
      "Epoch 1704/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.2005 - val_loss: 3.0466 - val_mae: 1.5941\n",
      "Epoch 1705/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1984 - val_loss: 3.0267 - val_mae: 1.5877\n",
      "Epoch 1706/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0622 - mae: 0.2126 - val_loss: 3.1077 - val_mae: 1.6131\n",
      "Epoch 1707/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0611 - mae: 0.2063 - val_loss: 3.2119 - val_mae: 1.6451\n",
      "Epoch 1708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1967 - val_loss: 3.2260 - val_mae: 1.6495\n",
      "Epoch 1709/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1948 - val_loss: 3.1675 - val_mae: 1.6316\n",
      "Epoch 1710/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1920 - val_loss: 3.0040 - val_mae: 1.5806\n",
      "Epoch 1711/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.2056 - val_loss: 2.8823 - val_mae: 1.5416\n",
      "Epoch 1712/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0721 - mae: 0.2293 - val_loss: 2.9232 - val_mae: 1.5548\n",
      "Epoch 1713/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0652 - mae: 0.2167 - val_loss: 3.1075 - val_mae: 1.6131\n",
      "Epoch 1714/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1934 - val_loss: 3.2440 - val_mae: 1.6550\n",
      "Epoch 1715/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0710 - mae: 0.2068 - val_loss: 3.1685 - val_mae: 1.6321\n",
      "Epoch 1716/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0680 - mae: 0.2044 - val_loss: 3.0614 - val_mae: 1.5989\n",
      "Epoch 1717/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.1902 - val_loss: 2.9449 - val_mae: 1.5620\n",
      "Epoch 1718/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1912 - val_loss: 2.8529 - val_mae: 1.5321\n",
      "Epoch 1719/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0572 - mae: 0.2007 - val_loss: 2.8791 - val_mae: 1.5407\n",
      "Epoch 1720/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0556 - mae: 0.1957 - val_loss: 2.9793 - val_mae: 1.5730\n",
      "Epoch 1721/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1850 - val_loss: 3.1269 - val_mae: 1.6193\n",
      "Epoch 1722/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0714 - mae: 0.2136 - val_loss: 3.1899 - val_mae: 1.6387\n",
      "Epoch 1723/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0795 - mae: 0.2263 - val_loss: 3.0940 - val_mae: 1.6091\n",
      "Epoch 1724/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0633 - mae: 0.1958 - val_loss: 2.9204 - val_mae: 1.5540\n",
      "Epoch 1725/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0566 - mae: 0.1961 - val_loss: 2.8403 - val_mae: 1.5280\n",
      "Epoch 1726/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.2074 - val_loss: 2.8668 - val_mae: 1.5366\n",
      "Epoch 1727/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.2057 - val_loss: 2.9399 - val_mae: 1.5602\n",
      "Epoch 1728/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1995 - val_loss: 2.9832 - val_mae: 1.5741\n",
      "Epoch 1729/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1893 - val_loss: 3.0053 - val_mae: 1.5811\n",
      "Epoch 1730/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1874 - val_loss: 3.0546 - val_mae: 1.5966\n",
      "Epoch 1731/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1871 - val_loss: 3.0336 - val_mae: 1.5900\n",
      "Epoch 1732/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1883 - val_loss: 2.9869 - val_mae: 1.5752\n",
      "Epoch 1733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1951 - val_loss: 3.0737 - val_mae: 1.6026\n",
      "Epoch 1734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1901 - val_loss: 3.1657 - val_mae: 1.6310\n",
      "Epoch 1735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.1899 - val_loss: 3.1171 - val_mae: 1.6160\n",
      "Epoch 1736/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1883 - val_loss: 3.0394 - val_mae: 1.5918\n",
      "Epoch 1737/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1901 - val_loss: 2.9930 - val_mae: 1.5771\n",
      "Epoch 1738/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0550 - mae: 0.1920 - val_loss: 2.9106 - val_mae: 1.5507\n",
      "Epoch 1739/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1997 - val_loss: 2.8258 - val_mae: 1.5231\n",
      "Epoch 1740/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.2039 - val_loss: 2.8620 - val_mae: 1.5350\n",
      "Epoch 1741/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1922 - val_loss: 2.9606 - val_mae: 1.5669\n",
      "Epoch 1742/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.1953 - val_loss: 2.9897 - val_mae: 1.5761\n",
      "Epoch 1743/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0602 - mae: 0.1934 - val_loss: 2.9566 - val_mae: 1.5655\n",
      "Epoch 1744/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1883 - val_loss: 2.9519 - val_mae: 1.5639\n",
      "Epoch 1745/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0559 - mae: 0.1966 - val_loss: 2.9939 - val_mae: 1.5773\n",
      "Epoch 1746/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1920 - val_loss: 3.1392 - val_mae: 1.6228\n",
      "Epoch 1747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1897 - val_loss: 3.2627 - val_mae: 1.6605\n",
      "Epoch 1748/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2000 - val_loss: 3.2160 - val_mae: 1.6463\n",
      "Epoch 1749/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0616 - mae: 0.1919 - val_loss: 3.1780 - val_mae: 1.6346\n",
      "Epoch 1750/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0568 - mae: 0.1891 - val_loss: 3.2355 - val_mae: 1.6522\n",
      "Epoch 1751/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1861 - val_loss: 3.2081 - val_mae: 1.6438\n",
      "Epoch 1752/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.1953 - val_loss: 3.1744 - val_mae: 1.6335\n",
      "Epoch 1753/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.1986 - val_loss: 3.1078 - val_mae: 1.6130\n",
      "Epoch 1754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.2041 - val_loss: 3.0630 - val_mae: 1.5990\n",
      "Epoch 1755/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1992 - val_loss: 3.1319 - val_mae: 1.6205\n",
      "Epoch 1756/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1864 - val_loss: 3.2230 - val_mae: 1.6485\n",
      "Epoch 1757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0654 - mae: 0.1948 - val_loss: 3.2727 - val_mae: 1.6635\n",
      "Epoch 1758/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0759 - mae: 0.2173 - val_loss: 3.1850 - val_mae: 1.6369\n",
      "Epoch 1759/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0655 - mae: 0.1997 - val_loss: 2.9868 - val_mae: 1.5751\n",
      "Epoch 1760/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0555 - mae: 0.1897 - val_loss: 2.8114 - val_mae: 1.5183\n",
      "Epoch 1761/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0615 - mae: 0.2107 - val_loss: 2.7796 - val_mae: 1.5078\n",
      "Epoch 1762/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2051 - val_loss: 2.9006 - val_mae: 1.5476\n",
      "Epoch 1763/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.1914 - val_loss: 3.0542 - val_mae: 1.5966\n",
      "Epoch 1764/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0833 - mae: 0.2386 - val_loss: 3.0790 - val_mae: 1.6043\n",
      "Epoch 1765/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0823 - mae: 0.2358 - val_loss: 2.9613 - val_mae: 1.5670\n",
      "Epoch 1766/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1887 - val_loss: 2.7896 - val_mae: 1.5111\n",
      "Epoch 1767/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.2242 - val_loss: 2.7397 - val_mae: 1.4944\n",
      "Epoch 1768/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0895 - mae: 0.2592 - val_loss: 2.8710 - val_mae: 1.5378\n",
      "Epoch 1769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0707 - mae: 0.2269 - val_loss: 3.1485 - val_mae: 1.6257\n",
      "Epoch 1770/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1868 - val_loss: 3.4511 - val_mae: 1.7164\n",
      "Epoch 1771/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0915 - mae: 0.2396 - val_loss: 3.5642 - val_mae: 1.7491\n",
      "Epoch 1772/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1096 - mae: 0.2693 - val_loss: 3.4332 - val_mae: 1.7111\n",
      "Epoch 1773/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0745 - mae: 0.2074 - val_loss: 3.1813 - val_mae: 1.6357\n",
      "Epoch 1774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2005 - val_loss: 3.0156 - val_mae: 1.5842\n",
      "Epoch 1775/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0698 - mae: 0.2259 - val_loss: 3.0859 - val_mae: 1.6063\n",
      "Epoch 1776/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0587 - mae: 0.2006 - val_loss: 3.2927 - val_mae: 1.6696\n",
      "Epoch 1777/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0648 - mae: 0.1914 - val_loss: 3.4258 - val_mae: 1.7090\n",
      "Epoch 1778/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0852 - mae: 0.2300 - val_loss: 3.3455 - val_mae: 1.6854\n",
      "Epoch 1779/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0706 - mae: 0.2038 - val_loss: 3.1285 - val_mae: 1.6196\n",
      "Epoch 1780/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1919 - val_loss: 2.9265 - val_mae: 1.5558\n",
      "Epoch 1781/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0707 - mae: 0.2292 - val_loss: 2.8602 - val_mae: 1.5343\n",
      "Epoch 1782/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0737 - mae: 0.2349 - val_loss: 2.9392 - val_mae: 1.5600\n",
      "Epoch 1783/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1987 - val_loss: 3.0610 - val_mae: 1.5987\n",
      "Epoch 1784/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1878 - val_loss: 3.0929 - val_mae: 1.6087\n",
      "Epoch 1785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0645 - mae: 0.1980 - val_loss: 2.9795 - val_mae: 1.5730\n",
      "Epoch 1786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1852 - val_loss: 2.8069 - val_mae: 1.5170\n",
      "Epoch 1787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2021 - val_loss: 2.6808 - val_mae: 1.4748\n",
      "Epoch 1788/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0676 - mae: 0.2213 - val_loss: 2.6594 - val_mae: 1.4676\n",
      "Epoch 1789/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0628 - mae: 0.2093 - val_loss: 2.7961 - val_mae: 1.5136\n",
      "Epoch 1790/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.1945 - val_loss: 2.9213 - val_mae: 1.5546\n",
      "Epoch 1791/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0756 - mae: 0.2270 - val_loss: 2.7924 - val_mae: 1.5125\n",
      "Epoch 1792/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0658 - mae: 0.2078 - val_loss: 2.5559 - val_mae: 1.4319\n",
      "Epoch 1793/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0613 - mae: 0.1993 - val_loss: 2.4009 - val_mae: 1.3766\n",
      "Epoch 1794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0861 - mae: 0.2431 - val_loss: 2.4132 - val_mae: 1.3810\n",
      "Epoch 1795/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0869 - mae: 0.2455 - val_loss: 2.5476 - val_mae: 1.4290\n",
      "Epoch 1796/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0650 - mae: 0.2100 - val_loss: 2.7412 - val_mae: 1.4953\n",
      "Epoch 1797/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0581 - mae: 0.1950 - val_loss: 2.8870 - val_mae: 1.5434\n",
      "Epoch 1798/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2009 - val_loss: 2.9503 - val_mae: 1.5637\n",
      "Epoch 1799/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0585 - mae: 0.1975 - val_loss: 2.8847 - val_mae: 1.5425\n",
      "Epoch 1800/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1921 - val_loss: 2.7100 - val_mae: 1.4846\n",
      "Epoch 1801/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0880 - mae: 0.2548 - val_loss: 2.7278 - val_mae: 1.4906\n",
      "Epoch 1802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0971 - mae: 0.2687 - val_loss: 3.0471 - val_mae: 1.5943\n",
      "Epoch 1803/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0617 - mae: 0.2087 - val_loss: 3.4277 - val_mae: 1.7097\n",
      "Epoch 1804/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0807 - mae: 0.2191 - val_loss: 3.4754 - val_mae: 1.7236\n",
      "Epoch 1805/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0799 - mae: 0.2169 - val_loss: 3.2373 - val_mae: 1.6529\n",
      "Epoch 1806/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0591 - mae: 0.1934 - val_loss: 2.9761 - val_mae: 1.5717\n",
      "Epoch 1807/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0872 - mae: 0.2527 - val_loss: 2.8838 - val_mae: 1.5420\n",
      "Epoch 1808/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0974 - mae: 0.2699 - val_loss: 3.0569 - val_mae: 1.5973\n",
      "Epoch 1809/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0626 - mae: 0.2100 - val_loss: 3.3312 - val_mae: 1.6812\n",
      "Epoch 1810/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0746 - mae: 0.2087 - val_loss: 3.3655 - val_mae: 1.6914\n",
      "Epoch 1811/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0817 - mae: 0.2193 - val_loss: 3.1230 - val_mae: 1.6180\n",
      "Epoch 1812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1967 - val_loss: 2.8414 - val_mae: 1.5284\n",
      "Epoch 1813/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0668 - mae: 0.2217 - val_loss: 2.7337 - val_mae: 1.4927\n",
      "Epoch 1814/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0652 - mae: 0.2180 - val_loss: 2.8132 - val_mae: 1.5193\n",
      "Epoch 1815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1983 - val_loss: 2.8504 - val_mae: 1.5316\n",
      "Epoch 1816/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0658 - mae: 0.2106 - val_loss: 2.7796 - val_mae: 1.5083\n",
      "Epoch 1817/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0694 - mae: 0.2188 - val_loss: 2.6554 - val_mae: 1.4665\n",
      "Epoch 1818/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0636 - mae: 0.2082 - val_loss: 2.4944 - val_mae: 1.4104\n",
      "Epoch 1819/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0626 - mae: 0.2016 - val_loss: 2.3619 - val_mae: 1.3625\n",
      "Epoch 1820/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0856 - mae: 0.2398 - val_loss: 2.4137 - val_mae: 1.3814\n",
      "Epoch 1821/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0786 - mae: 0.2299 - val_loss: 2.6315 - val_mae: 1.4583\n",
      "Epoch 1822/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.1975 - val_loss: 2.8103 - val_mae: 1.5185\n",
      "Epoch 1823/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.2008 - val_loss: 2.8654 - val_mae: 1.5366\n",
      "Epoch 1824/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0615 - mae: 0.1976 - val_loss: 2.8357 - val_mae: 1.5269\n",
      "Epoch 1825/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1901 - val_loss: 2.8153 - val_mae: 1.5201\n",
      "Epoch 1826/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1912 - val_loss: 2.7846 - val_mae: 1.5099\n",
      "Epoch 1827/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.2069 - val_loss: 2.7481 - val_mae: 1.4977\n",
      "Epoch 1828/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.2236 - val_loss: 2.8324 - val_mae: 1.5256\n",
      "Epoch 1829/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.2048 - val_loss: 3.0125 - val_mae: 1.5837\n",
      "Epoch 1830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1861 - val_loss: 3.1037 - val_mae: 1.6123\n",
      "Epoch 1831/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0607 - mae: 0.1901 - val_loss: 3.0179 - val_mae: 1.5854\n",
      "Epoch 1832/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1878 - val_loss: 2.8940 - val_mae: 1.5458\n",
      "Epoch 1833/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1898 - val_loss: 2.7983 - val_mae: 1.5144\n",
      "Epoch 1834/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0576 - mae: 0.1994 - val_loss: 2.7787 - val_mae: 1.5080\n",
      "Epoch 1835/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1951 - val_loss: 2.8621 - val_mae: 1.5355\n",
      "Epoch 1836/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0564 - mae: 0.1901 - val_loss: 2.8862 - val_mae: 1.5433\n",
      "Epoch 1837/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0581 - mae: 0.1934 - val_loss: 2.7839 - val_mae: 1.5097\n",
      "Epoch 1838/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0543 - mae: 0.1893 - val_loss: 2.6489 - val_mae: 1.4641\n",
      "Epoch 1839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0642 - mae: 0.2142 - val_loss: 2.6179 - val_mae: 1.4535\n",
      "Epoch 1840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0671 - mae: 0.2198 - val_loss: 2.7353 - val_mae: 1.4934\n",
      "Epoch 1841/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0563 - mae: 0.1937 - val_loss: 2.8563 - val_mae: 1.5335\n",
      "Epoch 1842/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0597 - mae: 0.1963 - val_loss: 2.8762 - val_mae: 1.5400\n",
      "Epoch 1843/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0622 - mae: 0.2016 - val_loss: 2.8076 - val_mae: 1.5174\n",
      "Epoch 1844/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1919 - val_loss: 2.7200 - val_mae: 1.4882\n",
      "Epoch 1845/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.2030 - val_loss: 2.7029 - val_mae: 1.4824\n",
      "Epoch 1846/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0647 - mae: 0.2169 - val_loss: 2.8163 - val_mae: 1.5202\n",
      "Epoch 1847/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0562 - mae: 0.1993 - val_loss: 3.0174 - val_mae: 1.5851\n",
      "Epoch 1848/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1878 - val_loss: 3.1718 - val_mae: 1.6332\n",
      "Epoch 1849/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0720 - mae: 0.2120 - val_loss: 3.1134 - val_mae: 1.6151\n",
      "Epoch 1850/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0582 - mae: 0.1898 - val_loss: 2.8854 - val_mae: 1.5427\n",
      "Epoch 1851/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.2136 - val_loss: 2.7921 - val_mae: 1.5120\n",
      "Epoch 1852/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0895 - mae: 0.2594 - val_loss: 2.8737 - val_mae: 1.5388\n",
      "Epoch 1853/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0834 - mae: 0.2501 - val_loss: 3.0620 - val_mae: 1.5989\n",
      "Epoch 1854/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.2067 - val_loss: 3.3133 - val_mae: 1.6757\n",
      "Epoch 1855/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0632 - mae: 0.1942 - val_loss: 3.4303 - val_mae: 1.7104\n",
      "Epoch 1856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0721 - mae: 0.2044 - val_loss: 3.3712 - val_mae: 1.6930\n",
      "Epoch 1857/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0662 - mae: 0.1941 - val_loss: 3.2897 - val_mae: 1.6687\n",
      "Epoch 1858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1881 - val_loss: 3.2193 - val_mae: 1.6474\n",
      "Epoch 1859/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.1891 - val_loss: 3.1824 - val_mae: 1.6362\n",
      "Epoch 1860/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1889 - val_loss: 3.2058 - val_mae: 1.6434\n",
      "Epoch 1861/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.1865 - val_loss: 3.2003 - val_mae: 1.6417\n",
      "Epoch 1862/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0594 - mae: 0.1860 - val_loss: 3.1090 - val_mae: 1.6136\n",
      "Epoch 1863/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.1893 - val_loss: 3.0826 - val_mae: 1.6054\n",
      "Epoch 1864/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1931 - val_loss: 3.1320 - val_mae: 1.6207\n",
      "Epoch 1865/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1925 - val_loss: 3.1752 - val_mae: 1.6340\n",
      "Epoch 1866/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1921 - val_loss: 3.1489 - val_mae: 1.6259\n",
      "Epoch 1867/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1929 - val_loss: 3.0218 - val_mae: 1.5863\n",
      "Epoch 1868/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.2049 - val_loss: 2.9125 - val_mae: 1.5514\n",
      "Epoch 1869/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0620 - mae: 0.2119 - val_loss: 2.8865 - val_mae: 1.5430\n",
      "Epoch 1870/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.2054 - val_loss: 2.9754 - val_mae: 1.5717\n",
      "Epoch 1871/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0560 - mae: 0.1925 - val_loss: 3.0060 - val_mae: 1.5814\n",
      "Epoch 1872/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1891 - val_loss: 2.8977 - val_mae: 1.5468\n",
      "Epoch 1873/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0549 - mae: 0.1913 - val_loss: 2.8480 - val_mae: 1.5306\n",
      "Epoch 1874/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1933 - val_loss: 2.8984 - val_mae: 1.5470\n",
      "Epoch 1875/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1889 - val_loss: 2.9361 - val_mae: 1.5592\n",
      "Epoch 1876/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0549 - mae: 0.1868 - val_loss: 2.9429 - val_mae: 1.5614\n",
      "Epoch 1877/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1870 - val_loss: 2.9106 - val_mae: 1.5510\n",
      "Epoch 1878/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1865 - val_loss: 2.7981 - val_mae: 1.5142\n",
      "Epoch 1879/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1946 - val_loss: 2.7079 - val_mae: 1.4841\n",
      "Epoch 1880/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0591 - mae: 0.2032 - val_loss: 2.7532 - val_mae: 1.4994\n",
      "Epoch 1881/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1944 - val_loss: 2.8440 - val_mae: 1.5294\n",
      "Epoch 1882/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.1987 - val_loss: 2.8483 - val_mae: 1.5308\n",
      "Epoch 1883/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0634 - mae: 0.2026 - val_loss: 2.7521 - val_mae: 1.4990\n",
      "Epoch 1884/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0556 - mae: 0.1918 - val_loss: 2.5711 - val_mae: 1.4372\n",
      "Epoch 1885/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0651 - mae: 0.2133 - val_loss: 2.4479 - val_mae: 1.3935\n",
      "Epoch 1886/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0933 - mae: 0.2553 - val_loss: 2.5541 - val_mae: 1.4312\n",
      "Epoch 1887/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0697 - mae: 0.2220 - val_loss: 2.9031 - val_mae: 1.5486\n",
      "Epoch 1888/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0616 - mae: 0.2034 - val_loss: 3.2137 - val_mae: 1.6460\n",
      "Epoch 1889/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1086 - mae: 0.2724 - val_loss: 3.1965 - val_mae: 1.6407\n",
      "Epoch 1890/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0920 - mae: 0.2447 - val_loss: 2.9888 - val_mae: 1.5759\n",
      "Epoch 1891/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0590 - mae: 0.1998 - val_loss: 2.8507 - val_mae: 1.5314\n",
      "Epoch 1892/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.2024 - val_loss: 2.8171 - val_mae: 1.5203\n",
      "Epoch 1893/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0608 - mae: 0.2107 - val_loss: 2.8623 - val_mae: 1.5351\n",
      "Epoch 1894/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0576 - mae: 0.2023 - val_loss: 2.9983 - val_mae: 1.5789\n",
      "Epoch 1895/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1933 - val_loss: 3.1018 - val_mae: 1.6114\n",
      "Epoch 1896/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1965 - val_loss: 3.0331 - val_mae: 1.5899\n",
      "Epoch 1897/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1898 - val_loss: 2.8432 - val_mae: 1.5289\n",
      "Epoch 1898/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.2128 - val_loss: 2.7617 - val_mae: 1.5020\n",
      "Epoch 1899/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0673 - mae: 0.2219 - val_loss: 2.8695 - val_mae: 1.5375\n",
      "Epoch 1900/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0577 - mae: 0.2023 - val_loss: 2.9290 - val_mae: 1.5568\n",
      "Epoch 1901/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1888 - val_loss: 2.8910 - val_mae: 1.5446\n",
      "Epoch 1902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0541 - mae: 0.1887 - val_loss: 2.8580 - val_mae: 1.5339\n",
      "Epoch 1903/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1901 - val_loss: 2.8829 - val_mae: 1.5420\n",
      "Epoch 1904/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1876 - val_loss: 2.9661 - val_mae: 1.5688\n",
      "Epoch 1905/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.1924 - val_loss: 3.0164 - val_mae: 1.5848\n",
      "Epoch 1906/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0640 - mae: 0.2009 - val_loss: 2.9867 - val_mae: 1.5754\n",
      "Epoch 1907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1897 - val_loss: 2.8904 - val_mae: 1.5444\n",
      "Epoch 1908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1879 - val_loss: 2.8182 - val_mae: 1.5208\n",
      "Epoch 1909/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.1991 - val_loss: 2.8002 - val_mae: 1.5148\n",
      "Epoch 1910/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0621 - mae: 0.2104 - val_loss: 2.8857 - val_mae: 1.5428\n",
      "Epoch 1911/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1970 - val_loss: 3.0816 - val_mae: 1.6051\n",
      "Epoch 1912/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1831 - val_loss: 3.2516 - val_mae: 1.6573\n",
      "Epoch 1913/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0692 - mae: 0.2016 - val_loss: 3.1846 - val_mae: 1.6369\n",
      "Epoch 1914/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.1884 - val_loss: 3.0008 - val_mae: 1.5796\n",
      "Epoch 1915/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.2058 - val_loss: 2.9924 - val_mae: 1.5769\n",
      "Epoch 1916/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.2048 - val_loss: 3.1040 - val_mae: 1.6120\n",
      "Epoch 1917/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0559 - mae: 0.1938 - val_loss: 3.1835 - val_mae: 1.6365\n",
      "Epoch 1918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.1941 - val_loss: 3.2512 - val_mae: 1.6571\n",
      "Epoch 1919/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0685 - mae: 0.2035 - val_loss: 3.2707 - val_mae: 1.6630\n",
      "Epoch 1920/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0700 - mae: 0.2060 - val_loss: 3.0782 - val_mae: 1.6039\n",
      "Epoch 1921/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1936 - val_loss: 2.8085 - val_mae: 1.5173\n",
      "Epoch 1922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0909 - mae: 0.2564 - val_loss: 2.7681 - val_mae: 1.5039\n",
      "Epoch 1923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1016 - mae: 0.2735 - val_loss: 2.9828 - val_mae: 1.5738\n",
      "Epoch 1924/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0628 - mae: 0.2130 - val_loss: 3.2404 - val_mae: 1.6538\n",
      "Epoch 1925/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0635 - mae: 0.1949 - val_loss: 3.3795 - val_mae: 1.6954\n",
      "Epoch 1926/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0910 - mae: 0.2384 - val_loss: 3.2383 - val_mae: 1.6532\n",
      "Epoch 1927/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0668 - mae: 0.2016 - val_loss: 2.8973 - val_mae: 1.5464\n",
      "Epoch 1928/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.2089 - val_loss: 2.6525 - val_mae: 1.4650\n",
      "Epoch 1929/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1053 - mae: 0.2817 - val_loss: 2.6393 - val_mae: 1.4605\n",
      "Epoch 1930/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0989 - mae: 0.2743 - val_loss: 2.9202 - val_mae: 1.5539\n",
      "Epoch 1931/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1848 - val_loss: 3.3441 - val_mae: 1.6852\n",
      "Epoch 1932/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0994 - mae: 0.2604 - val_loss: 3.5485 - val_mae: 1.7449\n",
      "Epoch 1933/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1567 - mae: 0.3406 - val_loss: 3.2440 - val_mae: 1.6551\n",
      "Epoch 1934/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0761 - mae: 0.2170 - val_loss: 2.7661 - val_mae: 1.5034\n",
      "Epoch 1935/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0830 - mae: 0.2479 - val_loss: 2.6439 - val_mae: 1.4621\n",
      "Epoch 1936/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1093 - mae: 0.2869 - val_loss: 2.8872 - val_mae: 1.5432\n",
      "Epoch 1937/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.2090 - val_loss: 3.2865 - val_mae: 1.6678\n",
      "Epoch 1938/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0717 - mae: 0.2093 - val_loss: 3.5562 - val_mae: 1.7469\n",
      "Epoch 1939/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1181 - mae: 0.2832 - val_loss: 3.4444 - val_mae: 1.7145\n",
      "Epoch 1940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0829 - mae: 0.2269 - val_loss: 3.0336 - val_mae: 1.5900\n",
      "Epoch 1941/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2037 - val_loss: 2.7147 - val_mae: 1.4862\n",
      "Epoch 1942/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1005 - mae: 0.2762 - val_loss: 2.6988 - val_mae: 1.4808\n",
      "Epoch 1943/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0888 - mae: 0.2597 - val_loss: 2.9115 - val_mae: 1.5512\n",
      "Epoch 1944/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1856 - val_loss: 3.1878 - val_mae: 1.6382\n",
      "Epoch 1945/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0856 - mae: 0.2387 - val_loss: 3.2701 - val_mae: 1.6632\n",
      "Epoch 1946/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1033 - mae: 0.2669 - val_loss: 2.9991 - val_mae: 1.5794\n",
      "Epoch 1947/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - mae: 0.1952 - val_loss: 2.6597 - val_mae: 1.4678\n",
      "Epoch 1948/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0715 - mae: 0.2301 - val_loss: 2.5756 - val_mae: 1.4388\n",
      "Epoch 1949/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0800 - mae: 0.2441 - val_loss: 2.7261 - val_mae: 1.4903\n",
      "Epoch 1950/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0586 - mae: 0.1992 - val_loss: 2.9275 - val_mae: 1.5566\n",
      "Epoch 1951/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0591 - mae: 0.1923 - val_loss: 3.0102 - val_mae: 1.5830\n",
      "Epoch 1952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.1980 - val_loss: 2.9460 - val_mae: 1.5625\n",
      "Epoch 1953/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0577 - mae: 0.1901 - val_loss: 2.8901 - val_mae: 1.5444\n",
      "Epoch 1954/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0548 - mae: 0.1886 - val_loss: 2.8537 - val_mae: 1.5326\n",
      "Epoch 1955/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1930 - val_loss: 2.8109 - val_mae: 1.5185\n",
      "Epoch 1956/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.2040 - val_loss: 2.8554 - val_mae: 1.5331\n",
      "Epoch 1957/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0577 - mae: 0.2009 - val_loss: 2.9655 - val_mae: 1.5686\n",
      "Epoch 1958/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0548 - mae: 0.1898 - val_loss: 3.0993 - val_mae: 1.6107\n",
      "Epoch 1959/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1859 - val_loss: 3.1823 - val_mae: 1.6363\n",
      "Epoch 1960/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0595 - mae: 0.1898 - val_loss: 3.1250 - val_mae: 1.6187\n",
      "Epoch 1961/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1868 - val_loss: 2.9598 - val_mae: 1.5667\n",
      "Epoch 1962/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0564 - mae: 0.1979 - val_loss: 2.8225 - val_mae: 1.5222\n",
      "Epoch 1963/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0633 - mae: 0.2151 - val_loss: 2.8519 - val_mae: 1.5318\n",
      "Epoch 1964/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.2003 - val_loss: 2.9651 - val_mae: 1.5685\n",
      "Epoch 1965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1936 - val_loss: 2.9999 - val_mae: 1.5796\n",
      "Epoch 1966/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1966 - val_loss: 2.9457 - val_mae: 1.5623\n",
      "Epoch 1967/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1972 - val_loss: 2.9252 - val_mae: 1.5557\n",
      "Epoch 1968/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1941 - val_loss: 2.9610 - val_mae: 1.5672\n",
      "Epoch 1969/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0566 - mae: 0.1938 - val_loss: 2.9248 - val_mae: 1.5556\n",
      "Epoch 1970/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1916 - val_loss: 2.8888 - val_mae: 1.5439\n",
      "Epoch 1971/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0545 - mae: 0.1913 - val_loss: 2.8851 - val_mae: 1.5427\n",
      "Epoch 1972/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1902 - val_loss: 2.8636 - val_mae: 1.5358\n",
      "Epoch 1973/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1906 - val_loss: 2.8497 - val_mae: 1.5313\n",
      "Epoch 1974/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1898 - val_loss: 2.7694 - val_mae: 1.5048\n",
      "Epoch 1975/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1955 - val_loss: 2.7154 - val_mae: 1.4868\n",
      "Epoch 1976/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1958 - val_loss: 2.7801 - val_mae: 1.5084\n",
      "Epoch 1977/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0550 - mae: 0.1890 - val_loss: 2.8511 - val_mae: 1.5318\n",
      "Epoch 1978/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0567 - mae: 0.1902 - val_loss: 2.9243 - val_mae: 1.5556\n",
      "Epoch 1979/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1956 - val_loss: 2.9667 - val_mae: 1.5691\n",
      "Epoch 1980/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1948 - val_loss: 2.8587 - val_mae: 1.5342\n",
      "Epoch 1981/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0534 - mae: 0.1873 - val_loss: 2.6784 - val_mae: 1.4741\n",
      "Epoch 1982/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0727 - mae: 0.2327 - val_loss: 2.6349 - val_mae: 1.4593\n",
      "Epoch 1983/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0793 - mae: 0.2434 - val_loss: 2.7821 - val_mae: 1.5090\n",
      "Epoch 1984/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0555 - mae: 0.1973 - val_loss: 3.0562 - val_mae: 1.5974\n",
      "Epoch 1985/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0691 - mae: 0.2110 - val_loss: 3.1669 - val_mae: 1.6318\n",
      "Epoch 1986/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0860 - mae: 0.2375 - val_loss: 2.9762 - val_mae: 1.5721\n",
      "Epoch 1987/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0615 - mae: 0.2043 - val_loss: 2.7794 - val_mae: 1.5081\n",
      "Epoch 1988/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0563 - mae: 0.1978 - val_loss: 2.6805 - val_mae: 1.4749\n",
      "Epoch 1989/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0660 - mae: 0.2187 - val_loss: 2.6357 - val_mae: 1.4596\n",
      "Epoch 1990/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0706 - mae: 0.2259 - val_loss: 2.6487 - val_mae: 1.4641\n",
      "Epoch 1991/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0654 - mae: 0.2158 - val_loss: 2.7535 - val_mae: 1.4996\n",
      "Epoch 1992/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0551 - mae: 0.1931 - val_loss: 2.9278 - val_mae: 1.5568\n",
      "Epoch 1993/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.1977 - val_loss: 2.9569 - val_mae: 1.5661\n",
      "Epoch 1994/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0620 - mae: 0.1981 - val_loss: 2.8014 - val_mae: 1.5155\n",
      "Epoch 1995/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0562 - mae: 0.1936 - val_loss: 2.7122 - val_mae: 1.4857\n",
      "Epoch 1996/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0601 - mae: 0.2065 - val_loss: 2.7740 - val_mae: 1.5064\n",
      "Epoch 1997/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.1986 - val_loss: 2.8919 - val_mae: 1.5451\n",
      "Epoch 1998/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1871 - val_loss: 2.9808 - val_mae: 1.5737\n",
      "Epoch 1999/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1874 - val_loss: 3.0100 - val_mae: 1.5829\n",
      "Epoch 2000/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0558 - mae: 0.1870 - val_loss: 2.9592 - val_mae: 1.5667\n",
      "Epoch 2001/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1871 - val_loss: 2.8627 - val_mae: 1.5355\n",
      "Epoch 2002/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0568 - mae: 0.1985 - val_loss: 2.8715 - val_mae: 1.5384\n",
      "Epoch 2003/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0546 - mae: 0.1912 - val_loss: 2.9928 - val_mae: 1.5774\n",
      "Epoch 2004/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1916 - val_loss: 3.0991 - val_mae: 1.6108\n",
      "Epoch 2005/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0639 - mae: 0.1999 - val_loss: 3.0809 - val_mae: 1.6051\n",
      "Epoch 2006/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0599 - mae: 0.1933 - val_loss: 2.9227 - val_mae: 1.5549\n",
      "Epoch 2007/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0541 - mae: 0.1920 - val_loss: 2.7589 - val_mae: 1.5012\n",
      "Epoch 2008/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0693 - mae: 0.2242 - val_loss: 2.8107 - val_mae: 1.5184\n",
      "Epoch 2009/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.2079 - val_loss: 2.9896 - val_mae: 1.5764\n",
      "Epoch 2010/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0553 - mae: 0.1859 - val_loss: 3.0899 - val_mae: 1.6080\n",
      "Epoch 2011/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0648 - mae: 0.1995 - val_loss: 3.0681 - val_mae: 1.6012\n",
      "Epoch 2012/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0657 - mae: 0.2032 - val_loss: 2.9329 - val_mae: 1.5584\n",
      "Epoch 2013/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0565 - mae: 0.1883 - val_loss: 2.7948 - val_mae: 1.5133\n",
      "Epoch 2014/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0544 - mae: 0.1888 - val_loss: 2.6794 - val_mae: 1.4746\n",
      "Epoch 2015/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0606 - mae: 0.2069 - val_loss: 2.6572 - val_mae: 1.4671\n",
      "Epoch 2016/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0607 - mae: 0.2060 - val_loss: 2.7457 - val_mae: 1.4970\n",
      "Epoch 2017/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0552 - mae: 0.1913 - val_loss: 2.8437 - val_mae: 1.5295\n",
      "Epoch 2018/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1896 - val_loss: 2.8679 - val_mae: 1.5374\n",
      "Epoch 2019/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0576 - mae: 0.1922 - val_loss: 2.8473 - val_mae: 1.5306\n",
      "Epoch 2020/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1904 - val_loss: 2.8651 - val_mae: 1.5364\n",
      "Epoch 2021/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1885 - val_loss: 2.9154 - val_mae: 1.5527\n",
      "Epoch 2022/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1896 - val_loss: 2.9647 - val_mae: 1.5685\n",
      "Epoch 2023/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0579 - mae: 0.1902 - val_loss: 2.9275 - val_mae: 1.5566\n",
      "Epoch 2024/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1867 - val_loss: 2.8304 - val_mae: 1.5250\n",
      "Epoch 2025/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1950 - val_loss: 2.8141 - val_mae: 1.5196\n",
      "Epoch 2026/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0563 - mae: 0.1968 - val_loss: 2.8742 - val_mae: 1.5393\n",
      "Epoch 2027/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1889 - val_loss: 2.9315 - val_mae: 1.5578\n",
      "Epoch 2028/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1887 - val_loss: 2.8713 - val_mae: 1.5383\n",
      "Epoch 2029/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1889 - val_loss: 2.7202 - val_mae: 1.4883\n",
      "Epoch 2030/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1991 - val_loss: 2.6143 - val_mae: 1.4523\n",
      "Epoch 2031/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0616 - mae: 0.2075 - val_loss: 2.6436 - val_mae: 1.4624\n",
      "Epoch 2032/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1958 - val_loss: 2.7255 - val_mae: 1.4902\n",
      "Epoch 2033/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.2017 - val_loss: 2.7059 - val_mae: 1.4836\n",
      "Epoch 2034/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1982 - val_loss: 2.6119 - val_mae: 1.4516\n",
      "Epoch 2035/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1944 - val_loss: 2.5438 - val_mae: 1.4279\n",
      "Epoch 2036/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1993 - val_loss: 2.5318 - val_mae: 1.4237\n",
      "Epoch 2037/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.1994 - val_loss: 2.5405 - val_mae: 1.4267\n",
      "Epoch 2038/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0606 - mae: 0.1972 - val_loss: 2.5692 - val_mae: 1.4368\n",
      "Epoch 2039/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1946 - val_loss: 2.6300 - val_mae: 1.4579\n",
      "Epoch 2040/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.1955 - val_loss: 2.6209 - val_mae: 1.4547\n",
      "Epoch 2041/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0607 - mae: 0.1962 - val_loss: 2.6475 - val_mae: 1.4639\n",
      "Epoch 2042/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1928 - val_loss: 2.8403 - val_mae: 1.5284\n",
      "Epoch 2043/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0652 - mae: 0.2063 - val_loss: 3.0374 - val_mae: 1.5916\n",
      "Epoch 2044/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0770 - mae: 0.2275 - val_loss: 3.0868 - val_mae: 1.6069\n",
      "Epoch 2045/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0663 - mae: 0.2041 - val_loss: 2.9874 - val_mae: 1.5755\n",
      "Epoch 2046/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1887 - val_loss: 2.8493 - val_mae: 1.5309\n",
      "Epoch 2047/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0705 - mae: 0.2288 - val_loss: 2.8313 - val_mae: 1.5250\n",
      "Epoch 2048/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0747 - mae: 0.2366 - val_loss: 3.0498 - val_mae: 1.5952\n",
      "Epoch 2049/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1918 - val_loss: 3.3779 - val_mae: 1.6951\n",
      "Epoch 2050/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0795 - mae: 0.2183 - val_loss: 3.4761 - val_mae: 1.7239\n",
      "Epoch 2051/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0971 - mae: 0.2519 - val_loss: 3.2525 - val_mae: 1.6577\n",
      "Epoch 2052/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0670 - mae: 0.1988 - val_loss: 2.8891 - val_mae: 1.5440\n",
      "Epoch 2053/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0554 - mae: 0.1944 - val_loss: 2.6146 - val_mae: 1.4522\n",
      "Epoch 2054/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0821 - mae: 0.2470 - val_loss: 2.5925 - val_mae: 1.4447\n",
      "Epoch 2055/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0670 - mae: 0.2202 - val_loss: 2.8547 - val_mae: 1.5330\n",
      "Epoch 2056/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0648 - mae: 0.2067 - val_loss: 3.0443 - val_mae: 1.5938\n",
      "Epoch 2057/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0964 - mae: 0.2599 - val_loss: 2.9745 - val_mae: 1.5717\n",
      "Epoch 2058/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0761 - mae: 0.2268 - val_loss: 2.8211 - val_mae: 1.5219\n",
      "Epoch 2059/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1898 - val_loss: 2.7135 - val_mae: 1.4860\n",
      "Epoch 2060/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.2123 - val_loss: 2.7997 - val_mae: 1.5148\n",
      "Epoch 2061/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0615 - mae: 0.2079 - val_loss: 3.0025 - val_mae: 1.5804\n",
      "Epoch 2062/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1858 - val_loss: 3.1823 - val_mae: 1.6364\n",
      "Epoch 2063/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.1891 - val_loss: 3.3073 - val_mae: 1.6742\n",
      "Epoch 2064/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0688 - mae: 0.2000 - val_loss: 3.2638 - val_mae: 1.6611\n",
      "Epoch 2065/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1848 - val_loss: 3.0842 - val_mae: 1.6060\n",
      "Epoch 2066/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0579 - mae: 0.1978 - val_loss: 2.9015 - val_mae: 1.5479\n",
      "Epoch 2067/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0755 - mae: 0.2356 - val_loss: 2.7974 - val_mae: 1.5139\n",
      "Epoch 2068/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0880 - mae: 0.2585 - val_loss: 2.9269 - val_mae: 1.5562\n",
      "Epoch 2069/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0626 - mae: 0.2094 - val_loss: 3.1598 - val_mae: 1.6295\n",
      "Epoch 2070/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0638 - mae: 0.1956 - val_loss: 3.1638 - val_mae: 1.6308\n",
      "Epoch 2071/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0749 - mae: 0.2191 - val_loss: 3.0096 - val_mae: 1.5828\n",
      "Epoch 2072/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0646 - mae: 0.2036 - val_loss: 2.8470 - val_mae: 1.5305\n",
      "Epoch 2073/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1933 - val_loss: 2.7227 - val_mae: 1.4892\n",
      "Epoch 2074/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0554 - mae: 0.1967 - val_loss: 2.5844 - val_mae: 1.4420\n",
      "Epoch 2075/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.2152 - val_loss: 2.5568 - val_mae: 1.4324\n",
      "Epoch 2076/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0622 - mae: 0.2060 - val_loss: 2.6607 - val_mae: 1.4684\n",
      "Epoch 2077/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2023 - val_loss: 2.7723 - val_mae: 1.5061\n",
      "Epoch 2078/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0734 - mae: 0.2240 - val_loss: 2.8136 - val_mae: 1.5197\n",
      "Epoch 2079/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0736 - mae: 0.2241 - val_loss: 2.7378 - val_mae: 1.4945\n",
      "Epoch 2080/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1983 - val_loss: 2.6742 - val_mae: 1.4730\n",
      "Epoch 2081/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1911 - val_loss: 2.5956 - val_mae: 1.4460\n",
      "Epoch 2082/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.2154 - val_loss: 2.5574 - val_mae: 1.4326\n",
      "Epoch 2083/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0763 - mae: 0.2345 - val_loss: 2.6672 - val_mae: 1.4705\n",
      "Epoch 2084/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0638 - mae: 0.2130 - val_loss: 2.8280 - val_mae: 1.5244\n",
      "Epoch 2085/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1864 - val_loss: 2.9111 - val_mae: 1.5514\n",
      "Epoch 2086/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1891 - val_loss: 2.8942 - val_mae: 1.5460\n",
      "Epoch 2087/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0567 - mae: 0.1901 - val_loss: 2.8900 - val_mae: 1.5446\n",
      "Epoch 2088/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1879 - val_loss: 2.9498 - val_mae: 1.5638\n",
      "Epoch 2089/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1905 - val_loss: 3.0291 - val_mae: 1.5890\n",
      "Epoch 2090/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1926 - val_loss: 3.1160 - val_mae: 1.6161\n",
      "Epoch 2091/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.1932 - val_loss: 3.1081 - val_mae: 1.6136\n",
      "Epoch 2092/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0568 - mae: 0.1875 - val_loss: 3.0233 - val_mae: 1.5870\n",
      "Epoch 2093/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.2007 - val_loss: 3.0493 - val_mae: 1.5951\n",
      "Epoch 2094/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.2018 - val_loss: 3.1732 - val_mae: 1.6335\n",
      "Epoch 2095/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.1935 - val_loss: 3.2028 - val_mae: 1.6426\n",
      "Epoch 2096/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0585 - mae: 0.1928 - val_loss: 3.0372 - val_mae: 1.5913\n",
      "Epoch 2097/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0596 - mae: 0.2050 - val_loss: 2.9051 - val_mae: 1.5492\n",
      "Epoch 2098/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0615 - mae: 0.2097 - val_loss: 2.9907 - val_mae: 1.5767\n",
      "Epoch 2099/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1999 - val_loss: 3.1057 - val_mae: 1.6128\n",
      "Epoch 2100/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0580 - mae: 0.1940 - val_loss: 3.1342 - val_mae: 1.6216\n",
      "Epoch 2101/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0612 - mae: 0.1962 - val_loss: 3.0365 - val_mae: 1.5912\n",
      "Epoch 2102/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1898 - val_loss: 2.8653 - val_mae: 1.5364\n",
      "Epoch 2103/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0573 - mae: 0.1979 - val_loss: 2.8289 - val_mae: 1.5244\n",
      "Epoch 2104/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0611 - mae: 0.2097 - val_loss: 2.9515 - val_mae: 1.5642\n",
      "Epoch 2105/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0567 - mae: 0.1982 - val_loss: 3.1772 - val_mae: 1.6348\n",
      "Epoch 2106/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0573 - mae: 0.1842 - val_loss: 3.4220 - val_mae: 1.7082\n",
      "Epoch 2107/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0762 - mae: 0.2129 - val_loss: 3.4624 - val_mae: 1.7199\n",
      "Epoch 2108/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0788 - mae: 0.2147 - val_loss: 3.3206 - val_mae: 1.6781\n",
      "Epoch 2109/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0637 - mae: 0.1905 - val_loss: 3.1611 - val_mae: 1.6298\n",
      "Epoch 2110/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0583 - mae: 0.1911 - val_loss: 3.0052 - val_mae: 1.5812\n",
      "Epoch 2111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2171 - val_loss: 2.9096 - val_mae: 1.5506\n",
      "Epoch 2112/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0713 - mae: 0.2292 - val_loss: 2.9697 - val_mae: 1.5700\n",
      "Epoch 2113/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.2092 - val_loss: 3.0510 - val_mae: 1.5957\n",
      "Epoch 2114/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1865 - val_loss: 3.0326 - val_mae: 1.5899\n",
      "Epoch 2115/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1853 - val_loss: 2.9991 - val_mae: 1.5794\n",
      "Epoch 2116/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1845 - val_loss: 3.0116 - val_mae: 1.5833\n",
      "Epoch 2117/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1841 - val_loss: 2.9720 - val_mae: 1.5708\n",
      "Epoch 2118/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1867 - val_loss: 2.9144 - val_mae: 1.5524\n",
      "Epoch 2119/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0548 - mae: 0.1867 - val_loss: 2.8994 - val_mae: 1.5476\n",
      "Epoch 2120/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1912 - val_loss: 2.8047 - val_mae: 1.5166\n",
      "Epoch 2121/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1907 - val_loss: 2.6626 - val_mae: 1.4689\n",
      "Epoch 2122/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.2007 - val_loss: 2.6056 - val_mae: 1.4493\n",
      "Epoch 2123/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.2049 - val_loss: 2.6191 - val_mae: 1.4540\n",
      "Epoch 2124/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.2054 - val_loss: 2.5536 - val_mae: 1.4313\n",
      "Epoch 2125/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0629 - mae: 0.2075 - val_loss: 2.4399 - val_mae: 1.3909\n",
      "Epoch 2126/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0797 - mae: 0.2311 - val_loss: 2.4801 - val_mae: 1.4053\n",
      "Epoch 2127/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0712 - mae: 0.2184 - val_loss: 2.6800 - val_mae: 1.4749\n",
      "Epoch 2128/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0594 - mae: 0.2051 - val_loss: 2.8657 - val_mae: 1.5367\n",
      "Epoch 2129/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0821 - mae: 0.2368 - val_loss: 2.8580 - val_mae: 1.5342\n",
      "Epoch 2130/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0762 - mae: 0.2274 - val_loss: 2.6526 - val_mae: 1.4656\n",
      "Epoch 2131/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.2012 - val_loss: 2.5019 - val_mae: 1.4131\n",
      "Epoch 2132/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0688 - mae: 0.2174 - val_loss: 2.5090 - val_mae: 1.4157\n",
      "Epoch 2133/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0665 - mae: 0.2134 - val_loss: 2.6718 - val_mae: 1.4722\n",
      "Epoch 2134/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1984 - val_loss: 2.8056 - val_mae: 1.5171\n",
      "Epoch 2135/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1979 - val_loss: 2.8071 - val_mae: 1.5176\n",
      "Epoch 2136/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.1955 - val_loss: 2.7833 - val_mae: 1.5097\n",
      "Epoch 2137/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1886 - val_loss: 2.7239 - val_mae: 1.4898\n",
      "Epoch 2138/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1904 - val_loss: 2.6732 - val_mae: 1.4727\n",
      "Epoch 2139/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0592 - mae: 0.2009 - val_loss: 2.6266 - val_mae: 1.4567\n",
      "Epoch 2140/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0635 - mae: 0.2109 - val_loss: 2.5475 - val_mae: 1.4292\n",
      "Epoch 2141/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0727 - mae: 0.2286 - val_loss: 2.5730 - val_mae: 1.4382\n",
      "Epoch 2142/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.2063 - val_loss: 2.7902 - val_mae: 1.5120\n",
      "Epoch 2143/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0577 - mae: 0.1954 - val_loss: 2.9980 - val_mae: 1.5794\n",
      "Epoch 2144/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0816 - mae: 0.2374 - val_loss: 2.9114 - val_mae: 1.5516\n",
      "Epoch 2145/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - mae: 0.2105 - val_loss: 2.6983 - val_mae: 1.4811\n",
      "Epoch 2146/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1950 - val_loss: 2.6154 - val_mae: 1.4527\n",
      "Epoch 2147/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2198 - val_loss: 2.7058 - val_mae: 1.4835\n",
      "Epoch 2148/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0606 - mae: 0.2056 - val_loss: 2.9115 - val_mae: 1.5514\n",
      "Epoch 2149/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1952 - val_loss: 2.9656 - val_mae: 1.5687\n",
      "Epoch 2150/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0553 - mae: 0.1938 - val_loss: 2.8882 - val_mae: 1.5438\n",
      "Epoch 2151/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1987 - val_loss: 2.8742 - val_mae: 1.5392\n",
      "Epoch 2152/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0554 - mae: 0.1987 - val_loss: 2.9811 - val_mae: 1.5736\n",
      "Epoch 2153/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0567 - mae: 0.1939 - val_loss: 3.0592 - val_mae: 1.5983\n",
      "Epoch 2154/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.1995 - val_loss: 3.0115 - val_mae: 1.5833\n",
      "Epoch 2155/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.1951 - val_loss: 2.9457 - val_mae: 1.5623\n",
      "Epoch 2156/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0545 - mae: 0.1939 - val_loss: 2.8854 - val_mae: 1.5428\n",
      "Epoch 2157/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1989 - val_loss: 2.8153 - val_mae: 1.5199\n",
      "Epoch 2158/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0606 - mae: 0.2085 - val_loss: 2.8306 - val_mae: 1.5250\n",
      "Epoch 2159/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1993 - val_loss: 2.8902 - val_mae: 1.5445\n",
      "Epoch 2160/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0539 - mae: 0.1907 - val_loss: 2.8946 - val_mae: 1.5459\n",
      "Epoch 2161/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0545 - mae: 0.1908 - val_loss: 2.9212 - val_mae: 1.5545\n",
      "Epoch 2162/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0558 - mae: 0.1929 - val_loss: 2.9116 - val_mae: 1.5514\n",
      "Epoch 2163/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0550 - mae: 0.1926 - val_loss: 2.8322 - val_mae: 1.5255\n",
      "Epoch 2164/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0540 - mae: 0.1929 - val_loss: 2.7940 - val_mae: 1.5129\n",
      "Epoch 2165/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0548 - mae: 0.1938 - val_loss: 2.8492 - val_mae: 1.5311\n",
      "Epoch 2166/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0543 - mae: 0.1920 - val_loss: 2.9104 - val_mae: 1.5509\n",
      "Epoch 2167/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0535 - mae: 0.1897 - val_loss: 2.9037 - val_mae: 1.5487\n",
      "Epoch 2168/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0544 - mae: 0.1920 - val_loss: 2.9573 - val_mae: 1.5659\n",
      "Epoch 2169/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0540 - mae: 0.1900 - val_loss: 3.0797 - val_mae: 1.6046\n",
      "Epoch 2170/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0554 - mae: 0.1890 - val_loss: 3.1976 - val_mae: 1.6410\n",
      "Epoch 2171/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0639 - mae: 0.1961 - val_loss: 3.1466 - val_mae: 1.6253\n",
      "Epoch 2172/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0589 - mae: 0.1915 - val_loss: 2.9864 - val_mae: 1.5751\n",
      "Epoch 2173/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1963 - val_loss: 2.9067 - val_mae: 1.5496\n",
      "Epoch 2174/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0612 - mae: 0.2095 - val_loss: 2.9237 - val_mae: 1.5551\n",
      "Epoch 2175/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0546 - mae: 0.1959 - val_loss: 3.0923 - val_mae: 1.6085\n",
      "Epoch 2176/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0591 - mae: 0.1946 - val_loss: 3.2219 - val_mae: 1.6485\n",
      "Epoch 2177/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0874 - mae: 0.2411 - val_loss: 3.1847 - val_mae: 1.6372\n",
      "Epoch 2178/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0878 - mae: 0.2437 - val_loss: 2.9063 - val_mae: 1.5496\n",
      "Epoch 2179/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0507 - mae: 0.1873 - val_loss: 2.5215 - val_mae: 1.4197\n",
      "Epoch 2180/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1022 - mae: 0.2714 - val_loss: 2.4014 - val_mae: 1.3766\n",
      "Epoch 2181/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1376 - mae: 0.3195 - val_loss: 2.6559 - val_mae: 1.4664\n",
      "Epoch 2182/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0699 - mae: 0.2216 - val_loss: 3.1135 - val_mae: 1.6152\n",
      "Epoch 2183/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0721 - mae: 0.2123 - val_loss: 3.3230 - val_mae: 1.6789\n",
      "Epoch 2184/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0914 - mae: 0.2479 - val_loss: 3.1939 - val_mae: 1.6399\n",
      "Epoch 2185/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0619 - mae: 0.1923 - val_loss: 3.0338 - val_mae: 1.5902\n",
      "Epoch 2186/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0616 - mae: 0.2020 - val_loss: 2.9763 - val_mae: 1.5720\n",
      "Epoch 2187/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0706 - mae: 0.2261 - val_loss: 3.0779 - val_mae: 1.6040\n",
      "Epoch 2188/5000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0635 - mae: 0.2079 - val_loss: 3.2830 - val_mae: 1.6668\n",
      "Epoch 2189/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0634 - mae: 0.1897 - val_loss: 3.3791 - val_mae: 1.6954\n",
      "Epoch 2190/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0668 - mae: 0.1947 - val_loss: 3.2401 - val_mae: 1.6538\n",
      "Epoch 2191/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.1837 - val_loss: 3.0494 - val_mae: 1.5950\n",
      "Epoch 2192/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0594 - mae: 0.2011 - val_loss: 2.9903 - val_mae: 1.5764\n",
      "Epoch 2193/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0584 - mae: 0.2008 - val_loss: 3.0289 - val_mae: 1.5886\n",
      "Epoch 2194/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1878 - val_loss: 3.0119 - val_mae: 1.5833\n",
      "Epoch 2195/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0540 - mae: 0.1874 - val_loss: 2.9693 - val_mae: 1.5698\n",
      "Epoch 2196/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1877 - val_loss: 2.9215 - val_mae: 1.5545\n",
      "Epoch 2197/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0535 - mae: 0.1879 - val_loss: 2.8750 - val_mae: 1.5394\n",
      "Epoch 2198/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0535 - mae: 0.1877 - val_loss: 2.8742 - val_mae: 1.5392\n",
      "Epoch 2199/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1874 - val_loss: 2.8608 - val_mae: 1.5348\n",
      "Epoch 2200/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1876 - val_loss: 2.8547 - val_mae: 1.5328\n",
      "Epoch 2201/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1877 - val_loss: 2.8854 - val_mae: 1.5428\n",
      "Epoch 2202/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1874 - val_loss: 2.9136 - val_mae: 1.5519\n",
      "Epoch 2203/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0541 - mae: 0.1886 - val_loss: 2.8956 - val_mae: 1.5461\n",
      "Epoch 2204/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1890 - val_loss: 2.8522 - val_mae: 1.5320\n",
      "Epoch 2205/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1915 - val_loss: 2.8908 - val_mae: 1.5445\n",
      "Epoch 2206/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0544 - mae: 0.1920 - val_loss: 2.9216 - val_mae: 1.5545\n",
      "Epoch 2207/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1897 - val_loss: 2.8736 - val_mae: 1.5389\n",
      "Epoch 2208/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1956 - val_loss: 2.9057 - val_mae: 1.5492\n",
      "Epoch 2209/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1934 - val_loss: 3.0304 - val_mae: 1.5890\n",
      "Epoch 2210/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1965 - val_loss: 3.0428 - val_mae: 1.5929\n",
      "Epoch 2211/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1962 - val_loss: 2.9688 - val_mae: 1.5695\n",
      "Epoch 2212/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1902 - val_loss: 2.9653 - val_mae: 1.5684\n",
      "Epoch 2213/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1886 - val_loss: 2.9938 - val_mae: 1.5775\n",
      "Epoch 2214/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1864 - val_loss: 3.0622 - val_mae: 1.5991\n",
      "Epoch 2215/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0547 - mae: 0.1846 - val_loss: 3.1563 - val_mae: 1.6283\n",
      "Epoch 2216/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0645 - mae: 0.1978 - val_loss: 3.1563 - val_mae: 1.6283\n",
      "Epoch 2217/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0655 - mae: 0.2013 - val_loss: 3.0486 - val_mae: 1.5948\n",
      "Epoch 2218/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0570 - mae: 0.1863 - val_loss: 2.9494 - val_mae: 1.5634\n",
      "Epoch 2219/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1869 - val_loss: 2.9145 - val_mae: 1.5521\n",
      "Epoch 2220/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1903 - val_loss: 2.9623 - val_mae: 1.5675\n",
      "Epoch 2221/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1856 - val_loss: 3.0500 - val_mae: 1.5952\n",
      "Epoch 2222/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1831 - val_loss: 3.0913 - val_mae: 1.6082\n",
      "Epoch 2223/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0596 - mae: 0.1885 - val_loss: 2.9823 - val_mae: 1.5738\n",
      "Epoch 2224/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0546 - mae: 0.1851 - val_loss: 2.8101 - val_mae: 1.5180\n",
      "Epoch 2225/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1984 - val_loss: 2.7583 - val_mae: 1.5008\n",
      "Epoch 2226/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.2072 - val_loss: 2.8119 - val_mae: 1.5186\n",
      "Epoch 2227/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1988 - val_loss: 2.8568 - val_mae: 1.5333\n",
      "Epoch 2228/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1919 - val_loss: 2.8539 - val_mae: 1.5324\n",
      "Epoch 2229/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1928 - val_loss: 2.8553 - val_mae: 1.5329\n",
      "Epoch 2230/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0540 - mae: 0.1910 - val_loss: 2.9328 - val_mae: 1.5580\n",
      "Epoch 2231/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1886 - val_loss: 3.0360 - val_mae: 1.5908\n",
      "Epoch 2232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1898 - val_loss: 3.0388 - val_mae: 1.5917\n",
      "Epoch 2233/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1870 - val_loss: 3.0116 - val_mae: 1.5831\n",
      "Epoch 2234/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1872 - val_loss: 3.0265 - val_mae: 1.5878\n",
      "Epoch 2235/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0533 - mae: 0.1847 - val_loss: 3.1044 - val_mae: 1.6121\n",
      "Epoch 2236/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1845 - val_loss: 3.1271 - val_mae: 1.6192\n",
      "Epoch 2237/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1835 - val_loss: 3.0422 - val_mae: 1.5927\n",
      "Epoch 2238/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1876 - val_loss: 2.9580 - val_mae: 1.5660\n",
      "Epoch 2239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1956 - val_loss: 3.0033 - val_mae: 1.5804\n",
      "Epoch 2240/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1927 - val_loss: 3.0099 - val_mae: 1.5824\n",
      "Epoch 2241/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1903 - val_loss: 2.9488 - val_mae: 1.5630\n",
      "Epoch 2242/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1899 - val_loss: 3.0119 - val_mae: 1.5831\n",
      "Epoch 2243/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1884 - val_loss: 3.0678 - val_mae: 1.6007\n",
      "Epoch 2244/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1945 - val_loss: 2.9883 - val_mae: 1.5757\n",
      "Epoch 2245/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1898 - val_loss: 2.8563 - val_mae: 1.5331\n",
      "Epoch 2246/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0538 - mae: 0.1928 - val_loss: 2.7537 - val_mae: 1.4993\n",
      "Epoch 2247/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.2040 - val_loss: 2.7242 - val_mae: 1.4894\n",
      "Epoch 2248/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0570 - mae: 0.1994 - val_loss: 2.8285 - val_mae: 1.5241\n",
      "Epoch 2249/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0549 - mae: 0.1911 - val_loss: 2.9830 - val_mae: 1.5741\n",
      "Epoch 2250/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0685 - mae: 0.2133 - val_loss: 2.9557 - val_mae: 1.5653\n",
      "Epoch 2251/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.2006 - val_loss: 2.8226 - val_mae: 1.5221\n",
      "Epoch 2252/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0540 - mae: 0.1899 - val_loss: 2.7977 - val_mae: 1.5139\n",
      "Epoch 2253/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.2009 - val_loss: 2.8758 - val_mae: 1.5394\n",
      "Epoch 2254/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1967 - val_loss: 3.0304 - val_mae: 1.5889\n",
      "Epoch 2255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1855 - val_loss: 3.1545 - val_mae: 1.6275\n",
      "Epoch 2256/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1871 - val_loss: 3.1162 - val_mae: 1.6157\n",
      "Epoch 2257/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0544 - mae: 0.1838 - val_loss: 2.9582 - val_mae: 1.5659\n",
      "Epoch 2258/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1969 - val_loss: 2.7988 - val_mae: 1.5141\n",
      "Epoch 2259/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0645 - mae: 0.2173 - val_loss: 2.7844 - val_mae: 1.5094\n",
      "Epoch 2260/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1983 - val_loss: 2.9377 - val_mae: 1.5595\n",
      "Epoch 2261/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0594 - mae: 0.1970 - val_loss: 3.0592 - val_mae: 1.5981\n",
      "Epoch 2262/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0802 - mae: 0.2340 - val_loss: 3.0259 - val_mae: 1.5876\n",
      "Epoch 2263/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0740 - mae: 0.2235 - val_loss: 2.9474 - val_mae: 1.5626\n",
      "Epoch 2264/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0597 - mae: 0.1981 - val_loss: 2.9502 - val_mae: 1.5634\n",
      "Epoch 2265/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1937 - val_loss: 3.0073 - val_mae: 1.5816\n",
      "Epoch 2266/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1936 - val_loss: 3.0143 - val_mae: 1.5838\n",
      "Epoch 2267/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1930 - val_loss: 2.9917 - val_mae: 1.5766\n",
      "Epoch 2268/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1921 - val_loss: 3.0243 - val_mae: 1.5870\n",
      "Epoch 2269/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1893 - val_loss: 3.0839 - val_mae: 1.6057\n",
      "Epoch 2270/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1986 - val_loss: 2.9845 - val_mae: 1.5744\n",
      "Epoch 2271/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1909 - val_loss: 2.7301 - val_mae: 1.4913\n",
      "Epoch 2272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.2058 - val_loss: 2.6283 - val_mae: 1.4567\n",
      "Epoch 2273/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0694 - mae: 0.2233 - val_loss: 2.8183 - val_mae: 1.5206\n",
      "Epoch 2274/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1916 - val_loss: 3.1372 - val_mae: 1.6222\n",
      "Epoch 2275/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1939 - val_loss: 3.3959 - val_mae: 1.7002\n",
      "Epoch 2276/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0893 - mae: 0.2395 - val_loss: 3.3520 - val_mae: 1.6871\n",
      "Epoch 2277/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0653 - mae: 0.1853 - val_loss: 3.1215 - val_mae: 1.6171\n",
      "Epoch 2278/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0647 - mae: 0.2142 - val_loss: 3.0495 - val_mae: 1.5946\n",
      "Epoch 2279/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0841 - mae: 0.2488 - val_loss: 3.2928 - val_mae: 1.6693\n",
      "Epoch 2280/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.1967 - val_loss: 3.7201 - val_mae: 1.7929\n",
      "Epoch 2281/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0944 - mae: 0.2399 - val_loss: 3.9141 - val_mae: 1.8463\n",
      "Epoch 2282/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1315 - mae: 0.2999 - val_loss: 3.6813 - val_mae: 1.7820\n",
      "Epoch 2283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0829 - mae: 0.2203 - val_loss: 3.2659 - val_mae: 1.6612\n",
      "Epoch 2284/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0674 - mae: 0.2114 - val_loss: 3.0570 - val_mae: 1.5970\n",
      "Epoch 2285/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0771 - mae: 0.2388 - val_loss: 3.1039 - val_mae: 1.6117\n",
      "Epoch 2286/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0620 - mae: 0.2070 - val_loss: 3.2265 - val_mae: 1.6494\n",
      "Epoch 2287/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0580 - mae: 0.1834 - val_loss: 3.2693 - val_mae: 1.6625\n",
      "Epoch 2288/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0662 - mae: 0.1980 - val_loss: 3.0879 - val_mae: 1.6070\n",
      "Epoch 2289/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1843 - val_loss: 2.7742 - val_mae: 1.5060\n",
      "Epoch 2290/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.2028 - val_loss: 2.5574 - val_mae: 1.4321\n",
      "Epoch 2291/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0826 - mae: 0.2448 - val_loss: 2.6492 - val_mae: 1.4639\n",
      "Epoch 2292/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0612 - mae: 0.2010 - val_loss: 2.9570 - val_mae: 1.5657\n",
      "Epoch 2293/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2062 - val_loss: 3.1541 - val_mae: 1.6276\n",
      "Epoch 2294/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0948 - mae: 0.2583 - val_loss: 3.1318 - val_mae: 1.6206\n",
      "Epoch 2295/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0818 - mae: 0.2375 - val_loss: 3.0067 - val_mae: 1.5814\n",
      "Epoch 2296/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1893 - val_loss: 2.8615 - val_mae: 1.5347\n",
      "Epoch 2297/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0576 - mae: 0.2022 - val_loss: 2.7997 - val_mae: 1.5143\n",
      "Epoch 2298/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0695 - mae: 0.2271 - val_loss: 2.9588 - val_mae: 1.5661\n",
      "Epoch 2299/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0530 - mae: 0.1856 - val_loss: 3.2491 - val_mae: 1.6563\n",
      "Epoch 2300/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0688 - mae: 0.2033 - val_loss: 3.4360 - val_mae: 1.7119\n",
      "Epoch 2301/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1082 - mae: 0.2708 - val_loss: 3.2852 - val_mae: 1.6673\n",
      "Epoch 2302/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0784 - mae: 0.2205 - val_loss: 2.8812 - val_mae: 1.5411\n",
      "Epoch 2303/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1964 - val_loss: 2.6231 - val_mae: 1.4548\n",
      "Epoch 2304/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0837 - mae: 0.2494 - val_loss: 2.6129 - val_mae: 1.4514\n",
      "Epoch 2305/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0791 - mae: 0.2413 - val_loss: 2.7656 - val_mae: 1.5032\n",
      "Epoch 2306/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0571 - mae: 0.1903 - val_loss: 2.9976 - val_mae: 1.5787\n",
      "Epoch 2307/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0714 - mae: 0.2173 - val_loss: 3.0899 - val_mae: 1.6077\n",
      "Epoch 2308/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0845 - mae: 0.2395 - val_loss: 2.9677 - val_mae: 1.5692\n",
      "Epoch 2309/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0654 - mae: 0.2024 - val_loss: 2.8221 - val_mae: 1.5220\n",
      "Epoch 2310/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0574 - mae: 0.1916 - val_loss: 2.7317 - val_mae: 1.4919\n",
      "Epoch 2311/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0650 - mae: 0.2143 - val_loss: 2.7790 - val_mae: 1.5076\n",
      "Epoch 2312/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.2142 - val_loss: 2.9069 - val_mae: 1.5495\n",
      "Epoch 2313/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1924 - val_loss: 3.0117 - val_mae: 1.5830\n",
      "Epoch 2314/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1863 - val_loss: 3.0833 - val_mae: 1.6055\n",
      "Epoch 2315/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1847 - val_loss: 3.0392 - val_mae: 1.5917\n",
      "Epoch 2316/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0547 - mae: 0.1838 - val_loss: 2.9061 - val_mae: 1.5493\n",
      "Epoch 2317/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1910 - val_loss: 2.8288 - val_mae: 1.5241\n",
      "Epoch 2318/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.2010 - val_loss: 2.8976 - val_mae: 1.5465\n",
      "Epoch 2319/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0541 - mae: 0.1934 - val_loss: 3.0124 - val_mae: 1.5832\n",
      "Epoch 2320/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1930 - val_loss: 3.0786 - val_mae: 1.6040\n",
      "Epoch 2321/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0605 - mae: 0.1998 - val_loss: 3.0527 - val_mae: 1.5959\n",
      "Epoch 2322/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0581 - mae: 0.1965 - val_loss: 2.9124 - val_mae: 1.5513\n",
      "Epoch 2323/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0543 - mae: 0.1959 - val_loss: 2.7851 - val_mae: 1.5096\n",
      "Epoch 2324/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.2030 - val_loss: 2.8138 - val_mae: 1.5191\n",
      "Epoch 2325/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1964 - val_loss: 2.8796 - val_mae: 1.5407\n",
      "Epoch 2326/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0531 - mae: 0.1879 - val_loss: 2.8934 - val_mae: 1.5453\n",
      "Epoch 2327/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1913 - val_loss: 2.9294 - val_mae: 1.5570\n",
      "Epoch 2328/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0673 - mae: 0.2122 - val_loss: 2.9082 - val_mae: 1.5502\n",
      "Epoch 2329/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0678 - mae: 0.2148 - val_loss: 2.7399 - val_mae: 1.4948\n",
      "Epoch 2330/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1924 - val_loss: 2.6011 - val_mae: 1.4475\n",
      "Epoch 2331/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.2054 - val_loss: 2.6268 - val_mae: 1.4564\n",
      "Epoch 2332/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0634 - mae: 0.2079 - val_loss: 2.7140 - val_mae: 1.4861\n",
      "Epoch 2333/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1894 - val_loss: 2.8377 - val_mae: 1.5272\n",
      "Epoch 2334/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0559 - mae: 0.1855 - val_loss: 2.9345 - val_mae: 1.5587\n",
      "Epoch 2335/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1973 - val_loss: 2.9477 - val_mae: 1.5629\n",
      "Epoch 2336/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1921 - val_loss: 2.8688 - val_mae: 1.5374\n",
      "Epoch 2337/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1860 - val_loss: 2.8045 - val_mae: 1.5163\n",
      "Epoch 2338/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1899 - val_loss: 2.8700 - val_mae: 1.5377\n",
      "Epoch 2339/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1822 - val_loss: 3.0143 - val_mae: 1.5841\n",
      "Epoch 2340/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0580 - mae: 0.1892 - val_loss: 3.0981 - val_mae: 1.6103\n",
      "Epoch 2341/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0609 - mae: 0.1952 - val_loss: 2.9780 - val_mae: 1.5725\n",
      "Epoch 2342/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0512 - mae: 0.1795 - val_loss: 2.7610 - val_mae: 1.5017\n",
      "Epoch 2343/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0733 - mae: 0.2354 - val_loss: 2.6503 - val_mae: 1.4643\n",
      "Epoch 2344/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1017 - mae: 0.2798 - val_loss: 2.8071 - val_mae: 1.5170\n",
      "Epoch 2345/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0697 - mae: 0.2250 - val_loss: 3.1489 - val_mae: 1.6259\n",
      "Epoch 2346/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1940 - val_loss: 3.3190 - val_mae: 1.6775\n",
      "Epoch 2347/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0743 - mae: 0.2131 - val_loss: 3.2124 - val_mae: 1.6454\n",
      "Epoch 2348/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0609 - mae: 0.1906 - val_loss: 2.9580 - val_mae: 1.5661\n",
      "Epoch 2349/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1922 - val_loss: 2.8012 - val_mae: 1.5151\n",
      "Epoch 2350/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2075 - val_loss: 2.8078 - val_mae: 1.5173\n",
      "Epoch 2351/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1958 - val_loss: 2.9238 - val_mae: 1.5552\n",
      "Epoch 2352/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1838 - val_loss: 3.0639 - val_mae: 1.5997\n",
      "Epoch 2353/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.1903 - val_loss: 3.0819 - val_mae: 1.6053\n",
      "Epoch 2354/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.1895 - val_loss: 3.0297 - val_mae: 1.5888\n",
      "Epoch 2355/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0536 - mae: 0.1811 - val_loss: 2.9855 - val_mae: 1.5748\n",
      "Epoch 2356/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1954 - val_loss: 3.0275 - val_mae: 1.5880\n",
      "Epoch 2357/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.2009 - val_loss: 3.1015 - val_mae: 1.6112\n",
      "Epoch 2358/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1932 - val_loss: 3.1788 - val_mae: 1.6350\n",
      "Epoch 2359/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1864 - val_loss: 3.2241 - val_mae: 1.6489\n",
      "Epoch 2360/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1893 - val_loss: 3.0935 - val_mae: 1.6087\n",
      "Epoch 2361/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0551 - mae: 0.1897 - val_loss: 2.9386 - val_mae: 1.5598\n",
      "Epoch 2362/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0526 - mae: 0.1879 - val_loss: 2.8630 - val_mae: 1.5354\n",
      "Epoch 2363/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0526 - mae: 0.1869 - val_loss: 2.8123 - val_mae: 1.5189\n",
      "Epoch 2364/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1903 - val_loss: 2.7734 - val_mae: 1.5061\n",
      "Epoch 2365/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0587 - mae: 0.1942 - val_loss: 2.6992 - val_mae: 1.4813\n",
      "Epoch 2366/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1899 - val_loss: 2.6051 - val_mae: 1.4491\n",
      "Epoch 2367/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1922 - val_loss: 2.5650 - val_mae: 1.4351\n",
      "Epoch 2368/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0621 - mae: 0.2014 - val_loss: 2.5852 - val_mae: 1.4421\n",
      "Epoch 2369/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0636 - mae: 0.2077 - val_loss: 2.6892 - val_mae: 1.4778\n",
      "Epoch 2370/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1958 - val_loss: 2.8620 - val_mae: 1.5353\n",
      "Epoch 2371/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0537 - mae: 0.1821 - val_loss: 2.9966 - val_mae: 1.5785\n",
      "Epoch 2372/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0595 - mae: 0.1932 - val_loss: 3.0109 - val_mae: 1.5830\n",
      "Epoch 2373/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0597 - mae: 0.1944 - val_loss: 2.9464 - val_mae: 1.5625\n",
      "Epoch 2374/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1908 - val_loss: 2.9001 - val_mae: 1.5475\n",
      "Epoch 2375/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1883 - val_loss: 2.8753 - val_mae: 1.5395\n",
      "Epoch 2376/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0532 - mae: 0.1907 - val_loss: 2.9493 - val_mae: 1.5633\n",
      "Epoch 2377/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0519 - mae: 0.1881 - val_loss: 3.1951 - val_mae: 1.6401\n",
      "Epoch 2378/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2021 - val_loss: 3.3589 - val_mae: 1.6893\n",
      "Epoch 2379/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0772 - mae: 0.2149 - val_loss: 3.2661 - val_mae: 1.6616\n",
      "Epoch 2380/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0612 - mae: 0.1932 - val_loss: 3.0744 - val_mae: 1.6027\n",
      "Epoch 2381/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1874 - val_loss: 2.8677 - val_mae: 1.5368\n",
      "Epoch 2382/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0640 - mae: 0.2152 - val_loss: 2.7523 - val_mae: 1.4988\n",
      "Epoch 2383/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0719 - mae: 0.2313 - val_loss: 2.8120 - val_mae: 1.5186\n",
      "Epoch 2384/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0604 - mae: 0.2077 - val_loss: 3.0064 - val_mae: 1.5814\n",
      "Epoch 2385/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0543 - mae: 0.1900 - val_loss: 3.1618 - val_mae: 1.6299\n",
      "Epoch 2386/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1865 - val_loss: 3.1372 - val_mae: 1.6223\n",
      "Epoch 2387/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1853 - val_loss: 3.1109 - val_mae: 1.6141\n",
      "Epoch 2388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1818 - val_loss: 3.2057 - val_mae: 1.6432\n",
      "Epoch 2389/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1840 - val_loss: 3.2051 - val_mae: 1.6431\n",
      "Epoch 2390/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.1816 - val_loss: 3.0999 - val_mae: 1.6107\n",
      "Epoch 2391/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0563 - mae: 0.1908 - val_loss: 3.1011 - val_mae: 1.6110\n",
      "Epoch 2392/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1896 - val_loss: 3.1093 - val_mae: 1.6136\n",
      "Epoch 2393/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1849 - val_loss: 3.0942 - val_mae: 1.6089\n",
      "Epoch 2394/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1831 - val_loss: 3.1032 - val_mae: 1.6117\n",
      "Epoch 2395/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1813 - val_loss: 3.0983 - val_mae: 1.6102\n",
      "Epoch 2396/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1821 - val_loss: 3.0791 - val_mae: 1.6043\n",
      "Epoch 2397/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1858 - val_loss: 3.0255 - val_mae: 1.5875\n",
      "Epoch 2398/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1862 - val_loss: 2.8430 - val_mae: 1.5288\n",
      "Epoch 2399/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1828 - val_loss: 2.6183 - val_mae: 1.4534\n",
      "Epoch 2400/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0662 - mae: 0.2144 - val_loss: 2.5672 - val_mae: 1.4357\n",
      "Epoch 2401/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0685 - mae: 0.2180 - val_loss: 2.6957 - val_mae: 1.4798\n",
      "Epoch 2402/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1915 - val_loss: 2.8313 - val_mae: 1.5250\n",
      "Epoch 2403/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1913 - val_loss: 2.8457 - val_mae: 1.5298\n",
      "Epoch 2404/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1935 - val_loss: 2.8023 - val_mae: 1.5155\n",
      "Epoch 2405/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1860 - val_loss: 2.7755 - val_mae: 1.5066\n",
      "Epoch 2406/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1857 - val_loss: 2.7294 - val_mae: 1.4911\n",
      "Epoch 2407/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1945 - val_loss: 2.7605 - val_mae: 1.5015\n",
      "Epoch 2408/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1858 - val_loss: 2.8999 - val_mae: 1.5474\n",
      "Epoch 2409/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1876 - val_loss: 2.9597 - val_mae: 1.5666\n",
      "Epoch 2410/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1978 - val_loss: 2.8649 - val_mae: 1.5360\n",
      "Epoch 2411/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1880 - val_loss: 2.7730 - val_mae: 1.5057\n",
      "Epoch 2412/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0546 - mae: 0.1888 - val_loss: 2.8188 - val_mae: 1.5208\n",
      "Epoch 2413/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0539 - mae: 0.1876 - val_loss: 2.9939 - val_mae: 1.5774\n",
      "Epoch 2414/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1820 - val_loss: 3.0947 - val_mae: 1.6091\n",
      "Epoch 2415/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1832 - val_loss: 2.9902 - val_mae: 1.5762\n",
      "Epoch 2416/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1844 - val_loss: 2.8809 - val_mae: 1.5411\n",
      "Epoch 2417/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1989 - val_loss: 2.8610 - val_mae: 1.5346\n",
      "Epoch 2418/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1995 - val_loss: 2.9601 - val_mae: 1.5666\n",
      "Epoch 2419/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1859 - val_loss: 3.1355 - val_mae: 1.6217\n",
      "Epoch 2420/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0649 - mae: 0.2019 - val_loss: 3.2320 - val_mae: 1.6513\n",
      "Epoch 2421/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0844 - mae: 0.2327 - val_loss: 3.2222 - val_mae: 1.6483\n",
      "Epoch 2422/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0811 - mae: 0.2253 - val_loss: 3.0834 - val_mae: 1.6056\n",
      "Epoch 2423/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.1967 - val_loss: 2.8622 - val_mae: 1.5350\n",
      "Epoch 2424/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.2070 - val_loss: 2.7468 - val_mae: 1.4968\n",
      "Epoch 2425/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0693 - mae: 0.2224 - val_loss: 2.7918 - val_mae: 1.5118\n",
      "Epoch 2426/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2084 - val_loss: 2.9304 - val_mae: 1.5571\n",
      "Epoch 2427/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1928 - val_loss: 3.0557 - val_mae: 1.5969\n",
      "Epoch 2428/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1933 - val_loss: 3.1061 - val_mae: 1.6126\n",
      "Epoch 2429/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.1952 - val_loss: 2.9853 - val_mae: 1.5747\n",
      "Epoch 2430/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0530 - mae: 0.1895 - val_loss: 2.7627 - val_mae: 1.5022\n",
      "Epoch 2431/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.2084 - val_loss: 2.6987 - val_mae: 1.4807\n",
      "Epoch 2432/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.2062 - val_loss: 2.8068 - val_mae: 1.5169\n",
      "Epoch 2433/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1892 - val_loss: 2.8621 - val_mae: 1.5351\n",
      "Epoch 2434/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1916 - val_loss: 2.8188 - val_mae: 1.5209\n",
      "Epoch 2435/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1912 - val_loss: 2.7867 - val_mae: 1.5103\n",
      "Epoch 2436/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1900 - val_loss: 2.7569 - val_mae: 1.5003\n",
      "Epoch 2437/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1954 - val_loss: 2.8065 - val_mae: 1.5167\n",
      "Epoch 2438/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.2019 - val_loss: 2.8860 - val_mae: 1.5427\n",
      "Epoch 2439/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1996 - val_loss: 2.9581 - val_mae: 1.5660\n",
      "Epoch 2440/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1973 - val_loss: 3.0837 - val_mae: 1.6056\n",
      "Epoch 2441/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0583 - mae: 0.1985 - val_loss: 3.0821 - val_mae: 1.6051\n",
      "Epoch 2442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1987 - val_loss: 2.9863 - val_mae: 1.5749\n",
      "Epoch 2443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1951 - val_loss: 2.9268 - val_mae: 1.5559\n",
      "Epoch 2444/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1969 - val_loss: 2.8849 - val_mae: 1.5424\n",
      "Epoch 2445/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.2049 - val_loss: 2.9716 - val_mae: 1.5703\n",
      "Epoch 2446/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0525 - mae: 0.1854 - val_loss: 3.1045 - val_mae: 1.6122\n",
      "Epoch 2447/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1928 - val_loss: 3.0652 - val_mae: 1.6000\n",
      "Epoch 2448/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0661 - mae: 0.2075 - val_loss: 2.8521 - val_mae: 1.5319\n",
      "Epoch 2449/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0578 - mae: 0.1923 - val_loss: 2.6830 - val_mae: 1.4756\n",
      "Epoch 2450/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0558 - mae: 0.1884 - val_loss: 2.6560 - val_mae: 1.4664\n",
      "Epoch 2451/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1884 - val_loss: 2.7139 - val_mae: 1.4861\n",
      "Epoch 2452/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0589 - mae: 0.1938 - val_loss: 2.7370 - val_mae: 1.4939\n",
      "Epoch 2453/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1986 - val_loss: 2.6954 - val_mae: 1.4798\n",
      "Epoch 2454/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1919 - val_loss: 2.7045 - val_mae: 1.4829\n",
      "Epoch 2455/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1867 - val_loss: 2.7637 - val_mae: 1.5026\n",
      "Epoch 2456/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0538 - mae: 0.1886 - val_loss: 2.8418 - val_mae: 1.5284\n",
      "Epoch 2457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1902 - val_loss: 2.9418 - val_mae: 1.5608\n",
      "Epoch 2458/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1865 - val_loss: 2.9832 - val_mae: 1.5740\n",
      "Epoch 2459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1877 - val_loss: 3.0023 - val_mae: 1.5801\n",
      "Epoch 2460/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1879 - val_loss: 3.0979 - val_mae: 1.6101\n",
      "Epoch 2461/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1797 - val_loss: 3.2974 - val_mae: 1.6710\n",
      "Epoch 2462/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.1961 - val_loss: 3.3791 - val_mae: 1.6953\n",
      "Epoch 2463/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0747 - mae: 0.2117 - val_loss: 3.2322 - val_mae: 1.6513\n",
      "Epoch 2464/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0617 - mae: 0.1873 - val_loss: 3.1387 - val_mae: 1.6227\n",
      "Epoch 2465/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1802 - val_loss: 3.1140 - val_mae: 1.6150\n",
      "Epoch 2466/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1855 - val_loss: 3.0347 - val_mae: 1.5903\n",
      "Epoch 2467/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1956 - val_loss: 2.9224 - val_mae: 1.5545\n",
      "Epoch 2468/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0606 - mae: 0.2071 - val_loss: 2.9005 - val_mae: 1.5475\n",
      "Epoch 2469/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1906 - val_loss: 2.9948 - val_mae: 1.5778\n",
      "Epoch 2470/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0537 - mae: 0.1780 - val_loss: 3.0452 - val_mae: 1.5937\n",
      "Epoch 2471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0635 - mae: 0.2027 - val_loss: 2.9686 - val_mae: 1.5695\n",
      "Epoch 2472/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0629 - mae: 0.2030 - val_loss: 2.7653 - val_mae: 1.5033\n",
      "Epoch 2473/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0553 - mae: 0.1886 - val_loss: 2.6000 - val_mae: 1.4471\n",
      "Epoch 2474/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0575 - mae: 0.1918 - val_loss: 2.5728 - val_mae: 1.4377\n",
      "Epoch 2475/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1981 - val_loss: 2.6199 - val_mae: 1.4540\n",
      "Epoch 2476/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0566 - mae: 0.1919 - val_loss: 2.7560 - val_mae: 1.5001\n",
      "Epoch 2477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1915 - val_loss: 2.8699 - val_mae: 1.5377\n",
      "Epoch 2478/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0661 - mae: 0.2094 - val_loss: 2.8267 - val_mae: 1.5236\n",
      "Epoch 2479/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0623 - mae: 0.2029 - val_loss: 2.6595 - val_mae: 1.4675\n",
      "Epoch 2480/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0554 - mae: 0.1935 - val_loss: 2.5108 - val_mae: 1.4159\n",
      "Epoch 2481/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0644 - mae: 0.2055 - val_loss: 2.4906 - val_mae: 1.4087\n",
      "Epoch 2482/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0665 - mae: 0.2082 - val_loss: 2.5726 - val_mae: 1.4376\n",
      "Epoch 2483/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0587 - mae: 0.1927 - val_loss: 2.6772 - val_mae: 1.4736\n",
      "Epoch 2484/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0550 - mae: 0.1886 - val_loss: 2.7335 - val_mae: 1.4926\n",
      "Epoch 2485/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1867 - val_loss: 2.7688 - val_mae: 1.5044\n",
      "Epoch 2486/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1849 - val_loss: 2.7917 - val_mae: 1.5119\n",
      "Epoch 2487/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1841 - val_loss: 2.8929 - val_mae: 1.5451\n",
      "Epoch 2488/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0527 - mae: 0.1812 - val_loss: 3.0301 - val_mae: 1.5889\n",
      "Epoch 2489/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1813 - val_loss: 3.0085 - val_mae: 1.5820\n",
      "Epoch 2490/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1828 - val_loss: 2.9879 - val_mae: 1.5755\n",
      "Epoch 2491/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0524 - mae: 0.1792 - val_loss: 2.9989 - val_mae: 1.5790\n",
      "Epoch 2492/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1806 - val_loss: 3.0043 - val_mae: 1.5807\n",
      "Epoch 2493/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1805 - val_loss: 3.0618 - val_mae: 1.5988\n",
      "Epoch 2494/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1819 - val_loss: 3.0282 - val_mae: 1.5882\n",
      "Epoch 2495/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0521 - mae: 0.1788 - val_loss: 2.8682 - val_mae: 1.5370\n",
      "Epoch 2496/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0557 - mae: 0.1954 - val_loss: 2.7869 - val_mae: 1.5102\n",
      "Epoch 2497/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.2019 - val_loss: 2.9219 - val_mae: 1.5544\n",
      "Epoch 2498/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0521 - mae: 0.1835 - val_loss: 3.1016 - val_mae: 1.6112\n",
      "Epoch 2499/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.1915 - val_loss: 3.1657 - val_mae: 1.6310\n",
      "Epoch 2500/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1912 - val_loss: 3.1321 - val_mae: 1.6206\n",
      "Epoch 2501/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1816 - val_loss: 3.0224 - val_mae: 1.5863\n",
      "Epoch 2502/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1956 - val_loss: 2.9951 - val_mae: 1.5777\n",
      "Epoch 2503/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.2038 - val_loss: 3.0584 - val_mae: 1.5976\n",
      "Epoch 2504/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0561 - mae: 0.1960 - val_loss: 3.1297 - val_mae: 1.6198\n",
      "Epoch 2505/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1874 - val_loss: 3.2397 - val_mae: 1.6535\n",
      "Epoch 2506/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.1890 - val_loss: 3.1822 - val_mae: 1.6360\n",
      "Epoch 2507/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1805 - val_loss: 2.9078 - val_mae: 1.5497\n",
      "Epoch 2508/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.2116 - val_loss: 2.7302 - val_mae: 1.4913\n",
      "Epoch 2509/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0773 - mae: 0.2406 - val_loss: 2.7620 - val_mae: 1.5020\n",
      "Epoch 2510/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0609 - mae: 0.2077 - val_loss: 2.9185 - val_mae: 1.5533\n",
      "Epoch 2511/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0547 - mae: 0.1808 - val_loss: 3.0154 - val_mae: 1.5843\n",
      "Epoch 2512/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1952 - val_loss: 2.9515 - val_mae: 1.5640\n",
      "Epoch 2513/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1863 - val_loss: 2.8503 - val_mae: 1.5313\n",
      "Epoch 2514/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1785 - val_loss: 2.7827 - val_mae: 1.5090\n",
      "Epoch 2515/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1864 - val_loss: 2.8169 - val_mae: 1.5203\n",
      "Epoch 2516/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1827 - val_loss: 2.9122 - val_mae: 1.5514\n",
      "Epoch 2517/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0528 - mae: 0.1800 - val_loss: 2.9243 - val_mae: 1.5553\n",
      "Epoch 2518/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1878 - val_loss: 2.8450 - val_mae: 1.5296\n",
      "Epoch 2519/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1917 - val_loss: 2.7550 - val_mae: 1.4998\n",
      "Epoch 2520/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1943 - val_loss: 2.6926 - val_mae: 1.4788\n",
      "Epoch 2521/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0549 - mae: 0.1956 - val_loss: 2.7364 - val_mae: 1.4935\n",
      "Epoch 2522/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1942 - val_loss: 2.8451 - val_mae: 1.5295\n",
      "Epoch 2523/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0524 - mae: 0.1884 - val_loss: 2.8988 - val_mae: 1.5470\n",
      "Epoch 2524/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1855 - val_loss: 2.8633 - val_mae: 1.5355\n",
      "Epoch 2525/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1852 - val_loss: 2.7749 - val_mae: 1.5063\n",
      "Epoch 2526/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1939 - val_loss: 2.7653 - val_mae: 1.5032\n",
      "Epoch 2527/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0525 - mae: 0.1845 - val_loss: 2.8516 - val_mae: 1.5317\n",
      "Epoch 2528/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1914 - val_loss: 2.9242 - val_mae: 1.5553\n",
      "Epoch 2529/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0600 - mae: 0.1964 - val_loss: 2.8794 - val_mae: 1.5407\n",
      "Epoch 2530/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1874 - val_loss: 2.7075 - val_mae: 1.4838\n",
      "Epoch 2531/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1996 - val_loss: 2.6074 - val_mae: 1.4496\n",
      "Epoch 2532/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0669 - mae: 0.2159 - val_loss: 2.6233 - val_mae: 1.4551\n",
      "Epoch 2533/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0622 - mae: 0.2069 - val_loss: 2.6742 - val_mae: 1.4725\n",
      "Epoch 2534/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1922 - val_loss: 2.7414 - val_mae: 1.4952\n",
      "Epoch 2535/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1877 - val_loss: 2.7262 - val_mae: 1.4902\n",
      "Epoch 2536/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1862 - val_loss: 2.6565 - val_mae: 1.4665\n",
      "Epoch 2537/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0550 - mae: 0.1875 - val_loss: 2.6428 - val_mae: 1.4618\n",
      "Epoch 2538/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1900 - val_loss: 2.7394 - val_mae: 1.4946\n",
      "Epoch 2539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1865 - val_loss: 2.8554 - val_mae: 1.5329\n",
      "Epoch 2540/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1881 - val_loss: 2.8534 - val_mae: 1.5322\n",
      "Epoch 2541/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0531 - mae: 0.1857 - val_loss: 2.8103 - val_mae: 1.5181\n",
      "Epoch 2542/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1832 - val_loss: 2.8203 - val_mae: 1.5214\n",
      "Epoch 2543/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1846 - val_loss: 2.8284 - val_mae: 1.5240\n",
      "Epoch 2544/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1885 - val_loss: 2.8175 - val_mae: 1.5204\n",
      "Epoch 2545/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0548 - mae: 0.1933 - val_loss: 2.8744 - val_mae: 1.5390\n",
      "Epoch 2546/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1892 - val_loss: 2.9621 - val_mae: 1.5673\n",
      "Epoch 2547/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1831 - val_loss: 2.9960 - val_mae: 1.5781\n",
      "Epoch 2548/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1822 - val_loss: 3.0306 - val_mae: 1.5890\n",
      "Epoch 2549/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1807 - val_loss: 3.0239 - val_mae: 1.5869\n",
      "Epoch 2550/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1792 - val_loss: 3.0086 - val_mae: 1.5821\n",
      "Epoch 2551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1767 - val_loss: 3.0282 - val_mae: 1.5883\n",
      "Epoch 2552/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1779 - val_loss: 3.0942 - val_mae: 1.6090\n",
      "Epoch 2553/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1800 - val_loss: 3.2464 - val_mae: 1.6556\n",
      "Epoch 2554/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.1923 - val_loss: 3.3258 - val_mae: 1.6794\n",
      "Epoch 2555/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.1922 - val_loss: 3.1217 - val_mae: 1.6174\n",
      "Epoch 2556/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1868 - val_loss: 2.9204 - val_mae: 1.5538\n",
      "Epoch 2557/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0617 - mae: 0.2097 - val_loss: 2.8977 - val_mae: 1.5465\n",
      "Epoch 2558/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.2044 - val_loss: 2.9712 - val_mae: 1.5701\n",
      "Epoch 2559/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1894 - val_loss: 3.0680 - val_mae: 1.6007\n",
      "Epoch 2560/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1874 - val_loss: 3.0983 - val_mae: 1.6101\n",
      "Epoch 2561/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.1954 - val_loss: 3.0216 - val_mae: 1.5861\n",
      "Epoch 2562/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1905 - val_loss: 2.7711 - val_mae: 1.5050\n",
      "Epoch 2563/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.2012 - val_loss: 2.6035 - val_mae: 1.4481\n",
      "Epoch 2564/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0765 - mae: 0.2349 - val_loss: 2.6434 - val_mae: 1.4619\n",
      "Epoch 2565/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - mae: 0.2158 - val_loss: 2.8263 - val_mae: 1.5233\n",
      "Epoch 2566/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1811 - val_loss: 3.0213 - val_mae: 1.5861\n",
      "Epoch 2567/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0683 - mae: 0.2121 - val_loss: 3.0391 - val_mae: 1.5917\n",
      "Epoch 2568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0683 - mae: 0.2102 - val_loss: 2.9127 - val_mae: 1.5515\n",
      "Epoch 2569/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1818 - val_loss: 2.7810 - val_mae: 1.5083\n",
      "Epoch 2570/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1841 - val_loss: 2.7831 - val_mae: 1.5090\n",
      "Epoch 2571/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1953 - val_loss: 2.8862 - val_mae: 1.5428\n",
      "Epoch 2572/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0524 - mae: 0.1867 - val_loss: 3.0702 - val_mae: 1.6014\n",
      "Epoch 2573/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1811 - val_loss: 3.2520 - val_mae: 1.6572\n",
      "Epoch 2574/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.1863 - val_loss: 3.2296 - val_mae: 1.6504\n",
      "Epoch 2575/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1801 - val_loss: 3.0953 - val_mae: 1.6091\n",
      "Epoch 2576/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0560 - mae: 0.1954 - val_loss: 3.0458 - val_mae: 1.5936\n",
      "Epoch 2577/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.2022 - val_loss: 3.0981 - val_mae: 1.6100\n",
      "Epoch 2578/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1882 - val_loss: 3.2282 - val_mae: 1.6500\n",
      "Epoch 2579/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1804 - val_loss: 3.4061 - val_mae: 1.7031\n",
      "Epoch 2580/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0812 - mae: 0.2232 - val_loss: 3.3489 - val_mae: 1.6862\n",
      "Epoch 2581/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0795 - mae: 0.2250 - val_loss: 2.9830 - val_mae: 1.5739\n",
      "Epoch 2582/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1833 - val_loss: 2.6248 - val_mae: 1.4554\n",
      "Epoch 2583/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0775 - mae: 0.2352 - val_loss: 2.5046 - val_mae: 1.4135\n",
      "Epoch 2584/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0846 - mae: 0.2427 - val_loss: 2.7083 - val_mae: 1.4839\n",
      "Epoch 2585/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1862 - val_loss: 3.0782 - val_mae: 1.6040\n",
      "Epoch 2586/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0856 - mae: 0.2465 - val_loss: 3.1966 - val_mae: 1.6405\n",
      "Epoch 2587/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0908 - mae: 0.2526 - val_loss: 3.0240 - val_mae: 1.5868\n",
      "Epoch 2588/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1802 - val_loss: 2.8210 - val_mae: 1.5214\n",
      "Epoch 2589/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.2089 - val_loss: 2.7196 - val_mae: 1.4876\n",
      "Epoch 2590/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0819 - mae: 0.2496 - val_loss: 2.8013 - val_mae: 1.5149\n",
      "Epoch 2591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0707 - mae: 0.2315 - val_loss: 3.1023 - val_mae: 1.6113\n",
      "Epoch 2592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1835 - val_loss: 3.3816 - val_mae: 1.6959\n",
      "Epoch 2593/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0764 - mae: 0.2156 - val_loss: 3.2472 - val_mae: 1.6557\n",
      "Epoch 2594/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.1922 - val_loss: 2.9165 - val_mae: 1.5524\n",
      "Epoch 2595/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0665 - mae: 0.2138 - val_loss: 2.7666 - val_mae: 1.5033\n",
      "Epoch 2596/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0858 - mae: 0.2439 - val_loss: 2.8101 - val_mae: 1.5178\n",
      "Epoch 2597/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0750 - mae: 0.2290 - val_loss: 2.8890 - val_mae: 1.5436\n",
      "Epoch 2598/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2100 - val_loss: 3.0305 - val_mae: 1.5889\n",
      "Epoch 2599/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1986 - val_loss: 3.0981 - val_mae: 1.6101\n",
      "Epoch 2600/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.1957 - val_loss: 3.0185 - val_mae: 1.5852\n",
      "Epoch 2601/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1835 - val_loss: 2.9118 - val_mae: 1.5511\n",
      "Epoch 2602/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1813 - val_loss: 2.8152 - val_mae: 1.5196\n",
      "Epoch 2603/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2057 - val_loss: 2.9346 - val_mae: 1.5584\n",
      "Epoch 2604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1922 - val_loss: 3.1575 - val_mae: 1.6284\n",
      "Epoch 2605/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0566 - mae: 0.1822 - val_loss: 3.2998 - val_mae: 1.6716\n",
      "Epoch 2606/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0629 - mae: 0.1869 - val_loss: 3.4124 - val_mae: 1.7049\n",
      "Epoch 2607/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0725 - mae: 0.2054 - val_loss: 3.4387 - val_mae: 1.7126\n",
      "Epoch 2608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0752 - mae: 0.2132 - val_loss: 3.2780 - val_mae: 1.6650\n",
      "Epoch 2609/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1930 - val_loss: 3.0719 - val_mae: 1.6018\n",
      "Epoch 2610/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1970 - val_loss: 3.0325 - val_mae: 1.5894\n",
      "Epoch 2611/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0553 - mae: 0.1976 - val_loss: 3.0719 - val_mae: 1.6018\n",
      "Epoch 2612/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0541 - mae: 0.1929 - val_loss: 3.0595 - val_mae: 1.5979\n",
      "Epoch 2613/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1929 - val_loss: 2.9343 - val_mae: 1.5583\n",
      "Epoch 2614/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1887 - val_loss: 2.6909 - val_mae: 1.4780\n",
      "Epoch 2615/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0598 - mae: 0.2008 - val_loss: 2.5922 - val_mae: 1.4442\n",
      "Epoch 2616/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1977 - val_loss: 2.7352 - val_mae: 1.4931\n",
      "Epoch 2617/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1892 - val_loss: 2.9259 - val_mae: 1.5557\n",
      "Epoch 2618/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0732 - mae: 0.2262 - val_loss: 2.9552 - val_mae: 1.5652\n",
      "Epoch 2619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0734 - mae: 0.2240 - val_loss: 2.8776 - val_mae: 1.5401\n",
      "Epoch 2620/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1909 - val_loss: 2.8473 - val_mae: 1.5301\n",
      "Epoch 2621/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0515 - mae: 0.1788 - val_loss: 2.8777 - val_mae: 1.5400\n",
      "Epoch 2622/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0529 - mae: 0.1838 - val_loss: 2.9954 - val_mae: 1.5778\n",
      "Epoch 2623/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0538 - mae: 0.1840 - val_loss: 3.0762 - val_mae: 1.6032\n",
      "Epoch 2624/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1812 - val_loss: 3.0836 - val_mae: 1.6055\n",
      "Epoch 2625/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1820 - val_loss: 3.1548 - val_mae: 1.6275\n",
      "Epoch 2626/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1798 - val_loss: 3.2214 - val_mae: 1.6478\n",
      "Epoch 2627/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1781 - val_loss: 3.1199 - val_mae: 1.6167\n",
      "Epoch 2628/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1793 - val_loss: 2.9272 - val_mae: 1.5559\n",
      "Epoch 2629/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1909 - val_loss: 2.8110 - val_mae: 1.5181\n",
      "Epoch 2630/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1947 - val_loss: 2.7388 - val_mae: 1.4941\n",
      "Epoch 2631/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1890 - val_loss: 2.7409 - val_mae: 1.4949\n",
      "Epoch 2632/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1858 - val_loss: 2.7591 - val_mae: 1.5010\n",
      "Epoch 2633/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1875 - val_loss: 2.7832 - val_mae: 1.5090\n",
      "Epoch 2634/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1868 - val_loss: 2.8937 - val_mae: 1.5452\n",
      "Epoch 2635/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1916 - val_loss: 2.9134 - val_mae: 1.5515\n",
      "Epoch 2636/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1931 - val_loss: 2.8626 - val_mae: 1.5350\n",
      "Epoch 2637/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1864 - val_loss: 2.8348 - val_mae: 1.5259\n",
      "Epoch 2638/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1875 - val_loss: 2.8695 - val_mae: 1.5372\n",
      "Epoch 2639/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0513 - mae: 0.1860 - val_loss: 2.9866 - val_mae: 1.5749\n",
      "Epoch 2640/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1834 - val_loss: 3.0667 - val_mae: 1.6001\n",
      "Epoch 2641/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1796 - val_loss: 3.0846 - val_mae: 1.6057\n",
      "Epoch 2642/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1766 - val_loss: 3.0170 - val_mae: 1.5845\n",
      "Epoch 2643/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0521 - mae: 0.1807 - val_loss: 2.9253 - val_mae: 1.5552\n",
      "Epoch 2644/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0583 - mae: 0.2042 - val_loss: 2.9440 - val_mae: 1.5612\n",
      "Epoch 2645/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.2046 - val_loss: 3.0559 - val_mae: 1.5967\n",
      "Epoch 2646/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0525 - mae: 0.1825 - val_loss: 3.2499 - val_mae: 1.6564\n",
      "Epoch 2647/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1787 - val_loss: 3.3110 - val_mae: 1.6748\n",
      "Epoch 2648/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0628 - mae: 0.1901 - val_loss: 3.0851 - val_mae: 1.6059\n",
      "Epoch 2649/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1874 - val_loss: 2.8359 - val_mae: 1.5262\n",
      "Epoch 2650/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.2006 - val_loss: 2.7292 - val_mae: 1.4908\n",
      "Epoch 2651/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - mae: 0.2128 - val_loss: 2.8020 - val_mae: 1.5150\n",
      "Epoch 2652/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0565 - mae: 0.2008 - val_loss: 2.9678 - val_mae: 1.5689\n",
      "Epoch 2653/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0546 - mae: 0.1905 - val_loss: 3.0150 - val_mae: 1.5839\n",
      "Epoch 2654/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1854 - val_loss: 2.9758 - val_mae: 1.5715\n",
      "Epoch 2655/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1821 - val_loss: 2.9427 - val_mae: 1.5609\n",
      "Epoch 2656/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0521 - mae: 0.1795 - val_loss: 2.9430 - val_mae: 1.5611\n",
      "Epoch 2657/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0523 - mae: 0.1782 - val_loss: 2.8990 - val_mae: 1.5469\n",
      "Epoch 2658/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0526 - mae: 0.1770 - val_loss: 2.9399 - val_mae: 1.5600\n",
      "Epoch 2659/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0514 - mae: 0.1759 - val_loss: 3.0958 - val_mae: 1.6092\n",
      "Epoch 2660/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0528 - mae: 0.1754 - val_loss: 3.1483 - val_mae: 1.6254\n",
      "Epoch 2661/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0529 - mae: 0.1753 - val_loss: 3.0732 - val_mae: 1.6021\n",
      "Epoch 2662/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1798 - val_loss: 3.0074 - val_mae: 1.5814\n",
      "Epoch 2663/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0511 - mae: 0.1810 - val_loss: 3.0484 - val_mae: 1.5943\n",
      "Epoch 2664/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0508 - mae: 0.1806 - val_loss: 3.0920 - val_mae: 1.6080\n",
      "Epoch 2665/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0541 - mae: 0.1848 - val_loss: 3.0979 - val_mae: 1.6098\n",
      "Epoch 2666/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0570 - mae: 0.1878 - val_loss: 3.1069 - val_mae: 1.6126\n",
      "Epoch 2667/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0582 - mae: 0.1887 - val_loss: 3.0245 - val_mae: 1.5868\n",
      "Epoch 2668/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0524 - mae: 0.1809 - val_loss: 2.9396 - val_mae: 1.5598\n",
      "Epoch 2669/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0515 - mae: 0.1805 - val_loss: 2.9188 - val_mae: 1.5530\n",
      "Epoch 2670/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0588 - mae: 0.2060 - val_loss: 2.9772 - val_mae: 1.5718\n",
      "Epoch 2671/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0559 - mae: 0.1969 - val_loss: 3.1906 - val_mae: 1.6383\n",
      "Epoch 2672/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0541 - mae: 0.1794 - val_loss: 3.3170 - val_mae: 1.6765\n",
      "Epoch 2673/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0612 - mae: 0.1835 - val_loss: 3.1844 - val_mae: 1.6365\n",
      "Epoch 2674/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0529 - mae: 0.1793 - val_loss: 2.9263 - val_mae: 1.5555\n",
      "Epoch 2675/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0530 - mae: 0.1894 - val_loss: 2.7129 - val_mae: 1.4852\n",
      "Epoch 2676/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0749 - mae: 0.2352 - val_loss: 2.7201 - val_mae: 1.4877\n",
      "Epoch 2677/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0644 - mae: 0.2124 - val_loss: 2.8997 - val_mae: 1.5470\n",
      "Epoch 2678/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0528 - mae: 0.1871 - val_loss: 2.9280 - val_mae: 1.5562\n",
      "Epoch 2679/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0571 - mae: 0.1904 - val_loss: 2.7775 - val_mae: 1.5070\n",
      "Epoch 2680/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1837 - val_loss: 2.6073 - val_mae: 1.4493\n",
      "Epoch 2681/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0582 - mae: 0.1893 - val_loss: 2.5642 - val_mae: 1.4344\n",
      "Epoch 2682/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0618 - mae: 0.1975 - val_loss: 2.6876 - val_mae: 1.4768\n",
      "Epoch 2683/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0539 - mae: 0.1844 - val_loss: 2.8939 - val_mae: 1.5451\n",
      "Epoch 2684/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0537 - mae: 0.1812 - val_loss: 3.0867 - val_mae: 1.6064\n",
      "Epoch 2685/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0651 - mae: 0.2053 - val_loss: 3.1413 - val_mae: 1.6233\n",
      "Epoch 2686/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0626 - mae: 0.1955 - val_loss: 3.0728 - val_mae: 1.6020\n",
      "Epoch 2687/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0526 - mae: 0.1799 - val_loss: 2.9688 - val_mae: 1.5691\n",
      "Epoch 2688/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0523 - mae: 0.1844 - val_loss: 2.8227 - val_mae: 1.5218\n",
      "Epoch 2689/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0609 - mae: 0.2096 - val_loss: 2.7570 - val_mae: 1.5001\n",
      "Epoch 2690/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0627 - mae: 0.2147 - val_loss: 2.8468 - val_mae: 1.5298\n",
      "Epoch 2691/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0537 - mae: 0.1886 - val_loss: 2.9770 - val_mae: 1.5718\n",
      "Epoch 2692/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0500 - mae: 0.1761 - val_loss: 3.0864 - val_mae: 1.6062\n",
      "Epoch 2693/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0534 - mae: 0.1833 - val_loss: 3.1328 - val_mae: 1.6206\n",
      "Epoch 2694/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1914 - val_loss: 3.0150 - val_mae: 1.5838\n",
      "Epoch 2695/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1897 - val_loss: 2.7893 - val_mae: 1.5108\n",
      "Epoch 2696/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.2037 - val_loss: 2.6849 - val_mae: 1.4758\n",
      "Epoch 2697/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0625 - mae: 0.2083 - val_loss: 2.7318 - val_mae: 1.4917\n",
      "Epoch 2698/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1928 - val_loss: 2.8343 - val_mae: 1.5257\n",
      "Epoch 2699/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0517 - mae: 0.1843 - val_loss: 2.8672 - val_mae: 1.5365\n",
      "Epoch 2700/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0515 - mae: 0.1821 - val_loss: 2.7539 - val_mae: 1.4992\n",
      "Epoch 2701/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0514 - mae: 0.1801 - val_loss: 2.6221 - val_mae: 1.4545\n",
      "Epoch 2702/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0545 - mae: 0.1811 - val_loss: 2.5565 - val_mae: 1.4318\n",
      "Epoch 2703/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1831 - val_loss: 2.5781 - val_mae: 1.4394\n",
      "Epoch 2704/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.1848 - val_loss: 2.6192 - val_mae: 1.4536\n",
      "Epoch 2705/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0554 - mae: 0.1822 - val_loss: 2.6769 - val_mae: 1.4733\n",
      "Epoch 2706/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0532 - mae: 0.1790 - val_loss: 2.8139 - val_mae: 1.5191\n",
      "Epoch 2707/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1805 - val_loss: 2.9172 - val_mae: 1.5527\n",
      "Epoch 2708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1818 - val_loss: 2.9743 - val_mae: 1.5710\n",
      "Epoch 2709/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1811 - val_loss: 2.9587 - val_mae: 1.5660\n",
      "Epoch 2710/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1787 - val_loss: 2.9538 - val_mae: 1.5644\n",
      "Epoch 2711/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0503 - mae: 0.1797 - val_loss: 2.9948 - val_mae: 1.5774\n",
      "Epoch 2712/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1813 - val_loss: 2.9850 - val_mae: 1.5743\n",
      "Epoch 2713/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0519 - mae: 0.1864 - val_loss: 2.9967 - val_mae: 1.5780\n",
      "Epoch 2714/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0522 - mae: 0.1866 - val_loss: 3.0566 - val_mae: 1.5969\n",
      "Epoch 2715/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0512 - mae: 0.1802 - val_loss: 3.0851 - val_mae: 1.6058\n",
      "Epoch 2716/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0508 - mae: 0.1767 - val_loss: 3.0700 - val_mae: 1.6011\n",
      "Epoch 2717/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0509 - mae: 0.1754 - val_loss: 3.0555 - val_mae: 1.5966\n",
      "Epoch 2718/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1740 - val_loss: 2.9229 - val_mae: 1.5544\n",
      "Epoch 2719/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1770 - val_loss: 2.7282 - val_mae: 1.4904\n",
      "Epoch 2720/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0644 - mae: 0.2186 - val_loss: 2.7110 - val_mae: 1.4847\n",
      "Epoch 2721/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.2063 - val_loss: 2.8859 - val_mae: 1.5426\n",
      "Epoch 2722/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1705 - val_loss: 3.1143 - val_mae: 1.6150\n",
      "Epoch 2723/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0733 - mae: 0.2203 - val_loss: 3.1877 - val_mae: 1.6376\n",
      "Epoch 2724/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0822 - mae: 0.2362 - val_loss: 3.0274 - val_mae: 1.5878\n",
      "Epoch 2725/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0573 - mae: 0.1857 - val_loss: 2.8569 - val_mae: 1.5331\n",
      "Epoch 2726/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0518 - mae: 0.1811 - val_loss: 2.7938 - val_mae: 1.5123\n",
      "Epoch 2727/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.2063 - val_loss: 2.8910 - val_mae: 1.5441\n",
      "Epoch 2728/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1839 - val_loss: 3.1096 - val_mae: 1.6134\n",
      "Epoch 2729/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1790 - val_loss: 3.2333 - val_mae: 1.6514\n",
      "Epoch 2730/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1870 - val_loss: 3.1228 - val_mae: 1.6175\n",
      "Epoch 2731/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1756 - val_loss: 2.9097 - val_mae: 1.5501\n",
      "Epoch 2732/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1938 - val_loss: 2.7936 - val_mae: 1.5121\n",
      "Epoch 2733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0673 - mae: 0.2205 - val_loss: 2.8604 - val_mae: 1.5341\n",
      "Epoch 2734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.2007 - val_loss: 3.0509 - val_mae: 1.5951\n",
      "Epoch 2735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1794 - val_loss: 3.2129 - val_mae: 1.6452\n",
      "Epoch 2736/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1894 - val_loss: 3.2137 - val_mae: 1.6454\n",
      "Epoch 2737/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0604 - mae: 0.1887 - val_loss: 3.0765 - val_mae: 1.6031\n",
      "Epoch 2738/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1752 - val_loss: 2.9071 - val_mae: 1.5493\n",
      "Epoch 2739/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1890 - val_loss: 2.8479 - val_mae: 1.5300\n",
      "Epoch 2740/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1933 - val_loss: 2.9298 - val_mae: 1.5566\n",
      "Epoch 2741/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1771 - val_loss: 3.0443 - val_mae: 1.5930\n",
      "Epoch 2742/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1784 - val_loss: 3.1022 - val_mae: 1.6111\n",
      "Epoch 2743/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1838 - val_loss: 2.9894 - val_mae: 1.5757\n",
      "Epoch 2744/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1755 - val_loss: 2.7917 - val_mae: 1.5115\n",
      "Epoch 2745/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1887 - val_loss: 2.6979 - val_mae: 1.4802\n",
      "Epoch 2746/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0576 - mae: 0.1947 - val_loss: 2.7664 - val_mae: 1.5032\n",
      "Epoch 2747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1808 - val_loss: 2.9058 - val_mae: 1.5489\n",
      "Epoch 2748/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1883 - val_loss: 2.9160 - val_mae: 1.5522\n",
      "Epoch 2749/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0554 - mae: 0.1831 - val_loss: 2.8145 - val_mae: 1.5191\n",
      "Epoch 2750/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1765 - val_loss: 2.7009 - val_mae: 1.4812\n",
      "Epoch 2751/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1890 - val_loss: 2.7039 - val_mae: 1.4822\n",
      "Epoch 2752/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1928 - val_loss: 2.8437 - val_mae: 1.5287\n",
      "Epoch 2753/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1852 - val_loss: 2.8924 - val_mae: 1.5446\n",
      "Epoch 2754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1813 - val_loss: 2.9161 - val_mae: 1.5522\n",
      "Epoch 2755/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0496 - mae: 0.1789 - val_loss: 2.9959 - val_mae: 1.5777\n",
      "Epoch 2756/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1762 - val_loss: 3.0725 - val_mae: 1.6018\n",
      "Epoch 2757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1743 - val_loss: 3.1196 - val_mae: 1.6165\n",
      "Epoch 2758/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1727 - val_loss: 3.1577 - val_mae: 1.6282\n",
      "Epoch 2759/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0520 - mae: 0.1716 - val_loss: 3.2068 - val_mae: 1.6432\n",
      "Epoch 2760/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1737 - val_loss: 3.2635 - val_mae: 1.6604\n",
      "Epoch 2761/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.1785 - val_loss: 3.2526 - val_mae: 1.6571\n",
      "Epoch 2762/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.1798 - val_loss: 3.1455 - val_mae: 1.6245\n",
      "Epoch 2763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1724 - val_loss: 3.0335 - val_mae: 1.5896\n",
      "Epoch 2764/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0505 - mae: 0.1740 - val_loss: 2.9634 - val_mae: 1.5673\n",
      "Epoch 2765/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1794 - val_loss: 2.9874 - val_mae: 1.5750\n",
      "Epoch 2766/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1735 - val_loss: 3.0838 - val_mae: 1.6053\n",
      "Epoch 2767/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1828 - val_loss: 3.0640 - val_mae: 1.5991\n",
      "Epoch 2768/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1787 - val_loss: 2.8754 - val_mae: 1.5390\n",
      "Epoch 2769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1918 - val_loss: 2.7408 - val_mae: 1.4946\n",
      "Epoch 2770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.2163 - val_loss: 2.8318 - val_mae: 1.5247\n",
      "Epoch 2771/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1887 - val_loss: 3.0764 - val_mae: 1.6030\n",
      "Epoch 2772/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1753 - val_loss: 3.2647 - val_mae: 1.6608\n",
      "Epoch 2773/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.2027 - val_loss: 3.1685 - val_mae: 1.6315\n",
      "Epoch 2774/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0583 - mae: 0.1797 - val_loss: 2.9423 - val_mae: 1.5606\n",
      "Epoch 2775/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0511 - mae: 0.1770 - val_loss: 2.9401 - val_mae: 1.5599\n",
      "Epoch 2776/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1741 - val_loss: 3.0527 - val_mae: 1.5956\n",
      "Epoch 2777/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0512 - mae: 0.1761 - val_loss: 3.0771 - val_mae: 1.6033\n",
      "Epoch 2778/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0548 - mae: 0.1834 - val_loss: 3.0201 - val_mae: 1.5854\n",
      "Epoch 2779/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0519 - mae: 0.1804 - val_loss: 2.8818 - val_mae: 1.5411\n",
      "Epoch 2780/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1777 - val_loss: 2.7529 - val_mae: 1.4986\n",
      "Epoch 2781/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0598 - mae: 0.2044 - val_loss: 2.7593 - val_mae: 1.5007\n",
      "Epoch 2782/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.2089 - val_loss: 2.9394 - val_mae: 1.5596\n",
      "Epoch 2783/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1771 - val_loss: 3.2111 - val_mae: 1.6445\n",
      "Epoch 2784/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1782 - val_loss: 3.3090 - val_mae: 1.6741\n",
      "Epoch 2785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.1871 - val_loss: 3.1494 - val_mae: 1.6256\n",
      "Epoch 2786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1751 - val_loss: 2.9614 - val_mae: 1.5666\n",
      "Epoch 2787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1967 - val_loss: 2.9762 - val_mae: 1.5714\n",
      "Epoch 2788/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1926 - val_loss: 3.1384 - val_mae: 1.6222\n",
      "Epoch 2789/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1699 - val_loss: 3.2679 - val_mae: 1.6617\n",
      "Epoch 2790/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0571 - mae: 0.1752 - val_loss: 3.2451 - val_mae: 1.6548\n",
      "Epoch 2791/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1738 - val_loss: 3.1326 - val_mae: 1.6204\n",
      "Epoch 2792/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0515 - mae: 0.1742 - val_loss: 3.1219 - val_mae: 1.6171\n",
      "Epoch 2793/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0520 - mae: 0.1801 - val_loss: 3.1688 - val_mae: 1.6315\n",
      "Epoch 2794/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0516 - mae: 0.1732 - val_loss: 3.1664 - val_mae: 1.6308\n",
      "Epoch 2795/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0513 - mae: 0.1710 - val_loss: 3.1009 - val_mae: 1.6106\n",
      "Epoch 2796/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1705 - val_loss: 2.9939 - val_mae: 1.5770\n",
      "Epoch 2797/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1754 - val_loss: 2.9167 - val_mae: 1.5523\n",
      "Epoch 2798/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1785 - val_loss: 2.8769 - val_mae: 1.5394\n",
      "Epoch 2799/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1807 - val_loss: 2.8824 - val_mae: 1.5412\n",
      "Epoch 2800/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1904 - val_loss: 2.9710 - val_mae: 1.5697\n",
      "Epoch 2801/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1900 - val_loss: 3.0130 - val_mae: 1.5830\n",
      "Epoch 2802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1819 - val_loss: 2.9504 - val_mae: 1.5631\n",
      "Epoch 2803/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1883 - val_loss: 2.9722 - val_mae: 1.5701\n",
      "Epoch 2804/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1814 - val_loss: 3.1050 - val_mae: 1.6119\n",
      "Epoch 2805/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1683 - val_loss: 3.2318 - val_mae: 1.6508\n",
      "Epoch 2806/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0595 - mae: 0.1802 - val_loss: 3.2809 - val_mae: 1.6656\n",
      "Epoch 2807/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0642 - mae: 0.1883 - val_loss: 3.2631 - val_mae: 1.6602\n",
      "Epoch 2808/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1758 - val_loss: 3.1445 - val_mae: 1.6241\n",
      "Epoch 2809/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1748 - val_loss: 3.0053 - val_mae: 1.5806\n",
      "Epoch 2810/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1919 - val_loss: 2.9508 - val_mae: 1.5633\n",
      "Epoch 2811/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1904 - val_loss: 2.9190 - val_mae: 1.5531\n",
      "Epoch 2812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1793 - val_loss: 2.9605 - val_mae: 1.5664\n",
      "Epoch 2813/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1759 - val_loss: 2.9980 - val_mae: 1.5784\n",
      "Epoch 2814/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0556 - mae: 0.1853 - val_loss: 2.8772 - val_mae: 1.5396\n",
      "Epoch 2815/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1833 - val_loss: 2.7081 - val_mae: 1.4837\n",
      "Epoch 2816/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1772 - val_loss: 2.5840 - val_mae: 1.4412\n",
      "Epoch 2817/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1799 - val_loss: 2.6118 - val_mae: 1.4508\n",
      "Epoch 2818/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0548 - mae: 0.1763 - val_loss: 2.7736 - val_mae: 1.5056\n",
      "Epoch 2819/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1887 - val_loss: 2.8926 - val_mae: 1.5447\n",
      "Epoch 2820/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0608 - mae: 0.1956 - val_loss: 2.9201 - val_mae: 1.5535\n",
      "Epoch 2821/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1801 - val_loss: 2.9533 - val_mae: 1.5641\n",
      "Epoch 2822/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1693 - val_loss: 3.0319 - val_mae: 1.5890\n",
      "Epoch 2823/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1711 - val_loss: 3.0791 - val_mae: 1.6038\n",
      "Epoch 2824/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0530 - mae: 0.1857 - val_loss: 3.1848 - val_mae: 1.6364\n",
      "Epoch 2825/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1953 - val_loss: 3.2987 - val_mae: 1.6709\n",
      "Epoch 2826/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0633 - mae: 0.2044 - val_loss: 3.2994 - val_mae: 1.6711\n",
      "Epoch 2827/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0644 - mae: 0.2076 - val_loss: 3.1910 - val_mae: 1.6383\n",
      "Epoch 2828/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0611 - mae: 0.2043 - val_loss: 2.9678 - val_mae: 1.5687\n",
      "Epoch 2829/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0647 - mae: 0.2087 - val_loss: 2.7865 - val_mae: 1.5097\n",
      "Epoch 2830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.2110 - val_loss: 2.8043 - val_mae: 1.5157\n",
      "Epoch 2831/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1809 - val_loss: 2.8557 - val_mae: 1.5326\n",
      "Epoch 2832/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1745 - val_loss: 2.8969 - val_mae: 1.5461\n",
      "Epoch 2833/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0625 - mae: 0.2013 - val_loss: 2.9098 - val_mae: 1.5503\n",
      "Epoch 2834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0681 - mae: 0.2120 - val_loss: 2.7948 - val_mae: 1.5127\n",
      "Epoch 2835/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0587 - mae: 0.1893 - val_loss: 2.6715 - val_mae: 1.4713\n",
      "Epoch 2836/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1780 - val_loss: 2.5734 - val_mae: 1.4375\n",
      "Epoch 2837/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1844 - val_loss: 2.5155 - val_mae: 1.4172\n",
      "Epoch 2838/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1861 - val_loss: 2.5406 - val_mae: 1.4260\n",
      "Epoch 2839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1851 - val_loss: 2.6076 - val_mae: 1.4494\n",
      "Epoch 2840/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1879 - val_loss: 2.7304 - val_mae: 1.4912\n",
      "Epoch 2841/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0594 - mae: 0.1942 - val_loss: 2.7128 - val_mae: 1.4852\n",
      "Epoch 2842/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0509 - mae: 0.1790 - val_loss: 2.5640 - val_mae: 1.4341\n",
      "Epoch 2843/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - mae: 0.2063 - val_loss: 2.5927 - val_mae: 1.4441\n",
      "Epoch 2844/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0659 - mae: 0.2132 - val_loss: 2.7769 - val_mae: 1.5066\n",
      "Epoch 2845/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1801 - val_loss: 2.9379 - val_mae: 1.5592\n",
      "Epoch 2846/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1744 - val_loss: 2.9926 - val_mae: 1.5767\n",
      "Epoch 2847/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1762 - val_loss: 2.8747 - val_mae: 1.5388\n",
      "Epoch 2848/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1730 - val_loss: 2.7079 - val_mae: 1.4835\n",
      "Epoch 2849/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1987 - val_loss: 2.7242 - val_mae: 1.4890\n",
      "Epoch 2850/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1894 - val_loss: 2.8990 - val_mae: 1.5467\n",
      "Epoch 2851/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0540 - mae: 0.1776 - val_loss: 3.0212 - val_mae: 1.5858\n",
      "Epoch 2852/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0624 - mae: 0.1955 - val_loss: 2.9298 - val_mae: 1.5566\n",
      "Epoch 2853/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0562 - mae: 0.1826 - val_loss: 2.7826 - val_mae: 1.5085\n",
      "Epoch 2854/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1822 - val_loss: 2.7562 - val_mae: 1.4997\n",
      "Epoch 2855/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1887 - val_loss: 2.7644 - val_mae: 1.5024\n",
      "Epoch 2856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1878 - val_loss: 2.8522 - val_mae: 1.5314\n",
      "Epoch 2857/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1789 - val_loss: 2.9188 - val_mae: 1.5530\n",
      "Epoch 2858/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0503 - mae: 0.1799 - val_loss: 2.9323 - val_mae: 1.5573\n",
      "Epoch 2859/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1850 - val_loss: 3.0320 - val_mae: 1.5890\n",
      "Epoch 2860/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1863 - val_loss: 3.0728 - val_mae: 1.6019\n",
      "Epoch 2861/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1905 - val_loss: 2.9968 - val_mae: 1.5779\n",
      "Epoch 2862/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1769 - val_loss: 2.9072 - val_mae: 1.5492\n",
      "Epoch 2863/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1850 - val_loss: 2.9189 - val_mae: 1.5530\n",
      "Epoch 2864/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1844 - val_loss: 3.0104 - val_mae: 1.5822\n",
      "Epoch 2865/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1730 - val_loss: 3.1576 - val_mae: 1.6281\n",
      "Epoch 2866/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1782 - val_loss: 3.1507 - val_mae: 1.6260\n",
      "Epoch 2867/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1730 - val_loss: 2.9942 - val_mae: 1.5771\n",
      "Epoch 2868/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1828 - val_loss: 2.9036 - val_mae: 1.5480\n",
      "Epoch 2869/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.2094 - val_loss: 2.9479 - val_mae: 1.5623\n",
      "Epoch 2870/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1921 - val_loss: 3.0650 - val_mae: 1.5994\n",
      "Epoch 2871/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1768 - val_loss: 3.1403 - val_mae: 1.6228\n",
      "Epoch 2872/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0523 - mae: 0.1785 - val_loss: 3.1350 - val_mae: 1.6211\n",
      "Epoch 2873/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0522 - mae: 0.1786 - val_loss: 3.0599 - val_mae: 1.5978\n",
      "Epoch 2874/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1733 - val_loss: 2.9991 - val_mae: 1.5786\n",
      "Epoch 2875/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1718 - val_loss: 2.9926 - val_mae: 1.5766\n",
      "Epoch 2876/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1735 - val_loss: 3.0209 - val_mae: 1.5856\n",
      "Epoch 2877/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1788 - val_loss: 3.0348 - val_mae: 1.5900\n",
      "Epoch 2878/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0565 - mae: 0.1820 - val_loss: 2.9671 - val_mae: 1.5685\n",
      "Epoch 2879/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1751 - val_loss: 2.8844 - val_mae: 1.5419\n",
      "Epoch 2880/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1711 - val_loss: 2.9248 - val_mae: 1.5549\n",
      "Epoch 2881/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0486 - mae: 0.1702 - val_loss: 2.9804 - val_mae: 1.5727\n",
      "Epoch 2882/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1717 - val_loss: 2.9968 - val_mae: 1.5779\n",
      "Epoch 2883/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0488 - mae: 0.1721 - val_loss: 3.0354 - val_mae: 1.5901\n",
      "Epoch 2884/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0493 - mae: 0.1729 - val_loss: 3.0100 - val_mae: 1.5820\n",
      "Epoch 2885/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0512 - mae: 0.1796 - val_loss: 3.0151 - val_mae: 1.5836\n",
      "Epoch 2886/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1911 - val_loss: 3.2371 - val_mae: 1.6523\n",
      "Epoch 2887/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1788 - val_loss: 3.5127 - val_mae: 1.7337\n",
      "Epoch 2888/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0653 - mae: 0.1877 - val_loss: 3.6434 - val_mae: 1.7711\n",
      "Epoch 2889/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0747 - mae: 0.2035 - val_loss: 3.5547 - val_mae: 1.7458\n",
      "Epoch 2890/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0646 - mae: 0.1806 - val_loss: 3.2721 - val_mae: 1.6628\n",
      "Epoch 2891/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0575 - mae: 0.1883 - val_loss: 2.9987 - val_mae: 1.5783\n",
      "Epoch 2892/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0711 - mae: 0.2319 - val_loss: 2.8979 - val_mae: 1.5461\n",
      "Epoch 2893/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0670 - mae: 0.2255 - val_loss: 3.0085 - val_mae: 1.5815\n",
      "Epoch 2894/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0504 - mae: 0.1764 - val_loss: 3.1926 - val_mae: 1.6388\n",
      "Epoch 2895/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0664 - mae: 0.2038 - val_loss: 3.1990 - val_mae: 1.6408\n",
      "Epoch 2896/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0793 - mae: 0.2356 - val_loss: 3.0109 - val_mae: 1.5823\n",
      "Epoch 2897/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1962 - val_loss: 2.8362 - val_mae: 1.5261\n",
      "Epoch 2898/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1822 - val_loss: 2.8408 - val_mae: 1.5275\n",
      "Epoch 2899/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0517 - mae: 0.1829 - val_loss: 2.9990 - val_mae: 1.5785\n",
      "Epoch 2900/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0489 - mae: 0.1740 - val_loss: 3.1270 - val_mae: 1.6186\n",
      "Epoch 2901/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1728 - val_loss: 3.0953 - val_mae: 1.6088\n",
      "Epoch 2902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0499 - mae: 0.1691 - val_loss: 2.9003 - val_mae: 1.5469\n",
      "Epoch 2903/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1742 - val_loss: 2.7045 - val_mae: 1.4822\n",
      "Epoch 2904/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.2080 - val_loss: 2.6228 - val_mae: 1.4543\n",
      "Epoch 2905/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0703 - mae: 0.2272 - val_loss: 2.6627 - val_mae: 1.4680\n",
      "Epoch 2906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.2098 - val_loss: 2.8181 - val_mae: 1.5201\n",
      "Epoch 2907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1724 - val_loss: 2.9973 - val_mae: 1.5780\n",
      "Epoch 2908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1979 - val_loss: 3.0496 - val_mae: 1.5945\n",
      "Epoch 2909/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1914 - val_loss: 2.9087 - val_mae: 1.5496\n",
      "Epoch 2910/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1802 - val_loss: 2.8074 - val_mae: 1.5166\n",
      "Epoch 2911/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0585 - mae: 0.1994 - val_loss: 2.9544 - val_mae: 1.5644\n",
      "Epoch 2912/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1905 - val_loss: 3.1708 - val_mae: 1.6321\n",
      "Epoch 2913/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2132 - val_loss: 3.1933 - val_mae: 1.6390\n",
      "Epoch 2914/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0692 - mae: 0.2055 - val_loss: 3.1367 - val_mae: 1.6216\n",
      "Epoch 2915/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1827 - val_loss: 3.0389 - val_mae: 1.5911\n",
      "Epoch 2916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1925 - val_loss: 3.0490 - val_mae: 1.5943\n",
      "Epoch 2917/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0547 - mae: 0.1915 - val_loss: 3.2630 - val_mae: 1.6601\n",
      "Epoch 2918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1739 - val_loss: 3.4746 - val_mae: 1.7227\n",
      "Epoch 2919/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.1930 - val_loss: 3.5019 - val_mae: 1.7306\n",
      "Epoch 2920/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0684 - mae: 0.2000 - val_loss: 3.3240 - val_mae: 1.6784\n",
      "Epoch 2921/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1849 - val_loss: 3.1446 - val_mae: 1.6240\n",
      "Epoch 2922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1863 - val_loss: 3.0361 - val_mae: 1.5902\n",
      "Epoch 2923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1879 - val_loss: 3.0174 - val_mae: 1.5843\n",
      "Epoch 2924/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1773 - val_loss: 3.0850 - val_mae: 1.6055\n",
      "Epoch 2925/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0506 - mae: 0.1755 - val_loss: 3.1153 - val_mae: 1.6150\n",
      "Epoch 2926/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1821 - val_loss: 3.0694 - val_mae: 1.6007\n",
      "Epoch 2927/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0540 - mae: 0.1780 - val_loss: 3.0558 - val_mae: 1.5964\n",
      "Epoch 2928/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1725 - val_loss: 2.9630 - val_mae: 1.5670\n",
      "Epoch 2929/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0503 - mae: 0.1746 - val_loss: 2.8539 - val_mae: 1.5318\n",
      "Epoch 2930/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1893 - val_loss: 2.8712 - val_mae: 1.5374\n",
      "Epoch 2931/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0497 - mae: 0.1751 - val_loss: 2.8525 - val_mae: 1.5313\n",
      "Epoch 2932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1740 - val_loss: 2.8243 - val_mae: 1.5221\n",
      "Epoch 2933/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1823 - val_loss: 2.8303 - val_mae: 1.5241\n",
      "Epoch 2934/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1856 - val_loss: 2.7868 - val_mae: 1.5097\n",
      "Epoch 2935/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1848 - val_loss: 2.7914 - val_mae: 1.5113\n",
      "Epoch 2936/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1785 - val_loss: 2.8774 - val_mae: 1.5396\n",
      "Epoch 2937/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1800 - val_loss: 2.8666 - val_mae: 1.5360\n",
      "Epoch 2938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1708 - val_loss: 2.7409 - val_mae: 1.4945\n",
      "Epoch 2939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1783 - val_loss: 2.6601 - val_mae: 1.4672\n",
      "Epoch 2940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1983 - val_loss: 2.7471 - val_mae: 1.4966\n",
      "Epoch 2941/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1769 - val_loss: 2.9890 - val_mae: 1.5754\n",
      "Epoch 2942/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1852 - val_loss: 3.2243 - val_mae: 1.6485\n",
      "Epoch 2943/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0785 - mae: 0.2297 - val_loss: 3.2582 - val_mae: 1.6587\n",
      "Epoch 2944/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0704 - mae: 0.2115 - val_loss: 3.1239 - val_mae: 1.6177\n",
      "Epoch 2945/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1739 - val_loss: 2.9863 - val_mae: 1.5745\n",
      "Epoch 2946/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1845 - val_loss: 2.9032 - val_mae: 1.5478\n",
      "Epoch 2947/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1986 - val_loss: 2.8972 - val_mae: 1.5459\n",
      "Epoch 2948/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1938 - val_loss: 3.0474 - val_mae: 1.5938\n",
      "Epoch 2949/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1698 - val_loss: 3.2353 - val_mae: 1.6517\n",
      "Epoch 2950/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0542 - mae: 0.1748 - val_loss: 3.2207 - val_mae: 1.6473\n",
      "Epoch 2951/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0522 - mae: 0.1743 - val_loss: 3.0790 - val_mae: 1.6036\n",
      "Epoch 2952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1867 - val_loss: 3.0164 - val_mae: 1.5839\n",
      "Epoch 2953/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1938 - val_loss: 2.9716 - val_mae: 1.5698\n",
      "Epoch 2954/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0530 - mae: 0.1898 - val_loss: 2.8782 - val_mae: 1.5397\n",
      "Epoch 2955/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1942 - val_loss: 2.9031 - val_mae: 1.5478\n",
      "Epoch 2956/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0479 - mae: 0.1713 - val_loss: 3.1053 - val_mae: 1.6119\n",
      "Epoch 2957/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1916 - val_loss: 3.2328 - val_mae: 1.6511\n",
      "Epoch 2958/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0729 - mae: 0.2151 - val_loss: 3.0986 - val_mae: 1.6098\n",
      "Epoch 2959/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1780 - val_loss: 2.9524 - val_mae: 1.5636\n",
      "Epoch 2960/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1902 - val_loss: 2.9140 - val_mae: 1.5513\n",
      "Epoch 2961/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.2162 - val_loss: 3.0661 - val_mae: 1.5996\n",
      "Epoch 2962/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.1996 - val_loss: 3.2965 - val_mae: 1.6701\n",
      "Epoch 2963/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1762 - val_loss: 3.4077 - val_mae: 1.7031\n",
      "Epoch 2964/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.1746 - val_loss: 3.4645 - val_mae: 1.7197\n",
      "Epoch 2965/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0597 - mae: 0.1756 - val_loss: 3.4235 - val_mae: 1.7077\n",
      "Epoch 2966/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0589 - mae: 0.1809 - val_loss: 3.3649 - val_mae: 1.6905\n",
      "Epoch 2967/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1825 - val_loss: 3.2394 - val_mae: 1.6529\n",
      "Epoch 2968/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1840 - val_loss: 2.9609 - val_mae: 1.5663\n",
      "Epoch 2969/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0553 - mae: 0.1922 - val_loss: 2.7671 - val_mae: 1.5031\n",
      "Epoch 2970/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1906 - val_loss: 2.7028 - val_mae: 1.4816\n",
      "Epoch 2971/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0532 - mae: 0.1786 - val_loss: 2.6256 - val_mae: 1.4553\n",
      "Epoch 2972/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1762 - val_loss: 2.5607 - val_mae: 1.4328\n",
      "Epoch 2973/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1805 - val_loss: 2.6452 - val_mae: 1.4621\n",
      "Epoch 2974/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1772 - val_loss: 2.7537 - val_mae: 1.4987\n",
      "Epoch 2975/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1782 - val_loss: 2.7549 - val_mae: 1.4991\n",
      "Epoch 2976/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1748 - val_loss: 2.7469 - val_mae: 1.4964\n",
      "Epoch 2977/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1828 - val_loss: 2.7787 - val_mae: 1.5070\n",
      "Epoch 2978/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0497 - mae: 0.1767 - val_loss: 2.9416 - val_mae: 1.5602\n",
      "Epoch 2979/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1767 - val_loss: 3.0597 - val_mae: 1.5976\n",
      "Epoch 2980/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1933 - val_loss: 2.9831 - val_mae: 1.5734\n",
      "Epoch 2981/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0483 - mae: 0.1689 - val_loss: 2.8516 - val_mae: 1.5310\n",
      "Epoch 2982/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0536 - mae: 0.1939 - val_loss: 2.8098 - val_mae: 1.5172\n",
      "Epoch 2983/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.2196 - val_loss: 2.9653 - val_mae: 1.5677\n",
      "Epoch 2984/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1789 - val_loss: 3.2369 - val_mae: 1.6522\n",
      "Epoch 2985/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0619 - mae: 0.1891 - val_loss: 3.3236 - val_mae: 1.6782\n",
      "Epoch 2986/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0700 - mae: 0.2055 - val_loss: 3.0641 - val_mae: 1.5990\n",
      "Epoch 2987/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0508 - mae: 0.1749 - val_loss: 2.7825 - val_mae: 1.5082\n",
      "Epoch 2988/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0655 - mae: 0.2238 - val_loss: 2.7685 - val_mae: 1.5035\n",
      "Epoch 2989/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.2168 - val_loss: 2.9612 - val_mae: 1.5664\n",
      "Epoch 2990/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1698 - val_loss: 3.0710 - val_mae: 1.6011\n",
      "Epoch 2991/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0621 - mae: 0.2014 - val_loss: 2.9806 - val_mae: 1.5727\n",
      "Epoch 2992/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0641 - mae: 0.2057 - val_loss: 2.8789 - val_mae: 1.5400\n",
      "Epoch 2993/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1865 - val_loss: 2.7818 - val_mae: 1.5080\n",
      "Epoch 2994/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0507 - mae: 0.1744 - val_loss: 2.7261 - val_mae: 1.4894\n",
      "Epoch 2995/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0537 - mae: 0.1884 - val_loss: 2.8223 - val_mae: 1.5214\n",
      "Epoch 2996/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1789 - val_loss: 2.9704 - val_mae: 1.5694\n",
      "Epoch 2997/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1712 - val_loss: 3.0771 - val_mae: 1.6030\n",
      "Epoch 2998/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0532 - mae: 0.1735 - val_loss: 3.0423 - val_mae: 1.5921\n",
      "Epoch 2999/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1689 - val_loss: 2.9066 - val_mae: 1.5488\n",
      "Epoch 3000/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1953 - val_loss: 2.8521 - val_mae: 1.5311\n",
      "Epoch 3001/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2142 - val_loss: 2.8876 - val_mae: 1.5426\n",
      "Epoch 3002/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.2003 - val_loss: 2.9422 - val_mae: 1.5603\n",
      "Epoch 3003/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0487 - mae: 0.1734 - val_loss: 3.0223 - val_mae: 1.5858\n",
      "Epoch 3004/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1723 - val_loss: 3.0625 - val_mae: 1.5985\n",
      "Epoch 3005/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1779 - val_loss: 2.9534 - val_mae: 1.5639\n",
      "Epoch 3006/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1753 - val_loss: 2.8593 - val_mae: 1.5335\n",
      "Epoch 3007/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1847 - val_loss: 2.9235 - val_mae: 1.5543\n",
      "Epoch 3008/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1668 - val_loss: 3.1106 - val_mae: 1.6135\n",
      "Epoch 3009/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1792 - val_loss: 3.1799 - val_mae: 1.6348\n",
      "Epoch 3010/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0595 - mae: 0.1860 - val_loss: 3.0319 - val_mae: 1.5889\n",
      "Epoch 3011/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1679 - val_loss: 2.8565 - val_mae: 1.5326\n",
      "Epoch 3012/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.2086 - val_loss: 2.8289 - val_mae: 1.5235\n",
      "Epoch 3013/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.2233 - val_loss: 2.9725 - val_mae: 1.5700\n",
      "Epoch 3014/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1931 - val_loss: 3.1352 - val_mae: 1.6210\n",
      "Epoch 3015/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1656 - val_loss: 3.1329 - val_mae: 1.6203\n",
      "Epoch 3016/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1716 - val_loss: 3.0237 - val_mae: 1.5863\n",
      "Epoch 3017/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1687 - val_loss: 2.8324 - val_mae: 1.5247\n",
      "Epoch 3018/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0489 - mae: 0.1740 - val_loss: 2.6567 - val_mae: 1.4659\n",
      "Epoch 3019/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0629 - mae: 0.2093 - val_loss: 2.6316 - val_mae: 1.4573\n",
      "Epoch 3020/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0656 - mae: 0.2117 - val_loss: 2.7107 - val_mae: 1.4842\n",
      "Epoch 3021/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1886 - val_loss: 2.8579 - val_mae: 1.5331\n",
      "Epoch 3022/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0486 - mae: 0.1707 - val_loss: 3.0297 - val_mae: 1.5882\n",
      "Epoch 3023/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0595 - mae: 0.1909 - val_loss: 3.0788 - val_mae: 1.6037\n",
      "Epoch 3024/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0591 - mae: 0.1885 - val_loss: 2.9087 - val_mae: 1.5496\n",
      "Epoch 3025/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1821 - val_loss: 2.7896 - val_mae: 1.5105\n",
      "Epoch 3026/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2118 - val_loss: 2.8993 - val_mae: 1.5465\n",
      "Epoch 3027/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1932 - val_loss: 3.0432 - val_mae: 1.5923\n",
      "Epoch 3028/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1707 - val_loss: 3.0149 - val_mae: 1.5834\n",
      "Epoch 3029/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1774 - val_loss: 2.9264 - val_mae: 1.5552\n",
      "Epoch 3030/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1866 - val_loss: 2.9677 - val_mae: 1.5684\n",
      "Epoch 3031/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1676 - val_loss: 3.0534 - val_mae: 1.5956\n",
      "Epoch 3032/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1829 - val_loss: 3.0098 - val_mae: 1.5820\n",
      "Epoch 3033/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1931 - val_loss: 2.8901 - val_mae: 1.5436\n",
      "Epoch 3034/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1807 - val_loss: 2.7573 - val_mae: 1.4999\n",
      "Epoch 3035/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1943 - val_loss: 2.7730 - val_mae: 1.5051\n",
      "Epoch 3036/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1970 - val_loss: 2.9419 - val_mae: 1.5602\n",
      "Epoch 3037/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1812 - val_loss: 3.0328 - val_mae: 1.5891\n",
      "Epoch 3038/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1730 - val_loss: 3.0454 - val_mae: 1.5930\n",
      "Epoch 3039/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0480 - mae: 0.1708 - val_loss: 3.0268 - val_mae: 1.5872\n",
      "Epoch 3040/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0509 - mae: 0.1821 - val_loss: 3.0265 - val_mae: 1.5871\n",
      "Epoch 3041/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1978 - val_loss: 2.9884 - val_mae: 1.5750\n",
      "Epoch 3042/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.2113 - val_loss: 2.8760 - val_mae: 1.5389\n",
      "Epoch 3043/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0618 - mae: 0.2113 - val_loss: 2.7795 - val_mae: 1.5072\n",
      "Epoch 3044/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0587 - mae: 0.1987 - val_loss: 2.7595 - val_mae: 1.5006\n",
      "Epoch 3045/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1831 - val_loss: 2.8510 - val_mae: 1.5308\n",
      "Epoch 3046/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1744 - val_loss: 2.8955 - val_mae: 1.5454\n",
      "Epoch 3047/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0521 - mae: 0.1739 - val_loss: 2.8231 - val_mae: 1.5217\n",
      "Epoch 3048/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0518 - mae: 0.1739 - val_loss: 2.7066 - val_mae: 1.4829\n",
      "Epoch 3049/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1855 - val_loss: 2.6258 - val_mae: 1.4554\n",
      "Epoch 3050/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1872 - val_loss: 2.7948 - val_mae: 1.5124\n",
      "Epoch 3051/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0513 - mae: 0.1745 - val_loss: 3.1096 - val_mae: 1.6132\n",
      "Epoch 3052/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0721 - mae: 0.2225 - val_loss: 3.3437 - val_mae: 1.6843\n",
      "Epoch 3053/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0876 - mae: 0.2420 - val_loss: 3.3213 - val_mae: 1.6775\n",
      "Epoch 3054/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0634 - mae: 0.1889 - val_loss: 3.1231 - val_mae: 1.6173\n",
      "Epoch 3055/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1818 - val_loss: 2.9265 - val_mae: 1.5552\n",
      "Epoch 3056/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0712 - mae: 0.2317 - val_loss: 2.7844 - val_mae: 1.5088\n",
      "Epoch 3057/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0902 - mae: 0.2632 - val_loss: 2.8533 - val_mae: 1.5315\n",
      "Epoch 3058/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0675 - mae: 0.2266 - val_loss: 3.1214 - val_mae: 1.6168\n",
      "Epoch 3059/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1789 - val_loss: 3.3240 - val_mae: 1.6783\n",
      "Epoch 3060/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.1894 - val_loss: 3.2219 - val_mae: 1.6476\n",
      "Epoch 3061/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1792 - val_loss: 3.0436 - val_mae: 1.5925\n",
      "Epoch 3062/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1776 - val_loss: 2.9962 - val_mae: 1.5776\n",
      "Epoch 3063/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0501 - mae: 0.1753 - val_loss: 2.8913 - val_mae: 1.5440\n",
      "Epoch 3064/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1746 - val_loss: 2.6521 - val_mae: 1.4644\n",
      "Epoch 3065/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.2180 - val_loss: 2.5795 - val_mae: 1.4394\n",
      "Epoch 3066/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0659 - mae: 0.2136 - val_loss: 2.6934 - val_mae: 1.4785\n",
      "Epoch 3067/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1768 - val_loss: 2.7811 - val_mae: 1.5079\n",
      "Epoch 3068/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1900 - val_loss: 2.7461 - val_mae: 1.4963\n",
      "Epoch 3069/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1841 - val_loss: 2.6441 - val_mae: 1.4617\n",
      "Epoch 3070/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1828 - val_loss: 2.6397 - val_mae: 1.4603\n",
      "Epoch 3071/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1783 - val_loss: 2.7041 - val_mae: 1.4822\n",
      "Epoch 3072/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1810 - val_loss: 2.7237 - val_mae: 1.4888\n",
      "Epoch 3073/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0590 - mae: 0.1904 - val_loss: 2.6871 - val_mae: 1.4765\n",
      "Epoch 3074/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0559 - mae: 0.1809 - val_loss: 2.6598 - val_mae: 1.4672\n",
      "Epoch 3075/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1822 - val_loss: 2.6672 - val_mae: 1.4697\n",
      "Epoch 3076/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1824 - val_loss: 2.7308 - val_mae: 1.4912\n",
      "Epoch 3077/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1755 - val_loss: 2.7927 - val_mae: 1.5118\n",
      "Epoch 3078/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1740 - val_loss: 2.7682 - val_mae: 1.5037\n",
      "Epoch 3079/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1766 - val_loss: 2.6236 - val_mae: 1.4547\n",
      "Epoch 3080/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1838 - val_loss: 2.5090 - val_mae: 1.4147\n",
      "Epoch 3081/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.1973 - val_loss: 2.6404 - val_mae: 1.4605\n",
      "Epoch 3082/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1774 - val_loss: 2.8831 - val_mae: 1.5415\n",
      "Epoch 3083/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1779 - val_loss: 2.9399 - val_mae: 1.5598\n",
      "Epoch 3084/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1697 - val_loss: 2.8465 - val_mae: 1.5295\n",
      "Epoch 3085/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1747 - val_loss: 2.8079 - val_mae: 1.5168\n",
      "Epoch 3086/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0503 - mae: 0.1815 - val_loss: 2.9052 - val_mae: 1.5486\n",
      "Epoch 3087/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0479 - mae: 0.1715 - val_loss: 3.0470 - val_mae: 1.5937\n",
      "Epoch 3088/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1695 - val_loss: 3.1837 - val_mae: 1.6361\n",
      "Epoch 3089/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1729 - val_loss: 3.3023 - val_mae: 1.6719\n",
      "Epoch 3090/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1785 - val_loss: 3.3427 - val_mae: 1.6840\n",
      "Epoch 3091/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1748 - val_loss: 3.2693 - val_mae: 1.6620\n",
      "Epoch 3092/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1791 - val_loss: 3.1667 - val_mae: 1.6308\n",
      "Epoch 3093/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1850 - val_loss: 3.1178 - val_mae: 1.6157\n",
      "Epoch 3094/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1822 - val_loss: 3.2129 - val_mae: 1.6449\n",
      "Epoch 3095/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1717 - val_loss: 3.2714 - val_mae: 1.6627\n",
      "Epoch 3096/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1820 - val_loss: 3.0826 - val_mae: 1.6048\n",
      "Epoch 3097/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0492 - mae: 0.1626 - val_loss: 2.8113 - val_mae: 1.5178\n",
      "Epoch 3098/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0534 - mae: 0.1929 - val_loss: 2.6384 - val_mae: 1.4597\n",
      "Epoch 3099/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0609 - mae: 0.2091 - val_loss: 2.6228 - val_mae: 1.4544\n",
      "Epoch 3100/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1851 - val_loss: 2.6914 - val_mae: 1.4779\n",
      "Epoch 3101/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1753 - val_loss: 2.7920 - val_mae: 1.5117\n",
      "Epoch 3102/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.1982 - val_loss: 2.7859 - val_mae: 1.5096\n",
      "Epoch 3103/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0600 - mae: 0.1922 - val_loss: 2.7588 - val_mae: 1.5006\n",
      "Epoch 3104/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1779 - val_loss: 2.7958 - val_mae: 1.5128\n",
      "Epoch 3105/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0527 - mae: 0.1833 - val_loss: 2.8580 - val_mae: 1.5331\n",
      "Epoch 3106/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1842 - val_loss: 3.0435 - val_mae: 1.5925\n",
      "Epoch 3107/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1665 - val_loss: 3.2684 - val_mae: 1.6616\n",
      "Epoch 3108/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0587 - mae: 0.1827 - val_loss: 3.3555 - val_mae: 1.6877\n",
      "Epoch 3109/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.1828 - val_loss: 3.3385 - val_mae: 1.6826\n",
      "Epoch 3110/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0545 - mae: 0.1720 - val_loss: 3.3068 - val_mae: 1.6731\n",
      "Epoch 3111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1869 - val_loss: 3.3157 - val_mae: 1.6757\n",
      "Epoch 3112/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.1945 - val_loss: 3.3208 - val_mae: 1.6773\n",
      "Epoch 3113/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1936 - val_loss: 3.2403 - val_mae: 1.6531\n",
      "Epoch 3114/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2003 - val_loss: 3.0563 - val_mae: 1.5964\n",
      "Epoch 3115/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2194 - val_loss: 2.9318 - val_mae: 1.5569\n",
      "Epoch 3116/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.2110 - val_loss: 3.0466 - val_mae: 1.5935\n",
      "Epoch 3117/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1846 - val_loss: 3.2077 - val_mae: 1.6434\n",
      "Epoch 3118/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1019 - mae: 0.2666 - val_loss: 3.1070 - val_mae: 1.6125\n",
      "Epoch 3119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0873 - mae: 0.2508 - val_loss: 2.7674 - val_mae: 1.5033\n",
      "Epoch 3120/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1790 - val_loss: 2.5288 - val_mae: 1.4216\n",
      "Epoch 3121/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0866 - mae: 0.2503 - val_loss: 2.6085 - val_mae: 1.4494\n",
      "Epoch 3122/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0820 - mae: 0.2384 - val_loss: 2.8929 - val_mae: 1.5446\n",
      "Epoch 3123/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0692 - mae: 0.2070 - val_loss: 3.1598 - val_mae: 1.6288\n",
      "Epoch 3124/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0917 - mae: 0.2440 - val_loss: 3.1920 - val_mae: 1.6386\n",
      "Epoch 3125/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0822 - mae: 0.2273 - val_loss: 3.0676 - val_mae: 1.6001\n",
      "Epoch 3126/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0669 - mae: 0.2038 - val_loss: 2.9883 - val_mae: 1.5750\n",
      "Epoch 3127/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0828 - mae: 0.2446 - val_loss: 3.0807 - val_mae: 1.6041\n",
      "Epoch 3128/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0814 - mae: 0.2387 - val_loss: 3.3642 - val_mae: 1.6903\n",
      "Epoch 3129/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.2002 - val_loss: 3.5804 - val_mae: 1.7532\n",
      "Epoch 3130/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0739 - mae: 0.2040 - val_loss: 3.6372 - val_mae: 1.7694\n",
      "Epoch 3131/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0857 - mae: 0.2252 - val_loss: 3.4668 - val_mae: 1.7205\n",
      "Epoch 3132/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0656 - mae: 0.1932 - val_loss: 3.0747 - val_mae: 1.6024\n",
      "Epoch 3133/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0774 - mae: 0.2341 - val_loss: 2.8069 - val_mae: 1.5164\n",
      "Epoch 3134/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1263 - mae: 0.3057 - val_loss: 2.9161 - val_mae: 1.5521\n",
      "Epoch 3135/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0756 - mae: 0.2255 - val_loss: 3.3006 - val_mae: 1.6716\n",
      "Epoch 3136/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0742 - mae: 0.2082 - val_loss: 3.4480 - val_mae: 1.7152\n",
      "Epoch 3137/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1046 - mae: 0.2685 - val_loss: 3.1361 - val_mae: 1.6216\n",
      "Epoch 3138/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0644 - mae: 0.1966 - val_loss: 2.7571 - val_mae: 1.5000\n",
      "Epoch 3139/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0591 - mae: 0.1997 - val_loss: 2.5650 - val_mae: 1.4345\n",
      "Epoch 3140/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0761 - mae: 0.2316 - val_loss: 2.6325 - val_mae: 1.4579\n",
      "Epoch 3141/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1970 - val_loss: 2.8770 - val_mae: 1.5397\n",
      "Epoch 3142/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.1948 - val_loss: 2.9833 - val_mae: 1.5739\n",
      "Epoch 3143/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0648 - mae: 0.2062 - val_loss: 2.8707 - val_mae: 1.5376\n",
      "Epoch 3144/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1802 - val_loss: 2.7419 - val_mae: 1.4950\n",
      "Epoch 3145/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.2087 - val_loss: 2.7380 - val_mae: 1.4936\n",
      "Epoch 3146/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0697 - mae: 0.2230 - val_loss: 2.9034 - val_mae: 1.5481\n",
      "Epoch 3147/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.2001 - val_loss: 3.0384 - val_mae: 1.5911\n",
      "Epoch 3148/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1803 - val_loss: 3.1117 - val_mae: 1.6141\n",
      "Epoch 3149/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1805 - val_loss: 3.1292 - val_mae: 1.6195\n",
      "Epoch 3150/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1827 - val_loss: 2.9965 - val_mae: 1.5780\n",
      "Epoch 3151/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1811 - val_loss: 2.8886 - val_mae: 1.5434\n",
      "Epoch 3152/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1807 - val_loss: 2.7897 - val_mae: 1.5110\n",
      "Epoch 3153/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1847 - val_loss: 2.6828 - val_mae: 1.4752\n",
      "Epoch 3154/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1877 - val_loss: 2.6837 - val_mae: 1.4756\n",
      "Epoch 3155/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1779 - val_loss: 2.7204 - val_mae: 1.4881\n",
      "Epoch 3156/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0518 - mae: 0.1784 - val_loss: 2.6790 - val_mae: 1.4742\n",
      "Epoch 3157/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1787 - val_loss: 2.5673 - val_mae: 1.4357\n",
      "Epoch 3158/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1778 - val_loss: 2.4564 - val_mae: 1.3965\n",
      "Epoch 3159/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1927 - val_loss: 2.4552 - val_mae: 1.3960\n",
      "Epoch 3160/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0607 - mae: 0.1935 - val_loss: 2.6806 - val_mae: 1.4746\n",
      "Epoch 3161/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0482 - mae: 0.1740 - val_loss: 3.0757 - val_mae: 1.6032\n",
      "Epoch 3162/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0756 - mae: 0.2309 - val_loss: 3.3382 - val_mae: 1.6832\n",
      "Epoch 3163/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0997 - mae: 0.2651 - val_loss: 3.2069 - val_mae: 1.6435\n",
      "Epoch 3164/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0624 - mae: 0.1931 - val_loss: 2.8858 - val_mae: 1.5424\n",
      "Epoch 3165/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0600 - mae: 0.2078 - val_loss: 2.7616 - val_mae: 1.5015\n",
      "Epoch 3166/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0764 - mae: 0.2406 - val_loss: 2.9754 - val_mae: 1.5712\n",
      "Epoch 3167/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0583 - mae: 0.1936 - val_loss: 3.2399 - val_mae: 1.6534\n",
      "Epoch 3168/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0657 - mae: 0.1953 - val_loss: 3.2318 - val_mae: 1.6510\n",
      "Epoch 3169/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0679 - mae: 0.1987 - val_loss: 3.0568 - val_mae: 1.5970\n",
      "Epoch 3170/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0549 - mae: 0.1804 - val_loss: 2.8486 - val_mae: 1.5303\n",
      "Epoch 3171/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0559 - mae: 0.1949 - val_loss: 2.7226 - val_mae: 1.4884\n",
      "Epoch 3172/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0654 - mae: 0.2207 - val_loss: 2.7433 - val_mae: 1.4954\n",
      "Epoch 3173/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0616 - mae: 0.2119 - val_loss: 2.8507 - val_mae: 1.5309\n",
      "Epoch 3174/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0504 - mae: 0.1804 - val_loss: 2.9758 - val_mae: 1.5714\n",
      "Epoch 3175/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0518 - mae: 0.1810 - val_loss: 3.0900 - val_mae: 1.6074\n",
      "Epoch 3176/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0648 - mae: 0.2042 - val_loss: 3.0274 - val_mae: 1.5877\n",
      "Epoch 3177/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0580 - mae: 0.1951 - val_loss: 2.8345 - val_mae: 1.5256\n",
      "Epoch 3178/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0501 - mae: 0.1826 - val_loss: 2.7321 - val_mae: 1.4916\n",
      "Epoch 3179/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0571 - mae: 0.1964 - val_loss: 2.7006 - val_mae: 1.4810\n",
      "Epoch 3180/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0616 - mae: 0.2058 - val_loss: 2.7516 - val_mae: 1.4981\n",
      "Epoch 3181/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0540 - mae: 0.1904 - val_loss: 2.9572 - val_mae: 1.5654\n",
      "Epoch 3182/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0488 - mae: 0.1754 - val_loss: 3.2239 - val_mae: 1.6485\n",
      "Epoch 3183/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0696 - mae: 0.2068 - val_loss: 3.1557 - val_mae: 1.6277\n",
      "Epoch 3184/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0602 - mae: 0.1885 - val_loss: 2.8303 - val_mae: 1.5242\n",
      "Epoch 3185/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0519 - mae: 0.1775 - val_loss: 2.6707 - val_mae: 1.4709\n",
      "Epoch 3186/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0606 - mae: 0.2098 - val_loss: 2.7426 - val_mae: 1.4952\n",
      "Epoch 3187/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0552 - mae: 0.1941 - val_loss: 2.8496 - val_mae: 1.5306\n",
      "Epoch 3188/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0504 - mae: 0.1733 - val_loss: 2.8919 - val_mae: 1.5444\n",
      "Epoch 3189/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0519 - mae: 0.1746 - val_loss: 2.8944 - val_mae: 1.5452\n",
      "Epoch 3190/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0529 - mae: 0.1770 - val_loss: 2.7562 - val_mae: 1.4998\n",
      "Epoch 3191/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0509 - mae: 0.1760 - val_loss: 2.5962 - val_mae: 1.4454\n",
      "Epoch 3192/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0540 - mae: 0.1818 - val_loss: 2.6164 - val_mae: 1.4523\n",
      "Epoch 3193/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0532 - mae: 0.1805 - val_loss: 2.6668 - val_mae: 1.4696\n",
      "Epoch 3194/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0510 - mae: 0.1758 - val_loss: 2.6326 - val_mae: 1.4579\n",
      "Epoch 3195/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0527 - mae: 0.1806 - val_loss: 2.6333 - val_mae: 1.4581\n",
      "Epoch 3196/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0570 - mae: 0.1978 - val_loss: 2.7443 - val_mae: 1.4957\n",
      "Epoch 3197/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0532 - mae: 0.1868 - val_loss: 2.8346 - val_mae: 1.5256\n",
      "Epoch 3198/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0499 - mae: 0.1759 - val_loss: 2.8937 - val_mae: 1.5449\n",
      "Epoch 3199/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0492 - mae: 0.1716 - val_loss: 2.9823 - val_mae: 1.5733\n",
      "Epoch 3200/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0502 - mae: 0.1706 - val_loss: 2.9973 - val_mae: 1.5780\n",
      "Epoch 3201/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0492 - mae: 0.1694 - val_loss: 2.9277 - val_mae: 1.5558\n",
      "Epoch 3202/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0481 - mae: 0.1737 - val_loss: 2.8736 - val_mae: 1.5382\n",
      "Epoch 3203/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1884 - val_loss: 2.8861 - val_mae: 1.5423\n",
      "Epoch 3204/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1943 - val_loss: 3.0070 - val_mae: 1.5810\n",
      "Epoch 3205/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1999 - val_loss: 3.0880 - val_mae: 1.6065\n",
      "Epoch 3206/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1992 - val_loss: 3.1128 - val_mae: 1.6141\n",
      "Epoch 3207/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1938 - val_loss: 3.0826 - val_mae: 1.6048\n",
      "Epoch 3208/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1822 - val_loss: 2.9275 - val_mae: 1.5556\n",
      "Epoch 3209/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1875 - val_loss: 2.8707 - val_mae: 1.5373\n",
      "Epoch 3210/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1869 - val_loss: 2.9969 - val_mae: 1.5779\n",
      "Epoch 3211/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1677 - val_loss: 3.1606 - val_mae: 1.6291\n",
      "Epoch 3212/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0641 - mae: 0.1946 - val_loss: 3.1523 - val_mae: 1.6265\n",
      "Epoch 3213/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1968 - val_loss: 2.9479 - val_mae: 1.5623\n",
      "Epoch 3214/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1726 - val_loss: 2.7350 - val_mae: 1.4925\n",
      "Epoch 3215/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1825 - val_loss: 2.6598 - val_mae: 1.4670\n",
      "Epoch 3216/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1987 - val_loss: 2.6941 - val_mae: 1.4787\n",
      "Epoch 3217/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1944 - val_loss: 2.7107 - val_mae: 1.4843\n",
      "Epoch 3218/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1767 - val_loss: 2.7503 - val_mae: 1.4976\n",
      "Epoch 3219/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1717 - val_loss: 2.8786 - val_mae: 1.5400\n",
      "Epoch 3220/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1786 - val_loss: 2.8758 - val_mae: 1.5390\n",
      "Epoch 3221/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1735 - val_loss: 2.7298 - val_mae: 1.4908\n",
      "Epoch 3222/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1824 - val_loss: 2.6745 - val_mae: 1.4720\n",
      "Epoch 3223/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1916 - val_loss: 2.7360 - val_mae: 1.4928\n",
      "Epoch 3224/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1800 - val_loss: 2.8907 - val_mae: 1.5438\n",
      "Epoch 3225/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0487 - mae: 0.1725 - val_loss: 3.0335 - val_mae: 1.5894\n",
      "Epoch 3226/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1778 - val_loss: 2.9892 - val_mae: 1.5754\n",
      "Epoch 3227/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1750 - val_loss: 2.8718 - val_mae: 1.5377\n",
      "Epoch 3228/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1758 - val_loss: 2.8476 - val_mae: 1.5298\n",
      "Epoch 3229/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0489 - mae: 0.1772 - val_loss: 2.8972 - val_mae: 1.5459\n",
      "Epoch 3230/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0477 - mae: 0.1727 - val_loss: 2.9766 - val_mae: 1.5714\n",
      "Epoch 3231/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0481 - mae: 0.1702 - val_loss: 3.0623 - val_mae: 1.5985\n",
      "Epoch 3232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1729 - val_loss: 3.0684 - val_mae: 1.6004\n",
      "Epoch 3233/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1718 - val_loss: 2.9800 - val_mae: 1.5725\n",
      "Epoch 3234/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1686 - val_loss: 2.8217 - val_mae: 1.5213\n",
      "Epoch 3235/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0514 - mae: 0.1863 - val_loss: 2.7068 - val_mae: 1.4830\n",
      "Epoch 3236/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0563 - mae: 0.1991 - val_loss: 2.7872 - val_mae: 1.5099\n",
      "Epoch 3237/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1770 - val_loss: 2.9527 - val_mae: 1.5639\n",
      "Epoch 3238/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0532 - mae: 0.1744 - val_loss: 3.0826 - val_mae: 1.6049\n",
      "Epoch 3239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0642 - mae: 0.2013 - val_loss: 3.0726 - val_mae: 1.6018\n",
      "Epoch 3240/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1829 - val_loss: 2.8340 - val_mae: 1.5253\n",
      "Epoch 3241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0485 - mae: 0.1776 - val_loss: 2.5851 - val_mae: 1.4413\n",
      "Epoch 3242/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0740 - mae: 0.2323 - val_loss: 2.5812 - val_mae: 1.4400\n",
      "Epoch 3243/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.2062 - val_loss: 2.8651 - val_mae: 1.5356\n",
      "Epoch 3244/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0550 - mae: 0.1865 - val_loss: 3.1239 - val_mae: 1.6178\n",
      "Epoch 3245/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0776 - mae: 0.2316 - val_loss: 3.0741 - val_mae: 1.6022\n",
      "Epoch 3246/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0573 - mae: 0.1820 - val_loss: 2.8224 - val_mae: 1.5215\n",
      "Epoch 3247/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1988 - val_loss: 2.6946 - val_mae: 1.4788\n",
      "Epoch 3248/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0715 - mae: 0.2309 - val_loss: 2.7931 - val_mae: 1.5118\n",
      "Epoch 3249/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0599 - mae: 0.2000 - val_loss: 2.9219 - val_mae: 1.5539\n",
      "Epoch 3250/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1850 - val_loss: 2.9678 - val_mae: 1.5687\n",
      "Epoch 3251/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.2002 - val_loss: 2.9316 - val_mae: 1.5571\n",
      "Epoch 3252/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.2046 - val_loss: 2.9356 - val_mae: 1.5584\n",
      "Epoch 3253/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.1970 - val_loss: 2.9978 - val_mae: 1.5782\n",
      "Epoch 3254/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1896 - val_loss: 2.9693 - val_mae: 1.5691\n",
      "Epoch 3255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1734 - val_loss: 2.8403 - val_mae: 1.5274\n",
      "Epoch 3256/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.2056 - val_loss: 2.8403 - val_mae: 1.5274\n",
      "Epoch 3257/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0759 - mae: 0.2286 - val_loss: 3.1316 - val_mae: 1.6200\n",
      "Epoch 3258/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.1968 - val_loss: 3.5163 - val_mae: 1.7348\n",
      "Epoch 3259/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0730 - mae: 0.2125 - val_loss: 3.7205 - val_mae: 1.7928\n",
      "Epoch 3260/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0960 - mae: 0.2457 - val_loss: 3.5250 - val_mae: 1.7373\n",
      "Epoch 3261/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.1834 - val_loss: 3.0640 - val_mae: 1.5989\n",
      "Epoch 3262/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0774 - mae: 0.2385 - val_loss: 2.7284 - val_mae: 1.4902\n",
      "Epoch 3263/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1339 - mae: 0.3220 - val_loss: 2.7658 - val_mae: 1.5027\n",
      "Epoch 3264/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0961 - mae: 0.2734 - val_loss: 3.1160 - val_mae: 1.6152\n",
      "Epoch 3265/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1806 - val_loss: 3.4112 - val_mae: 1.7043\n",
      "Epoch 3266/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0857 - mae: 0.2335 - val_loss: 3.3684 - val_mae: 1.6917\n",
      "Epoch 3267/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0838 - mae: 0.2364 - val_loss: 3.0418 - val_mae: 1.5921\n",
      "Epoch 3268/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1677 - val_loss: 2.6672 - val_mae: 1.4697\n",
      "Epoch 3269/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.2101 - val_loss: 2.5140 - val_mae: 1.4166\n",
      "Epoch 3270/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2256 - val_loss: 2.5475 - val_mae: 1.4284\n",
      "Epoch 3271/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1869 - val_loss: 2.6081 - val_mae: 1.4496\n",
      "Epoch 3272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1763 - val_loss: 2.7278 - val_mae: 1.4905\n",
      "Epoch 3273/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0619 - mae: 0.2033 - val_loss: 2.7850 - val_mae: 1.5097\n",
      "Epoch 3274/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0704 - mae: 0.2182 - val_loss: 2.7449 - val_mae: 1.4963\n",
      "Epoch 3275/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.2011 - val_loss: 2.6990 - val_mae: 1.4808\n",
      "Epoch 3276/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1791 - val_loss: 2.6406 - val_mae: 1.4608\n",
      "Epoch 3277/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1830 - val_loss: 2.6113 - val_mae: 1.4507\n",
      "Epoch 3278/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1987 - val_loss: 2.7047 - val_mae: 1.4825\n",
      "Epoch 3279/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1983 - val_loss: 2.8745 - val_mae: 1.5387\n",
      "Epoch 3280/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1821 - val_loss: 3.0611 - val_mae: 1.5982\n",
      "Epoch 3281/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1674 - val_loss: 3.2541 - val_mae: 1.6575\n",
      "Epoch 3282/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0571 - mae: 0.1733 - val_loss: 3.3510 - val_mae: 1.6865\n",
      "Epoch 3283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1806 - val_loss: 3.2435 - val_mae: 1.6543\n",
      "Epoch 3284/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1737 - val_loss: 3.0547 - val_mae: 1.5961\n",
      "Epoch 3285/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2118 - val_loss: 3.0118 - val_mae: 1.5826\n",
      "Epoch 3286/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0706 - mae: 0.2267 - val_loss: 3.1679 - val_mae: 1.6312\n",
      "Epoch 3287/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1924 - val_loss: 3.3221 - val_mae: 1.6779\n",
      "Epoch 3288/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0576 - mae: 0.1736 - val_loss: 3.3417 - val_mae: 1.6838\n",
      "Epoch 3289/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0634 - mae: 0.1897 - val_loss: 3.1318 - val_mae: 1.6202\n",
      "Epoch 3290/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1775 - val_loss: 2.8109 - val_mae: 1.5179\n",
      "Epoch 3291/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1785 - val_loss: 2.7286 - val_mae: 1.4906\n",
      "Epoch 3292/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0478 - mae: 0.1669 - val_loss: 2.8767 - val_mae: 1.5396\n",
      "Epoch 3293/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1901 - val_loss: 2.9102 - val_mae: 1.5506\n",
      "Epoch 3294/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.2076 - val_loss: 2.6816 - val_mae: 1.4748\n",
      "Epoch 3295/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0533 - mae: 0.1777 - val_loss: 2.4241 - val_mae: 1.3846\n",
      "Epoch 3296/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1903 - val_loss: 2.3416 - val_mae: 1.3544\n",
      "Epoch 3297/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0687 - mae: 0.2055 - val_loss: 2.4048 - val_mae: 1.3775\n",
      "Epoch 3298/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.1892 - val_loss: 2.5685 - val_mae: 1.4358\n",
      "Epoch 3299/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1802 - val_loss: 2.8065 - val_mae: 1.5165\n",
      "Epoch 3300/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0587 - mae: 0.1950 - val_loss: 2.9073 - val_mae: 1.5493\n",
      "Epoch 3301/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1768 - val_loss: 2.8724 - val_mae: 1.5379\n",
      "Epoch 3302/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1713 - val_loss: 2.8036 - val_mae: 1.5153\n",
      "Epoch 3303/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0569 - mae: 0.2008 - val_loss: 2.8000 - val_mae: 1.5141\n",
      "Epoch 3304/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0646 - mae: 0.2192 - val_loss: 2.9001 - val_mae: 1.5468\n",
      "Epoch 3305/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1997 - val_loss: 3.0623 - val_mae: 1.5985\n",
      "Epoch 3306/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1767 - val_loss: 3.2238 - val_mae: 1.6483\n",
      "Epoch 3307/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1893 - val_loss: 3.2231 - val_mae: 1.6481\n",
      "Epoch 3308/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0652 - mae: 0.1986 - val_loss: 3.1772 - val_mae: 1.6341\n",
      "Epoch 3309/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.1862 - val_loss: 3.0657 - val_mae: 1.5995\n",
      "Epoch 3310/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1710 - val_loss: 2.9097 - val_mae: 1.5500\n",
      "Epoch 3311/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0484 - mae: 0.1697 - val_loss: 2.9115 - val_mae: 1.5505\n",
      "Epoch 3312/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0485 - mae: 0.1727 - val_loss: 3.0064 - val_mae: 1.5809\n",
      "Epoch 3313/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0492 - mae: 0.1683 - val_loss: 3.0590 - val_mae: 1.5974\n",
      "Epoch 3314/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1653 - val_loss: 3.0709 - val_mae: 1.6011\n",
      "Epoch 3315/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1652 - val_loss: 3.0525 - val_mae: 1.5954\n",
      "Epoch 3316/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1708 - val_loss: 2.9679 - val_mae: 1.5686\n",
      "Epoch 3317/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1752 - val_loss: 2.8947 - val_mae: 1.5450\n",
      "Epoch 3318/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1816 - val_loss: 2.9610 - val_mae: 1.5663\n",
      "Epoch 3319/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1746 - val_loss: 3.1055 - val_mae: 1.6119\n",
      "Epoch 3320/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1692 - val_loss: 3.2274 - val_mae: 1.6493\n",
      "Epoch 3321/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1669 - val_loss: 3.1475 - val_mae: 1.6248\n",
      "Epoch 3322/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1616 - val_loss: 2.8692 - val_mae: 1.5367\n",
      "Epoch 3323/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0595 - mae: 0.2103 - val_loss: 2.7058 - val_mae: 1.4825\n",
      "Epoch 3324/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0800 - mae: 0.2483 - val_loss: 2.7696 - val_mae: 1.5039\n",
      "Epoch 3325/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0631 - mae: 0.2169 - val_loss: 3.0140 - val_mae: 1.5831\n",
      "Epoch 3326/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1689 - val_loss: 3.1778 - val_mae: 1.6341\n",
      "Epoch 3327/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0545 - mae: 0.1751 - val_loss: 3.1318 - val_mae: 1.6199\n",
      "Epoch 3328/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1750 - val_loss: 3.0806 - val_mae: 1.6040\n",
      "Epoch 3329/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1717 - val_loss: 3.0749 - val_mae: 1.6022\n",
      "Epoch 3330/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1724 - val_loss: 3.1405 - val_mae: 1.6226\n",
      "Epoch 3331/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1693 - val_loss: 3.2296 - val_mae: 1.6498\n",
      "Epoch 3332/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1662 - val_loss: 3.2483 - val_mae: 1.6555\n",
      "Epoch 3333/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0518 - mae: 0.1647 - val_loss: 3.1645 - val_mae: 1.6300\n",
      "Epoch 3334/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1660 - val_loss: 3.0576 - val_mae: 1.5968\n",
      "Epoch 3335/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1696 - val_loss: 2.9849 - val_mae: 1.5739\n",
      "Epoch 3336/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0478 - mae: 0.1720 - val_loss: 3.0138 - val_mae: 1.5830\n",
      "Epoch 3337/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0472 - mae: 0.1660 - val_loss: 3.0626 - val_mae: 1.5984\n",
      "Epoch 3338/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1686 - val_loss: 2.9775 - val_mae: 1.5716\n",
      "Epoch 3339/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1637 - val_loss: 2.7631 - val_mae: 1.5017\n",
      "Epoch 3340/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1820 - val_loss: 2.6594 - val_mae: 1.4667\n",
      "Epoch 3341/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.2114 - val_loss: 2.7556 - val_mae: 1.4992\n",
      "Epoch 3342/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1862 - val_loss: 2.9415 - val_mae: 1.5600\n",
      "Epoch 3343/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1689 - val_loss: 3.1024 - val_mae: 1.6108\n",
      "Epoch 3344/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1857 - val_loss: 3.1230 - val_mae: 1.6172\n",
      "Epoch 3345/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1807 - val_loss: 2.9848 - val_mae: 1.5738\n",
      "Epoch 3346/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0486 - mae: 0.1761 - val_loss: 2.7943 - val_mae: 1.5120\n",
      "Epoch 3347/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0680 - mae: 0.2282 - val_loss: 2.7714 - val_mae: 1.5043\n",
      "Epoch 3348/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0746 - mae: 0.2389 - val_loss: 2.9706 - val_mae: 1.5692\n",
      "Epoch 3349/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1853 - val_loss: 3.1554 - val_mae: 1.6272\n",
      "Epoch 3350/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1853 - val_loss: 3.0908 - val_mae: 1.6072\n",
      "Epoch 3351/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0551 - mae: 0.1811 - val_loss: 2.8921 - val_mae: 1.5441\n",
      "Epoch 3352/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0476 - mae: 0.1667 - val_loss: 2.7545 - val_mae: 1.4988\n",
      "Epoch 3353/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0516 - mae: 0.1844 - val_loss: 2.7905 - val_mae: 1.5108\n",
      "Epoch 3354/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1726 - val_loss: 2.9478 - val_mae: 1.5621\n",
      "Epoch 3355/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0484 - mae: 0.1665 - val_loss: 3.0830 - val_mae: 1.6048\n",
      "Epoch 3356/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0521 - mae: 0.1778 - val_loss: 3.1558 - val_mae: 1.6273\n",
      "Epoch 3357/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1767 - val_loss: 3.0556 - val_mae: 1.5961\n",
      "Epoch 3358/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1808 - val_loss: 2.8606 - val_mae: 1.5337\n",
      "Epoch 3359/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0674 - mae: 0.2196 - val_loss: 2.8075 - val_mae: 1.5163\n",
      "Epoch 3360/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0706 - mae: 0.2241 - val_loss: 2.9171 - val_mae: 1.5521\n",
      "Epoch 3361/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1930 - val_loss: 3.0528 - val_mae: 1.5953\n",
      "Epoch 3362/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1778 - val_loss: 3.0633 - val_mae: 1.5986\n",
      "Epoch 3363/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0481 - mae: 0.1668 - val_loss: 2.9580 - val_mae: 1.5652\n",
      "Epoch 3364/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1714 - val_loss: 2.8609 - val_mae: 1.5339\n",
      "Epoch 3365/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0541 - mae: 0.1973 - val_loss: 2.8989 - val_mae: 1.5462\n",
      "Epoch 3366/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0521 - mae: 0.1881 - val_loss: 2.9278 - val_mae: 1.5556\n",
      "Epoch 3367/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1687 - val_loss: 2.9028 - val_mae: 1.5476\n",
      "Epoch 3368/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0470 - mae: 0.1663 - val_loss: 2.9395 - val_mae: 1.5594\n",
      "Epoch 3369/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1758 - val_loss: 2.9349 - val_mae: 1.5580\n",
      "Epoch 3370/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1823 - val_loss: 2.9184 - val_mae: 1.5527\n",
      "Epoch 3371/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1736 - val_loss: 2.8215 - val_mae: 1.5211\n",
      "Epoch 3372/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1751 - val_loss: 2.7683 - val_mae: 1.5034\n",
      "Epoch 3373/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.2041 - val_loss: 2.9167 - val_mae: 1.5520\n",
      "Epoch 3374/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1956 - val_loss: 3.0875 - val_mae: 1.6061\n",
      "Epoch 3375/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1753 - val_loss: 3.1717 - val_mae: 1.6321\n",
      "Epoch 3376/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1698 - val_loss: 3.0669 - val_mae: 1.5996\n",
      "Epoch 3377/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1787 - val_loss: 2.9644 - val_mae: 1.5672\n",
      "Epoch 3378/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1991 - val_loss: 3.0330 - val_mae: 1.5890\n",
      "Epoch 3379/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1883 - val_loss: 3.1497 - val_mae: 1.6254\n",
      "Epoch 3380/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1715 - val_loss: 3.1986 - val_mae: 1.6404\n",
      "Epoch 3381/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0532 - mae: 0.1762 - val_loss: 3.1676 - val_mae: 1.6309\n",
      "Epoch 3382/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1741 - val_loss: 2.9676 - val_mae: 1.5683\n",
      "Epoch 3383/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1667 - val_loss: 2.7133 - val_mae: 1.4849\n",
      "Epoch 3384/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.2008 - val_loss: 2.6332 - val_mae: 1.4577\n",
      "Epoch 3385/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0671 - mae: 0.2182 - val_loss: 2.7175 - val_mae: 1.4864\n",
      "Epoch 3386/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1895 - val_loss: 2.9051 - val_mae: 1.5482\n",
      "Epoch 3387/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1706 - val_loss: 3.1344 - val_mae: 1.6207\n",
      "Epoch 3388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.2054 - val_loss: 3.2110 - val_mae: 1.6442\n",
      "Epoch 3389/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0657 - mae: 0.2056 - val_loss: 3.0705 - val_mae: 1.6008\n",
      "Epoch 3390/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1691 - val_loss: 2.9289 - val_mae: 1.5559\n",
      "Epoch 3391/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1971 - val_loss: 2.9701 - val_mae: 1.5690\n",
      "Epoch 3392/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1931 - val_loss: 3.1553 - val_mae: 1.6271\n",
      "Epoch 3393/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1736 - val_loss: 3.2546 - val_mae: 1.6574\n",
      "Epoch 3394/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0596 - mae: 0.1797 - val_loss: 3.1832 - val_mae: 1.6357\n",
      "Epoch 3395/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1757 - val_loss: 3.0023 - val_mae: 1.5793\n",
      "Epoch 3396/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1746 - val_loss: 2.8640 - val_mae: 1.5348\n",
      "Epoch 3397/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1934 - val_loss: 2.8696 - val_mae: 1.5367\n",
      "Epoch 3398/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0525 - mae: 0.1891 - val_loss: 2.9961 - val_mae: 1.5773\n",
      "Epoch 3399/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1789 - val_loss: 3.1765 - val_mae: 1.6336\n",
      "Epoch 3400/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1770 - val_loss: 3.2083 - val_mae: 1.6433\n",
      "Epoch 3401/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1711 - val_loss: 3.0055 - val_mae: 1.5803\n",
      "Epoch 3402/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1941 - val_loss: 2.8930 - val_mae: 1.5443\n",
      "Epoch 3403/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2199 - val_loss: 2.9603 - val_mae: 1.5659\n",
      "Epoch 3404/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1992 - val_loss: 2.9731 - val_mae: 1.5700\n",
      "Epoch 3405/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1825 - val_loss: 2.9383 - val_mae: 1.5589\n",
      "Epoch 3406/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1831 - val_loss: 2.8246 - val_mae: 1.5220\n",
      "Epoch 3407/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0516 - mae: 0.1887 - val_loss: 2.7176 - val_mae: 1.4865\n",
      "Epoch 3408/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0512 - mae: 0.1821 - val_loss: 2.6553 - val_mae: 1.4654\n",
      "Epoch 3409/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1718 - val_loss: 2.6040 - val_mae: 1.4479\n",
      "Epoch 3410/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1737 - val_loss: 2.6401 - val_mae: 1.4603\n",
      "Epoch 3411/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1763 - val_loss: 2.8292 - val_mae: 1.5238\n",
      "Epoch 3412/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.2007 - val_loss: 3.0039 - val_mae: 1.5801\n",
      "Epoch 3413/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0660 - mae: 0.2067 - val_loss: 3.0341 - val_mae: 1.5895\n",
      "Epoch 3414/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1753 - val_loss: 2.9966 - val_mae: 1.5776\n",
      "Epoch 3415/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1804 - val_loss: 2.9047 - val_mae: 1.5481\n",
      "Epoch 3416/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0615 - mae: 0.2134 - val_loss: 2.9491 - val_mae: 1.5624\n",
      "Epoch 3417/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.2015 - val_loss: 3.1579 - val_mae: 1.6279\n",
      "Epoch 3418/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1729 - val_loss: 3.3536 - val_mae: 1.6870\n",
      "Epoch 3419/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0687 - mae: 0.2033 - val_loss: 3.4920 - val_mae: 1.7276\n",
      "Epoch 3420/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0851 - mae: 0.2269 - val_loss: 3.3809 - val_mae: 1.6951\n",
      "Epoch 3421/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0591 - mae: 0.1876 - val_loss: 3.0957 - val_mae: 1.6086\n",
      "Epoch 3422/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0692 - mae: 0.2162 - val_loss: 3.0597 - val_mae: 1.5973\n",
      "Epoch 3423/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0691 - mae: 0.2225 - val_loss: 3.3010 - val_mae: 1.6713\n",
      "Epoch 3424/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1713 - val_loss: 3.4564 - val_mae: 1.7172\n",
      "Epoch 3425/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.1918 - val_loss: 3.3067 - val_mae: 1.6731\n",
      "Epoch 3426/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0603 - mae: 0.1800 - val_loss: 2.9782 - val_mae: 1.5717\n",
      "Epoch 3427/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1801 - val_loss: 2.6461 - val_mae: 1.4621\n",
      "Epoch 3428/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0760 - mae: 0.2391 - val_loss: 2.4812 - val_mae: 1.4046\n",
      "Epoch 3429/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0866 - mae: 0.2473 - val_loss: 2.5463 - val_mae: 1.4277\n",
      "Epoch 3430/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0664 - mae: 0.2135 - val_loss: 2.7444 - val_mae: 1.4957\n",
      "Epoch 3431/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0978 - mae: 0.2425 - val_loss: 2.8526 - val_mae: 1.5316\n",
      "Epoch 3432/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0832 - mae: 0.2478 - val_loss: 2.7183 - val_mae: 1.4871\n",
      "Epoch 3433/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1816 - val_loss: 2.4895 - val_mae: 1.4078\n",
      "Epoch 3434/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0720 - mae: 0.2212 - val_loss: 2.5303 - val_mae: 1.4221\n",
      "Epoch 3435/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0785 - mae: 0.2412 - val_loss: 2.9625 - val_mae: 1.5669\n",
      "Epoch 3436/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1886 - val_loss: 3.4931 - val_mae: 1.7280\n",
      "Epoch 3437/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0773 - mae: 0.2150 - val_loss: 3.8016 - val_mae: 1.8151\n",
      "Epoch 3438/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0999 - mae: 0.2524 - val_loss: 3.6798 - val_mae: 1.7811\n",
      "Epoch 3439/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0745 - mae: 0.1991 - val_loss: 3.3477 - val_mae: 1.6851\n",
      "Epoch 3440/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0873 - mae: 0.2363 - val_loss: 3.3330 - val_mae: 1.6807\n",
      "Epoch 3441/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0772 - mae: 0.2253 - val_loss: 3.5977 - val_mae: 1.7579\n",
      "Epoch 3442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0725 - mae: 0.1991 - val_loss: 3.6067 - val_mae: 1.7605\n",
      "Epoch 3443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0730 - mae: 0.2004 - val_loss: 3.3347 - val_mae: 1.6814\n",
      "Epoch 3444/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1753 - val_loss: 3.0277 - val_mae: 1.5874\n",
      "Epoch 3445/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1932 - val_loss: 2.7727 - val_mae: 1.5048\n",
      "Epoch 3446/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0647 - mae: 0.2192 - val_loss: 2.7061 - val_mae: 1.4826\n",
      "Epoch 3447/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.2009 - val_loss: 2.7838 - val_mae: 1.5088\n",
      "Epoch 3448/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1752 - val_loss: 2.8411 - val_mae: 1.5278\n",
      "Epoch 3449/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1875 - val_loss: 2.8263 - val_mae: 1.5230\n",
      "Epoch 3450/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1898 - val_loss: 2.7206 - val_mae: 1.4878\n",
      "Epoch 3451/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1783 - val_loss: 2.6064 - val_mae: 1.4487\n",
      "Epoch 3452/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0616 - mae: 0.2061 - val_loss: 2.7155 - val_mae: 1.4858\n",
      "Epoch 3453/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1949 - val_loss: 2.9541 - val_mae: 1.5641\n",
      "Epoch 3454/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1776 - val_loss: 3.0309 - val_mae: 1.5885\n",
      "Epoch 3455/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1765 - val_loss: 3.0062 - val_mae: 1.5806\n",
      "Epoch 3456/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1758 - val_loss: 2.9448 - val_mae: 1.5610\n",
      "Epoch 3457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1799 - val_loss: 2.8853 - val_mae: 1.5418\n",
      "Epoch 3458/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1845 - val_loss: 2.8454 - val_mae: 1.5288\n",
      "Epoch 3459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1867 - val_loss: 2.7700 - val_mae: 1.5040\n",
      "Epoch 3460/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0551 - mae: 0.1913 - val_loss: 2.6985 - val_mae: 1.4800\n",
      "Epoch 3461/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2012 - val_loss: 2.7459 - val_mae: 1.4959\n",
      "Epoch 3462/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1900 - val_loss: 2.8648 - val_mae: 1.5352\n",
      "Epoch 3463/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1757 - val_loss: 2.9883 - val_mae: 1.5750\n",
      "Epoch 3464/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1746 - val_loss: 3.1156 - val_mae: 1.6149\n",
      "Epoch 3465/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0516 - mae: 0.1756 - val_loss: 3.1214 - val_mae: 1.6167\n",
      "Epoch 3466/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1706 - val_loss: 3.0193 - val_mae: 1.5847\n",
      "Epoch 3467/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1781 - val_loss: 2.9182 - val_mae: 1.5523\n",
      "Epoch 3468/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0651 - mae: 0.2200 - val_loss: 2.9591 - val_mae: 1.5654\n",
      "Epoch 3469/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2116 - val_loss: 3.1506 - val_mae: 1.6256\n",
      "Epoch 3470/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1680 - val_loss: 3.3618 - val_mae: 1.6894\n",
      "Epoch 3471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0770 - mae: 0.2204 - val_loss: 3.3144 - val_mae: 1.6753\n",
      "Epoch 3472/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0757 - mae: 0.2143 - val_loss: 3.0557 - val_mae: 1.5961\n",
      "Epoch 3473/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1900 - val_loss: 2.8868 - val_mae: 1.5422\n",
      "Epoch 3474/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.2025 - val_loss: 2.8734 - val_mae: 1.5378\n",
      "Epoch 3475/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0608 - mae: 0.2022 - val_loss: 2.9819 - val_mae: 1.5728\n",
      "Epoch 3476/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1890 - val_loss: 3.0605 - val_mae: 1.5976\n",
      "Epoch 3477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1854 - val_loss: 3.0465 - val_mae: 1.5933\n",
      "Epoch 3478/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1797 - val_loss: 2.9998 - val_mae: 1.5786\n",
      "Epoch 3479/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1753 - val_loss: 2.8657 - val_mae: 1.5355\n",
      "Epoch 3480/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0500 - mae: 0.1741 - val_loss: 2.7834 - val_mae: 1.5084\n",
      "Epoch 3481/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1822 - val_loss: 2.8532 - val_mae: 1.5314\n",
      "Epoch 3482/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1757 - val_loss: 2.9216 - val_mae: 1.5536\n",
      "Epoch 3483/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1700 - val_loss: 2.9878 - val_mae: 1.5748\n",
      "Epoch 3484/5000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0489 - mae: 0.1692 - val_loss: 3.0335 - val_mae: 1.5892\n",
      "Epoch 3485/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0493 - mae: 0.1686 - val_loss: 3.0165 - val_mae: 1.5838\n",
      "Epoch 3486/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1676 - val_loss: 2.9358 - val_mae: 1.5581\n",
      "Epoch 3487/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1711 - val_loss: 2.8264 - val_mae: 1.5225\n",
      "Epoch 3488/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1849 - val_loss: 2.7552 - val_mae: 1.4989\n",
      "Epoch 3489/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.2015 - val_loss: 2.7204 - val_mae: 1.4873\n",
      "Epoch 3490/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0565 - mae: 0.1937 - val_loss: 2.7621 - val_mae: 1.5013\n",
      "Epoch 3491/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1947 - val_loss: 2.9282 - val_mae: 1.5557\n",
      "Epoch 3492/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1756 - val_loss: 3.1507 - val_mae: 1.6257\n",
      "Epoch 3493/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1835 - val_loss: 3.2967 - val_mae: 1.6701\n",
      "Epoch 3494/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.1984 - val_loss: 3.2071 - val_mae: 1.6429\n",
      "Epoch 3495/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1781 - val_loss: 3.0344 - val_mae: 1.5894\n",
      "Epoch 3496/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1908 - val_loss: 2.9167 - val_mae: 1.5518\n",
      "Epoch 3497/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.2194 - val_loss: 2.9058 - val_mae: 1.5483\n",
      "Epoch 3498/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.2145 - val_loss: 3.0032 - val_mae: 1.5795\n",
      "Epoch 3499/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1817 - val_loss: 3.1180 - val_mae: 1.6155\n",
      "Epoch 3500/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1793 - val_loss: 3.2076 - val_mae: 1.6431\n",
      "Epoch 3501/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0620 - mae: 0.1949 - val_loss: 3.2028 - val_mae: 1.6417\n",
      "Epoch 3502/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0600 - mae: 0.1859 - val_loss: 3.0827 - val_mae: 1.6046\n",
      "Epoch 3503/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1775 - val_loss: 2.9660 - val_mae: 1.5678\n",
      "Epoch 3504/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1879 - val_loss: 2.9802 - val_mae: 1.5723\n",
      "Epoch 3505/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1928 - val_loss: 3.0087 - val_mae: 1.5814\n",
      "Epoch 3506/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1921 - val_loss: 3.0511 - val_mae: 1.5947\n",
      "Epoch 3507/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1882 - val_loss: 3.1707 - val_mae: 1.6318\n",
      "Epoch 3508/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1804 - val_loss: 3.3339 - val_mae: 1.6811\n",
      "Epoch 3509/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - mae: 0.1808 - val_loss: 3.2862 - val_mae: 1.6668\n",
      "Epoch 3510/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1771 - val_loss: 3.0630 - val_mae: 1.5984\n",
      "Epoch 3511/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1858 - val_loss: 2.9394 - val_mae: 1.5592\n",
      "Epoch 3512/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1958 - val_loss: 2.9195 - val_mae: 1.5528\n",
      "Epoch 3513/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1897 - val_loss: 2.9457 - val_mae: 1.5612\n",
      "Epoch 3514/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1796 - val_loss: 2.9812 - val_mae: 1.5726\n",
      "Epoch 3515/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1774 - val_loss: 3.0742 - val_mae: 1.6019\n",
      "Epoch 3516/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1826 - val_loss: 3.1822 - val_mae: 1.6354\n",
      "Epoch 3517/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1929 - val_loss: 3.1305 - val_mae: 1.6194\n",
      "Epoch 3518/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0506 - mae: 0.1733 - val_loss: 2.9806 - val_mae: 1.5723\n",
      "Epoch 3519/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0530 - mae: 0.1879 - val_loss: 2.9387 - val_mae: 1.5589\n",
      "Epoch 3520/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0554 - mae: 0.1958 - val_loss: 2.9688 - val_mae: 1.5686\n",
      "Epoch 3521/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1778 - val_loss: 2.9921 - val_mae: 1.5760\n",
      "Epoch 3522/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0492 - mae: 0.1795 - val_loss: 2.9384 - val_mae: 1.5589\n",
      "Epoch 3523/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0508 - mae: 0.1820 - val_loss: 2.8097 - val_mae: 1.5171\n",
      "Epoch 3524/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0497 - mae: 0.1793 - val_loss: 2.7760 - val_mae: 1.5060\n",
      "Epoch 3525/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0496 - mae: 0.1718 - val_loss: 2.7581 - val_mae: 1.5000\n",
      "Epoch 3526/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1698 - val_loss: 2.6627 - val_mae: 1.4678\n",
      "Epoch 3527/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1890 - val_loss: 2.5860 - val_mae: 1.4413\n",
      "Epoch 3528/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2069 - val_loss: 2.6179 - val_mae: 1.4524\n",
      "Epoch 3529/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0639 - mae: 0.2096 - val_loss: 2.7237 - val_mae: 1.4884\n",
      "Epoch 3530/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0624 - mae: 0.2111 - val_loss: 2.8474 - val_mae: 1.5294\n",
      "Epoch 3531/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1975 - val_loss: 2.9337 - val_mae: 1.5574\n",
      "Epoch 3532/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0478 - mae: 0.1737 - val_loss: 3.0180 - val_mae: 1.5843\n",
      "Epoch 3533/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1686 - val_loss: 3.0624 - val_mae: 1.5982\n",
      "Epoch 3534/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1724 - val_loss: 3.0023 - val_mae: 1.5793\n",
      "Epoch 3535/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0530 - mae: 0.1825 - val_loss: 3.0276 - val_mae: 1.5873\n",
      "Epoch 3536/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1821 - val_loss: 3.1055 - val_mae: 1.6116\n",
      "Epoch 3537/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1800 - val_loss: 3.1345 - val_mae: 1.6206\n",
      "Epoch 3538/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1821 - val_loss: 3.1308 - val_mae: 1.6194\n",
      "Epoch 3539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1851 - val_loss: 3.0964 - val_mae: 1.6087\n",
      "Epoch 3540/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1879 - val_loss: 3.0078 - val_mae: 1.5810\n",
      "Epoch 3541/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1957 - val_loss: 2.9108 - val_mae: 1.5500\n",
      "Epoch 3542/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0584 - mae: 0.2062 - val_loss: 2.8818 - val_mae: 1.5406\n",
      "Epoch 3543/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0531 - mae: 0.1956 - val_loss: 2.9027 - val_mae: 1.5475\n",
      "Epoch 3544/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1774 - val_loss: 2.8946 - val_mae: 1.5449\n",
      "Epoch 3545/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0500 - mae: 0.1707 - val_loss: 2.7280 - val_mae: 1.4900\n",
      "Epoch 3546/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0506 - mae: 0.1716 - val_loss: 2.4808 - val_mae: 1.4046\n",
      "Epoch 3547/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2027 - val_loss: 2.2928 - val_mae: 1.3359\n",
      "Epoch 3548/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0869 - mae: 0.2365 - val_loss: 2.2709 - val_mae: 1.3278\n",
      "Epoch 3549/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0822 - mae: 0.2271 - val_loss: 2.4496 - val_mae: 1.3938\n",
      "Epoch 3550/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0630 - mae: 0.1939 - val_loss: 2.7365 - val_mae: 1.4935\n",
      "Epoch 3551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0848 - mae: 0.2421 - val_loss: 2.8563 - val_mae: 1.5331\n",
      "Epoch 3552/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0915 - mae: 0.2581 - val_loss: 2.7599 - val_mae: 1.5010\n",
      "Epoch 3553/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1965 - val_loss: 2.6249 - val_mae: 1.4550\n",
      "Epoch 3554/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1734 - val_loss: 2.5330 - val_mae: 1.4229\n",
      "Epoch 3555/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0652 - mae: 0.2087 - val_loss: 2.6185 - val_mae: 1.4527\n",
      "Epoch 3556/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1967 - val_loss: 2.8482 - val_mae: 1.5299\n",
      "Epoch 3557/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0502 - mae: 0.1797 - val_loss: 2.9921 - val_mae: 1.5763\n",
      "Epoch 3558/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1735 - val_loss: 2.9797 - val_mae: 1.5723\n",
      "Epoch 3559/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1730 - val_loss: 2.9184 - val_mae: 1.5526\n",
      "Epoch 3560/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1819 - val_loss: 2.8265 - val_mae: 1.5227\n",
      "Epoch 3561/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1998 - val_loss: 2.8499 - val_mae: 1.5303\n",
      "Epoch 3562/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1833 - val_loss: 3.1042 - val_mae: 1.6114\n",
      "Epoch 3563/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1805 - val_loss: 3.2981 - val_mae: 1.6705\n",
      "Epoch 3564/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0794 - mae: 0.2278 - val_loss: 3.2418 - val_mae: 1.6535\n",
      "Epoch 3565/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.1918 - val_loss: 3.0415 - val_mae: 1.5917\n",
      "Epoch 3566/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1742 - val_loss: 2.8883 - val_mae: 1.5427\n",
      "Epoch 3567/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.2038 - val_loss: 2.9091 - val_mae: 1.5494\n",
      "Epoch 3568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1977 - val_loss: 3.0090 - val_mae: 1.5814\n",
      "Epoch 3569/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1781 - val_loss: 3.0778 - val_mae: 1.6030\n",
      "Epoch 3570/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1757 - val_loss: 3.0977 - val_mae: 1.6092\n",
      "Epoch 3571/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1651 - val_loss: 3.0577 - val_mae: 1.5967\n",
      "Epoch 3572/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1743 - val_loss: 2.9908 - val_mae: 1.5757\n",
      "Epoch 3573/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1880 - val_loss: 2.9089 - val_mae: 1.5494\n",
      "Epoch 3574/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.2040 - val_loss: 2.8557 - val_mae: 1.5321\n",
      "Epoch 3575/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2074 - val_loss: 2.8707 - val_mae: 1.5370\n",
      "Epoch 3576/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0546 - mae: 0.1906 - val_loss: 2.9709 - val_mae: 1.5694\n",
      "Epoch 3577/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0504 - mae: 0.1709 - val_loss: 3.0889 - val_mae: 1.6066\n",
      "Epoch 3578/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1771 - val_loss: 3.0747 - val_mae: 1.6021\n",
      "Epoch 3579/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1726 - val_loss: 2.9740 - val_mae: 1.5703\n",
      "Epoch 3580/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0473 - mae: 0.1646 - val_loss: 2.8948 - val_mae: 1.5449\n",
      "Epoch 3581/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1694 - val_loss: 2.8663 - val_mae: 1.5356\n",
      "Epoch 3582/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0477 - mae: 0.1729 - val_loss: 2.8962 - val_mae: 1.5453\n",
      "Epoch 3583/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1683 - val_loss: 2.9100 - val_mae: 1.5498\n",
      "Epoch 3584/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0464 - mae: 0.1654 - val_loss: 2.8731 - val_mae: 1.5379\n",
      "Epoch 3585/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1671 - val_loss: 2.8373 - val_mae: 1.5262\n",
      "Epoch 3586/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1675 - val_loss: 2.7810 - val_mae: 1.5076\n",
      "Epoch 3587/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1677 - val_loss: 2.7563 - val_mae: 1.4994\n",
      "Epoch 3588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1670 - val_loss: 2.7530 - val_mae: 1.4983\n",
      "Epoch 3589/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1674 - val_loss: 2.8130 - val_mae: 1.5182\n",
      "Epoch 3590/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0497 - mae: 0.1660 - val_loss: 2.8496 - val_mae: 1.5302\n",
      "Epoch 3591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1650 - val_loss: 2.8180 - val_mae: 1.5198\n",
      "Epoch 3592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1913 - val_loss: 2.9207 - val_mae: 1.5532\n",
      "Epoch 3593/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0515 - mae: 0.1891 - val_loss: 3.0639 - val_mae: 1.5987\n",
      "Epoch 3594/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1725 - val_loss: 3.1854 - val_mae: 1.6363\n",
      "Epoch 3595/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1681 - val_loss: 3.3207 - val_mae: 1.6771\n",
      "Epoch 3596/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1676 - val_loss: 3.4203 - val_mae: 1.7065\n",
      "Epoch 3597/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1724 - val_loss: 3.2617 - val_mae: 1.6593\n",
      "Epoch 3598/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1710 - val_loss: 2.9840 - val_mae: 1.5734\n",
      "Epoch 3599/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1991 - val_loss: 2.8922 - val_mae: 1.5440\n",
      "Epoch 3600/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1773 - val_loss: 2.9555 - val_mae: 1.5644\n",
      "Epoch 3601/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0524 - mae: 0.1823 - val_loss: 2.9379 - val_mae: 1.5588\n",
      "Epoch 3602/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0594 - mae: 0.1969 - val_loss: 2.8104 - val_mae: 1.5172\n",
      "Epoch 3603/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1854 - val_loss: 2.7163 - val_mae: 1.4859\n",
      "Epoch 3604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1873 - val_loss: 2.7860 - val_mae: 1.5092\n",
      "Epoch 3605/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1792 - val_loss: 2.9036 - val_mae: 1.5477\n",
      "Epoch 3606/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0471 - mae: 0.1644 - val_loss: 2.8805 - val_mae: 1.5402\n",
      "Epoch 3607/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0475 - mae: 0.1658 - val_loss: 2.8399 - val_mae: 1.5270\n",
      "Epoch 3608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1707 - val_loss: 2.8389 - val_mae: 1.5266\n",
      "Epoch 3609/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1693 - val_loss: 2.8396 - val_mae: 1.5269\n",
      "Epoch 3610/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1710 - val_loss: 2.9420 - val_mae: 1.5600\n",
      "Epoch 3611/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0471 - mae: 0.1703 - val_loss: 3.1253 - val_mae: 1.6177\n",
      "Epoch 3612/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1679 - val_loss: 3.1605 - val_mae: 1.6285\n",
      "Epoch 3613/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1710 - val_loss: 3.1592 - val_mae: 1.6281\n",
      "Epoch 3614/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1720 - val_loss: 3.1757 - val_mae: 1.6332\n",
      "Epoch 3615/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1706 - val_loss: 3.0857 - val_mae: 1.6054\n",
      "Epoch 3616/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1731 - val_loss: 2.9396 - val_mae: 1.5592\n",
      "Epoch 3617/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0502 - mae: 0.1828 - val_loss: 2.8922 - val_mae: 1.5439\n",
      "Epoch 3618/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1705 - val_loss: 2.9272 - val_mae: 1.5553\n",
      "Epoch 3619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1639 - val_loss: 2.9383 - val_mae: 1.5590\n",
      "Epoch 3620/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0537 - mae: 0.1787 - val_loss: 2.8409 - val_mae: 1.5273\n",
      "Epoch 3621/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0489 - mae: 0.1660 - val_loss: 2.6917 - val_mae: 1.4776\n",
      "Epoch 3622/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1753 - val_loss: 2.5514 - val_mae: 1.4292\n",
      "Epoch 3623/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0656 - mae: 0.2107 - val_loss: 2.5239 - val_mae: 1.4196\n",
      "Epoch 3624/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0689 - mae: 0.2138 - val_loss: 2.6350 - val_mae: 1.4582\n",
      "Epoch 3625/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1829 - val_loss: 2.8275 - val_mae: 1.5229\n",
      "Epoch 3626/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1796 - val_loss: 3.0440 - val_mae: 1.5926\n",
      "Epoch 3627/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0679 - mae: 0.2132 - val_loss: 3.0267 - val_mae: 1.5870\n",
      "Epoch 3628/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1721 - val_loss: 2.8129 - val_mae: 1.5180\n",
      "Epoch 3629/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.2022 - val_loss: 2.6810 - val_mae: 1.4738\n",
      "Epoch 3630/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0864 - mae: 0.2593 - val_loss: 2.7952 - val_mae: 1.5121\n",
      "Epoch 3631/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0708 - mae: 0.2326 - val_loss: 3.1747 - val_mae: 1.6329\n",
      "Epoch 3632/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0491 - mae: 0.1610 - val_loss: 3.5435 - val_mae: 1.7423\n",
      "Epoch 3633/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0872 - mae: 0.2385 - val_loss: 3.5522 - val_mae: 1.7448\n",
      "Epoch 3634/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0896 - mae: 0.2411 - val_loss: 3.2686 - val_mae: 1.6615\n",
      "Epoch 3635/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1690 - val_loss: 2.8946 - val_mae: 1.5446\n",
      "Epoch 3636/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0647 - mae: 0.2202 - val_loss: 2.6949 - val_mae: 1.4785\n",
      "Epoch 3637/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0870 - mae: 0.2579 - val_loss: 2.7435 - val_mae: 1.4949\n",
      "Epoch 3638/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0662 - mae: 0.2228 - val_loss: 2.9028 - val_mae: 1.5474\n",
      "Epoch 3639/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1661 - val_loss: 3.1207 - val_mae: 1.6164\n",
      "Epoch 3640/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0656 - mae: 0.2058 - val_loss: 3.2001 - val_mae: 1.6409\n",
      "Epoch 3641/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0843 - mae: 0.2430 - val_loss: 2.9522 - val_mae: 1.5634\n",
      "Epoch 3642/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1769 - val_loss: 2.6539 - val_mae: 1.4647\n",
      "Epoch 3643/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - mae: 0.2189 - val_loss: 2.6589 - val_mae: 1.4664\n",
      "Epoch 3644/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2240 - val_loss: 2.9389 - val_mae: 1.5590\n",
      "Epoch 3645/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1719 - val_loss: 3.2683 - val_mae: 1.6614\n",
      "Epoch 3646/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0622 - mae: 0.1876 - val_loss: 3.2729 - val_mae: 1.6627\n",
      "Epoch 3647/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0553 - mae: 0.1756 - val_loss: 3.0713 - val_mae: 1.6008\n",
      "Epoch 3648/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0581 - mae: 0.1944 - val_loss: 2.9925 - val_mae: 1.5760\n",
      "Epoch 3649/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0758 - mae: 0.2331 - val_loss: 3.1470 - val_mae: 1.6243\n",
      "Epoch 3650/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0638 - mae: 0.2044 - val_loss: 3.3216 - val_mae: 1.6773\n",
      "Epoch 3651/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0560 - mae: 0.1722 - val_loss: 3.2111 - val_mae: 1.6440\n",
      "Epoch 3652/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0524 - mae: 0.1666 - val_loss: 3.0337 - val_mae: 1.5891\n",
      "Epoch 3653/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1733 - val_loss: 2.9664 - val_mae: 1.5679\n",
      "Epoch 3654/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1659 - val_loss: 2.9965 - val_mae: 1.5775\n",
      "Epoch 3655/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1661 - val_loss: 3.0481 - val_mae: 1.5938\n",
      "Epoch 3656/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0532 - mae: 0.1796 - val_loss: 2.9857 - val_mae: 1.5741\n",
      "Epoch 3657/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1711 - val_loss: 2.8940 - val_mae: 1.5446\n",
      "Epoch 3658/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0471 - mae: 0.1639 - val_loss: 2.8361 - val_mae: 1.5258\n",
      "Epoch 3659/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1691 - val_loss: 2.7390 - val_mae: 1.4936\n",
      "Epoch 3660/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1834 - val_loss: 2.6389 - val_mae: 1.4596\n",
      "Epoch 3661/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1914 - val_loss: 2.6731 - val_mae: 1.4713\n",
      "Epoch 3662/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1768 - val_loss: 2.7887 - val_mae: 1.5102\n",
      "Epoch 3663/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1862 - val_loss: 2.9040 - val_mae: 1.5481\n",
      "Epoch 3664/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0631 - mae: 0.2058 - val_loss: 2.9784 - val_mae: 1.5720\n",
      "Epoch 3665/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2031 - val_loss: 2.9390 - val_mae: 1.5593\n",
      "Epoch 3666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1899 - val_loss: 2.8746 - val_mae: 1.5384\n",
      "Epoch 3667/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1768 - val_loss: 2.8529 - val_mae: 1.5312\n",
      "Epoch 3668/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0474 - mae: 0.1670 - val_loss: 2.9249 - val_mae: 1.5546\n",
      "Epoch 3669/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0458 - mae: 0.1657 - val_loss: 3.1789 - val_mae: 1.6342\n",
      "Epoch 3670/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1866 - val_loss: 3.3279 - val_mae: 1.6792\n",
      "Epoch 3671/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.1874 - val_loss: 3.2569 - val_mae: 1.6578\n",
      "Epoch 3672/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1723 - val_loss: 3.1396 - val_mae: 1.6220\n",
      "Epoch 3673/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0587 - mae: 0.1993 - val_loss: 3.0783 - val_mae: 1.6030\n",
      "Epoch 3674/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2196 - val_loss: 3.0962 - val_mae: 1.6086\n",
      "Epoch 3675/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0603 - mae: 0.2086 - val_loss: 2.9935 - val_mae: 1.5763\n",
      "Epoch 3676/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.2003 - val_loss: 2.8244 - val_mae: 1.5218\n",
      "Epoch 3677/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1974 - val_loss: 2.7798 - val_mae: 1.5072\n",
      "Epoch 3678/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0486 - mae: 0.1725 - val_loss: 2.8050 - val_mae: 1.5156\n",
      "Epoch 3679/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1772 - val_loss: 2.7161 - val_mae: 1.4860\n",
      "Epoch 3680/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0530 - mae: 0.1746 - val_loss: 2.5512 - val_mae: 1.4294\n",
      "Epoch 3681/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0577 - mae: 0.1886 - val_loss: 2.5510 - val_mae: 1.4294\n",
      "Epoch 3682/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0562 - mae: 0.1841 - val_loss: 2.7275 - val_mae: 1.4899\n",
      "Epoch 3683/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1815 - val_loss: 2.9755 - val_mae: 1.5710\n",
      "Epoch 3684/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0725 - mae: 0.2216 - val_loss: 3.1035 - val_mae: 1.6112\n",
      "Epoch 3685/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0728 - mae: 0.2228 - val_loss: 2.9667 - val_mae: 1.5680\n",
      "Epoch 3686/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0494 - mae: 0.1702 - val_loss: 2.8048 - val_mae: 1.5154\n",
      "Epoch 3687/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0517 - mae: 0.1873 - val_loss: 2.7659 - val_mae: 1.5025\n",
      "Epoch 3688/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0556 - mae: 0.1988 - val_loss: 2.9267 - val_mae: 1.5551\n",
      "Epoch 3689/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0463 - mae: 0.1658 - val_loss: 3.1817 - val_mae: 1.6351\n",
      "Epoch 3690/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0558 - mae: 0.1750 - val_loss: 3.2578 - val_mae: 1.6583\n",
      "Epoch 3691/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.1784 - val_loss: 3.1749 - val_mae: 1.6330\n",
      "Epoch 3692/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0499 - mae: 0.1677 - val_loss: 3.1219 - val_mae: 1.6167\n",
      "Epoch 3693/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0484 - mae: 0.1686 - val_loss: 3.1816 - val_mae: 1.6350\n",
      "Epoch 3694/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0495 - mae: 0.1677 - val_loss: 3.2342 - val_mae: 1.6510\n",
      "Epoch 3695/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0501 - mae: 0.1680 - val_loss: 3.0910 - val_mae: 1.6070\n",
      "Epoch 3696/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0555 - mae: 0.1934 - val_loss: 2.9251 - val_mae: 1.5545\n",
      "Epoch 3697/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0610 - mae: 0.2056 - val_loss: 2.9006 - val_mae: 1.5466\n",
      "Epoch 3698/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0584 - mae: 0.2034 - val_loss: 2.8482 - val_mae: 1.5296\n",
      "Epoch 3699/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0480 - mae: 0.1730 - val_loss: 2.8390 - val_mae: 1.5267\n",
      "Epoch 3700/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0573 - mae: 0.1931 - val_loss: 2.9391 - val_mae: 1.5592\n",
      "Epoch 3701/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0702 - mae: 0.2153 - val_loss: 2.9763 - val_mae: 1.5712\n",
      "Epoch 3702/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0772 - mae: 0.2262 - val_loss: 2.9683 - val_mae: 1.5686\n",
      "Epoch 3703/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0760 - mae: 0.2219 - val_loss: 2.9561 - val_mae: 1.5646\n",
      "Epoch 3704/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0706 - mae: 0.2105 - val_loss: 2.9105 - val_mae: 1.5499\n",
      "Epoch 3705/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0636 - mae: 0.2005 - val_loss: 2.9133 - val_mae: 1.5508\n",
      "Epoch 3706/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0571 - mae: 0.1931 - val_loss: 3.0205 - val_mae: 1.5851\n",
      "Epoch 3707/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0502 - mae: 0.1744 - val_loss: 3.1577 - val_mae: 1.6279\n",
      "Epoch 3708/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0536 - mae: 0.1803 - val_loss: 3.2603 - val_mae: 1.6591\n",
      "Epoch 3709/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0628 - mae: 0.2003 - val_loss: 3.2570 - val_mae: 1.6581\n",
      "Epoch 3710/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0629 - mae: 0.2050 - val_loss: 3.1080 - val_mae: 1.6125\n",
      "Epoch 3711/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.1979 - val_loss: 2.9694 - val_mae: 1.5689\n",
      "Epoch 3712/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1861 - val_loss: 2.9297 - val_mae: 1.5562\n",
      "Epoch 3713/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0491 - mae: 0.1768 - val_loss: 2.8360 - val_mae: 1.5259\n",
      "Epoch 3714/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1755 - val_loss: 2.7222 - val_mae: 1.4882\n",
      "Epoch 3715/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1870 - val_loss: 2.6522 - val_mae: 1.4646\n",
      "Epoch 3716/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.1972 - val_loss: 2.5982 - val_mae: 1.4461\n",
      "Epoch 3717/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0618 - mae: 0.1979 - val_loss: 2.6278 - val_mae: 1.4564\n",
      "Epoch 3718/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0594 - mae: 0.1921 - val_loss: 2.7240 - val_mae: 1.4890\n",
      "Epoch 3719/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1798 - val_loss: 2.7825 - val_mae: 1.5084\n",
      "Epoch 3720/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1680 - val_loss: 2.8269 - val_mae: 1.5229\n",
      "Epoch 3721/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1780 - val_loss: 2.8765 - val_mae: 1.5391\n",
      "Epoch 3722/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0498 - mae: 0.1822 - val_loss: 2.8978 - val_mae: 1.5460\n",
      "Epoch 3723/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0506 - mae: 0.1843 - val_loss: 3.0031 - val_mae: 1.5797\n",
      "Epoch 3724/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0493 - mae: 0.1786 - val_loss: 3.1733 - val_mae: 1.6328\n",
      "Epoch 3725/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1762 - val_loss: 3.2085 - val_mae: 1.6435\n",
      "Epoch 3726/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0513 - mae: 0.1686 - val_loss: 3.0653 - val_mae: 1.5993\n",
      "Epoch 3727/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0486 - mae: 0.1752 - val_loss: 2.8026 - val_mae: 1.5148\n",
      "Epoch 3728/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0685 - mae: 0.2253 - val_loss: 2.7024 - val_mae: 1.4813\n",
      "Epoch 3729/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0619 - mae: 0.2081 - val_loss: 2.9604 - val_mae: 1.5663\n",
      "Epoch 3730/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.1958 - val_loss: 3.2610 - val_mae: 1.6598\n",
      "Epoch 3731/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1075 - mae: 0.2696 - val_loss: 3.2370 - val_mae: 1.6526\n",
      "Epoch 3732/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0774 - mae: 0.2238 - val_loss: 3.0096 - val_mae: 1.5821\n",
      "Epoch 3733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1801 - val_loss: 2.8174 - val_mae: 1.5199\n",
      "Epoch 3734/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0704 - mae: 0.2223 - val_loss: 2.8053 - val_mae: 1.5158\n",
      "Epoch 3735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0781 - mae: 0.2328 - val_loss: 2.9074 - val_mae: 1.5492\n",
      "Epoch 3736/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0683 - mae: 0.2111 - val_loss: 3.0545 - val_mae: 1.5961\n",
      "Epoch 3737/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0629 - mae: 0.1999 - val_loss: 3.3028 - val_mae: 1.6722\n",
      "Epoch 3738/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0755 - mae: 0.2148 - val_loss: 3.4026 - val_mae: 1.7016\n",
      "Epoch 3739/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0748 - mae: 0.2123 - val_loss: 3.1817 - val_mae: 1.6352\n",
      "Epoch 3740/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0510 - mae: 0.1678 - val_loss: 2.8611 - val_mae: 1.5339\n",
      "Epoch 3741/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0719 - mae: 0.2304 - val_loss: 2.7249 - val_mae: 1.4887\n",
      "Epoch 3742/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0950 - mae: 0.2629 - val_loss: 2.8702 - val_mae: 1.5368\n",
      "Epoch 3743/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0644 - mae: 0.2044 - val_loss: 3.2113 - val_mae: 1.6443\n",
      "Epoch 3744/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1953 - val_loss: 3.4372 - val_mae: 1.7117\n",
      "Epoch 3745/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0868 - mae: 0.2389 - val_loss: 3.2829 - val_mae: 1.6660\n",
      "Epoch 3746/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1806 - val_loss: 2.9926 - val_mae: 1.5763\n",
      "Epoch 3747/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0598 - mae: 0.2042 - val_loss: 2.8361 - val_mae: 1.5258\n",
      "Epoch 3748/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0823 - mae: 0.2443 - val_loss: 2.8505 - val_mae: 1.5305\n",
      "Epoch 3749/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0815 - mae: 0.2380 - val_loss: 2.9273 - val_mae: 1.5555\n",
      "Epoch 3750/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0726 - mae: 0.2132 - val_loss: 2.9731 - val_mae: 1.5703\n",
      "Epoch 3751/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0717 - mae: 0.2113 - val_loss: 2.9533 - val_mae: 1.5641\n",
      "Epoch 3752/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0721 - mae: 0.2126 - val_loss: 2.8000 - val_mae: 1.5142\n",
      "Epoch 3753/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0714 - mae: 0.2121 - val_loss: 2.6259 - val_mae: 1.4555\n",
      "Epoch 3754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0753 - mae: 0.2196 - val_loss: 2.5565 - val_mae: 1.4314\n",
      "Epoch 3755/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0783 - mae: 0.2267 - val_loss: 2.6569 - val_mae: 1.4661\n",
      "Epoch 3756/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2060 - val_loss: 2.9571 - val_mae: 1.5653\n",
      "Epoch 3757/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0687 - mae: 0.2116 - val_loss: 3.1627 - val_mae: 1.6297\n",
      "Epoch 3758/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0808 - mae: 0.2308 - val_loss: 3.1173 - val_mae: 1.6156\n",
      "Epoch 3759/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0652 - mae: 0.2039 - val_loss: 2.9054 - val_mae: 1.5485\n",
      "Epoch 3760/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.2064 - val_loss: 2.7589 - val_mae: 1.5004\n",
      "Epoch 3761/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0739 - mae: 0.2216 - val_loss: 2.8635 - val_mae: 1.5349\n",
      "Epoch 3762/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.2083 - val_loss: 3.0066 - val_mae: 1.5809\n",
      "Epoch 3763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1969 - val_loss: 3.1135 - val_mae: 1.6144\n",
      "Epoch 3764/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.2082 - val_loss: 3.1030 - val_mae: 1.6112\n",
      "Epoch 3765/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0621 - mae: 0.2060 - val_loss: 2.9233 - val_mae: 1.5543\n",
      "Epoch 3766/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1929 - val_loss: 2.8120 - val_mae: 1.5180\n",
      "Epoch 3767/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.2047 - val_loss: 2.8429 - val_mae: 1.5282\n",
      "Epoch 3768/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1980 - val_loss: 2.9821 - val_mae: 1.5731\n",
      "Epoch 3769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1824 - val_loss: 3.1307 - val_mae: 1.6197\n",
      "Epoch 3770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1800 - val_loss: 3.2400 - val_mae: 1.6532\n",
      "Epoch 3771/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.1868 - val_loss: 3.2406 - val_mae: 1.6534\n",
      "Epoch 3772/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1758 - val_loss: 3.0891 - val_mae: 1.6068\n",
      "Epoch 3773/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1811 - val_loss: 2.9243 - val_mae: 1.5546\n",
      "Epoch 3774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.2053 - val_loss: 2.8563 - val_mae: 1.5325\n",
      "Epoch 3775/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.2107 - val_loss: 2.9544 - val_mae: 1.5643\n",
      "Epoch 3776/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1779 - val_loss: 3.1549 - val_mae: 1.6273\n",
      "Epoch 3777/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1747 - val_loss: 3.2347 - val_mae: 1.6517\n",
      "Epoch 3778/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0724 - mae: 0.2140 - val_loss: 3.1442 - val_mae: 1.6241\n",
      "Epoch 3779/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0659 - mae: 0.2033 - val_loss: 2.9508 - val_mae: 1.5633\n",
      "Epoch 3780/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1670 - val_loss: 2.7312 - val_mae: 1.4912\n",
      "Epoch 3781/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1981 - val_loss: 2.6814 - val_mae: 1.4744\n",
      "Epoch 3782/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0645 - mae: 0.2185 - val_loss: 2.7789 - val_mae: 1.5071\n",
      "Epoch 3783/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1929 - val_loss: 2.9057 - val_mae: 1.5487\n",
      "Epoch 3784/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1681 - val_loss: 3.0275 - val_mae: 1.5876\n",
      "Epoch 3785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1821 - val_loss: 3.1026 - val_mae: 1.6111\n",
      "Epoch 3786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.1969 - val_loss: 3.0239 - val_mae: 1.5865\n",
      "Epoch 3787/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0499 - mae: 0.1721 - val_loss: 2.9048 - val_mae: 1.5484\n",
      "Epoch 3788/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0503 - mae: 0.1801 - val_loss: 2.8696 - val_mae: 1.5369\n",
      "Epoch 3789/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1961 - val_loss: 2.9048 - val_mae: 1.5484\n",
      "Epoch 3790/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1910 - val_loss: 2.9477 - val_mae: 1.5622\n",
      "Epoch 3791/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1862 - val_loss: 3.0298 - val_mae: 1.5883\n",
      "Epoch 3792/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1773 - val_loss: 3.1238 - val_mae: 1.6176\n",
      "Epoch 3793/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0544 - mae: 0.1718 - val_loss: 3.1487 - val_mae: 1.6253\n",
      "Epoch 3794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1688 - val_loss: 3.1202 - val_mae: 1.6164\n",
      "Epoch 3795/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0502 - mae: 0.1684 - val_loss: 2.9754 - val_mae: 1.5709\n",
      "Epoch 3796/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1812 - val_loss: 2.7831 - val_mae: 1.5084\n",
      "Epoch 3797/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0617 - mae: 0.2052 - val_loss: 2.7884 - val_mae: 1.5102\n",
      "Epoch 3798/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0553 - mae: 0.1945 - val_loss: 2.9889 - val_mae: 1.5753\n",
      "Epoch 3799/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1875 - val_loss: 3.1245 - val_mae: 1.6178\n",
      "Epoch 3800/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.1933 - val_loss: 3.0552 - val_mae: 1.5962\n",
      "Epoch 3801/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0517 - mae: 0.1814 - val_loss: 2.8826 - val_mae: 1.5411\n",
      "Epoch 3802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1840 - val_loss: 2.7880 - val_mae: 1.5100\n",
      "Epoch 3803/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1908 - val_loss: 2.8520 - val_mae: 1.5311\n",
      "Epoch 3804/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1752 - val_loss: 2.9859 - val_mae: 1.5743\n",
      "Epoch 3805/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1682 - val_loss: 3.0873 - val_mae: 1.6062\n",
      "Epoch 3806/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1823 - val_loss: 3.1186 - val_mae: 1.6159\n",
      "Epoch 3807/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1810 - val_loss: 3.0872 - val_mae: 1.6061\n",
      "Epoch 3808/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1710 - val_loss: 3.0499 - val_mae: 1.5944\n",
      "Epoch 3809/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1688 - val_loss: 3.1254 - val_mae: 1.6179\n",
      "Epoch 3810/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0503 - mae: 0.1665 - val_loss: 3.2520 - val_mae: 1.6566\n",
      "Epoch 3811/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0571 - mae: 0.1729 - val_loss: 3.2516 - val_mae: 1.6564\n",
      "Epoch 3812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1685 - val_loss: 3.1260 - val_mae: 1.6179\n",
      "Epoch 3813/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1698 - val_loss: 3.1197 - val_mae: 1.6157\n",
      "Epoch 3814/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1765 - val_loss: 3.4786 - val_mae: 1.7213\n",
      "Epoch 3815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1918 - val_loss: 3.1052 - val_mae: 1.6115\n",
      "Epoch 3816/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0557 - mae: 0.1987 - val_loss: 2.9781 - val_mae: 1.5717\n",
      "Epoch 3817/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1931 - val_loss: 2.8769 - val_mae: 1.5392\n",
      "Epoch 3818/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0489 - mae: 0.1802 - val_loss: 2.7752 - val_mae: 1.5058\n",
      "Epoch 3819/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1798 - val_loss: 2.6776 - val_mae: 1.4730\n",
      "Epoch 3820/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1831 - val_loss: 2.6018 - val_mae: 1.4471\n",
      "Epoch 3821/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1826 - val_loss: 2.5703 - val_mae: 1.4361\n",
      "Epoch 3822/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1821 - val_loss: 2.6035 - val_mae: 1.4477\n",
      "Epoch 3823/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0513 - mae: 0.1726 - val_loss: 2.6357 - val_mae: 1.4588\n",
      "Epoch 3824/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0505 - mae: 0.1696 - val_loss: 2.6435 - val_mae: 1.4615\n",
      "Epoch 3825/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0516 - mae: 0.1741 - val_loss: 2.6891 - val_mae: 1.4771\n",
      "Epoch 3826/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0523 - mae: 0.1764 - val_loss: 2.8194 - val_mae: 1.5206\n",
      "Epoch 3827/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1796 - val_loss: 2.9461 - val_mae: 1.5617\n",
      "Epoch 3828/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1908 - val_loss: 2.9593 - val_mae: 1.5659\n",
      "Epoch 3829/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0539 - mae: 0.1818 - val_loss: 2.8732 - val_mae: 1.5380\n",
      "Epoch 3830/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0483 - mae: 0.1684 - val_loss: 2.9383 - val_mae: 1.5590\n",
      "Epoch 3831/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1731 - val_loss: 3.1276 - val_mae: 1.6185\n",
      "Epoch 3832/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1685 - val_loss: 3.1534 - val_mae: 1.6264\n",
      "Epoch 3833/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1702 - val_loss: 3.1487 - val_mae: 1.6250\n",
      "Epoch 3834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1716 - val_loss: 3.1012 - val_mae: 1.6103\n",
      "Epoch 3835/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1853 - val_loss: 3.1010 - val_mae: 1.6102\n",
      "Epoch 3836/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1787 - val_loss: 3.2297 - val_mae: 1.6498\n",
      "Epoch 3837/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1669 - val_loss: 3.1820 - val_mae: 1.6353\n",
      "Epoch 3838/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0496 - mae: 0.1677 - val_loss: 2.8774 - val_mae: 1.5393\n",
      "Epoch 3839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1756 - val_loss: 2.6167 - val_mae: 1.4520\n",
      "Epoch 3840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1966 - val_loss: 2.5506 - val_mae: 1.4291\n",
      "Epoch 3841/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1826 - val_loss: 2.6453 - val_mae: 1.4620\n",
      "Epoch 3842/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1724 - val_loss: 2.8639 - val_mae: 1.5350\n",
      "Epoch 3843/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0633 - mae: 0.2063 - val_loss: 3.0078 - val_mae: 1.5812\n",
      "Epoch 3844/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2048 - val_loss: 2.9401 - val_mae: 1.5595\n",
      "Epoch 3845/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1594 - val_loss: 2.7461 - val_mae: 1.4959\n",
      "Epoch 3846/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0636 - mae: 0.2154 - val_loss: 2.7421 - val_mae: 1.4945\n",
      "Epoch 3847/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0768 - mae: 0.2417 - val_loss: 3.0150 - val_mae: 1.5833\n",
      "Epoch 3848/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1961 - val_loss: 3.2223 - val_mae: 1.6475\n",
      "Epoch 3849/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0496 - mae: 0.1677 - val_loss: 3.2744 - val_mae: 1.6632\n",
      "Epoch 3850/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0519 - mae: 0.1650 - val_loss: 3.3267 - val_mae: 1.6789\n",
      "Epoch 3851/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0565 - mae: 0.1696 - val_loss: 3.2838 - val_mae: 1.6661\n",
      "Epoch 3852/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0526 - mae: 0.1639 - val_loss: 3.1166 - val_mae: 1.6150\n",
      "Epoch 3853/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0502 - mae: 0.1780 - val_loss: 3.0448 - val_mae: 1.5926\n",
      "Epoch 3854/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1852 - val_loss: 3.1167 - val_mae: 1.6151\n",
      "Epoch 3855/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1705 - val_loss: 3.1440 - val_mae: 1.6235\n",
      "Epoch 3856/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0512 - mae: 0.1654 - val_loss: 2.9864 - val_mae: 1.5742\n",
      "Epoch 3857/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1732 - val_loss: 2.8439 - val_mae: 1.5282\n",
      "Epoch 3858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1881 - val_loss: 2.9363 - val_mae: 1.5582\n",
      "Epoch 3859/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0467 - mae: 0.1674 - val_loss: 3.1296 - val_mae: 1.6191\n",
      "Epoch 3860/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0499 - mae: 0.1670 - val_loss: 3.1815 - val_mae: 1.6350\n",
      "Epoch 3861/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1704 - val_loss: 3.1412 - val_mae: 1.6226\n",
      "Epoch 3862/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0482 - mae: 0.1662 - val_loss: 3.0951 - val_mae: 1.6083\n",
      "Epoch 3863/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1687 - val_loss: 3.0411 - val_mae: 1.5914\n",
      "Epoch 3864/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1881 - val_loss: 2.9702 - val_mae: 1.5689\n",
      "Epoch 3865/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1898 - val_loss: 2.9649 - val_mae: 1.5673\n",
      "Epoch 3866/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0479 - mae: 0.1736 - val_loss: 3.0316 - val_mae: 1.5885\n",
      "Epoch 3867/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0514 - mae: 0.1812 - val_loss: 2.9370 - val_mae: 1.5584\n",
      "Epoch 3868/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1796 - val_loss: 2.6963 - val_mae: 1.4791\n",
      "Epoch 3869/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0513 - mae: 0.1805 - val_loss: 2.5758 - val_mae: 1.4379\n",
      "Epoch 3870/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1807 - val_loss: 2.6229 - val_mae: 1.4542\n",
      "Epoch 3871/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0513 - mae: 0.1703 - val_loss: 2.7760 - val_mae: 1.5060\n",
      "Epoch 3872/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1821 - val_loss: 2.9347 - val_mae: 1.5579\n",
      "Epoch 3873/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0665 - mae: 0.2061 - val_loss: 2.9430 - val_mae: 1.5605\n",
      "Epoch 3874/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1835 - val_loss: 2.8608 - val_mae: 1.5338\n",
      "Epoch 3875/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1649 - val_loss: 2.8554 - val_mae: 1.5320\n",
      "Epoch 3876/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0485 - mae: 0.1772 - val_loss: 2.9995 - val_mae: 1.5784\n",
      "Epoch 3877/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0455 - mae: 0.1676 - val_loss: 3.2677 - val_mae: 1.6612\n",
      "Epoch 3878/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1697 - val_loss: 3.4775 - val_mae: 1.7233\n",
      "Epoch 3879/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0690 - mae: 0.1968 - val_loss: 3.3363 - val_mae: 1.6817\n",
      "Epoch 3880/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1722 - val_loss: 3.1106 - val_mae: 1.6131\n",
      "Epoch 3881/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1798 - val_loss: 2.9829 - val_mae: 1.5730\n",
      "Epoch 3882/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1937 - val_loss: 2.9187 - val_mae: 1.5525\n",
      "Epoch 3883/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0477 - mae: 0.1743 - val_loss: 2.9693 - val_mae: 1.5688\n",
      "Epoch 3884/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0491 - mae: 0.1715 - val_loss: 2.9715 - val_mae: 1.5695\n",
      "Epoch 3885/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1926 - val_loss: 2.8078 - val_mae: 1.5164\n",
      "Epoch 3886/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0481 - mae: 0.1707 - val_loss: 2.6446 - val_mae: 1.4615\n",
      "Epoch 3887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0709 - mae: 0.2179 - val_loss: 2.7779 - val_mae: 1.5065\n",
      "Epoch 3888/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0644 - mae: 0.2021 - val_loss: 3.0102 - val_mae: 1.5818\n",
      "Epoch 3889/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0709 - mae: 0.2152 - val_loss: 3.0809 - val_mae: 1.6041\n",
      "Epoch 3890/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0721 - mae: 0.2178 - val_loss: 3.0830 - val_mae: 1.6047\n",
      "Epoch 3891/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0599 - mae: 0.1911 - val_loss: 3.0182 - val_mae: 1.5843\n",
      "Epoch 3892/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1681 - val_loss: 2.9580 - val_mae: 1.5652\n",
      "Epoch 3893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1834 - val_loss: 2.9598 - val_mae: 1.5657\n",
      "Epoch 3894/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0591 - mae: 0.2012 - val_loss: 3.0027 - val_mae: 1.5794\n",
      "Epoch 3895/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0640 - mae: 0.2084 - val_loss: 3.1381 - val_mae: 1.6217\n",
      "Epoch 3896/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1983 - val_loss: 3.1727 - val_mae: 1.6324\n",
      "Epoch 3897/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1880 - val_loss: 3.0632 - val_mae: 1.5985\n",
      "Epoch 3898/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0492 - mae: 0.1786 - val_loss: 2.9972 - val_mae: 1.5777\n",
      "Epoch 3899/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1662 - val_loss: 2.9050 - val_mae: 1.5482\n",
      "Epoch 3900/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0474 - mae: 0.1683 - val_loss: 2.7693 - val_mae: 1.5037\n",
      "Epoch 3901/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1734 - val_loss: 2.7090 - val_mae: 1.4835\n",
      "Epoch 3902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0485 - mae: 0.1690 - val_loss: 2.7585 - val_mae: 1.5002\n",
      "Epoch 3903/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1737 - val_loss: 2.8307 - val_mae: 1.5241\n",
      "Epoch 3904/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1780 - val_loss: 2.8253 - val_mae: 1.5223\n",
      "Epoch 3905/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0474 - mae: 0.1714 - val_loss: 2.7800 - val_mae: 1.5073\n",
      "Epoch 3906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1729 - val_loss: 2.7451 - val_mae: 1.4956\n",
      "Epoch 3907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1967 - val_loss: 2.8526 - val_mae: 1.5311\n",
      "Epoch 3908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1822 - val_loss: 3.1482 - val_mae: 1.6249\n",
      "Epoch 3909/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0526 - mae: 0.1749 - val_loss: 3.3702 - val_mae: 1.6919\n",
      "Epoch 3910/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0695 - mae: 0.2049 - val_loss: 3.2892 - val_mae: 1.6678\n",
      "Epoch 3911/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1715 - val_loss: 3.0731 - val_mae: 1.6016\n",
      "Epoch 3912/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0514 - mae: 0.1791 - val_loss: 2.9630 - val_mae: 1.5668\n",
      "Epoch 3913/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0555 - mae: 0.1949 - val_loss: 3.0016 - val_mae: 1.5791\n",
      "Epoch 3914/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0542 - mae: 0.1831 - val_loss: 3.1577 - val_mae: 1.6279\n",
      "Epoch 3915/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0629 - mae: 0.1911 - val_loss: 3.3169 - val_mae: 1.6762\n",
      "Epoch 3916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0803 - mae: 0.2232 - val_loss: 3.3600 - val_mae: 1.6889\n",
      "Epoch 3917/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0776 - mae: 0.2175 - val_loss: 3.3014 - val_mae: 1.6714\n",
      "Epoch 3918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1731 - val_loss: 3.1634 - val_mae: 1.6296\n",
      "Epoch 3919/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1694 - val_loss: 2.9774 - val_mae: 1.5714\n",
      "Epoch 3920/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0636 - mae: 0.2084 - val_loss: 2.9064 - val_mae: 1.5486\n",
      "Epoch 3921/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0717 - mae: 0.2223 - val_loss: 3.0048 - val_mae: 1.5801\n",
      "Epoch 3922/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.2109 - val_loss: 3.0457 - val_mae: 1.5930\n",
      "Epoch 3923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1756 - val_loss: 2.8813 - val_mae: 1.5405\n",
      "Epoch 3924/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1923 - val_loss: 2.7285 - val_mae: 1.4900\n",
      "Epoch 3925/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0635 - mae: 0.2168 - val_loss: 2.7792 - val_mae: 1.5070\n",
      "Epoch 3926/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0568 - mae: 0.1955 - val_loss: 2.9132 - val_mae: 1.5509\n",
      "Epoch 3927/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1727 - val_loss: 3.0754 - val_mae: 1.6024\n",
      "Epoch 3928/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1684 - val_loss: 3.2671 - val_mae: 1.6612\n",
      "Epoch 3929/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.1960 - val_loss: 3.3048 - val_mae: 1.6725\n",
      "Epoch 3930/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.1811 - val_loss: 3.1454 - val_mae: 1.6240\n",
      "Epoch 3931/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1852 - val_loss: 3.0034 - val_mae: 1.5796\n",
      "Epoch 3932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0714 - mae: 0.2293 - val_loss: 2.9254 - val_mae: 1.5546\n",
      "Epoch 3933/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0856 - mae: 0.2543 - val_loss: 2.9889 - val_mae: 1.5749\n",
      "Epoch 3934/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0682 - mae: 0.2233 - val_loss: 3.2578 - val_mae: 1.6582\n",
      "Epoch 3935/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1768 - val_loss: 3.4373 - val_mae: 1.7116\n",
      "Epoch 3936/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0744 - mae: 0.2115 - val_loss: 3.3331 - val_mae: 1.6809\n",
      "Epoch 3937/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0658 - mae: 0.1940 - val_loss: 3.0889 - val_mae: 1.6065\n",
      "Epoch 3938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1679 - val_loss: 2.8948 - val_mae: 1.5448\n",
      "Epoch 3939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1847 - val_loss: 2.8122 - val_mae: 1.5178\n",
      "Epoch 3940/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1916 - val_loss: 2.8778 - val_mae: 1.5393\n",
      "Epoch 3941/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0479 - mae: 0.1756 - val_loss: 3.0247 - val_mae: 1.5864\n",
      "Epoch 3942/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1757 - val_loss: 3.0883 - val_mae: 1.6063\n",
      "Epoch 3943/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1779 - val_loss: 2.9750 - val_mae: 1.5706\n",
      "Epoch 3944/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0460 - mae: 0.1662 - val_loss: 2.8104 - val_mae: 1.5172\n",
      "Epoch 3945/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0583 - mae: 0.2034 - val_loss: 2.8626 - val_mae: 1.5343\n",
      "Epoch 3946/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0537 - mae: 0.1940 - val_loss: 3.0438 - val_mae: 1.5923\n",
      "Epoch 3947/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0466 - mae: 0.1653 - val_loss: 3.1188 - val_mae: 1.6158\n",
      "Epoch 3948/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1663 - val_loss: 3.1177 - val_mae: 1.6154\n",
      "Epoch 3949/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1683 - val_loss: 3.0654 - val_mae: 1.5991\n",
      "Epoch 3950/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1672 - val_loss: 3.0211 - val_mae: 1.5852\n",
      "Epoch 3951/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1671 - val_loss: 3.0358 - val_mae: 1.5898\n",
      "Epoch 3952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1673 - val_loss: 3.0890 - val_mae: 1.6064\n",
      "Epoch 3953/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1641 - val_loss: 3.1322 - val_mae: 1.6199\n",
      "Epoch 3954/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1630 - val_loss: 3.1590 - val_mae: 1.6281\n",
      "Epoch 3955/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1652 - val_loss: 3.1771 - val_mae: 1.6337\n",
      "Epoch 3956/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0501 - mae: 0.1638 - val_loss: 3.0959 - val_mae: 1.6086\n",
      "Epoch 3957/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0467 - mae: 0.1651 - val_loss: 2.9484 - val_mae: 1.5620\n",
      "Epoch 3958/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1770 - val_loss: 2.8883 - val_mae: 1.5426\n",
      "Epoch 3959/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0513 - mae: 0.1855 - val_loss: 2.9328 - val_mae: 1.5570\n",
      "Epoch 3960/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1720 - val_loss: 3.1138 - val_mae: 1.6142\n",
      "Epoch 3961/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1773 - val_loss: 3.2031 - val_mae: 1.6416\n",
      "Epoch 3962/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0555 - mae: 0.1781 - val_loss: 3.0696 - val_mae: 1.6004\n",
      "Epoch 3963/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1637 - val_loss: 2.9663 - val_mae: 1.5677\n",
      "Epoch 3964/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1732 - val_loss: 2.9564 - val_mae: 1.5645\n",
      "Epoch 3965/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0480 - mae: 0.1760 - val_loss: 2.9925 - val_mae: 1.5760\n",
      "Epoch 3966/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0460 - mae: 0.1629 - val_loss: 3.0076 - val_mae: 1.5809\n",
      "Epoch 3967/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1617 - val_loss: 2.9720 - val_mae: 1.5696\n",
      "Epoch 3968/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1624 - val_loss: 2.8140 - val_mae: 1.5184\n",
      "Epoch 3969/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0474 - mae: 0.1732 - val_loss: 2.6335 - val_mae: 1.4576\n",
      "Epoch 3970/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0638 - mae: 0.2107 - val_loss: 2.6330 - val_mae: 1.4575\n",
      "Epoch 3971/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0616 - mae: 0.2057 - val_loss: 2.7903 - val_mae: 1.5105\n",
      "Epoch 3972/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0484 - mae: 0.1780 - val_loss: 3.0149 - val_mae: 1.5833\n",
      "Epoch 3973/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0516 - mae: 0.1768 - val_loss: 3.1723 - val_mae: 1.6322\n",
      "Epoch 3974/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1766 - val_loss: 3.1566 - val_mae: 1.6274\n",
      "Epoch 3975/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1742 - val_loss: 3.0945 - val_mae: 1.6081\n",
      "Epoch 3976/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1867 - val_loss: 3.0782 - val_mae: 1.6030\n",
      "Epoch 3977/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.2036 - val_loss: 3.1243 - val_mae: 1.6173\n",
      "Epoch 3978/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1945 - val_loss: 3.2256 - val_mae: 1.6484\n",
      "Epoch 3979/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.1829 - val_loss: 3.2042 - val_mae: 1.6419\n",
      "Epoch 3980/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1752 - val_loss: 2.9953 - val_mae: 1.5770\n",
      "Epoch 3981/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1961 - val_loss: 2.8333 - val_mae: 1.5247\n",
      "Epoch 3982/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.2117 - val_loss: 2.9075 - val_mae: 1.5489\n",
      "Epoch 3983/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1773 - val_loss: 3.1009 - val_mae: 1.6103\n",
      "Epoch 3984/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1793 - val_loss: 3.0769 - val_mae: 1.6028\n",
      "Epoch 3985/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1843 - val_loss: 2.8528 - val_mae: 1.5312\n",
      "Epoch 3986/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1699 - val_loss: 2.6696 - val_mae: 1.4701\n",
      "Epoch 3987/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1833 - val_loss: 2.6001 - val_mae: 1.4463\n",
      "Epoch 3988/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1846 - val_loss: 2.6252 - val_mae: 1.4549\n",
      "Epoch 3989/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1728 - val_loss: 2.7286 - val_mae: 1.4901\n",
      "Epoch 3990/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1760 - val_loss: 2.7799 - val_mae: 1.5072\n",
      "Epoch 3991/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0559 - mae: 0.1849 - val_loss: 2.6665 - val_mae: 1.4691\n",
      "Epoch 3992/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1720 - val_loss: 2.5145 - val_mae: 1.4163\n",
      "Epoch 3993/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1799 - val_loss: 2.4675 - val_mae: 1.3996\n",
      "Epoch 3994/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0598 - mae: 0.1891 - val_loss: 2.6057 - val_mae: 1.4482\n",
      "Epoch 3995/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0532 - mae: 0.1754 - val_loss: 2.7536 - val_mae: 1.4984\n",
      "Epoch 3996/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1699 - val_loss: 2.7415 - val_mae: 1.4943\n",
      "Epoch 3997/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0499 - mae: 0.1780 - val_loss: 2.6686 - val_mae: 1.4696\n",
      "Epoch 3998/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0785 - mae: 0.2388 - val_loss: 2.7120 - val_mae: 1.4842\n",
      "Epoch 3999/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0876 - mae: 0.2475 - val_loss: 2.9486 - val_mae: 1.5620\n",
      "Epoch 4000/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1977 - val_loss: 3.3017 - val_mae: 1.6713\n",
      "Epoch 4001/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1895 - val_loss: 3.6561 - val_mae: 1.7743\n",
      "Epoch 4002/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1074 - mae: 0.2748 - val_loss: 3.6433 - val_mae: 1.7707\n",
      "Epoch 4003/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0875 - mae: 0.2373 - val_loss: 3.1987 - val_mae: 1.6401\n",
      "Epoch 4004/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0526 - mae: 0.1819 - val_loss: 2.8028 - val_mae: 1.5145\n",
      "Epoch 4005/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0835 - mae: 0.2530 - val_loss: 2.7167 - val_mae: 1.4858\n",
      "Epoch 4006/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0805 - mae: 0.2451 - val_loss: 2.9105 - val_mae: 1.5498\n",
      "Epoch 4007/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1867 - val_loss: 3.1388 - val_mae: 1.6220\n",
      "Epoch 4008/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0734 - mae: 0.2158 - val_loss: 3.1017 - val_mae: 1.6105\n",
      "Epoch 4009/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0686 - mae: 0.2100 - val_loss: 2.7480 - val_mae: 1.4965\n",
      "Epoch 4010/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0539 - mae: 0.1870 - val_loss: 2.4671 - val_mae: 1.3993\n",
      "Epoch 4011/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0803 - mae: 0.2372 - val_loss: 2.4847 - val_mae: 1.4056\n",
      "Epoch 4012/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0739 - mae: 0.2174 - val_loss: 2.6845 - val_mae: 1.4751\n",
      "Epoch 4013/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1986 - val_loss: 2.9425 - val_mae: 1.5603\n",
      "Epoch 4014/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0735 - mae: 0.2240 - val_loss: 2.9613 - val_mae: 1.5664\n",
      "Epoch 4015/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2011 - val_loss: 2.8020 - val_mae: 1.5146\n",
      "Epoch 4016/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1720 - val_loss: 2.6314 - val_mae: 1.4571\n",
      "Epoch 4017/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1991 - val_loss: 2.5742 - val_mae: 1.4373\n",
      "Epoch 4018/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0637 - mae: 0.2105 - val_loss: 2.6715 - val_mae: 1.4708\n",
      "Epoch 4019/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1836 - val_loss: 2.7813 - val_mae: 1.5077\n",
      "Epoch 4020/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1649 - val_loss: 2.8566 - val_mae: 1.5325\n",
      "Epoch 4021/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0504 - mae: 0.1698 - val_loss: 2.7935 - val_mae: 1.5118\n",
      "Epoch 4022/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0477 - mae: 0.1703 - val_loss: 2.7082 - val_mae: 1.4832\n",
      "Epoch 4023/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0514 - mae: 0.1852 - val_loss: 2.7724 - val_mae: 1.5046\n",
      "Epoch 4024/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0501 - mae: 0.1816 - val_loss: 2.9230 - val_mae: 1.5539\n",
      "Epoch 4025/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0459 - mae: 0.1642 - val_loss: 3.1190 - val_mae: 1.6158\n",
      "Epoch 4026/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1682 - val_loss: 3.3135 - val_mae: 1.6750\n",
      "Epoch 4027/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.1965 - val_loss: 3.3329 - val_mae: 1.6807\n",
      "Epoch 4028/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0605 - mae: 0.1818 - val_loss: 3.0942 - val_mae: 1.6080\n",
      "Epoch 4029/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1704 - val_loss: 2.7962 - val_mae: 1.5124\n",
      "Epoch 4030/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0707 - mae: 0.2324 - val_loss: 2.6919 - val_mae: 1.4775\n",
      "Epoch 4031/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0787 - mae: 0.2429 - val_loss: 2.8125 - val_mae: 1.5179\n",
      "Epoch 4032/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1913 - val_loss: 3.0084 - val_mae: 1.5812\n",
      "Epoch 4033/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0502 - mae: 0.1658 - val_loss: 3.0685 - val_mae: 1.6002\n",
      "Epoch 4034/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0594 - mae: 0.1924 - val_loss: 2.9406 - val_mae: 1.5597\n",
      "Epoch 4035/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1773 - val_loss: 2.7133 - val_mae: 1.4849\n",
      "Epoch 4036/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0489 - mae: 0.1731 - val_loss: 2.5486 - val_mae: 1.4283\n",
      "Epoch 4037/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0576 - mae: 0.1968 - val_loss: 2.5589 - val_mae: 1.4320\n",
      "Epoch 4038/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1817 - val_loss: 2.6875 - val_mae: 1.4763\n",
      "Epoch 4039/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0482 - mae: 0.1660 - val_loss: 2.8476 - val_mae: 1.5297\n",
      "Epoch 4040/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0598 - mae: 0.1989 - val_loss: 2.8329 - val_mae: 1.5248\n",
      "Epoch 4041/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1829 - val_loss: 2.6659 - val_mae: 1.4689\n",
      "Epoch 4042/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.1977 - val_loss: 2.5492 - val_mae: 1.4286\n",
      "Epoch 4043/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0783 - mae: 0.2240 - val_loss: 2.6007 - val_mae: 1.4465\n",
      "Epoch 4044/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0761 - mae: 0.2201 - val_loss: 2.7856 - val_mae: 1.5091\n",
      "Epoch 4045/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0652 - mae: 0.2016 - val_loss: 2.9570 - val_mae: 1.5649\n",
      "Epoch 4046/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.1947 - val_loss: 2.9998 - val_mae: 1.5785\n",
      "Epoch 4047/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1827 - val_loss: 2.8833 - val_mae: 1.5411\n",
      "Epoch 4048/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1920 - val_loss: 2.7456 - val_mae: 1.4957\n",
      "Epoch 4049/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.2126 - val_loss: 2.6878 - val_mae: 1.4763\n",
      "Epoch 4050/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.2099 - val_loss: 2.7981 - val_mae: 1.5133\n",
      "Epoch 4051/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0512 - mae: 0.1813 - val_loss: 2.9755 - val_mae: 1.5709\n",
      "Epoch 4052/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1829 - val_loss: 3.0376 - val_mae: 1.5906\n",
      "Epoch 4053/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.1993 - val_loss: 2.9660 - val_mae: 1.5679\n",
      "Epoch 4054/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0550 - mae: 0.1822 - val_loss: 2.7867 - val_mae: 1.5095\n",
      "Epoch 4055/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1803 - val_loss: 2.7144 - val_mae: 1.4853\n",
      "Epoch 4056/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1892 - val_loss: 2.8599 - val_mae: 1.5336\n",
      "Epoch 4057/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1729 - val_loss: 3.1181 - val_mae: 1.6156\n",
      "Epoch 4058/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.1834 - val_loss: 3.2734 - val_mae: 1.6630\n",
      "Epoch 4059/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0734 - mae: 0.2167 - val_loss: 3.1542 - val_mae: 1.6267\n",
      "Epoch 4060/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0577 - mae: 0.1770 - val_loss: 3.0100 - val_mae: 1.5817\n",
      "Epoch 4061/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1770 - val_loss: 2.9401 - val_mae: 1.5593\n",
      "Epoch 4062/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1990 - val_loss: 2.8449 - val_mae: 1.5285\n",
      "Epoch 4063/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0639 - mae: 0.2151 - val_loss: 2.9056 - val_mae: 1.5482\n",
      "Epoch 4064/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0528 - mae: 0.1893 - val_loss: 3.0797 - val_mae: 1.6036\n",
      "Epoch 4065/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1676 - val_loss: 3.1737 - val_mae: 1.6327\n",
      "Epoch 4066/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1699 - val_loss: 3.1544 - val_mae: 1.6267\n",
      "Epoch 4067/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1692 - val_loss: 3.0364 - val_mae: 1.5900\n",
      "Epoch 4068/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1671 - val_loss: 2.9772 - val_mae: 1.5712\n",
      "Epoch 4069/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0466 - mae: 0.1669 - val_loss: 2.9606 - val_mae: 1.5659\n",
      "Epoch 4070/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0456 - mae: 0.1661 - val_loss: 2.8457 - val_mae: 1.5287\n",
      "Epoch 4071/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1819 - val_loss: 2.6940 - val_mae: 1.4782\n",
      "Epoch 4072/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0674 - mae: 0.2163 - val_loss: 2.7217 - val_mae: 1.4876\n",
      "Epoch 4073/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.1984 - val_loss: 2.9068 - val_mae: 1.5486\n",
      "Epoch 4074/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0479 - mae: 0.1778 - val_loss: 3.0827 - val_mae: 1.6045\n",
      "Epoch 4075/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1825 - val_loss: 3.1820 - val_mae: 1.6352\n",
      "Epoch 4076/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0657 - mae: 0.2008 - val_loss: 3.1001 - val_mae: 1.6099\n",
      "Epoch 4077/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1796 - val_loss: 2.8802 - val_mae: 1.5400\n",
      "Epoch 4078/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0498 - mae: 0.1772 - val_loss: 2.7252 - val_mae: 1.4888\n",
      "Epoch 4079/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1972 - val_loss: 2.7078 - val_mae: 1.4830\n",
      "Epoch 4080/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1872 - val_loss: 2.8139 - val_mae: 1.5184\n",
      "Epoch 4081/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1720 - val_loss: 2.9277 - val_mae: 1.5555\n",
      "Epoch 4082/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1869 - val_loss: 2.9254 - val_mae: 1.5547\n",
      "Epoch 4083/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1787 - val_loss: 2.8614 - val_mae: 1.5340\n",
      "Epoch 4084/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1661 - val_loss: 2.8375 - val_mae: 1.5261\n",
      "Epoch 4085/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0488 - mae: 0.1784 - val_loss: 2.8885 - val_mae: 1.5427\n",
      "Epoch 4086/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1843 - val_loss: 2.9511 - val_mae: 1.5629\n",
      "Epoch 4087/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0499 - mae: 0.1814 - val_loss: 3.0349 - val_mae: 1.5895\n",
      "Epoch 4088/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0543 - mae: 0.1791 - val_loss: 3.0263 - val_mae: 1.5867\n",
      "Epoch 4089/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0485 - mae: 0.1661 - val_loss: 2.8961 - val_mae: 1.5450\n",
      "Epoch 4090/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1735 - val_loss: 2.8781 - val_mae: 1.5392\n",
      "Epoch 4091/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1792 - val_loss: 2.9382 - val_mae: 1.5586\n",
      "Epoch 4092/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1683 - val_loss: 2.9750 - val_mae: 1.5704\n",
      "Epoch 4093/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1665 - val_loss: 3.0208 - val_mae: 1.5849\n",
      "Epoch 4094/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1727 - val_loss: 2.9429 - val_mae: 1.5602\n",
      "Epoch 4095/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1667 - val_loss: 2.6635 - val_mae: 1.4679\n",
      "Epoch 4096/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0501 - mae: 0.1762 - val_loss: 2.4655 - val_mae: 1.3989\n",
      "Epoch 4097/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1977 - val_loss: 2.5052 - val_mae: 1.4131\n",
      "Epoch 4098/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1668 - val_loss: 2.7345 - val_mae: 1.4922\n",
      "Epoch 4099/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1994 - val_loss: 2.9371 - val_mae: 1.5587\n",
      "Epoch 4100/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0811 - mae: 0.2438 - val_loss: 2.9088 - val_mae: 1.5495\n",
      "Epoch 4101/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1958 - val_loss: 2.6748 - val_mae: 1.4719\n",
      "Epoch 4102/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0658 - mae: 0.2052 - val_loss: 2.5529 - val_mae: 1.4297\n",
      "Epoch 4103/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0975 - mae: 0.2607 - val_loss: 2.7837 - val_mae: 1.5083\n",
      "Epoch 4104/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0768 - mae: 0.2282 - val_loss: 3.2133 - val_mae: 1.6447\n",
      "Epoch 4105/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0681 - mae: 0.1950 - val_loss: 3.4924 - val_mae: 1.7275\n",
      "Epoch 4106/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0741 - mae: 0.2043 - val_loss: 3.4541 - val_mae: 1.7163\n",
      "Epoch 4107/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.1981 - val_loss: 3.2730 - val_mae: 1.6627\n",
      "Epoch 4108/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0844 - mae: 0.2361 - val_loss: 3.2359 - val_mae: 1.6515\n",
      "Epoch 4109/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0942 - mae: 0.2504 - val_loss: 3.3604 - val_mae: 1.6888\n",
      "Epoch 4110/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0739 - mae: 0.2130 - val_loss: 3.4070 - val_mae: 1.7026\n",
      "Epoch 4111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2007 - val_loss: 3.2791 - val_mae: 1.6647\n",
      "Epoch 4112/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1945 - val_loss: 3.0535 - val_mae: 1.5954\n",
      "Epoch 4113/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0538 - mae: 0.1873 - val_loss: 2.8720 - val_mae: 1.5375\n",
      "Epoch 4114/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1873 - val_loss: 2.7881 - val_mae: 1.5100\n",
      "Epoch 4115/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0514 - mae: 0.1833 - val_loss: 2.7376 - val_mae: 1.4932\n",
      "Epoch 4116/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1826 - val_loss: 2.7545 - val_mae: 1.4989\n",
      "Epoch 4117/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1841 - val_loss: 2.7996 - val_mae: 1.5139\n",
      "Epoch 4118/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1818 - val_loss: 2.7813 - val_mae: 1.5078\n",
      "Epoch 4119/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1783 - val_loss: 2.8204 - val_mae: 1.5207\n",
      "Epoch 4120/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1738 - val_loss: 2.8907 - val_mae: 1.5436\n",
      "Epoch 4121/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1712 - val_loss: 2.8720 - val_mae: 1.5375\n",
      "Epoch 4122/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1742 - val_loss: 2.8004 - val_mae: 1.5140\n",
      "Epoch 4123/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1806 - val_loss: 2.7689 - val_mae: 1.5035\n",
      "Epoch 4124/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1837 - val_loss: 2.8561 - val_mae: 1.5323\n",
      "Epoch 4125/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1752 - val_loss: 3.0585 - val_mae: 1.5971\n",
      "Epoch 4126/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1747 - val_loss: 3.2264 - val_mae: 1.6488\n",
      "Epoch 4127/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.1879 - val_loss: 3.1969 - val_mae: 1.6398\n",
      "Epoch 4128/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1715 - val_loss: 3.1270 - val_mae: 1.6183\n",
      "Epoch 4129/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1679 - val_loss: 3.1436 - val_mae: 1.6233\n",
      "Epoch 4130/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1723 - val_loss: 3.1463 - val_mae: 1.6241\n",
      "Epoch 4131/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0523 - mae: 0.1793 - val_loss: 3.1827 - val_mae: 1.6353\n",
      "Epoch 4132/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1774 - val_loss: 3.2438 - val_mae: 1.6539\n",
      "Epoch 4133/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1712 - val_loss: 3.2077 - val_mae: 1.6429\n",
      "Epoch 4134/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0522 - mae: 0.1725 - val_loss: 3.1638 - val_mae: 1.6295\n",
      "Epoch 4135/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0504 - mae: 0.1708 - val_loss: 3.1696 - val_mae: 1.6313\n",
      "Epoch 4136/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1666 - val_loss: 3.1674 - val_mae: 1.6306\n",
      "Epoch 4137/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1706 - val_loss: 3.2336 - val_mae: 1.6508\n",
      "Epoch 4138/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1703 - val_loss: 3.2289 - val_mae: 1.6493\n",
      "Epoch 4139/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0523 - mae: 0.1742 - val_loss: 3.2027 - val_mae: 1.6414\n",
      "Epoch 4140/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0498 - mae: 0.1690 - val_loss: 3.2789 - val_mae: 1.6645\n",
      "Epoch 4141/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0531 - mae: 0.1661 - val_loss: 3.1266 - val_mae: 1.6180\n",
      "Epoch 4142/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1653 - val_loss: 2.8044 - val_mae: 1.5151\n",
      "Epoch 4143/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0510 - mae: 0.1872 - val_loss: 2.5797 - val_mae: 1.4390\n",
      "Epoch 4144/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0654 - mae: 0.2142 - val_loss: 2.5718 - val_mae: 1.4363\n",
      "Epoch 4145/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0567 - mae: 0.1924 - val_loss: 2.7562 - val_mae: 1.4993\n",
      "Epoch 4146/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1707 - val_loss: 2.9075 - val_mae: 1.5491\n",
      "Epoch 4147/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0608 - mae: 0.2023 - val_loss: 2.9304 - val_mae: 1.5565\n",
      "Epoch 4148/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0603 - mae: 0.2008 - val_loss: 2.8745 - val_mae: 1.5383\n",
      "Epoch 4149/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1747 - val_loss: 2.8586 - val_mae: 1.5330\n",
      "Epoch 4150/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1638 - val_loss: 2.9452 - val_mae: 1.5609\n",
      "Epoch 4151/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1645 - val_loss: 3.0259 - val_mae: 1.5864\n",
      "Epoch 4152/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1715 - val_loss: 3.0069 - val_mae: 1.5804\n",
      "Epoch 4153/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0524 - mae: 0.1874 - val_loss: 2.9020 - val_mae: 1.5468\n",
      "Epoch 4154/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0654 - mae: 0.2184 - val_loss: 2.8836 - val_mae: 1.5408\n",
      "Epoch 4155/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.2144 - val_loss: 3.0730 - val_mae: 1.6012\n",
      "Epoch 4156/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1683 - val_loss: 3.2593 - val_mae: 1.6585\n",
      "Epoch 4157/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1849 - val_loss: 3.2754 - val_mae: 1.6634\n",
      "Epoch 4158/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0649 - mae: 0.1986 - val_loss: 3.1678 - val_mae: 1.6307\n",
      "Epoch 4159/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1758 - val_loss: 3.0518 - val_mae: 1.5947\n",
      "Epoch 4160/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1663 - val_loss: 3.0171 - val_mae: 1.5837\n",
      "Epoch 4161/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1753 - val_loss: 3.0573 - val_mae: 1.5963\n",
      "Epoch 4162/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1815 - val_loss: 3.0157 - val_mae: 1.5832\n",
      "Epoch 4163/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1924 - val_loss: 2.9897 - val_mae: 1.5750\n",
      "Epoch 4164/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0507 - mae: 0.1838 - val_loss: 3.0430 - val_mae: 1.5918\n",
      "Epoch 4165/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1659 - val_loss: 3.0505 - val_mae: 1.5942\n",
      "Epoch 4166/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1638 - val_loss: 2.9890 - val_mae: 1.5748\n",
      "Epoch 4167/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0459 - mae: 0.1617 - val_loss: 2.8745 - val_mae: 1.5380\n",
      "Epoch 4168/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0473 - mae: 0.1726 - val_loss: 2.8408 - val_mae: 1.5269\n",
      "Epoch 4169/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1811 - val_loss: 2.8866 - val_mae: 1.5419\n",
      "Epoch 4170/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0473 - mae: 0.1730 - val_loss: 2.9712 - val_mae: 1.5691\n",
      "Epoch 4171/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0469 - mae: 0.1732 - val_loss: 3.0428 - val_mae: 1.5918\n",
      "Epoch 4172/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1750 - val_loss: 3.0647 - val_mae: 1.5986\n",
      "Epoch 4173/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1707 - val_loss: 3.0165 - val_mae: 1.5834\n",
      "Epoch 4174/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0457 - mae: 0.1650 - val_loss: 2.9212 - val_mae: 1.5531\n",
      "Epoch 4175/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0478 - mae: 0.1740 - val_loss: 2.9071 - val_mae: 1.5485\n",
      "Epoch 4176/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1778 - val_loss: 2.9636 - val_mae: 1.5666\n",
      "Epoch 4177/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1669 - val_loss: 2.9956 - val_mae: 1.5768\n",
      "Epoch 4178/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0457 - mae: 0.1645 - val_loss: 2.9154 - val_mae: 1.5512\n",
      "Epoch 4179/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0473 - mae: 0.1721 - val_loss: 2.8087 - val_mae: 1.5164\n",
      "Epoch 4180/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1799 - val_loss: 2.8688 - val_mae: 1.5361\n",
      "Epoch 4181/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0452 - mae: 0.1670 - val_loss: 3.0864 - val_mae: 1.6055\n",
      "Epoch 4182/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0521 - mae: 0.1770 - val_loss: 3.2873 - val_mae: 1.6669\n",
      "Epoch 4183/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0655 - mae: 0.1984 - val_loss: 3.2791 - val_mae: 1.6643\n",
      "Epoch 4184/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0576 - mae: 0.1765 - val_loss: 3.1059 - val_mae: 1.6114\n",
      "Epoch 4185/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0483 - mae: 0.1702 - val_loss: 2.9674 - val_mae: 1.5677\n",
      "Epoch 4186/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1945 - val_loss: 2.9233 - val_mae: 1.5536\n",
      "Epoch 4187/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.2022 - val_loss: 2.8710 - val_mae: 1.5367\n",
      "Epoch 4188/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.2025 - val_loss: 2.8377 - val_mae: 1.5258\n",
      "Epoch 4189/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1936 - val_loss: 2.8175 - val_mae: 1.5192\n",
      "Epoch 4190/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0482 - mae: 0.1762 - val_loss: 2.7698 - val_mae: 1.5035\n",
      "Epoch 4191/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0471 - mae: 0.1697 - val_loss: 2.7291 - val_mae: 1.4899\n",
      "Epoch 4192/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0471 - mae: 0.1642 - val_loss: 2.6489 - val_mae: 1.4628\n",
      "Epoch 4193/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0501 - mae: 0.1669 - val_loss: 2.6363 - val_mae: 1.4585\n",
      "Epoch 4194/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0507 - mae: 0.1687 - val_loss: 2.7659 - val_mae: 1.5024\n",
      "Epoch 4195/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0558 - mae: 0.1894 - val_loss: 2.8512 - val_mae: 1.5305\n",
      "Epoch 4196/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0553 - mae: 0.1861 - val_loss: 2.8336 - val_mae: 1.5246\n",
      "Epoch 4197/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0482 - mae: 0.1660 - val_loss: 2.8162 - val_mae: 1.5188\n",
      "Epoch 4198/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0488 - mae: 0.1766 - val_loss: 2.8879 - val_mae: 1.5422\n",
      "Epoch 4199/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0507 - mae: 0.1864 - val_loss: 3.0931 - val_mae: 1.6073\n",
      "Epoch 4200/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0479 - mae: 0.1656 - val_loss: 3.2198 - val_mae: 1.6463\n",
      "Epoch 4201/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0495 - mae: 0.1599 - val_loss: 3.2456 - val_mae: 1.6541\n",
      "Epoch 4202/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0522 - mae: 0.1631 - val_loss: 3.1305 - val_mae: 1.6189\n",
      "Epoch 4203/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0455 - mae: 0.1578 - val_loss: 2.8570 - val_mae: 1.5321\n",
      "Epoch 4204/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0593 - mae: 0.2081 - val_loss: 2.7500 - val_mae: 1.4967\n",
      "Epoch 4205/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0609 - mae: 0.2068 - val_loss: 2.9065 - val_mae: 1.5483\n",
      "Epoch 4206/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0483 - mae: 0.1750 - val_loss: 3.0980 - val_mae: 1.6091\n",
      "Epoch 4207/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0674 - mae: 0.2095 - val_loss: 3.1004 - val_mae: 1.6099\n",
      "Epoch 4208/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0655 - mae: 0.2080 - val_loss: 2.9576 - val_mae: 1.5648\n",
      "Epoch 4209/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0529 - mae: 0.1763 - val_loss: 2.7681 - val_mae: 1.5030\n",
      "Epoch 4210/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0548 - mae: 0.1887 - val_loss: 2.5643 - val_mae: 1.4334\n",
      "Epoch 4211/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0762 - mae: 0.2296 - val_loss: 2.4936 - val_mae: 1.4086\n",
      "Epoch 4212/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0807 - mae: 0.2361 - val_loss: 2.6920 - val_mae: 1.4774\n",
      "Epoch 4213/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0555 - mae: 0.1879 - val_loss: 2.9883 - val_mae: 1.5746\n",
      "Epoch 4214/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0635 - mae: 0.2055 - val_loss: 3.1425 - val_mae: 1.6229\n",
      "Epoch 4215/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0876 - mae: 0.2497 - val_loss: 3.0314 - val_mae: 1.5882\n",
      "Epoch 4216/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0485 - mae: 0.1688 - val_loss: 2.8281 - val_mae: 1.5227\n",
      "Epoch 4217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0644 - mae: 0.2166 - val_loss: 2.8025 - val_mae: 1.5142\n",
      "Epoch 4218/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0788 - mae: 0.2368 - val_loss: 2.8842 - val_mae: 1.5410\n",
      "Epoch 4219/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0726 - mae: 0.2177 - val_loss: 2.9953 - val_mae: 1.5767\n",
      "Epoch 4220/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0722 - mae: 0.2079 - val_loss: 3.0539 - val_mae: 1.5952\n",
      "Epoch 4221/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0722 - mae: 0.2066 - val_loss: 3.1081 - val_mae: 1.6121\n",
      "Epoch 4222/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0681 - mae: 0.2006 - val_loss: 3.3428 - val_mae: 1.6833\n",
      "Epoch 4223/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0720 - mae: 0.1973 - val_loss: 3.4854 - val_mae: 1.7252\n",
      "Epoch 4224/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0748 - mae: 0.2063 - val_loss: 3.3619 - val_mae: 1.6890\n",
      "Epoch 4225/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0642 - mae: 0.1923 - val_loss: 3.1563 - val_mae: 1.6270\n",
      "Epoch 4226/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.2044 - val_loss: 2.9580 - val_mae: 1.5649\n",
      "Epoch 4227/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0656 - mae: 0.2113 - val_loss: 2.7881 - val_mae: 1.5097\n",
      "Epoch 4228/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.2050 - val_loss: 2.6828 - val_mae: 1.4745\n",
      "Epoch 4229/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0638 - mae: 0.1995 - val_loss: 2.5945 - val_mae: 1.4443\n",
      "Epoch 4230/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0649 - mae: 0.1983 - val_loss: 2.5793 - val_mae: 1.4390\n",
      "Epoch 4231/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0634 - mae: 0.1997 - val_loss: 2.7151 - val_mae: 1.4855\n",
      "Epoch 4232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1936 - val_loss: 2.8883 - val_mae: 1.5427\n",
      "Epoch 4233/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1887 - val_loss: 3.0401 - val_mae: 1.5912\n",
      "Epoch 4234/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1876 - val_loss: 3.1199 - val_mae: 1.6161\n",
      "Epoch 4235/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1902 - val_loss: 3.1628 - val_mae: 1.6292\n",
      "Epoch 4236/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0616 - mae: 0.1989 - val_loss: 3.2327 - val_mae: 1.6506\n",
      "Epoch 4237/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0629 - mae: 0.1981 - val_loss: 3.3336 - val_mae: 1.6809\n",
      "Epoch 4238/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1942 - val_loss: 3.4771 - val_mae: 1.7232\n",
      "Epoch 4239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0688 - mae: 0.2013 - val_loss: 3.5297 - val_mae: 1.7385\n",
      "Epoch 4240/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0742 - mae: 0.2096 - val_loss: 3.3153 - val_mae: 1.6755\n",
      "Epoch 4241/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0591 - mae: 0.1902 - val_loss: 3.0517 - val_mae: 1.5947\n",
      "Epoch 4242/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0603 - mae: 0.2049 - val_loss: 2.9825 - val_mae: 1.5729\n",
      "Epoch 4243/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.2000 - val_loss: 3.0953 - val_mae: 1.6084\n",
      "Epoch 4244/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0512 - mae: 0.1761 - val_loss: 3.2598 - val_mae: 1.6589\n",
      "Epoch 4245/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1856 - val_loss: 3.2208 - val_mae: 1.6470\n",
      "Epoch 4246/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1732 - val_loss: 3.0346 - val_mae: 1.5893\n",
      "Epoch 4247/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1885 - val_loss: 2.8743 - val_mae: 1.5379\n",
      "Epoch 4248/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0714 - mae: 0.2287 - val_loss: 2.8834 - val_mae: 1.5409\n",
      "Epoch 4249/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0699 - mae: 0.2252 - val_loss: 2.9391 - val_mae: 1.5589\n",
      "Epoch 4250/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1961 - val_loss: 2.9870 - val_mae: 1.5743\n",
      "Epoch 4251/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1729 - val_loss: 3.1097 - val_mae: 1.6130\n",
      "Epoch 4252/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1956 - val_loss: 2.9862 - val_mae: 1.5742\n",
      "Epoch 4253/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1820 - val_loss: 2.7335 - val_mae: 1.4916\n",
      "Epoch 4254/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1964 - val_loss: 2.6363 - val_mae: 1.4585\n",
      "Epoch 4255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2135 - val_loss: 2.7076 - val_mae: 1.4829\n",
      "Epoch 4256/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1895 - val_loss: 2.8919 - val_mae: 1.5440\n",
      "Epoch 4257/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1857 - val_loss: 2.9720 - val_mae: 1.5698\n",
      "Epoch 4258/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0632 - mae: 0.2065 - val_loss: 2.8756 - val_mae: 1.5387\n",
      "Epoch 4259/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1818 - val_loss: 2.7147 - val_mae: 1.4853\n",
      "Epoch 4260/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0497 - mae: 0.1774 - val_loss: 2.5846 - val_mae: 1.4408\n",
      "Epoch 4261/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0664 - mae: 0.2146 - val_loss: 2.6669 - val_mae: 1.4691\n",
      "Epoch 4262/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1835 - val_loss: 2.9537 - val_mae: 1.5639\n",
      "Epoch 4263/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1954 - val_loss: 3.1270 - val_mae: 1.6185\n",
      "Epoch 4264/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0803 - mae: 0.2364 - val_loss: 3.0063 - val_mae: 1.5806\n",
      "Epoch 4265/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1852 - val_loss: 2.6871 - val_mae: 1.4759\n",
      "Epoch 4266/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1961 - val_loss: 2.4654 - val_mae: 1.3986\n",
      "Epoch 4267/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0940 - mae: 0.2606 - val_loss: 2.5037 - val_mae: 1.4123\n",
      "Epoch 4268/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0785 - mae: 0.2330 - val_loss: 2.6772 - val_mae: 1.4726\n",
      "Epoch 4269/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1829 - val_loss: 2.7869 - val_mae: 1.5095\n",
      "Epoch 4270/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1737 - val_loss: 2.7497 - val_mae: 1.4972\n",
      "Epoch 4271/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1775 - val_loss: 2.6726 - val_mae: 1.4712\n",
      "Epoch 4272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1715 - val_loss: 2.5733 - val_mae: 1.4369\n",
      "Epoch 4273/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1742 - val_loss: 2.5387 - val_mae: 1.4248\n",
      "Epoch 4274/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1754 - val_loss: 2.6911 - val_mae: 1.4774\n",
      "Epoch 4275/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1689 - val_loss: 2.8799 - val_mae: 1.5400\n",
      "Epoch 4276/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1930 - val_loss: 2.8766 - val_mae: 1.5389\n",
      "Epoch 4277/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1840 - val_loss: 2.7219 - val_mae: 1.4876\n",
      "Epoch 4278/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1745 - val_loss: 2.5952 - val_mae: 1.4443\n",
      "Epoch 4279/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1929 - val_loss: 2.5568 - val_mae: 1.4310\n",
      "Epoch 4280/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1991 - val_loss: 2.5985 - val_mae: 1.4455\n",
      "Epoch 4281/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1817 - val_loss: 2.6358 - val_mae: 1.4585\n",
      "Epoch 4282/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1677 - val_loss: 2.6225 - val_mae: 1.4539\n",
      "Epoch 4283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1727 - val_loss: 2.6650 - val_mae: 1.4684\n",
      "Epoch 4284/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1788 - val_loss: 2.7625 - val_mae: 1.5013\n",
      "Epoch 4285/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1785 - val_loss: 2.7800 - val_mae: 1.5070\n",
      "Epoch 4286/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1710 - val_loss: 2.7728 - val_mae: 1.5046\n",
      "Epoch 4287/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0467 - mae: 0.1665 - val_loss: 2.7993 - val_mae: 1.5133\n",
      "Epoch 4288/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1665 - val_loss: 2.7862 - val_mae: 1.5090\n",
      "Epoch 4289/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1719 - val_loss: 2.8058 - val_mae: 1.5155\n",
      "Epoch 4290/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1692 - val_loss: 2.9269 - val_mae: 1.5549\n",
      "Epoch 4291/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1725 - val_loss: 3.0750 - val_mae: 1.6019\n",
      "Epoch 4292/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1922 - val_loss: 3.1410 - val_mae: 1.6223\n",
      "Epoch 4293/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0581 - mae: 0.1859 - val_loss: 3.1793 - val_mae: 1.6340\n",
      "Epoch 4294/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1722 - val_loss: 3.1528 - val_mae: 1.6258\n",
      "Epoch 4295/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1637 - val_loss: 3.0653 - val_mae: 1.5987\n",
      "Epoch 4296/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1761 - val_loss: 3.1361 - val_mae: 1.6207\n",
      "Epoch 4297/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0503 - mae: 0.1712 - val_loss: 3.2284 - val_mae: 1.6489\n",
      "Epoch 4298/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1671 - val_loss: 3.1848 - val_mae: 1.6356\n",
      "Epoch 4299/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0506 - mae: 0.1691 - val_loss: 3.1159 - val_mae: 1.6143\n",
      "Epoch 4300/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1739 - val_loss: 3.0365 - val_mae: 1.5895\n",
      "Epoch 4301/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1792 - val_loss: 3.0058 - val_mae: 1.5799\n",
      "Epoch 4302/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1730 - val_loss: 3.0563 - val_mae: 1.5958\n",
      "Epoch 4303/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1812 - val_loss: 3.0985 - val_mae: 1.6090\n",
      "Epoch 4304/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0509 - mae: 0.1723 - val_loss: 2.9733 - val_mae: 1.5696\n",
      "Epoch 4305/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1718 - val_loss: 2.8198 - val_mae: 1.5199\n",
      "Epoch 4306/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0567 - mae: 0.1926 - val_loss: 2.7692 - val_mae: 1.5032\n",
      "Epoch 4307/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.2028 - val_loss: 2.7505 - val_mae: 1.4970\n",
      "Epoch 4308/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0649 - mae: 0.2058 - val_loss: 2.8674 - val_mae: 1.5356\n",
      "Epoch 4309/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0623 - mae: 0.1987 - val_loss: 3.0026 - val_mae: 1.5790\n",
      "Epoch 4310/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0635 - mae: 0.2022 - val_loss: 2.8695 - val_mae: 1.5363\n",
      "Epoch 4311/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0489 - mae: 0.1699 - val_loss: 2.7079 - val_mae: 1.4826\n",
      "Epoch 4312/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0765 - mae: 0.2345 - val_loss: 2.8898 - val_mae: 1.5428\n",
      "Epoch 4313/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0664 - mae: 0.2123 - val_loss: 3.1382 - val_mae: 1.6214\n",
      "Epoch 4314/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0576 - mae: 0.1942 - val_loss: 3.0601 - val_mae: 1.5972\n",
      "Epoch 4315/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1958 - val_loss: 2.8545 - val_mae: 1.5314\n",
      "Epoch 4316/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0481 - mae: 0.1736 - val_loss: 2.6483 - val_mae: 1.4625\n",
      "Epoch 4317/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1766 - val_loss: 2.5864 - val_mae: 1.4412\n",
      "Epoch 4318/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1814 - val_loss: 2.6426 - val_mae: 1.4606\n",
      "Epoch 4319/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0514 - mae: 0.1748 - val_loss: 2.7150 - val_mae: 1.4852\n",
      "Epoch 4320/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1721 - val_loss: 2.8481 - val_mae: 1.5293\n",
      "Epoch 4321/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1697 - val_loss: 2.9486 - val_mae: 1.5618\n",
      "Epoch 4322/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1677 - val_loss: 2.9435 - val_mae: 1.5601\n",
      "Epoch 4323/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1666 - val_loss: 2.9033 - val_mae: 1.5471\n",
      "Epoch 4324/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0475 - mae: 0.1742 - val_loss: 2.9227 - val_mae: 1.5533\n",
      "Epoch 4325/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0477 - mae: 0.1753 - val_loss: 2.9800 - val_mae: 1.5717\n",
      "Epoch 4326/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1687 - val_loss: 3.0138 - val_mae: 1.5824\n",
      "Epoch 4327/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0459 - mae: 0.1670 - val_loss: 2.9221 - val_mae: 1.5531\n",
      "Epoch 4328/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0457 - mae: 0.1692 - val_loss: 2.7224 - val_mae: 1.4875\n",
      "Epoch 4329/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1874 - val_loss: 2.6799 - val_mae: 1.4731\n",
      "Epoch 4330/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0496 - mae: 0.1729 - val_loss: 2.8405 - val_mae: 1.5268\n",
      "Epoch 4331/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1739 - val_loss: 2.9479 - val_mae: 1.5616\n",
      "Epoch 4332/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.1989 - val_loss: 2.8834 - val_mae: 1.5408\n",
      "Epoch 4333/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1799 - val_loss: 2.7209 - val_mae: 1.4870\n",
      "Epoch 4334/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1749 - val_loss: 2.6890 - val_mae: 1.4762\n",
      "Epoch 4335/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1927 - val_loss: 2.8904 - val_mae: 1.5429\n",
      "Epoch 4336/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0456 - mae: 0.1609 - val_loss: 3.1137 - val_mae: 1.6136\n",
      "Epoch 4337/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0548 - mae: 0.1785 - val_loss: 3.0884 - val_mae: 1.6057\n",
      "Epoch 4338/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1632 - val_loss: 2.9104 - val_mae: 1.5492\n",
      "Epoch 4339/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1869 - val_loss: 2.8563 - val_mae: 1.5316\n",
      "Epoch 4340/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0558 - mae: 0.1950 - val_loss: 2.9164 - val_mae: 1.5512\n",
      "Epoch 4341/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1684 - val_loss: 2.9864 - val_mae: 1.5737\n",
      "Epoch 4342/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0467 - mae: 0.1657 - val_loss: 3.0117 - val_mae: 1.5817\n",
      "Epoch 4343/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0509 - mae: 0.1720 - val_loss: 2.9166 - val_mae: 1.5514\n",
      "Epoch 4344/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1672 - val_loss: 2.6747 - val_mae: 1.4713\n",
      "Epoch 4345/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1997 - val_loss: 2.6034 - val_mae: 1.4468\n",
      "Epoch 4346/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0635 - mae: 0.2121 - val_loss: 2.8031 - val_mae: 1.5142\n",
      "Epoch 4347/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1750 - val_loss: 2.9944 - val_mae: 1.5762\n",
      "Epoch 4348/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1668 - val_loss: 3.0690 - val_mae: 1.5996\n",
      "Epoch 4349/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1739 - val_loss: 3.0464 - val_mae: 1.5925\n",
      "Epoch 4350/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1627 - val_loss: 2.8826 - val_mae: 1.5402\n",
      "Epoch 4351/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1722 - val_loss: 2.7628 - val_mae: 1.5007\n",
      "Epoch 4352/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1943 - val_loss: 2.8404 - val_mae: 1.5264\n",
      "Epoch 4353/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0460 - mae: 0.1708 - val_loss: 3.0138 - val_mae: 1.5822\n",
      "Epoch 4354/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1786 - val_loss: 3.1453 - val_mae: 1.6232\n",
      "Epoch 4355/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0678 - mae: 0.2108 - val_loss: 3.1219 - val_mae: 1.6158\n",
      "Epoch 4356/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0615 - mae: 0.1940 - val_loss: 3.0115 - val_mae: 1.5811\n",
      "Epoch 4357/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1739 - val_loss: 2.9413 - val_mae: 1.5585\n",
      "Epoch 4358/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0483 - mae: 0.1746 - val_loss: 2.9167 - val_mae: 1.5504\n",
      "Epoch 4359/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1802 - val_loss: 3.0285 - val_mae: 1.5854\n",
      "Epoch 4360/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1723 - val_loss: 3.3869 - val_mae: 1.6934\n",
      "Epoch 4361/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1764 - val_loss: 3.6085 - val_mae: 1.7572\n",
      "Epoch 4362/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1833 - val_loss: 3.2185 - val_mae: 1.6440\n",
      "Epoch 4363/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1580 - val_loss: 2.8573 - val_mae: 1.5318\n",
      "Epoch 4364/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1817 - val_loss: 2.8077 - val_mae: 1.5158\n",
      "Epoch 4365/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0502 - mae: 0.1812 - val_loss: 2.9516 - val_mae: 1.5626\n",
      "Epoch 4366/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0474 - mae: 0.1638 - val_loss: 3.1237 - val_mae: 1.6168\n",
      "Epoch 4367/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0595 - mae: 0.1946 - val_loss: 3.2155 - val_mae: 1.6450\n",
      "Epoch 4368/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0697 - mae: 0.2139 - val_loss: 3.1240 - val_mae: 1.6169\n",
      "Epoch 4369/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0475 - mae: 0.1608 - val_loss: 2.9109 - val_mae: 1.5495\n",
      "Epoch 4370/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0665 - mae: 0.2233 - val_loss: 2.8625 - val_mae: 1.5337\n",
      "Epoch 4371/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0793 - mae: 0.2387 - val_loss: 3.0375 - val_mae: 1.5898\n",
      "Epoch 4372/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2006 - val_loss: 3.3269 - val_mae: 1.6785\n",
      "Epoch 4373/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0862 - mae: 0.2263 - val_loss: 3.3206 - val_mae: 1.6766\n",
      "Epoch 4374/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0796 - mae: 0.2207 - val_loss: 3.0491 - val_mae: 1.5935\n",
      "Epoch 4375/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0620 - mae: 0.1967 - val_loss: 2.8705 - val_mae: 1.5364\n",
      "Epoch 4376/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0768 - mae: 0.2352 - val_loss: 2.8345 - val_mae: 1.5247\n",
      "Epoch 4377/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0730 - mae: 0.2317 - val_loss: 3.0477 - val_mae: 1.5932\n",
      "Epoch 4378/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1870 - val_loss: 3.2560 - val_mae: 1.6574\n",
      "Epoch 4379/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0668 - mae: 0.2011 - val_loss: 3.1448 - val_mae: 1.6235\n",
      "Epoch 4380/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1884 - val_loss: 2.8675 - val_mae: 1.5357\n",
      "Epoch 4381/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1823 - val_loss: 2.6580 - val_mae: 1.4658\n",
      "Epoch 4382/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2114 - val_loss: 2.5615 - val_mae: 1.4326\n",
      "Epoch 4383/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0727 - mae: 0.2151 - val_loss: 2.6212 - val_mae: 1.4534\n",
      "Epoch 4384/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0614 - mae: 0.1999 - val_loss: 2.6425 - val_mae: 1.4607\n",
      "Epoch 4385/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0585 - mae: 0.1940 - val_loss: 2.5859 - val_mae: 1.4412\n",
      "Epoch 4386/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1849 - val_loss: 2.5364 - val_mae: 1.4238\n",
      "Epoch 4387/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0564 - mae: 0.1826 - val_loss: 2.4832 - val_mae: 1.4050\n",
      "Epoch 4388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1890 - val_loss: 2.5575 - val_mae: 1.4312\n",
      "Epoch 4389/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1817 - val_loss: 2.6786 - val_mae: 1.4730\n",
      "Epoch 4390/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1803 - val_loss: 2.7784 - val_mae: 1.5066\n",
      "Epoch 4391/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1877 - val_loss: 2.9572 - val_mae: 1.5648\n",
      "Epoch 4392/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.2035 - val_loss: 3.0561 - val_mae: 1.5961\n",
      "Epoch 4393/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1895 - val_loss: 2.9665 - val_mae: 1.5676\n",
      "Epoch 4394/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1676 - val_loss: 2.8201 - val_mae: 1.5201\n",
      "Epoch 4395/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0577 - mae: 0.2040 - val_loss: 2.7971 - val_mae: 1.5125\n",
      "Epoch 4396/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.2089 - val_loss: 2.9598 - val_mae: 1.5654\n",
      "Epoch 4397/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0482 - mae: 0.1713 - val_loss: 3.0712 - val_mae: 1.6007\n",
      "Epoch 4398/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1685 - val_loss: 3.0082 - val_mae: 1.5809\n",
      "Epoch 4399/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1715 - val_loss: 2.8015 - val_mae: 1.5141\n",
      "Epoch 4400/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0470 - mae: 0.1698 - val_loss: 2.6026 - val_mae: 1.4469\n",
      "Epoch 4401/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1925 - val_loss: 2.5231 - val_mae: 1.4191\n",
      "Epoch 4402/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2023 - val_loss: 2.5784 - val_mae: 1.4385\n",
      "Epoch 4403/5000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0534 - mae: 0.1807 - val_loss: 2.7520 - val_mae: 1.4978\n",
      "Epoch 4404/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0495 - mae: 0.1720 - val_loss: 2.9172 - val_mae: 1.5521\n",
      "Epoch 4405/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0602 - mae: 0.1990 - val_loss: 2.9914 - val_mae: 1.5757\n",
      "Epoch 4406/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.1984 - val_loss: 2.9287 - val_mae: 1.5555\n",
      "Epoch 4407/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1646 - val_loss: 2.7879 - val_mae: 1.5094\n",
      "Epoch 4408/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0582 - mae: 0.2003 - val_loss: 2.8014 - val_mae: 1.5139\n",
      "Epoch 4409/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0637 - mae: 0.2098 - val_loss: 3.0527 - val_mae: 1.5948\n",
      "Epoch 4410/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0482 - mae: 0.1736 - val_loss: 3.3665 - val_mae: 1.6904\n",
      "Epoch 4411/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0715 - mae: 0.2138 - val_loss: 3.4480 - val_mae: 1.7144\n",
      "Epoch 4412/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0790 - mae: 0.2260 - val_loss: 3.2364 - val_mae: 1.6515\n",
      "Epoch 4413/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1669 - val_loss: 2.9218 - val_mae: 1.5532\n",
      "Epoch 4414/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1962 - val_loss: 2.7217 - val_mae: 1.4873\n",
      "Epoch 4415/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.2253 - val_loss: 2.6829 - val_mae: 1.4743\n",
      "Epoch 4416/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1998 - val_loss: 2.7036 - val_mae: 1.4815\n",
      "Epoch 4417/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0537 - mae: 0.1864 - val_loss: 2.7477 - val_mae: 1.4964\n",
      "Epoch 4418/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0554 - mae: 0.1857 - val_loss: 2.7136 - val_mae: 1.4849\n",
      "Epoch 4419/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1795 - val_loss: 2.6141 - val_mae: 1.4509\n",
      "Epoch 4420/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1692 - val_loss: 2.5326 - val_mae: 1.4225\n",
      "Epoch 4421/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0550 - mae: 0.1778 - val_loss: 2.5916 - val_mae: 1.4430\n",
      "Epoch 4422/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1807 - val_loss: 2.7596 - val_mae: 1.5002\n",
      "Epoch 4423/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1800 - val_loss: 2.8297 - val_mae: 1.5233\n",
      "Epoch 4424/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0474 - mae: 0.1723 - val_loss: 2.7985 - val_mae: 1.5130\n",
      "Epoch 4425/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0473 - mae: 0.1708 - val_loss: 2.8070 - val_mae: 1.5158\n",
      "Epoch 4426/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1756 - val_loss: 2.8751 - val_mae: 1.5381\n",
      "Epoch 4427/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0473 - mae: 0.1696 - val_loss: 2.9814 - val_mae: 1.5723\n",
      "Epoch 4428/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1713 - val_loss: 3.0557 - val_mae: 1.5958\n",
      "Epoch 4429/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1724 - val_loss: 2.9708 - val_mae: 1.5689\n",
      "Epoch 4430/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1671 - val_loss: 2.8330 - val_mae: 1.5243\n",
      "Epoch 4431/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1802 - val_loss: 2.7652 - val_mae: 1.5019\n",
      "Epoch 4432/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1875 - val_loss: 2.8658 - val_mae: 1.5351\n",
      "Epoch 4433/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0458 - mae: 0.1661 - val_loss: 3.0161 - val_mae: 1.5834\n",
      "Epoch 4434/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.2036 - val_loss: 3.0298 - val_mae: 1.5878\n",
      "Epoch 4435/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0721 - mae: 0.2241 - val_loss: 2.9356 - val_mae: 1.5578\n",
      "Epoch 4436/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.1954 - val_loss: 2.7222 - val_mae: 1.4876\n",
      "Epoch 4437/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1661 - val_loss: 2.5053 - val_mae: 1.4127\n",
      "Epoch 4438/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.2085 - val_loss: 2.4936 - val_mae: 1.4086\n",
      "Epoch 4439/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.2009 - val_loss: 2.6585 - val_mae: 1.4661\n",
      "Epoch 4440/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1742 - val_loss: 2.8538 - val_mae: 1.5313\n",
      "Epoch 4441/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.1984 - val_loss: 2.9919 - val_mae: 1.5758\n",
      "Epoch 4442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0686 - mae: 0.2156 - val_loss: 2.9830 - val_mae: 1.5729\n",
      "Epoch 4443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1767 - val_loss: 2.8562 - val_mae: 1.5319\n",
      "Epoch 4444/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1678 - val_loss: 2.7696 - val_mae: 1.5033\n",
      "Epoch 4445/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.2041 - val_loss: 2.8545 - val_mae: 1.5313\n",
      "Epoch 4446/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0544 - mae: 0.1949 - val_loss: 2.9879 - val_mae: 1.5743\n",
      "Epoch 4447/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1662 - val_loss: 3.0494 - val_mae: 1.5938\n",
      "Epoch 4448/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0459 - mae: 0.1616 - val_loss: 3.0601 - val_mae: 1.5971\n",
      "Epoch 4449/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0468 - mae: 0.1593 - val_loss: 2.8819 - val_mae: 1.5403\n",
      "Epoch 4450/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0449 - mae: 0.1659 - val_loss: 2.5886 - val_mae: 1.4418\n",
      "Epoch 4451/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0781 - mae: 0.2409 - val_loss: 2.5622 - val_mae: 1.4326\n",
      "Epoch 4452/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0772 - mae: 0.2403 - val_loss: 2.8498 - val_mae: 1.5298\n",
      "Epoch 4453/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0469 - mae: 0.1696 - val_loss: 3.1117 - val_mae: 1.6132\n",
      "Epoch 4454/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1834 - val_loss: 3.1345 - val_mae: 1.6203\n",
      "Epoch 4455/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.1961 - val_loss: 2.9867 - val_mae: 1.5740\n",
      "Epoch 4456/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1662 - val_loss: 2.8067 - val_mae: 1.5156\n",
      "Epoch 4457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0457 - mae: 0.1640 - val_loss: 2.6409 - val_mae: 1.4599\n",
      "Epoch 4458/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1947 - val_loss: 2.5801 - val_mae: 1.4389\n",
      "Epoch 4459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1930 - val_loss: 2.6809 - val_mae: 1.4735\n",
      "Epoch 4460/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1774 - val_loss: 2.8871 - val_mae: 1.5420\n",
      "Epoch 4461/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.1892 - val_loss: 3.0554 - val_mae: 1.5957\n",
      "Epoch 4462/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0654 - mae: 0.2108 - val_loss: 3.0353 - val_mae: 1.5893\n",
      "Epoch 4463/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1756 - val_loss: 2.9061 - val_mae: 1.5481\n",
      "Epoch 4464/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1789 - val_loss: 2.8667 - val_mae: 1.5353\n",
      "Epoch 4465/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1991 - val_loss: 2.9481 - val_mae: 1.5616\n",
      "Epoch 4466/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1921 - val_loss: 3.1114 - val_mae: 1.6131\n",
      "Epoch 4467/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0540 - mae: 0.1792 - val_loss: 3.2243 - val_mae: 1.6477\n",
      "Epoch 4468/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1762 - val_loss: 3.2670 - val_mae: 1.6606\n",
      "Epoch 4469/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1790 - val_loss: 3.2873 - val_mae: 1.6667\n",
      "Epoch 4470/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1798 - val_loss: 3.2643 - val_mae: 1.6598\n",
      "Epoch 4471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1785 - val_loss: 3.2814 - val_mae: 1.6650\n",
      "Epoch 4472/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1763 - val_loss: 3.2288 - val_mae: 1.6491\n",
      "Epoch 4473/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1775 - val_loss: 3.1318 - val_mae: 1.6194\n",
      "Epoch 4474/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0498 - mae: 0.1747 - val_loss: 3.0964 - val_mae: 1.6084\n",
      "Epoch 4475/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0485 - mae: 0.1729 - val_loss: 2.9538 - val_mae: 1.5635\n",
      "Epoch 4476/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0516 - mae: 0.1839 - val_loss: 2.8361 - val_mae: 1.5253\n",
      "Epoch 4477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1956 - val_loss: 2.8875 - val_mae: 1.5421\n",
      "Epoch 4478/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1861 - val_loss: 2.9623 - val_mae: 1.5662\n",
      "Epoch 4479/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1733 - val_loss: 2.9487 - val_mae: 1.5619\n",
      "Epoch 4480/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1665 - val_loss: 2.8759 - val_mae: 1.5384\n",
      "Epoch 4481/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0466 - mae: 0.1635 - val_loss: 2.8657 - val_mae: 1.5350\n",
      "Epoch 4482/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1631 - val_loss: 2.8980 - val_mae: 1.5456\n",
      "Epoch 4483/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0492 - mae: 0.1665 - val_loss: 2.8555 - val_mae: 1.5317\n",
      "Epoch 4484/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0455 - mae: 0.1611 - val_loss: 2.7391 - val_mae: 1.4932\n",
      "Epoch 4485/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0473 - mae: 0.1699 - val_loss: 2.6085 - val_mae: 1.4487\n",
      "Epoch 4486/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1998 - val_loss: 2.6289 - val_mae: 1.4558\n",
      "Epoch 4487/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1827 - val_loss: 2.7935 - val_mae: 1.5113\n",
      "Epoch 4488/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1634 - val_loss: 2.9325 - val_mae: 1.5567\n",
      "Epoch 4489/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0515 - mae: 0.1768 - val_loss: 3.0496 - val_mae: 1.5938\n",
      "Epoch 4490/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1874 - val_loss: 3.0338 - val_mae: 1.5888\n",
      "Epoch 4491/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1614 - val_loss: 2.8971 - val_mae: 1.5452\n",
      "Epoch 4492/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1609 - val_loss: 2.8018 - val_mae: 1.5139\n",
      "Epoch 4493/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.2026 - val_loss: 2.8465 - val_mae: 1.5286\n",
      "Epoch 4494/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0542 - mae: 0.1962 - val_loss: 3.0011 - val_mae: 1.5784\n",
      "Epoch 4495/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0450 - mae: 0.1593 - val_loss: 3.1340 - val_mae: 1.6200\n",
      "Epoch 4496/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0530 - mae: 0.1679 - val_loss: 3.1677 - val_mae: 1.6304\n",
      "Epoch 4497/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1815 - val_loss: 3.0701 - val_mae: 1.6002\n",
      "Epoch 4498/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1652 - val_loss: 2.9427 - val_mae: 1.5598\n",
      "Epoch 4499/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0444 - mae: 0.1555 - val_loss: 2.7688 - val_mae: 1.5030\n",
      "Epoch 4500/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1864 - val_loss: 2.6107 - val_mae: 1.4494\n",
      "Epoch 4501/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0650 - mae: 0.2192 - val_loss: 2.6113 - val_mae: 1.4496\n",
      "Epoch 4502/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2074 - val_loss: 2.8698 - val_mae: 1.5363\n",
      "Epoch 4503/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1660 - val_loss: 3.1867 - val_mae: 1.6362\n",
      "Epoch 4504/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0590 - mae: 0.1855 - val_loss: 3.2557 - val_mae: 1.6571\n",
      "Epoch 4505/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1717 - val_loss: 3.1730 - val_mae: 1.6319\n",
      "Epoch 4506/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1691 - val_loss: 3.0749 - val_mae: 1.6015\n",
      "Epoch 4507/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.2078 - val_loss: 3.0365 - val_mae: 1.5894\n",
      "Epoch 4508/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0616 - mae: 0.2101 - val_loss: 3.0099 - val_mae: 1.5811\n",
      "Epoch 4509/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0557 - mae: 0.1896 - val_loss: 3.0268 - val_mae: 1.5865\n",
      "Epoch 4510/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1820 - val_loss: 3.1055 - val_mae: 1.6113\n",
      "Epoch 4511/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0724 - mae: 0.2137 - val_loss: 3.0643 - val_mae: 1.5985\n",
      "Epoch 4512/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0770 - mae: 0.2235 - val_loss: 2.8861 - val_mae: 1.5417\n",
      "Epoch 4513/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1927 - val_loss: 2.6969 - val_mae: 1.4790\n",
      "Epoch 4514/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1658 - val_loss: 2.5482 - val_mae: 1.4278\n",
      "Epoch 4515/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1919 - val_loss: 2.4954 - val_mae: 1.4092\n",
      "Epoch 4516/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0626 - mae: 0.2008 - val_loss: 2.5716 - val_mae: 1.4360\n",
      "Epoch 4517/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1776 - val_loss: 2.7182 - val_mae: 1.4862\n",
      "Epoch 4518/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1638 - val_loss: 2.8495 - val_mae: 1.5297\n",
      "Epoch 4519/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1649 - val_loss: 2.9647 - val_mae: 1.5669\n",
      "Epoch 4520/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1730 - val_loss: 3.0651 - val_mae: 1.5986\n",
      "Epoch 4521/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1733 - val_loss: 3.0544 - val_mae: 1.5952\n",
      "Epoch 4522/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1670 - val_loss: 3.0599 - val_mae: 1.5969\n",
      "Epoch 4523/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1641 - val_loss: 3.1221 - val_mae: 1.6161\n",
      "Epoch 4524/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1645 - val_loss: 3.1040 - val_mae: 1.6105\n",
      "Epoch 4525/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1642 - val_loss: 3.0370 - val_mae: 1.5896\n",
      "Epoch 4526/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0454 - mae: 0.1651 - val_loss: 2.9645 - val_mae: 1.5668\n",
      "Epoch 4527/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0453 - mae: 0.1672 - val_loss: 2.9117 - val_mae: 1.5499\n",
      "Epoch 4528/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1686 - val_loss: 2.8278 - val_mae: 1.5226\n",
      "Epoch 4529/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1656 - val_loss: 2.7948 - val_mae: 1.5117\n",
      "Epoch 4530/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1628 - val_loss: 2.8336 - val_mae: 1.5245\n",
      "Epoch 4531/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1633 - val_loss: 2.8856 - val_mae: 1.5415\n",
      "Epoch 4532/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1699 - val_loss: 2.9740 - val_mae: 1.5699\n",
      "Epoch 4533/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1784 - val_loss: 2.9835 - val_mae: 1.5729\n",
      "Epoch 4534/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0472 - mae: 0.1613 - val_loss: 2.9193 - val_mae: 1.5522\n",
      "Epoch 4535/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0463 - mae: 0.1690 - val_loss: 2.9354 - val_mae: 1.5573\n",
      "Epoch 4536/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0518 - mae: 0.1870 - val_loss: 3.0005 - val_mae: 1.5781\n",
      "Epoch 4537/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1857 - val_loss: 3.1123 - val_mae: 1.6131\n",
      "Epoch 4538/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1659 - val_loss: 3.2078 - val_mae: 1.6425\n",
      "Epoch 4539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1576 - val_loss: 3.1423 - val_mae: 1.6224\n",
      "Epoch 4540/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1601 - val_loss: 3.0607 - val_mae: 1.5971\n",
      "Epoch 4541/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0465 - mae: 0.1589 - val_loss: 2.9497 - val_mae: 1.5619\n",
      "Epoch 4542/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0466 - mae: 0.1710 - val_loss: 2.7902 - val_mae: 1.5100\n",
      "Epoch 4543/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.2023 - val_loss: 2.7962 - val_mae: 1.5119\n",
      "Epoch 4544/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1862 - val_loss: 2.9409 - val_mae: 1.5591\n",
      "Epoch 4545/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1675 - val_loss: 3.1020 - val_mae: 1.6100\n",
      "Epoch 4546/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0538 - mae: 0.1799 - val_loss: 3.1149 - val_mae: 1.6140\n",
      "Epoch 4547/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0516 - mae: 0.1729 - val_loss: 3.0141 - val_mae: 1.5824\n",
      "Epoch 4548/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1599 - val_loss: 2.9430 - val_mae: 1.5598\n",
      "Epoch 4549/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1634 - val_loss: 3.0018 - val_mae: 1.5785\n",
      "Epoch 4550/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1616 - val_loss: 3.1077 - val_mae: 1.6116\n",
      "Epoch 4551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0458 - mae: 0.1592 - val_loss: 3.1201 - val_mae: 1.6154\n",
      "Epoch 4552/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0458 - mae: 0.1587 - val_loss: 3.0261 - val_mae: 1.5861\n",
      "Epoch 4553/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0448 - mae: 0.1630 - val_loss: 2.9073 - val_mae: 1.5481\n",
      "Epoch 4554/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1836 - val_loss: 2.8536 - val_mae: 1.5306\n",
      "Epoch 4555/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0555 - mae: 0.1942 - val_loss: 2.8975 - val_mae: 1.5449\n",
      "Epoch 4556/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1780 - val_loss: 3.0346 - val_mae: 1.5886\n",
      "Epoch 4557/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0466 - mae: 0.1734 - val_loss: 3.1753 - val_mae: 1.6320\n",
      "Epoch 4558/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1789 - val_loss: 3.1600 - val_mae: 1.6273\n",
      "Epoch 4559/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1645 - val_loss: 2.9872 - val_mae: 1.5734\n",
      "Epoch 4560/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0466 - mae: 0.1727 - val_loss: 2.9213 - val_mae: 1.5524\n",
      "Epoch 4561/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1794 - val_loss: 2.9870 - val_mae: 1.5734\n",
      "Epoch 4562/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1636 - val_loss: 3.0946 - val_mae: 1.6070\n",
      "Epoch 4563/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0467 - mae: 0.1588 - val_loss: 3.1748 - val_mae: 1.6314\n",
      "Epoch 4564/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0502 - mae: 0.1656 - val_loss: 3.1910 - val_mae: 1.6357\n",
      "Epoch 4565/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0468 - mae: 0.1572 - val_loss: 2.9405 - val_mae: 1.5578\n",
      "Epoch 4566/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0450 - mae: 0.1696 - val_loss: 2.6786 - val_mae: 1.4721\n",
      "Epoch 4567/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0660 - mae: 0.2197 - val_loss: 2.6976 - val_mae: 1.4787\n",
      "Epoch 4568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1928 - val_loss: 2.9890 - val_mae: 1.5742\n",
      "Epoch 4569/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1711 - val_loss: 3.1383 - val_mae: 1.6210\n",
      "Epoch 4570/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1848 - val_loss: 2.9310 - val_mae: 1.5557\n",
      "Epoch 4571/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0445 - mae: 0.1615 - val_loss: 2.7699 - val_mae: 1.5031\n",
      "Epoch 4572/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1986 - val_loss: 2.7643 - val_mae: 1.5012\n",
      "Epoch 4573/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0536 - mae: 0.1946 - val_loss: 2.8470 - val_mae: 1.5286\n",
      "Epoch 4574/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0452 - mae: 0.1668 - val_loss: 2.9314 - val_mae: 1.5560\n",
      "Epoch 4575/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1830 - val_loss: 2.9788 - val_mae: 1.5712\n",
      "Epoch 4576/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0545 - mae: 0.1828 - val_loss: 2.8823 - val_mae: 1.5402\n",
      "Epoch 4577/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1612 - val_loss: 2.6680 - val_mae: 1.4689\n",
      "Epoch 4578/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1877 - val_loss: 2.5790 - val_mae: 1.4383\n",
      "Epoch 4579/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1967 - val_loss: 2.6836 - val_mae: 1.4743\n",
      "Epoch 4580/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1655 - val_loss: 2.9044 - val_mae: 1.5474\n",
      "Epoch 4581/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1808 - val_loss: 3.0044 - val_mae: 1.5794\n",
      "Epoch 4582/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0578 - mae: 0.1929 - val_loss: 2.9033 - val_mae: 1.5470\n",
      "Epoch 4583/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0460 - mae: 0.1621 - val_loss: 2.8107 - val_mae: 1.5167\n",
      "Epoch 4584/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1836 - val_loss: 2.8347 - val_mae: 1.5246\n",
      "Epoch 4585/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1934 - val_loss: 2.9070 - val_mae: 1.5481\n",
      "Epoch 4586/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1878 - val_loss: 2.9803 - val_mae: 1.5716\n",
      "Epoch 4587/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0492 - mae: 0.1749 - val_loss: 3.1004 - val_mae: 1.6094\n",
      "Epoch 4588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1650 - val_loss: 3.1913 - val_mae: 1.6374\n",
      "Epoch 4589/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1584 - val_loss: 3.1681 - val_mae: 1.6302\n",
      "Epoch 4590/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0486 - mae: 0.1695 - val_loss: 3.1627 - val_mae: 1.6285\n",
      "Epoch 4591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1772 - val_loss: 3.1719 - val_mae: 1.6314\n",
      "Epoch 4592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1714 - val_loss: 3.1076 - val_mae: 1.6116\n",
      "Epoch 4593/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1630 - val_loss: 2.9708 - val_mae: 1.5686\n",
      "Epoch 4594/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0439 - mae: 0.1588 - val_loss: 2.8298 - val_mae: 1.5231\n",
      "Epoch 4595/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0445 - mae: 0.1588 - val_loss: 2.7562 - val_mae: 1.4987\n",
      "Epoch 4596/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0460 - mae: 0.1621 - val_loss: 2.6822 - val_mae: 1.4739\n",
      "Epoch 4597/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0473 - mae: 0.1626 - val_loss: 2.5538 - val_mae: 1.4297\n",
      "Epoch 4598/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1662 - val_loss: 2.4644 - val_mae: 1.3980\n",
      "Epoch 4599/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1727 - val_loss: 2.4924 - val_mae: 1.4081\n",
      "Epoch 4600/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1737 - val_loss: 2.6274 - val_mae: 1.4553\n",
      "Epoch 4601/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1764 - val_loss: 2.8722 - val_mae: 1.5371\n",
      "Epoch 4602/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1909 - val_loss: 3.1005 - val_mae: 1.6096\n",
      "Epoch 4603/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0625 - mae: 0.1922 - val_loss: 3.2043 - val_mae: 1.6414\n",
      "Epoch 4604/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0559 - mae: 0.1706 - val_loss: 3.2162 - val_mae: 1.6449\n",
      "Epoch 4605/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0522 - mae: 0.1678 - val_loss: 3.2759 - val_mae: 1.6629\n",
      "Epoch 4606/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1877 - val_loss: 3.4895 - val_mae: 1.7259\n",
      "Epoch 4607/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0629 - mae: 0.1841 - val_loss: 3.5634 - val_mae: 1.7472\n",
      "Epoch 4608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0645 - mae: 0.1810 - val_loss: 3.4076 - val_mae: 1.7021\n",
      "Epoch 4609/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1675 - val_loss: 3.1633 - val_mae: 1.6288\n",
      "Epoch 4610/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0484 - mae: 0.1675 - val_loss: 2.9263 - val_mae: 1.5544\n",
      "Epoch 4611/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1746 - val_loss: 2.8057 - val_mae: 1.5151\n",
      "Epoch 4612/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1806 - val_loss: 2.8180 - val_mae: 1.5192\n",
      "Epoch 4613/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0699 - mae: 0.2094 - val_loss: 2.7588 - val_mae: 1.4996\n",
      "Epoch 4614/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0504 - mae: 0.1795 - val_loss: 2.7079 - val_mae: 1.4825\n",
      "Epoch 4615/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0738 - mae: 0.2168 - val_loss: 2.8180 - val_mae: 1.5192\n",
      "Epoch 4616/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0796 - mae: 0.2234 - val_loss: 2.9349 - val_mae: 1.5572\n",
      "Epoch 4617/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0795 - mae: 0.2217 - val_loss: 3.1234 - val_mae: 1.6166\n",
      "Epoch 4618/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0774 - mae: 0.2169 - val_loss: 3.4289 - val_mae: 1.7085\n",
      "Epoch 4619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0855 - mae: 0.2259 - val_loss: 3.5974 - val_mae: 1.7571\n",
      "Epoch 4620/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0832 - mae: 0.2164 - val_loss: 3.4808 - val_mae: 1.7236\n",
      "Epoch 4621/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0766 - mae: 0.2172 - val_loss: 3.3717 - val_mae: 1.6916\n",
      "Epoch 4622/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0787 - mae: 0.2248 - val_loss: 3.4254 - val_mae: 1.7075\n",
      "Epoch 4623/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0714 - mae: 0.2043 - val_loss: 3.4008 - val_mae: 1.7003\n",
      "Epoch 4624/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0703 - mae: 0.1976 - val_loss: 3.2392 - val_mae: 1.6522\n",
      "Epoch 4625/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0700 - mae: 0.1993 - val_loss: 3.0889 - val_mae: 1.6061\n",
      "Epoch 4626/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0665 - mae: 0.1980 - val_loss: 2.9009 - val_mae: 1.5464\n",
      "Epoch 4627/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0667 - mae: 0.2047 - val_loss: 2.8058 - val_mae: 1.5153\n",
      "Epoch 4628/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0691 - mae: 0.2131 - val_loss: 2.8908 - val_mae: 1.5431\n",
      "Epoch 4629/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.2056 - val_loss: 3.0460 - val_mae: 1.5926\n",
      "Epoch 4630/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0616 - mae: 0.1984 - val_loss: 3.1376 - val_mae: 1.6212\n",
      "Epoch 4631/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1941 - val_loss: 3.1318 - val_mae: 1.6194\n",
      "Epoch 4632/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0608 - mae: 0.1981 - val_loss: 3.1240 - val_mae: 1.6170\n",
      "Epoch 4633/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1986 - val_loss: 3.1009 - val_mae: 1.6098\n",
      "Epoch 4634/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0601 - mae: 0.1973 - val_loss: 3.0946 - val_mae: 1.6078\n",
      "Epoch 4635/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1982 - val_loss: 3.1828 - val_mae: 1.6351\n",
      "Epoch 4636/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1857 - val_loss: 3.2739 - val_mae: 1.6628\n",
      "Epoch 4637/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0690 - mae: 0.2049 - val_loss: 3.2667 - val_mae: 1.6607\n",
      "Epoch 4638/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0771 - mae: 0.2208 - val_loss: 3.1748 - val_mae: 1.6328\n",
      "Epoch 4639/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0657 - mae: 0.2000 - val_loss: 3.0066 - val_mae: 1.5803\n",
      "Epoch 4640/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1895 - val_loss: 2.8967 - val_mae: 1.5451\n",
      "Epoch 4641/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0579 - mae: 0.1965 - val_loss: 2.8759 - val_mae: 1.5384\n",
      "Epoch 4642/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0579 - mae: 0.1965 - val_loss: 2.8710 - val_mae: 1.5368\n",
      "Epoch 4643/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1990 - val_loss: 2.9290 - val_mae: 1.5556\n",
      "Epoch 4644/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1898 - val_loss: 2.9718 - val_mae: 1.5693\n",
      "Epoch 4645/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1840 - val_loss: 2.9418 - val_mae: 1.5597\n",
      "Epoch 4646/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1849 - val_loss: 2.9019 - val_mae: 1.5468\n",
      "Epoch 4647/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1860 - val_loss: 2.8612 - val_mae: 1.5336\n",
      "Epoch 4648/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0538 - mae: 0.1864 - val_loss: 2.9468 - val_mae: 1.5613\n",
      "Epoch 4649/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0539 - mae: 0.1846 - val_loss: 3.0642 - val_mae: 1.5985\n",
      "Epoch 4650/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1837 - val_loss: 2.9814 - val_mae: 1.5723\n",
      "Epoch 4651/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1856 - val_loss: 2.8912 - val_mae: 1.5433\n",
      "Epoch 4652/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1945 - val_loss: 2.9551 - val_mae: 1.5639\n",
      "Epoch 4653/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1789 - val_loss: 3.0887 - val_mae: 1.6062\n",
      "Epoch 4654/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1875 - val_loss: 3.0874 - val_mae: 1.6058\n",
      "Epoch 4655/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0627 - mae: 0.1974 - val_loss: 2.9555 - val_mae: 1.5641\n",
      "Epoch 4656/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1796 - val_loss: 2.7514 - val_mae: 1.4974\n",
      "Epoch 4657/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1911 - val_loss: 2.6025 - val_mae: 1.4468\n",
      "Epoch 4658/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2105 - val_loss: 2.5986 - val_mae: 1.4455\n",
      "Epoch 4659/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0580 - mae: 0.1923 - val_loss: 2.7104 - val_mae: 1.4838\n",
      "Epoch 4660/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0563 - mae: 0.1892 - val_loss: 2.8797 - val_mae: 1.5399\n",
      "Epoch 4661/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0672 - mae: 0.2136 - val_loss: 2.9533 - val_mae: 1.5636\n",
      "Epoch 4662/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0622 - mae: 0.1997 - val_loss: 2.9707 - val_mae: 1.5690\n",
      "Epoch 4663/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0537 - mae: 0.1804 - val_loss: 3.0520 - val_mae: 1.5947\n",
      "Epoch 4664/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0509 - mae: 0.1721 - val_loss: 3.2572 - val_mae: 1.6577\n",
      "Epoch 4665/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1707 - val_loss: 3.4258 - val_mae: 1.7077\n",
      "Epoch 4666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1813 - val_loss: 3.4552 - val_mae: 1.7162\n",
      "Epoch 4667/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.2096 - val_loss: 3.4713 - val_mae: 1.7207\n",
      "Epoch 4668/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0784 - mae: 0.2310 - val_loss: 3.5832 - val_mae: 1.7530\n",
      "Epoch 4669/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0752 - mae: 0.2208 - val_loss: 3.6023 - val_mae: 1.7585\n",
      "Epoch 4670/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0695 - mae: 0.1997 - val_loss: 3.2597 - val_mae: 1.6583\n",
      "Epoch 4671/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1864 - val_loss: 2.8272 - val_mae: 1.5224\n",
      "Epoch 4672/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0638 - mae: 0.2132 - val_loss: 2.6512 - val_mae: 1.4636\n",
      "Epoch 4673/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0613 - mae: 0.2058 - val_loss: 2.6000 - val_mae: 1.4464\n",
      "Epoch 4674/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1885 - val_loss: 2.4834 - val_mae: 1.4058\n",
      "Epoch 4675/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0622 - mae: 0.1937 - val_loss: 2.3199 - val_mae: 1.3463\n",
      "Epoch 4676/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0768 - mae: 0.2183 - val_loss: 2.2855 - val_mae: 1.3334\n",
      "Epoch 4677/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0805 - mae: 0.2237 - val_loss: 2.4718 - val_mae: 1.4017\n",
      "Epoch 4678/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0606 - mae: 0.1931 - val_loss: 2.6831 - val_mae: 1.4754\n",
      "Epoch 4679/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2081 - val_loss: 2.7344 - val_mae: 1.4924\n",
      "Epoch 4680/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1974 - val_loss: 2.6423 - val_mae: 1.4608\n",
      "Epoch 4681/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0549 - mae: 0.1911 - val_loss: 2.6431 - val_mae: 1.4609\n",
      "Epoch 4682/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0601 - mae: 0.2027 - val_loss: 2.8237 - val_mae: 1.5215\n",
      "Epoch 4683/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1871 - val_loss: 2.9766 - val_mae: 1.5709\n",
      "Epoch 4684/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1778 - val_loss: 3.1772 - val_mae: 1.6336\n",
      "Epoch 4685/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1753 - val_loss: 3.3608 - val_mae: 1.6888\n",
      "Epoch 4686/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0630 - mae: 0.1905 - val_loss: 3.4223 - val_mae: 1.7069\n",
      "Epoch 4687/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.1883 - val_loss: 3.4131 - val_mae: 1.7041\n",
      "Epoch 4688/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.1876 - val_loss: 3.3448 - val_mae: 1.6839\n",
      "Epoch 4689/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0656 - mae: 0.2020 - val_loss: 3.3200 - val_mae: 1.6765\n",
      "Epoch 4690/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0665 - mae: 0.2044 - val_loss: 3.2104 - val_mae: 1.6435\n",
      "Epoch 4691/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0644 - mae: 0.2045 - val_loss: 3.0569 - val_mae: 1.5961\n",
      "Epoch 4692/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0622 - mae: 0.2063 - val_loss: 2.9601 - val_mae: 1.5656\n",
      "Epoch 4693/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0559 - mae: 0.1897 - val_loss: 2.8981 - val_mae: 1.5459\n",
      "Epoch 4694/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0529 - mae: 0.1814 - val_loss: 2.9349 - val_mae: 1.5581\n",
      "Epoch 4695/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.2004 - val_loss: 2.9852 - val_mae: 1.5742\n",
      "Epoch 4696/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0683 - mae: 0.2149 - val_loss: 2.9131 - val_mae: 1.5508\n",
      "Epoch 4697/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0538 - mae: 0.1826 - val_loss: 2.8649 - val_mae: 1.5349\n",
      "Epoch 4698/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0503 - mae: 0.1811 - val_loss: 2.8515 - val_mae: 1.5305\n",
      "Epoch 4699/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0576 - mae: 0.1998 - val_loss: 2.8949 - val_mae: 1.5445\n",
      "Epoch 4700/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0612 - mae: 0.2044 - val_loss: 2.9923 - val_mae: 1.5758\n",
      "Epoch 4701/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0567 - mae: 0.1948 - val_loss: 3.0594 - val_mae: 1.5969\n",
      "Epoch 4702/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0541 - mae: 0.1889 - val_loss: 3.0923 - val_mae: 1.6072\n",
      "Epoch 4703/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0533 - mae: 0.1856 - val_loss: 3.1070 - val_mae: 1.6118\n",
      "Epoch 4704/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1818 - val_loss: 3.1031 - val_mae: 1.6107\n",
      "Epoch 4705/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0519 - mae: 0.1792 - val_loss: 3.0043 - val_mae: 1.5797\n",
      "Epoch 4706/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0503 - mae: 0.1787 - val_loss: 2.8393 - val_mae: 1.5266\n",
      "Epoch 4707/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0523 - mae: 0.1859 - val_loss: 2.7943 - val_mae: 1.5119\n",
      "Epoch 4708/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0518 - mae: 0.1835 - val_loss: 2.7866 - val_mae: 1.5095\n",
      "Epoch 4709/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0524 - mae: 0.1796 - val_loss: 2.7184 - val_mae: 1.4867\n",
      "Epoch 4710/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0522 - mae: 0.1808 - val_loss: 2.6223 - val_mae: 1.4539\n",
      "Epoch 4711/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0581 - mae: 0.1938 - val_loss: 2.6060 - val_mae: 1.4482\n",
      "Epoch 4712/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0634 - mae: 0.2075 - val_loss: 2.6842 - val_mae: 1.4749\n",
      "Epoch 4713/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.1939 - val_loss: 2.7927 - val_mae: 1.5113\n",
      "Epoch 4714/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0515 - mae: 0.1816 - val_loss: 2.9159 - val_mae: 1.5516\n",
      "Epoch 4715/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0512 - mae: 0.1776 - val_loss: 3.0075 - val_mae: 1.5809\n",
      "Epoch 4716/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0543 - mae: 0.1840 - val_loss: 3.0429 - val_mae: 1.5919\n",
      "Epoch 4717/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0514 - mae: 0.1760 - val_loss: 2.9672 - val_mae: 1.5678\n",
      "Epoch 4718/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0497 - mae: 0.1795 - val_loss: 2.9199 - val_mae: 1.5526\n",
      "Epoch 4719/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0559 - mae: 0.1970 - val_loss: 3.0462 - val_mae: 1.5928\n",
      "Epoch 4720/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0486 - mae: 0.1714 - val_loss: 3.2244 - val_mae: 1.6480\n",
      "Epoch 4721/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0633 - mae: 0.1983 - val_loss: 3.1638 - val_mae: 1.6295\n",
      "Epoch 4722/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.1870 - val_loss: 2.9543 - val_mae: 1.5637\n",
      "Epoch 4723/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0480 - mae: 0.1724 - val_loss: 2.7774 - val_mae: 1.5059\n",
      "Epoch 4724/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0573 - mae: 0.1996 - val_loss: 2.6585 - val_mae: 1.4660\n",
      "Epoch 4725/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0648 - mae: 0.2138 - val_loss: 2.6683 - val_mae: 1.4694\n",
      "Epoch 4726/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0553 - mae: 0.1894 - val_loss: 2.7678 - val_mae: 1.5030\n",
      "Epoch 4727/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0514 - mae: 0.1767 - val_loss: 2.7426 - val_mae: 1.4946\n",
      "Epoch 4728/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0521 - mae: 0.1806 - val_loss: 2.5356 - val_mae: 1.4236\n",
      "Epoch 4729/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0567 - mae: 0.1885 - val_loss: 2.3581 - val_mae: 1.3597\n",
      "Epoch 4730/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0761 - mae: 0.2197 - val_loss: 2.3782 - val_mae: 1.3671\n",
      "Epoch 4731/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0665 - mae: 0.1999 - val_loss: 2.5805 - val_mae: 1.4394\n",
      "Epoch 4732/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1895 - val_loss: 2.7292 - val_mae: 1.4902\n",
      "Epoch 4733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1861 - val_loss: 2.6828 - val_mae: 1.4744\n",
      "Epoch 4734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1743 - val_loss: 2.6360 - val_mae: 1.4583\n",
      "Epoch 4735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2070 - val_loss: 2.6963 - val_mae: 1.4787\n",
      "Epoch 4736/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2094 - val_loss: 2.8979 - val_mae: 1.5455\n",
      "Epoch 4737/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0479 - mae: 0.1732 - val_loss: 3.1890 - val_mae: 1.6371\n",
      "Epoch 4738/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0666 - mae: 0.2038 - val_loss: 3.2590 - val_mae: 1.6584\n",
      "Epoch 4739/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0700 - mae: 0.2095 - val_loss: 3.0464 - val_mae: 1.5928\n",
      "Epoch 4740/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1755 - val_loss: 2.7805 - val_mae: 1.5069\n",
      "Epoch 4741/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0634 - mae: 0.2131 - val_loss: 2.7060 - val_mae: 1.4820\n",
      "Epoch 4742/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0650 - mae: 0.2160 - val_loss: 2.8472 - val_mae: 1.5290\n",
      "Epoch 4743/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1827 - val_loss: 2.9490 - val_mae: 1.5620\n",
      "Epoch 4744/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1802 - val_loss: 2.9845 - val_mae: 1.5732\n",
      "Epoch 4745/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1772 - val_loss: 2.9945 - val_mae: 1.5764\n",
      "Epoch 4746/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1700 - val_loss: 2.9262 - val_mae: 1.5545\n",
      "Epoch 4747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1763 - val_loss: 2.9159 - val_mae: 1.5511\n",
      "Epoch 4748/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1739 - val_loss: 2.9796 - val_mae: 1.5716\n",
      "Epoch 4749/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1697 - val_loss: 2.9258 - val_mae: 1.5544\n",
      "Epoch 4750/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0498 - mae: 0.1735 - val_loss: 2.8936 - val_mae: 1.5440\n",
      "Epoch 4751/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0482 - mae: 0.1712 - val_loss: 2.9306 - val_mae: 1.5559\n",
      "Epoch 4752/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1719 - val_loss: 2.9300 - val_mae: 1.5556\n",
      "Epoch 4753/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1717 - val_loss: 2.8811 - val_mae: 1.5397\n",
      "Epoch 4754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1874 - val_loss: 2.9044 - val_mae: 1.5473\n",
      "Epoch 4755/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0498 - mae: 0.1812 - val_loss: 3.0166 - val_mae: 1.5832\n",
      "Epoch 4756/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489 - mae: 0.1739 - val_loss: 2.9866 - val_mae: 1.5736\n",
      "Epoch 4757/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1738 - val_loss: 2.8987 - val_mae: 1.5454\n",
      "Epoch 4758/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0466 - mae: 0.1705 - val_loss: 2.7690 - val_mae: 1.5029\n",
      "Epoch 4759/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1800 - val_loss: 2.6273 - val_mae: 1.4550\n",
      "Epoch 4760/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1946 - val_loss: 2.5676 - val_mae: 1.4343\n",
      "Epoch 4761/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1933 - val_loss: 2.6335 - val_mae: 1.4572\n",
      "Epoch 4762/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1771 - val_loss: 2.8097 - val_mae: 1.5164\n",
      "Epoch 4763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1842 - val_loss: 2.9770 - val_mae: 1.5706\n",
      "Epoch 4764/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0630 - mae: 0.2079 - val_loss: 3.0400 - val_mae: 1.5904\n",
      "Epoch 4765/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1933 - val_loss: 2.9577 - val_mae: 1.5642\n",
      "Epoch 4766/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0473 - mae: 0.1742 - val_loss: 2.9002 - val_mae: 1.5455\n",
      "Epoch 4767/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1877 - val_loss: 3.0302 - val_mae: 1.5868\n",
      "Epoch 4768/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0517 - mae: 0.1856 - val_loss: 3.2090 - val_mae: 1.6419\n",
      "Epoch 4769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1712 - val_loss: 3.2143 - val_mae: 1.6436\n",
      "Epoch 4770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1653 - val_loss: 3.1573 - val_mae: 1.6264\n",
      "Epoch 4771/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1656 - val_loss: 3.1676 - val_mae: 1.6294\n",
      "Epoch 4772/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1660 - val_loss: 3.2841 - val_mae: 1.6645\n",
      "Epoch 4773/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1658 - val_loss: 3.3905 - val_mae: 1.6958\n",
      "Epoch 4774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1712 - val_loss: 3.3329 - val_mae: 1.6786\n",
      "Epoch 4775/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1691 - val_loss: 3.1981 - val_mae: 1.6381\n",
      "Epoch 4776/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1805 - val_loss: 3.0166 - val_mae: 1.5822\n",
      "Epoch 4777/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1892 - val_loss: 2.8799 - val_mae: 1.5388\n",
      "Epoch 4778/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1898 - val_loss: 2.7854 - val_mae: 1.5079\n",
      "Epoch 4779/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0533 - mae: 0.1898 - val_loss: 2.8132 - val_mae: 1.5173\n",
      "Epoch 4780/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1724 - val_loss: 2.9439 - val_mae: 1.5599\n",
      "Epoch 4781/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1908 - val_loss: 2.9294 - val_mae: 1.5553\n",
      "Epoch 4782/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.2014 - val_loss: 2.7876 - val_mae: 1.5090\n",
      "Epoch 4783/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1815 - val_loss: 2.6851 - val_mae: 1.4746\n",
      "Epoch 4784/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1705 - val_loss: 2.6738 - val_mae: 1.4707\n",
      "Epoch 4785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1716 - val_loss: 2.7761 - val_mae: 1.5049\n",
      "Epoch 4786/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0465 - mae: 0.1693 - val_loss: 2.9915 - val_mae: 1.5746\n",
      "Epoch 4787/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0459 - mae: 0.1684 - val_loss: 3.1376 - val_mae: 1.6199\n",
      "Epoch 4788/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0461 - mae: 0.1680 - val_loss: 3.1480 - val_mae: 1.6227\n",
      "Epoch 4789/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1879 - val_loss: 3.0761 - val_mae: 1.6004\n",
      "Epoch 4790/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2171 - val_loss: 2.9940 - val_mae: 1.5750\n",
      "Epoch 4791/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0666 - mae: 0.2233 - val_loss: 2.9794 - val_mae: 1.5707\n",
      "Epoch 4792/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1965 - val_loss: 3.0598 - val_mae: 1.5963\n",
      "Epoch 4793/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1663 - val_loss: 3.1798 - val_mae: 1.6335\n",
      "Epoch 4794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1798 - val_loss: 3.0946 - val_mae: 1.6072\n",
      "Epoch 4795/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0472 - mae: 0.1657 - val_loss: 2.7863 - val_mae: 1.5083\n",
      "Epoch 4796/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1922 - val_loss: 2.5390 - val_mae: 1.4239\n",
      "Epoch 4797/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0802 - mae: 0.2400 - val_loss: 2.5546 - val_mae: 1.4295\n",
      "Epoch 4798/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.1991 - val_loss: 2.7498 - val_mae: 1.4962\n",
      "Epoch 4799/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1814 - val_loss: 2.8537 - val_mae: 1.5307\n",
      "Epoch 4800/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0687 - mae: 0.2208 - val_loss: 2.6806 - val_mae: 1.4731\n",
      "Epoch 4801/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0522 - mae: 0.1801 - val_loss: 2.4240 - val_mae: 1.3832\n",
      "Epoch 4802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0690 - mae: 0.2071 - val_loss: 2.4291 - val_mae: 1.3851\n",
      "Epoch 4803/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0701 - mae: 0.2098 - val_loss: 2.6362 - val_mae: 1.4580\n",
      "Epoch 4804/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1862 - val_loss: 2.8785 - val_mae: 1.5388\n",
      "Epoch 4805/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0609 - mae: 0.2001 - val_loss: 3.0621 - val_mae: 1.5973\n",
      "Epoch 4806/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0681 - mae: 0.2126 - val_loss: 3.0480 - val_mae: 1.5928\n",
      "Epoch 4807/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0526 - mae: 0.1772 - val_loss: 2.8871 - val_mae: 1.5413\n",
      "Epoch 4808/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1810 - val_loss: 2.7602 - val_mae: 1.4995\n",
      "Epoch 4809/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0735 - mae: 0.2315 - val_loss: 2.8113 - val_mae: 1.5164\n",
      "Epoch 4810/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - mae: 0.2160 - val_loss: 3.0702 - val_mae: 1.5995\n",
      "Epoch 4811/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1619 - val_loss: 3.3497 - val_mae: 1.6847\n",
      "Epoch 4812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0878 - mae: 0.2445 - val_loss: 3.2099 - val_mae: 1.6428\n",
      "Epoch 4813/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0668 - mae: 0.2084 - val_loss: 2.7220 - val_mae: 1.4868\n",
      "Epoch 4814/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0504 - mae: 0.1792 - val_loss: 2.3620 - val_mae: 1.3604\n",
      "Epoch 4815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1099 - mae: 0.2821 - val_loss: 2.3612 - val_mae: 1.3601\n",
      "Epoch 4816/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0956 - mae: 0.2567 - val_loss: 2.6697 - val_mae: 1.4693\n",
      "Epoch 4817/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1748 - val_loss: 3.0157 - val_mae: 1.5828\n",
      "Epoch 4818/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0729 - mae: 0.2269 - val_loss: 3.2538 - val_mae: 1.6563\n",
      "Epoch 4819/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1044 - mae: 0.2769 - val_loss: 3.1840 - val_mae: 1.6349\n",
      "Epoch 4820/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0697 - mae: 0.2154 - val_loss: 2.8862 - val_mae: 1.5409\n",
      "Epoch 4821/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0489 - mae: 0.1803 - val_loss: 2.7581 - val_mae: 1.4986\n",
      "Epoch 4822/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0696 - mae: 0.2278 - val_loss: 2.9640 - val_mae: 1.5655\n",
      "Epoch 4823/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0549 - mae: 0.1908 - val_loss: 3.3021 - val_mae: 1.6696\n",
      "Epoch 4824/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1700 - val_loss: 3.2942 - val_mae: 1.6674\n",
      "Epoch 4825/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1687 - val_loss: 3.0684 - val_mae: 1.5984\n",
      "Epoch 4826/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1688 - val_loss: 2.8915 - val_mae: 1.5422\n",
      "Epoch 4827/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1858 - val_loss: 2.8223 - val_mae: 1.5197\n",
      "Epoch 4828/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1851 - val_loss: 2.9143 - val_mae: 1.5497\n",
      "Epoch 4829/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1723 - val_loss: 3.0187 - val_mae: 1.5830\n",
      "Epoch 4830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1745 - val_loss: 2.9051 - val_mae: 1.5468\n",
      "Epoch 4831/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1701 - val_loss: 2.7614 - val_mae: 1.4996\n",
      "Epoch 4832/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1718 - val_loss: 2.8029 - val_mae: 1.5131\n",
      "Epoch 4833/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0463 - mae: 0.1714 - val_loss: 2.9602 - val_mae: 1.5638\n",
      "Epoch 4834/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0451 - mae: 0.1661 - val_loss: 3.0346 - val_mae: 1.5872\n",
      "Epoch 4835/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0450 - mae: 0.1639 - val_loss: 2.9529 - val_mae: 1.5612\n",
      "Epoch 4836/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1666 - val_loss: 2.8778 - val_mae: 1.5367\n",
      "Epoch 4837/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1808 - val_loss: 2.9158 - val_mae: 1.5484\n",
      "Epoch 4838/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1815 - val_loss: 3.0711 - val_mae: 1.5961\n",
      "Epoch 4839/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0477 - mae: 0.1775 - val_loss: 3.3405 - val_mae: 1.6749\n",
      "Epoch 4840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1718 - val_loss: 3.6409 - val_mae: 1.7591\n",
      "Epoch 4841/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0492 - mae: 0.1668 - val_loss: 3.2740 - val_mae: 1.6580\n",
      "Epoch 4842/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0459 - mae: 0.1611 - val_loss: 2.9795 - val_mae: 1.5702\n",
      "Epoch 4843/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0459 - mae: 0.1636 - val_loss: 2.9724 - val_mae: 1.5685\n",
      "Epoch 4844/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0468 - mae: 0.1650 - val_loss: 3.0502 - val_mae: 1.5933\n",
      "Epoch 4845/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1667 - val_loss: 3.0344 - val_mae: 1.5883\n",
      "Epoch 4846/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1634 - val_loss: 3.0257 - val_mae: 1.5855\n",
      "Epoch 4847/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0466 - mae: 0.1673 - val_loss: 3.0940 - val_mae: 1.6068\n",
      "Epoch 4848/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0472 - mae: 0.1700 - val_loss: 3.2206 - val_mae: 1.6455\n",
      "Epoch 4849/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1658 - val_loss: 3.2977 - val_mae: 1.6687\n",
      "Epoch 4850/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1629 - val_loss: 3.3144 - val_mae: 1.6737\n",
      "Epoch 4851/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0496 - mae: 0.1626 - val_loss: 3.2965 - val_mae: 1.6684\n",
      "Epoch 4852/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0509 - mae: 0.1688 - val_loss: 3.1536 - val_mae: 1.6252\n",
      "Epoch 4853/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1718 - val_loss: 3.0488 - val_mae: 1.5927\n",
      "Epoch 4854/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0455 - mae: 0.1660 - val_loss: 3.0475 - val_mae: 1.5924\n",
      "Epoch 4855/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1614 - val_loss: 3.0781 - val_mae: 1.6019\n",
      "Epoch 4856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0449 - mae: 0.1602 - val_loss: 3.0571 - val_mae: 1.5954\n",
      "Epoch 4857/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0450 - mae: 0.1591 - val_loss: 2.9782 - val_mae: 1.5704\n",
      "Epoch 4858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1705 - val_loss: 2.9456 - val_mae: 1.5600\n",
      "Epoch 4859/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1712 - val_loss: 2.9773 - val_mae: 1.5702\n",
      "Epoch 4860/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0471 - mae: 0.1651 - val_loss: 3.0416 - val_mae: 1.5905\n",
      "Epoch 4861/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1726 - val_loss: 3.0453 - val_mae: 1.5916\n",
      "Epoch 4862/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1698 - val_loss: 2.9032 - val_mae: 1.5462\n",
      "Epoch 4863/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0459 - mae: 0.1661 - val_loss: 2.8325 - val_mae: 1.5229\n",
      "Epoch 4864/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1905 - val_loss: 3.0296 - val_mae: 1.5860\n",
      "Epoch 4865/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0470 - mae: 0.1733 - val_loss: 3.2597 - val_mae: 1.6568\n",
      "Epoch 4866/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0592 - mae: 0.1855 - val_loss: 3.1751 - val_mae: 1.6314\n",
      "Epoch 4867/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0557 - mae: 0.1833 - val_loss: 2.9365 - val_mae: 1.5570\n",
      "Epoch 4868/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0453 - mae: 0.1607 - val_loss: 2.7049 - val_mae: 1.4809\n",
      "Epoch 4869/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1913 - val_loss: 2.6080 - val_mae: 1.4479\n",
      "Epoch 4870/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.2054 - val_loss: 2.7343 - val_mae: 1.4909\n",
      "Epoch 4871/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0465 - mae: 0.1654 - val_loss: 2.9333 - val_mae: 1.5563\n",
      "Epoch 4872/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1746 - val_loss: 3.0263 - val_mae: 1.5859\n",
      "Epoch 4873/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1818 - val_loss: 2.9449 - val_mae: 1.5600\n",
      "Epoch 4874/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0466 - mae: 0.1619 - val_loss: 2.8554 - val_mae: 1.5309\n",
      "Epoch 4875/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1700 - val_loss: 2.8078 - val_mae: 1.5152\n",
      "Epoch 4876/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1986 - val_loss: 2.8455 - val_mae: 1.5275\n",
      "Epoch 4877/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.2027 - val_loss: 3.0213 - val_mae: 1.5839\n",
      "Epoch 4878/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0463 - mae: 0.1690 - val_loss: 3.2378 - val_mae: 1.6508\n",
      "Epoch 4879/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0502 - mae: 0.1603 - val_loss: 3.3265 - val_mae: 1.6775\n",
      "Epoch 4880/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1784 - val_loss: 3.1570 - val_mae: 1.6263\n",
      "Epoch 4881/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1589 - val_loss: 2.8948 - val_mae: 1.5437\n",
      "Epoch 4882/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1754 - val_loss: 2.7209 - val_mae: 1.4863\n",
      "Epoch 4883/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.2262 - val_loss: 2.7844 - val_mae: 1.5075\n",
      "Epoch 4884/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0551 - mae: 0.1975 - val_loss: 3.0095 - val_mae: 1.5805\n",
      "Epoch 4885/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1571 - val_loss: 3.1618 - val_mae: 1.6280\n",
      "Epoch 4886/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1832 - val_loss: 3.1446 - val_mae: 1.6226\n",
      "Epoch 4887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1750 - val_loss: 2.9919 - val_mae: 1.5749\n",
      "Epoch 4888/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0443 - mae: 0.1588 - val_loss: 2.8480 - val_mae: 1.5285\n",
      "Epoch 4889/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0473 - mae: 0.1757 - val_loss: 2.8146 - val_mae: 1.5175\n",
      "Epoch 4890/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0491 - mae: 0.1821 - val_loss: 2.8967 - val_mae: 1.5442\n",
      "Epoch 4891/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0448 - mae: 0.1671 - val_loss: 3.0506 - val_mae: 1.5931\n",
      "Epoch 4892/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0452 - mae: 0.1612 - val_loss: 3.2025 - val_mae: 1.6400\n",
      "Epoch 4893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1823 - val_loss: 3.1881 - val_mae: 1.6356\n",
      "Epoch 4894/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0540 - mae: 0.1759 - val_loss: 2.9699 - val_mae: 1.5676\n",
      "Epoch 4895/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1697 - val_loss: 2.8381 - val_mae: 1.5250\n",
      "Epoch 4896/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1814 - val_loss: 2.9243 - val_mae: 1.5528\n",
      "Epoch 4897/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0457 - mae: 0.1707 - val_loss: 3.0688 - val_mae: 1.5985\n",
      "Epoch 4898/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0446 - mae: 0.1609 - val_loss: 3.2452 - val_mae: 1.6525\n",
      "Epoch 4899/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1866 - val_loss: 3.2189 - val_mae: 1.6444\n",
      "Epoch 4900/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1772 - val_loss: 2.9190 - val_mae: 1.5509\n",
      "Epoch 4901/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0440 - mae: 0.1680 - val_loss: 2.6636 - val_mae: 1.4665\n",
      "Epoch 4902/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2201 - val_loss: 2.5116 - val_mae: 1.4139\n",
      "Epoch 4903/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0856 - mae: 0.2492 - val_loss: 2.5086 - val_mae: 1.4130\n",
      "Epoch 4904/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0733 - mae: 0.2218 - val_loss: 2.7239 - val_mae: 1.4874\n",
      "Epoch 4905/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1805 - val_loss: 2.9847 - val_mae: 1.5727\n",
      "Epoch 4906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0730 - mae: 0.2231 - val_loss: 3.0948 - val_mae: 1.6074\n",
      "Epoch 4907/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0890 - mae: 0.2494 - val_loss: 3.0386 - val_mae: 1.5897\n",
      "Epoch 4908/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0716 - mae: 0.2219 - val_loss: 2.8748 - val_mae: 1.5372\n",
      "Epoch 4909/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0481 - mae: 0.1636 - val_loss: 2.6712 - val_mae: 1.4693\n",
      "Epoch 4910/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1855 - val_loss: 2.6331 - val_mae: 1.4562\n",
      "Epoch 4911/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1968 - val_loss: 2.8388 - val_mae: 1.5249\n",
      "Epoch 4912/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0447 - mae: 0.1671 - val_loss: 3.0722 - val_mae: 1.5993\n",
      "Epoch 4913/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1622 - val_loss: 3.1806 - val_mae: 1.6325\n",
      "Epoch 4914/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1694 - val_loss: 3.1214 - val_mae: 1.6141\n",
      "Epoch 4915/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0459 - mae: 0.1552 - val_loss: 3.0429 - val_mae: 1.5893\n",
      "Epoch 4916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0437 - mae: 0.1620 - val_loss: 3.0314 - val_mae: 1.5849\n",
      "Epoch 4917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1932 - val_loss: 3.0939 - val_mae: 1.6037\n",
      "Epoch 4918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.2006 - val_loss: 3.1669 - val_mae: 1.6263\n",
      "Epoch 4919/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1718 - val_loss: 3.0079 - val_mae: 1.5782\n",
      "Epoch 4920/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - mae: 0.1609 - val_loss: 2.7507 - val_mae: 1.4959\n",
      "Epoch 4921/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0449 - mae: 0.1640 - val_loss: 2.5428 - val_mae: 1.4252\n",
      "Epoch 4922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1807 - val_loss: 2.5254 - val_mae: 1.4193\n",
      "Epoch 4923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1720 - val_loss: 2.6461 - val_mae: 1.4613\n",
      "Epoch 4924/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1704 - val_loss: 2.7846 - val_mae: 1.5080\n",
      "Epoch 4925/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1868 - val_loss: 2.9535 - val_mae: 1.5630\n",
      "Epoch 4926/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1922 - val_loss: 3.0706 - val_mae: 1.5999\n",
      "Epoch 4927/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0509 - mae: 0.1706 - val_loss: 2.9932 - val_mae: 1.5754\n",
      "Epoch 4928/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0439 - mae: 0.1611 - val_loss: 2.8432 - val_mae: 1.5270\n",
      "Epoch 4929/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0627 - mae: 0.2159 - val_loss: 2.9146 - val_mae: 1.5502\n",
      "Epoch 4930/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2073 - val_loss: 3.2432 - val_mae: 1.6528\n",
      "Epoch 4931/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1690 - val_loss: 3.4387 - val_mae: 1.7109\n",
      "Epoch 4932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1815 - val_loss: 3.3091 - val_mae: 1.6727\n",
      "Epoch 4933/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1687 - val_loss: 3.0838 - val_mae: 1.6040\n",
      "Epoch 4934/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0436 - mae: 0.1592 - val_loss: 2.8439 - val_mae: 1.5273\n",
      "Epoch 4935/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1800 - val_loss: 2.6910 - val_mae: 1.4765\n",
      "Epoch 4936/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1947 - val_loss: 2.7037 - val_mae: 1.4808\n",
      "Epoch 4937/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0501 - mae: 0.1823 - val_loss: 2.7875 - val_mae: 1.5088\n",
      "Epoch 4938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1621 - val_loss: 2.8737 - val_mae: 1.5372\n",
      "Epoch 4939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0458 - mae: 0.1604 - val_loss: 2.8765 - val_mae: 1.5381\n",
      "Epoch 4940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1626 - val_loss: 2.8983 - val_mae: 1.5452\n",
      "Epoch 4941/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1583 - val_loss: 3.0219 - val_mae: 1.5846\n",
      "Epoch 4942/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0481 - mae: 0.1630 - val_loss: 3.0559 - val_mae: 1.5953\n",
      "Epoch 4943/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0470 - mae: 0.1601 - val_loss: 3.0525 - val_mae: 1.5942\n",
      "Epoch 4944/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1570 - val_loss: 3.0317 - val_mae: 1.5876\n",
      "Epoch 4945/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0442 - mae: 0.1613 - val_loss: 3.0045 - val_mae: 1.5790\n",
      "Epoch 4946/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0441 - mae: 0.1635 - val_loss: 3.0381 - val_mae: 1.5896\n",
      "Epoch 4947/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1572 - val_loss: 3.0777 - val_mae: 1.6020\n",
      "Epoch 4948/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1532 - val_loss: 3.0816 - val_mae: 1.6033\n",
      "Epoch 4949/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1560 - val_loss: 2.9840 - val_mae: 1.5726\n",
      "Epoch 4950/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1640 - val_loss: 2.8383 - val_mae: 1.5255\n",
      "Epoch 4951/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1717 - val_loss: 2.7116 - val_mae: 1.4834\n",
      "Epoch 4952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1869 - val_loss: 2.6879 - val_mae: 1.4753\n",
      "Epoch 4953/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1901 - val_loss: 2.7576 - val_mae: 1.4988\n",
      "Epoch 4954/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1741 - val_loss: 2.8977 - val_mae: 1.5449\n",
      "Epoch 4955/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1561 - val_loss: 3.0256 - val_mae: 1.5858\n",
      "Epoch 4956/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1746 - val_loss: 3.0210 - val_mae: 1.5843\n",
      "Epoch 4957/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1781 - val_loss: 2.9144 - val_mae: 1.5503\n",
      "Epoch 4958/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0449 - mae: 0.1557 - val_loss: 2.7629 - val_mae: 1.5005\n",
      "Epoch 4959/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0466 - mae: 0.1701 - val_loss: 2.6844 - val_mae: 1.4741\n",
      "Epoch 4960/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1868 - val_loss: 2.7089 - val_mae: 1.4824\n",
      "Epoch 4961/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1772 - val_loss: 2.8552 - val_mae: 1.5309\n",
      "Epoch 4962/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1548 - val_loss: 3.0828 - val_mae: 1.6036\n",
      "Epoch 4963/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1810 - val_loss: 3.1975 - val_mae: 1.6389\n",
      "Epoch 4964/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1921 - val_loss: 3.0855 - val_mae: 1.6044\n",
      "Epoch 4965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1617 - val_loss: 2.8908 - val_mae: 1.5425\n",
      "Epoch 4966/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0443 - mae: 0.1669 - val_loss: 2.7559 - val_mae: 1.4981\n",
      "Epoch 4967/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1898 - val_loss: 2.6806 - val_mae: 1.4728\n",
      "Epoch 4968/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1907 - val_loss: 2.7539 - val_mae: 1.4975\n",
      "Epoch 4969/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0434 - mae: 0.1567 - val_loss: 2.9509 - val_mae: 1.5620\n",
      "Epoch 4970/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0560 - mae: 0.1916 - val_loss: 3.0892 - val_mae: 1.6056\n",
      "Epoch 4971/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0757 - mae: 0.2346 - val_loss: 2.9626 - val_mae: 1.5656\n",
      "Epoch 4972/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1616 - val_loss: 2.6922 - val_mae: 1.4766\n",
      "Epoch 4973/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0601 - mae: 0.2051 - val_loss: 2.5995 - val_mae: 1.4449\n",
      "Epoch 4974/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0777 - mae: 0.2396 - val_loss: 2.7788 - val_mae: 1.5057\n",
      "Epoch 4975/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0462 - mae: 0.1699 - val_loss: 3.0352 - val_mae: 1.5886\n",
      "Epoch 4976/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0845 - mae: 0.2184 - val_loss: 3.1084 - val_mae: 1.6115\n",
      "Epoch 4977/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0585 - mae: 0.1906 - val_loss: 2.9760 - val_mae: 1.5699\n",
      "Epoch 4978/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0543 - mae: 0.1808 - val_loss: 2.7141 - val_mae: 1.4841\n",
      "Epoch 4979/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0683 - mae: 0.2072 - val_loss: 2.4884 - val_mae: 1.4060\n",
      "Epoch 4980/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1043 - mae: 0.2650 - val_loss: 2.5392 - val_mae: 1.4240\n",
      "Epoch 4981/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0958 - mae: 0.2524 - val_loss: 2.8039 - val_mae: 1.5141\n",
      "Epoch 4982/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0733 - mae: 0.2146 - val_loss: 2.9105 - val_mae: 1.5489\n",
      "Epoch 4983/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0682 - mae: 0.2085 - val_loss: 2.8892 - val_mae: 1.5420\n",
      "Epoch 4984/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0657 - mae: 0.2037 - val_loss: 2.8652 - val_mae: 1.5341\n",
      "Epoch 4985/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0613 - mae: 0.1952 - val_loss: 2.8098 - val_mae: 1.5159\n",
      "Epoch 4986/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1872 - val_loss: 2.8324 - val_mae: 1.5231\n",
      "Epoch 4987/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1842 - val_loss: 2.9242 - val_mae: 1.5527\n",
      "Epoch 4988/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1839 - val_loss: 2.9712 - val_mae: 1.5675\n",
      "Epoch 4989/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1869 - val_loss: 3.0116 - val_mae: 1.5802\n",
      "Epoch 4990/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1902 - val_loss: 3.1453 - val_mae: 1.6215\n",
      "Epoch 4991/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.1978 - val_loss: 3.3362 - val_mae: 1.6783\n",
      "Epoch 4992/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0626 - mae: 0.2020 - val_loss: 3.5456 - val_mae: 1.7374\n",
      "Epoch 4993/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0639 - mae: 0.2039 - val_loss: 3.4861 - val_mae: 1.7202\n",
      "Epoch 4994/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1912 - val_loss: 3.2745 - val_mae: 1.6596\n",
      "Epoch 4995/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1821 - val_loss: 3.2063 - val_mae: 1.6400\n",
      "Epoch 4996/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1730 - val_loss: 3.1194 - val_mae: 1.6140\n",
      "Epoch 4997/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0475 - mae: 0.1663 - val_loss: 2.9052 - val_mae: 1.5468\n",
      "Epoch 4998/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0466 - mae: 0.1676 - val_loss: 2.7746 - val_mae: 1.5042\n",
      "Epoch 4999/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1751 - val_loss: 2.7917 - val_mae: 1.5099\n",
      "Epoch 5000/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1715 - val_loss: 2.8540 - val_mae: 1.5305\n",
      "CPU times: user 3min 20s, sys: 11.3 s, total: 3min 31s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f008ff3de20>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=5000,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khe6ufw-E3f6",
    "outputId": "8ab6c582-7856-45bb-9060-438d548f2b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8540 - mae: 1.5305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8539867401123047, 1.5304752588272095]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.42342342, 0.04069176],\n",
       "        [0.02575758, 0.        , 0.42117117, 0.01831129],\n",
       "        [0.01698113, 0.        , 0.93675889, 0.04563758],\n",
       "        [0.03470716, 0.02191465, 1.        , 0.12589413],\n",
       "        [0.01094092, 0.        , 1.        , 0.10873147],\n",
       "        [0.        , 0.        , 0.87318841, 0.08862876],\n",
       "        [0.02466368, 0.02607562, 0.78985507, 0.09962406],\n",
       "        [0.        , 0.        , 0.93115942, 0.05252525],\n",
       "        [0.        , 0.        , 0.79347826, 0.05656566],\n",
       "        [0.04690832, 0.03911343, 0.90217391, 0.15353535]],\n",
       "\n",
       "       [[0.04242424, 0.01100917, 0.32657658, 0.04374364],\n",
       "        [0.        , 0.02678571, 0.42342342, 0.04069176],\n",
       "        [0.03207547, 0.00107643, 0.73913043, 0.02416107],\n",
       "        [0.01952278, 0.        , 0.91153846, 0.04864092],\n",
       "        [0.03501094, 0.02734839, 0.94202899, 0.14497529],\n",
       "        [0.01345291, 0.00737101, 1.        , 0.11036789],\n",
       "        [0.        , 0.        , 0.87318841, 0.09962406],\n",
       "        [0.0311804 , 0.05376344, 0.78985507, 0.10707071],\n",
       "        [0.04264392, 0.02998696, 0.93115942, 0.05252525],\n",
       "        [0.        , 0.        , 0.79347826, 0.05656566]]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.4 , 15.66, 15.77, 16.05, 16.25, 16.59, 16.49, 16.45, 16.7 ,\n",
       "       16.67, 16.96, 16.83, 16.8 , 16.8 , 17.12, 17.83, 17.75, 18.02,\n",
       "       18.39, 18.94, 19.13, 18.87, 18.75, 18.88, 18.95, 19.12, 19.57,\n",
       "       19.47, 19.34, 19.01, 18.87, 18.63, 19.07, 19.44, 19.69])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.583584 ],\n",
       "       [15.645204 ],\n",
       "       [15.782682 ],\n",
       "       [15.9726515],\n",
       "       [16.198883 ],\n",
       "       [16.368423 ],\n",
       "       [16.560165 ],\n",
       "       [16.56731  ],\n",
       "       [16.651947 ],\n",
       "       [16.777336 ],\n",
       "       [16.84516  ],\n",
       "       [16.800354 ],\n",
       "       [16.824154 ],\n",
       "       [16.988247 ],\n",
       "       [17.244648 ],\n",
       "       [17.509182 ],\n",
       "       [17.749893 ],\n",
       "       [18.070518 ],\n",
       "       [18.491175 ],\n",
       "       [18.81268  ],\n",
       "       [18.959585 ],\n",
       "       [19.010923 ],\n",
       "       [19.018316 ],\n",
       "       [19.029598 ],\n",
       "       [19.075611 ],\n",
       "       [19.140247 ],\n",
       "       [19.167849 ],\n",
       "       [19.193317 ],\n",
       "       [19.222908 ],\n",
       "       [19.24838  ],\n",
       "       [19.253098 ],\n",
       "       [19.24781  ],\n",
       "       [19.23994  ],\n",
       "       [19.251553 ],\n",
       "       [19.265457 ]], dtype=float32)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = np.array(model.predict(X_train))\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Wh0-FtF-YtmE",
    "outputId": "68ea4c84-9585-44ae-c125-70d0bc72745d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train_pred, '.r', label='predicted')\n",
    "plt.plot(np.array(y_train), 'g', label='true')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "XV-NsrhLYH0a",
    "outputId": "a6dce743-3de7-48f1-9364-70bbd509971d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAGbCAYAAABeXfDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABTZUlEQVR4nO3dd3hUVeLG8fekk0ILvSZAkE4KoiyoICJFFgVkJRSBoMnq+nPd4lpW17LqWtbeNsEMiDRRQMUKgtgQlZDQe5FOIBBqes7vj2SzIkECJLnJzPfzPDyZzD0zvNfrhcnLuecaa60AAAAAAADgmbycDgAAAAAAAADnUA4BAAAAAAB4MMohAAAAAAAAD0Y5BAAAAAAA4MEohwAAAAAAADyYj9MBSlOvXj0bFhbmdAwAAAAAAAC3kZKScshaW/+Xz1fJcigsLEzLly93OgYAAAAAAIDbMMb8VNrzXFYGAAAAAADgwSiHAAAAAAAAPBjlEAAAAAAAgAerkmsOAQAAAAAAz5KXl6fdu3crOzvb6SjVXkBAgJo1ayZfX98yjaccAgAAAAAAjtu9e7dCQkIUFhYmY4zTcaota60yMjK0e/duhYeHl+k1XFYGAAAAAAAcl52drdDQUIqhi2SMUWho6HnNwKIcAgAAAAAAVQLFUPk43/+OlEMAAAAAAAAejHIIAAAAAACgnC1ZskSDBw+WJH3wwQd68sknzzo2MzNTr7322nn/Hg8//LD+/e9/X3DG/6IcAgAAAAAAKKOCgoLzfs2QIUN07733nnX7hZZD5YVyCAAAAAAAVE/ffSf9619FX8vBjh071K5dO40bN05dunTRjTfeqFOnTiksLEyPPvqoevXqpXfeeUcLFixQjx49FB0drREjRujEiROSpE8//VTt2rVTr169NHfu3JL3nTJliu644w5J0oEDBzR06FB17dpVXbt21dKlS3Xvvfdq69atioyM1N133y1JeuaZZ3TppZeqS5cueuihh0re6/HHH9cll1yia665Rhs3biyX/eZW9gAAAAAAoPr57jupb18pN1fy85MWLZJ69Ljot924caOSk5PVs2dPxcXFlczoCQgI0DfffKNDhw5p2LBh+vzzzxUUFKSnnnpKzz33nP72t7/p1ltv1eLFi9WmTRvddNNNpb7/nXfeqauuukrz5s1TQUGBTpw4oSeffFJr1qxRWlqaJGnBggXavHmzfvjhB1lrNWTIEH311VcKCgrSrFmzlJqaqvz8fEVHRysmJuai95lyCAAAAAAAVD9LlhQVQwUFRV+XLCmXcqh58+bq2bOnJGnMmDF66aWXJKmk7Fm2bJnWrVtXMiY3N1c9evTQhg0bFB4eroiIiJLXJiUlnfH+ixcv1tSpUyVJ3t7eqlWrlo4cOXLamAULFmjBggWKioqSJJ04cUKbN2/W8ePHNXToUAUGBkoqulytPFAOAQAAAACA6qd376IZQ/+dOdS7d7m87S9vA//f74OCgiRJ1lr169dPM2fOPG1cWlraed9C/mystbrvvvuUkJBw2vMvvPBCuf0eP8eaQwAAABdo7/G9Op5z3OkYAAB4ph49ii4l++c/y+2SMknauXOnvitew2jmzJnq1avXadsvv/xyffvtt9qyZYsk6dSpU9q0aZPatWun7du3a+vWrSWvLU3fvn31+uuvSypa3PrYsWMKCQnR8eP/+0zRv39/uVyukrWM9uzZo/T0dF155ZWaN2+esrKydPz4cc2fP79c9pmZQwAAAOcpOz9bdy+4W6/8+IokqWFQQ0WERqht3baKCI1QRN0IRYRGqE3dNgr0DXQ4LQAAbqxHj3Irhf6rffv2evPNN5WQkKCIiAjddtttevnll0u2169fX1OmTFFsbKxycnIkSY899pjatm2rpKQkXXfddapXr5569eqlNWvWnPH+L774ouLj45WcnCxvb2+9/vrr6tGjh3r27KlOnTpp4MCBeuaZZ7R+/Xr1KN634OBgTZs2TdHR0brpppsUGRmpli1b6oorriiXfTbW2nJ5o/LUrVs3u3z5cqdjAAAAnGHdwXUa+e5IrU5frdu73a7mtZprc8ZmbT5c9Gv/if2njW8a0vR/hVFxaRRRN0Kt67ZWgE+AQ3sBAEDVs379erVv397RDDt27NDgwYNLLXWqm9L+expjUqy13X45lplDAAAAZWCtVWJKov702Z8U4heij0d9rIERA88YdzznuLYc3qJNGZtKCqPNGZs1b8M8HTp1qGSckVHzWs3PKI3ahrZVeJ1w+Xn7VebuAQAAD0Y5BAAAcA6Hsw7rlg9u0bwN89SvVT9NHTpVjYIblTo2xD9EUY2jFNU46oxtmdmZ/5tl9LPZRm+vfVtHsv93lxIv46Ww2mFnFEcRoREKqx0mHy8+wgEAUBHCwsLcYtbQ+eKTBQAAwK/4cseXGjNvjA6cOKBn+j2jP/f4s7zMhd3To3ZAbV3a9FJd2vTSM7ZlnMo4ozTanLFZS3ct1fHc/y1Q6ePlo/Da4aVeqtaiVgt5e3lf8L4CAADPRDkEAABQivzCfD365aN6/OvH1apOK3038TvFNImpsN8vNDBUoYGhurzZ5ac9b61V+sn0UoujJTuW6FTeqZKxft5+alWnVcnlaT8vjprWbHrBpRYAAHBvlEMAAAC/sCNzh0bPHa2lu5ZqXNdxenngywrxD3EkizFGDYMbqmFwQ/VqcfqtdK212ndiX6mXqi3ctlDZ+dklYwN8AtSmbptSL1VrHNxYxpjK3jUAAFBFUA4BAAD8zOy1sxU/P15WVjOGzVBs51inI52VMUZNQpqoSUgTXRV21WnbCm2h9hzbU1Ia/XeB7PWH1uujzR8ptyC3ZGyQb1BRcVTKpWoNghpQHAEA4OYohwAAACSdzD2pOz+5U640ly5vdrlmDJuh8DrhTse6YF7GS81rNVfzWs11dfjVp20rKCzQzqM7z5httHL/Sr234T3lF+aXjK3pX/P0mUY/exwaGFrZuwUAQIXJzMzUjBkzdPvttzsdpdJRDgEAAI+Xui9VI+eM1OaMzbq/1/16uPfD8vX2dTpWhfH28lZ4nXCF1wnXta2vPW1bXkGefjr60xmXqn2/+3vNXjtbhbawZGydgDqllkYRoRGqHVC7kvcKAICLk5mZqddee+2McqigoEDe3u59wwfKIQAA4LEKbaFeXPai7l10r+oF1tOimxepT3gfp2M5ytfbV23qtlGbum00UANP25ZbkKttR7adURx9vfNrzVg9Q1a2ZGy9wHolRVHbum1LiqM2dds4tn4TAAC/5t5779XWrVsVGRkpX19fBQcHq3HjxkpLS9PHH3+swYMHl9zm/t///rdOnDihhx9+WFu3btUf/vAHHTx4UIGBgZo0aZLatWvn8N6cH8ohAADgkQ6cOKDx74/Xp1s+1ZBLhih5SLLqBdZzOlaV5uftp3b12qldvTM/8GbnZ2vr4a1nXKq2aNsiTV059bSxjYIblTrbqE3dNgr0Days3QEAVGF3fXqX0vanlet7RjaK1AsDXjjr9ieffFJr1qxRWlqalixZouuuu05r1qxReHi4duzYcdbXxcfH6z//+Y8iIiL0/fff6/bbb9fixYvLNXtFoxwCAAAeZ8HWBbp53s3KzM7Uq4Ne1W3dbmPR5YsU4BOgjg06qmODjmdsO5l7UluPbC1aFPtnxdFHmz/SgbQDp41tGtK01EvVWtdtrQCfgMraHQAA1L17d4WH//r6gydOnNDSpUs1YsSIkudycnIqOlq5oxwCAAAeI7cgV/cvul/PfvesOtbvqIVjF6pzw85Ox3J7QX5B6tKwi7o07HLGtmM5x7Tl8JbTSqPNGZs1b8M8HTp1qGSckVGLWi1KLY7C64TLz9uvMncJAFDBfm2GT2UJCgoqeezj46PCwv+tu5ednS1JKiwsVO3atZWWllbZ8coV5RAAAPAImzI2KXZOrFbsW6Hbut2mZ699VjV8azgdy+PV9K+p6MbRim4cfca2zOzMM9Y32pSxSTPXzFRmdmbJOC/jpbDaYaVeqhZWO0w+XnzkBQCcW0hIiI4fP17qtoYNGyo9PV0ZGRkKDg7Whx9+qAEDBqhmzZoKDw/XO++8oxEjRshaq1WrVqlr166VnP7i8DclAABwa9ZavbnyTd3x8R3y9/HXvJvm6YZ2NzgdC2VQO6C2Lm16qS5teulpz1trlZGVcUZxtPnwZi3dtVTHc//3wd7Hy0fhtcNLCqO2oW1LiqPmNZvL28u97z4DACi70NBQ9ezZU506dVKNGjXUsGHDkm2+vr76xz/+ocsuu0zh4eGnLTg9ffp03XbbbXrssceUl5enkSNHVrtyyFhrzz2qknXr1s0uX77c6RgAAKCaO5p9VL//6PeatWaWrmp5laYNm6ZmNZs5HQsVyFqr9JPpZ5RG/318Ku9UyVg/bz+1rtO61EvVmtZsKi/j5eCeAIDnWb9+vdq3b+90DLdR2n9PY0yKtbbbL8cycwgAALilZbuXKXZOrHYd3aXH+jyme3vdyywRD2CMUcPghmoY3FC9WvQ6bZu1VvtO7DtjYezNGZv12ZbPlFPwvwVEa/jUUOu6rUu9VK1xcGMWMAcAuBXKIQAA4FYKCgv05DdP6qElD6l5reb6esLX6tG8h9OxUAUYY9QkpImahDRR77Dep20rtIXafWz3GZeqrT+0Xh9u+lB5hXklY4N8g0qdbRQRGqH6gfUpjgAA1Q7lEAAAcBt7ju3RmHljtGTHEo3sNFL/ue4/qhVQy+lYqAa8jJda1GqhFrVaqG+rvqdtKygs0M6jO89YGDt1f6rmrp+rAltQMramf83TC6OfPQ4NDK3s3QKAasdaS8leDs53CSHKIQAA4Bbe3/C+4j6IU05+jiZfP1njuo7jwyXKhbeXt8LrhCu8TriubX3tadvyCvK0I3PHGWscfb/7e81eO1uF9n+3Pa4TUOeM0ui/C2RTYgKAFBAQoIyMDIWGhvJ3+EWw1iojI0MBAQFlfg0LUgMAgGotKy9Lf13wV722/DVFN47WzOEz1Ta0rdOxAOXk52h75vZS76q26+guWf3vc3j9wPpnvVQt2C/Ywb0AgMqTl5en3bt3Kzs72+ko1V5AQICaNWsmX1/f054/24LUlEMAAKDaWpO+RrFzYrUmfY3+0uMvevzqx+Xv4+90LOCcsvKytPXI1lKLo73H9542tlFwo1JLozZ12yjQN9ChPQAAVEfcrQwAALgNa61eX/66/rLgL6rlX0ufjv5U/dv0dzoWUGY1fGuoU4NO6tSg0xnbTuae1JbDW84ojT7a/JEOpB04bWzTkKZFl6fVbXtacdSqTisF+JT9cgIAgGejHAIAANVKxqkMTfxgot7f+L4GtBmgKddPUcPghk7HAspNkF+Qujbqqq6Nup6x7VjOsaLi6GcLY28+vFlz1s9RRlZGyTgjoxa1WpR6qVp4nXD5eftV5i4BAKo4yiEAAFBtLNmxRGPmjlH6yXQ9d+1z+uPlf5SX8XI6FlBpavrXVHTjaEU3jj5j25GsI2fMNtqcsVkz18xUZnZmyThv462WtVuWujB2y9ot5ePFjwgA4Gn4kx8AAFR5eQV5enjJw/rXN/9SRGiElsUuK/WHY8CT1alRR92bdlf3pt1Pe95aq4ysjFLXN/p217c6kXuiZKyPl49a1WlV6hpHzWs2l7eXd2XvFgCgElAOAQCAKm37ke0aNXeUlu1eprjIOL048EXu3gScB2OM6gXWU73AeurRvMdp26y1OnDyQKnF0Rc7vtCpvFMlY/28/dS6TutSL1VrWrMps/gAoBqjHAIAAFXWzNUz9fuPfi9JmjV8lm7qdJPDiQD3YoxRo+BGahTcSFe0vOK0bdZa7T2+t9RL1T7b8plyCnJKxtbwqaHWdVuXXJ728+KoUXAjGWMqe9cAAOfhnOWQMaa5pKmSGkkqlJRkrX3RGDNC0sOS2kvqbq0t9d7zxpgdko5LKpCUX9ot0wAAAH7uRO4J/d8n/6cpaVPUo1kPzRg+Q2G1w5yOBXgUY4ya1myqpjWbqndY79O2FdpC7T62+4yFsdemr9X8jfOVV5hXMjbYL1ht6rYp9VK1+oH1KY4AoAow1tpfH2BMY0mNrbUrjDEhklIk3SDJqqgsSpT013OUQ92stYfKGqpbt252+fJS3w4AALi5lL0pip0Tqy2Ht+iBKx/QP676BwvkAtVIfmG+dh7dWeqlatuPbFeBLSgZW9O/5umF0c8WyK5bo66DewEA7skYk1LapJ1zftKy1u6TtK/48XFjzHpJTa21C4vfuLyzAgAAD1RoC/X8d8/rvkX3qWFwQ30x7gtdFXaV07EAnKf/Lmrdqk4r9Vf/07blFeRpR+aOM0qjZbuXafba2Sq0hSVj69aoW2pxFFE3QrUCalX2bgGAWzuvf4YzxoRJipL0/Xm8zEpaYIyxkhKttUlnee94SfGS1KJFi/OJBQAAqrn9J/Zr3HvjtGDrAg1tN1RvDHmDWQOAG/L19i0qeEIjpIjTt+Xk52jbkW1nFEdf7vhS01ZNO21s/cD6pZZGEaERLFgPABfgnJeVlQw0JljSl5Iet9bO/dnzS/Trl5U1sdbuNcY0kLRQ0v9Za7/6td+Ly8oAAPAcn2z+ROPfH69jOcf0Qv8XFB8Tz8xkAKfJysvS1iNbS71Ube/xvaeNbRTcSBF1I/63OHZxcdS6bmsF+gY6tAcAUDVc8GVlxS/2lTRH0vSfF0NlYa3dW/w13RgzT1J3Sb9aDgEAAPeXk5+j+xbdp+eXPa/ODTpr8c2L1bFBR6djAaiCavjWUKcGndSpQacztp3MPakth7ectjD25ozNmr9pvtJPpp82tlnNZqXONmpdp7X8ffwra3cAoMopy93KjKRkSeuttc+dz5sbY4IkeRWvVRQk6VpJj15QUgAA4DY2Htqo2DmxSt2fqjsuvUNP93taNXxrOB0LQDUU5Bekro26qmujrmdsO5ZzrNTZRnPWz1FGVkbJOCOjFrValLowdnjtcPl6+1bmLgFApSvL3cp6Sfpa0moV3Z1Mku6X5C/pZUn1JWVKSrPW9jfGNJH0hrV2kDGmlaR5xa/xkTTDWvv4uUJxWRkAAO7JWitXqkt3fnqnavjUkOt6l4ZcMsTpWAA80JGsI2eURv99nJmdWTLO23grrHZYSXEU1ShKN3a4USH+Ic6FB4ALdLbLysq85lBlohwCAMD9ZGZnKuHDBM1eO1t9wvroraFvqWnNpk7HAoDTWGt16NShsxZHJ3JPKNgvWKM6jVJ8TLximsQ4HRkAyoxyCAAAOGbprqUaNWeUdh/brX/2+af+1vNv8vbydjoWAJwXa62+3/O9klKSNGvNLGXlZymmcYziY+IV2ymW2UQAqjzKIQAAUOkKCgv0xNdP6JEvH1GLWi00c/hMXdbsMqdjAcBFy8zO1LRV05SYkqg16WtKZhMldEtQdONop+MBQKkohwAAQKXadXSXxswbo69++kqjOo/Sa4NeU62AWk7HAoByZa3Vst3LlJiSqLfXvq3s/Gx1a9JN8dHxiu0cq2C/YKcjAkAJyiEAAFBp5q2fp4kfTFReYZ5eHfSqxnYZq6IboAKA+zqSdaRkNtHag2sV4hei0Z1HKz4mXlGNo5yOBwCUQwAAoOKdyjulP3/2ZyWmJCqmcYxmDp+piNAIp2MBQKWy1uq73d8pMSVRs9fOVnZ+ti5tcqkSYhJ0U6ebmE0EwDGUQwAAoEKtOrBKsXNite7gOt39m7v12NWPyc/bz+lYAOCoI1lH9Naqt5SYkqh1B9cpxC9EY7qMUUJMgro26up0PAAehnIIAABUCGutXv3xVf11wV9Vp0YdTb1hqvq17ud0LACoUqy1WrpraclsopyCHHVv2r1oNlHHmxTkF+R0RAAegHIIAACUu0OnDinu/TjN3zRfgyIGafL1k9UgqIHTsQCgSjucdVhvrSyaTbT+0HrV9K+pMZ3HKKFbgro07OJ0PABujHIIAACUq8XbF2vM3DHKyMrQ09c8rTsvu5NFpwHgPFhr9e2ub5WYkqh31r6jnIIcXdb0spK1iQJ9A52OCMDNUA4BAIBykVeQp3988Q899e1TahvaVrNunKXIRpFOxwKAau1w1mFNXTlViSmJ2nBog2r51ypZm6hzw85OxwPgJiiHAADARdt6eKtGzR2lH/b8oFuibtELA15gnQwAKEfWWn2z8xslpiTq3XXvKqcgR5c3u1wJMQn6XcffMZsIwEWhHAIAABdl+qrpuu2j2+Tt5a1Jv52kGzvc6HQkAHBrGacySmYTbczYqFr+tTS2y1gldEtQpwadnI4HoBqiHAIAABfkeM5x3fHJHZq6cqp6Nu+p6cOmq2Xtlk7HAgCPYa3V1zu/LplNlFuQq980/43io+P1u46/Uw3fGk5HBFBNUA4BAIDz9uOeHzVq7ihtO7JND175oB648gH5ePk4HQsAPNahU4dKZhNtytik2gG1dXOXmxUfE6+ODTo6HQ9AFUc5BAAAyqzQFurZpc/q/sX3q3FwY00fNl1XtLzC6VgAgGLWWn3505dKSknSnPVzlFuQq57Neyo+Jl4jOoxgNhGAUlEOAQCAMtl3fJ/GvTdOC7ct1PD2wzXpt5NUp0Ydp2MBAM7i4MmDenPlm0pKSdLmw5tLZhMldEtQh/odnI4HoAqhHAIAAOf00aaPNP798TqZe1IvDnhRt0TfImOM07EAAGVgrdWSHUuUmJKouevnKq8wT71a9FJ8dLxu7HAjs4kAUA4BAICzy87P1j0L79FLP7ykLg27aNbwWWpfv73TsQAAF+jgyYOakjZFSSuStOXwFtUJqKNxXccpPiaeP98BD0Y5BAAASrX+4HrFzonVygMrdWf3O/VUv6cU4BPgdCwAQDkotIVasmOJklKSSmYTXdHiCiXEJGh4h+H8eQ94GMohAABwGmut3ljxhv746R8V5BekyddP1uC2g52OBQCoIOkn04tmE6UkaeuRrapbo27JbKJ29do5HQ9AJaAcAgAAJY5kHVH8h/F6d9276hveV28NfUuNQxo7HQsAUAkKbaG+2P6FElMSNW/DPOUX5uvKllcqISZBw9oPYzYR4MYohwAAgCTpm53faNScUdp3Yp8e6/OY7u55t7yMl9OxAAAOOHDiQMnaRNuObFNojdCS2USX1LvE6XgAyhnlEAAAHi6/MF+Pf/W4Hv3qUYXXDteM4TPUvWl3p2MBAKqAQluoxdsXKzElUe9teE/5hfnqHdZb8dHxGtZ+mPx9/J2OCKAcUA4BAODBdh7dqdFzR+ubnd9obJexenXQqwrxD3E6FgCgCjpw4oAmp03WpBWTSmYTjY8cr/iYeLUNbet0PAAXgXIIAAAP9e66d3Xr/FuVX5iv1697XWO6jHE6EgCgGii0hVq0bZESUxL1/sb3S2YTJcQkaGi7ocwmAqohyiEAADzMydyT+tNnf9KkFZPUvWl3zRg2Q63rtnY6FgCgGtp/Yr8mpxbNJtqeuV31AutpfNei2UQRoRFOxwNQRpRDAAB4kJX7V2rknJHaeGij7ul5jx7t86h8vX2djgUAqOYKbaE+3/Z50WyiDe+rwBbo6vCrFR8dr6Hth8rP28/piAB+BeUQAAAewFqrl394WXcvvFuhNUL11tC31LdVX6djAQDc0L7j+0rWJtqRuUP1A+trQuQE3Rpzq9rUbeN0PACloBwCAMDNHTx5UBPen6CPNn+kwW0HyzXEpfpB9Z2OBQBwc4W2UAu2LlBSSpI+2PiBCmyB+ob3VXxMvG5odwOziYAqhHIIAAA3tnDrQt383s06knVE/7723/rDpX+QMcbpWAAAD7P3+F65Ul2atGKSdh7dqQZBDYpmE0Xfyrp3QBVAOQQAgBvKLcjVg4sf1NNLn1b7eu0168ZZ6tKwi9OxAAAerqCwoGg20Yokzd84XwW2QNe0ukbx0fG6vt31zCYCHEI5BACAm9lyeIti58Rq+d7lio+O1/MDnlegb6DTsQAAOM2eY3vkSnXpjdQ3SmYTxUXG6daYW9WqTiun4wEehXIIAAA38tbKt3T7x7fLx8tHyUOSNaz9MKcjAQDwqwoKC/TZ1s+UlJKk+Zvmq9AWql+rfkqISdCQS4ZwV02gElAOAQDgBo7lHNPtH92u6aun64oWV2jasGlqUauF07EAADgve47tUXJqst5Y8YZ2HdulhkENFRcVp1ujb1V4nXCn4wFui3IIAIBq7vvd32vU3FHakblDD131kP5+xd/l7eXtdCwAAC5YQWGBPt3yqRJTEvXR5o9krVW/1kWziX7b9rfMJgLKGeUQAADVVKEt1NPfPq0Hv3hQTUKaaMawGerZoqfTsQAAKFe7j+1W8opkvZH6hnYf261GwY1K1iYKqx3mdDzALVAOAQBQDe09vldj543V4u2LNaLDCCUOTlSdGnWcjgUAQIXJL8wvmU308eaPZa1V/zb9FR8dr8FtBzObCLgIlEMAAFQz8zfO14T3JygrP0svDXhJcVFxMsY4HQsAgEqz6+iukrWJ9hzfo8bBjRUXFadbom9hNhFwASiHAACoJrLzs3X3grv1yo+vKLJRpGYOn6l29do5HQsAAMfkF+brk82flMwmkqT+bforISZBg9sOlo+Xj8MJgeqBcggAgGpg3cF1GvnuSK1OX627LrtLT17zpPx9/J2OBQBAlbHz6M6StYn2Ht+rJiFNFBdZNJuoZe2WTscDqjTKIQAAqjBrrZJSkvSnz/6kYL9gTblhigZFDHI6FgAAVVZ+Yb4+2vSRklYk6ZPNn0iSBkYMVHx0vK5rex2ziYBSUA4BAFBFHc46rFvn36q56+eqX6t+mjp0qhoFN3I6FgAA1cZPmT8pOTVZyanJ2nt8r5qGNNXEqImaGD1RLWq1cDoeUGVQDgEAUAV99dNXGj13tA6cOKAn+j6hP/f4s7yMl9OxAAColvIL8/Xhpg+VlJKkT7d8KmOMBrYZqISYBA2MGMhsIng8yiEAAKqQ/MJ8Pfrlo3r868fVqk4rzRw+U92anPH3NAAAuEA7MncoeUXRbKJ9J/apWc1mRbOJoiaqea3mTscDHEE5BABAFbEjc4dGzx2tpbuWalzXcXp54MsK8Q9xOhYAAG4pryCvaDbRiiR9tuUzGWM0KGJQ0WyiNgPl7eXtdESg0lAOAQBQBcxeO1vx8+NVaAv1n8H/0ajOo5yOBACAx9h+ZLveWPGGXGku7T+xX81qNtMtUbdoYvRENavZzOl4QIWjHAIAwEEnc0/qzk/ulCvNpcuaXqYZw2eoVZ1WTscCAMAj5RXkaf6m+UpKSdKCrQtkjNF1EdcpISZBA9oMYDYR3BblEAAADkndl6rYObHalLFJ9/W6Tw/3fli+3r5OxwIAACqaTTRpxSS5Ul06cPKAmtdsrluib9HEqIlqWrOp0/GAckU5BABAJSu0hXpx2Yu6d9G9qhdYT9OGTlOf8D5OxwIAAKXIK8jTBxs/UGJKohZuWygv46XBbQcrISZB/Vv3ZzYR3ALlEAAAlSj9ZLrGvzden2z5REMuGaLkIcmqF1jP6VgAAKAMth3Zpkkpk+RKcyn9ZLpa1GpRsjZRk5AmTscDLhjlEAAAlWTB1gW6ed7NyszO1HP9n9Nt3W6TMcbpWAAA4DzlFuSWzCb6fNvn8jbe+u0lv1V8dLyubX0ts4lQ7VAOAQBQwXILcnX/ovv17HfPqmP9jpo5fKY6N+zsdCwAAFAOth7eqkkrJmly2mSln0xXy1otdUv0LYqLimM2EaoNyiEAACrQ5ozNip0Tq5R9Kbqt22169tpnVcO3htOxAABAOcstyNX7G95XYkqiFm1fVDKbKCEmQde2vlZexsvpiMBZUQ4BAFABrLV6c+WbuuPjO+Tv46/kIcm6od0NTscCAACVYHPGZr2x4g1NTpusg6cOKqx2mG6JKppN1DiksdPxgDNQDgEAUM6OZh/V7z/6vWatmaWrWl6lacOmqVnNZk7HAgAAlSwnP0fvbyyaTbR4+2L5ePloyCVDFB8dr36t+zGbCFUG5RAAAOVo2e5lip0Tq11Hd+nh3g/rvl73sSglAADQ5ozNJWsTHTp1SOG1w3Vr9K2aEDVBjYIbOR0PHo5yCACAclBQWKCnvn1K//jiH2peq7lmDJuhHs17OB0LAABUMTn5OZq3YZ6SUpL0xY4v5OPlo+svuV4JMQnq26ovs4ngCMohAAAu0p5jezRm3hgt2bFEN3W8SYmDE1UroJbTsQAAQBW3KWOTJqUUzSbKyMpQqzqtimYTRU5Qw+CGTseDB6EcAgDgIry/4X3FfRCnnPwcvTzwZY2PHC9jjNOxAABANZKTn6O56+cqaUWSluxYIh8vH93Q7gYlxCTo6vCrmU2ECkc5BADABcjKy9JfF/xVry1/TdGNozVz+Ey1DW3rdCwAAFDNbTy0UUkpSZqycooOZx1W6zqtdWv0rRofOZ7ZRKgwlEMAAJynNelrFDsnVmvS1+gvPf6ix69+XP4+/k7HAgAAbiQ7P7toNlFKkr786Uv5evmWzCbqE96H2UQoV2crh875f5kxprkx5gtjzHpjzFpjzB+Lnx9R/H2hMeaMN/7Z6wcYYzYaY7YYY+69uN0AAKDiWWv1+o+v69JJlyr9ZLo+Gf2J/n3tvymGAABAuQvwCdCozqO0ZPwSrf/Det3R/Q4t2r5I17x1jS555RI9/e3TSj+Z7nRMuLlzzhwyxjSW1Nhau8IYEyIpRdINkqykQkmJkv5qrT1jqo8xxlvSJkn9JO2W9KOkWGvtul/7PZk5BABwSsapDN0y/xa9t+E9DWgzQFOun8LUbgAAUKmy87M1Z90cJaYk6uudX8vXy1dD2w9VQkyCeof1ZjYRLtjZZg75nOuF1tp9kvYVPz5ujFkvqam1dmHxG//ay7tL2mKt3VY8dpak6yX9ajkEAIATluxYojFzxyj9ZLqevfZZ3XX5XXz4AgAAlS7AJ0Cju4zW6C6jtf7geiWlJOnNlW9q9trZalO3jeKj4zU+crzqB9V3OircxHl94jXGhEmKkvR9GV/SVNKun32/u/i50t473hiz3Biz/ODBg+cTCwCAi5JXkKcHFj+gq9+8WkF+QVp2yzL9ucefKYYAAIDj2tdvr+cHPK+9f9mrt4a+pUbBjfS3z/+mZs83U+ycWH2x/QtVxbWEUb2U+VOvMSZY0hxJd1lrj5X1ZaU8V+r/tdbaJGttN2ttt/r1aT8BAJVj+5HtunLKlXr868c1PnK8UuJTFN042ulYAAAApwnwCdCYLmP09YSvtfb2tbqt2236dMununrq1brklUv076X/1qFTh5yOiWqqTOWQMcZXRcXQdGvt3PN4/92Smv/s+2aS9p7H6wEAqDAzV89UZGKk1h1cp1nDZ8l1vUvBfsFOxwIAAPhVHep30AsDXtDeP+/V1BumqkFQA9298G41fa6pRs0ZpSU7ljCbCOelLHcrM5KSJa231j53nu//o6QIY0y4McZP0khJH5x/TAAAys+J3BOa8P4EjZo7Sh3rd1RaQppu6nST07EAAADOSw3fGhrbday+iftGa25bo9/H/F6fbPlEfd7so3avttOzS59lNhHKpCx3K+sl6WtJq1V0dzJJul+Sv6SXJdWXlCkpzVrb3xjTRNIb1tpBxa8fJOkFSd6SXNbax88ViruVAQAqyop9KzTy3ZHacniL/n7F3/VQ74fk43XO+zMAAABUC6fyTundde8qMSVRS3ctlZ+3n27scKPio+N1Zcsrz3VTKbi5s92t7JzlkBMohwAA5a3QFur5757XfYvuU4OgBpo2bJp6h/V2OhYAAECFWZO+RkkpSZq6cqqO5hxVu3rtFB8dr5u73qzQwFCn48EBlEMAAI+1/8R+jXtvnBZsXaAb2t2gN377Bh+IAACAxziVd0qz185WUkqSvtv9nfy9/XVjhxuVEJOgXi16MZvIg1AOAQA80qdbPtW498bpWM4xPd//eSXEJPABCAAAeKzVB1YrMSVRb616S8dyjql9vfaKjymaTVS3Rl2n46GCUQ4BADxKTn6O7lt0n55f9rw6N+ismcNnqmODjk7HAgAAqBJO5p4smk20IknLdi+Tv7e/RnQcoYSYBPVs3pN/THNTlEMAAI+x8dBGxc6JVer+VP3h0j/omX7PqIZvDadjAQAAVEkr96/UpBWTSmYTdajfoWRtojo16jgdD+WIcggA4PastZqcNln/98n/qYZPDbmud2nIJUOcjgUAAFAtnMw9qbfXvq2klCR9v+d7BfgEaESHotlEv2n+G2YTuQHKIQCAW8vMzlTChwmavXa2+oT10VtD31LTmk2djgUAAFAtpe1PU1JKkqatmqbjucfVsX5HxcfEa2yXscwmqsYohwAAbmvprqUaNWeUdh/brX/2+af+1vNv8vbydjoWAABAtXcy96RmrZmlxJRE/bj3RwX4BOh3HX+nhJgE9WjWg9lE1QzlEADA7RQUFuiJr5/QI18+oha1WmjG8Bm6vNnlTscCAABwS6n7UpWUkqTpq6freO5xdWrQSfHR8RrbdaxqB9R2Oh7KgHIIAOBWdh3dpbHzxurLn77UqM6j9Nqg11QroJbTsQAAANzeidwTmrVmlpJSkvTj3h9Vw6eGbup0k+Kj43V5s8uZTVSFUQ4BANzGvPXzNPGDicotyNVr172msV3G8iEEAADAASv2rSiZTXQi94Q6N+is+Jh4jekyhtlEVRDlEACg2juVd0p//uzPSkxJVEzjGM0cPlMRoRFOxwIAAPB4x3OOl6xNlLIvRTV8amhkp5GKj4nXZU0v4x/yqgjKIQBAtbb6wGqNnDNS6w6u092/uVuPXf2Y/Lz9nI4FAACAX0jZm6KklCTNWDNDJ3JPqEvDLoqPLppNxDIAzqIcAgBUS9Zavfrjq/rrgr+qdkBtTR06Vde2vtbpWAAAADiH4znHNXPNTCWmJGrFvhUK9A3UyI5Fs4m6N+3ObCIHUA4BAKqdQ6cOKe79OM3fNF+DIgZp8vWT1SCogdOxAAAAcJ6W711eNJto9QydzDuprg27KiEmQaM6j2I2USWiHAIAVCuLty/W2HljdejUIT19zdO687I7+dclAACAau5YzjHNWD1DiSmJStufpkDfQMV2ilVCTIK6NenG570KRjkEAKgW8gry9I8v/qGnvn1KbUPbataNsxTZKNLpWAAAAChH1tqS2UQz18zUybyTimwUWTKbqKZ/TacjuiXKIQBAlbftyDbFzonVD3t+0C1Rt+iFAS8oyC/I6VgAAACoQMdyjmn6qulKTEnUygMrFeQbVDSbqFvRbCKUH8ohAECVNn3VdN320W3yMl6a9NtJGtFxhNORAAAAUImstfpx748ls4lO5Z1SdONoxUfHa1TnUQrxD3E6YrVHOQQAqJKO5xzXHZ/coakrp6pn856aPmy6WtZu6XQsAAAAOOho9lFNX100m2jVgVUK8g3SqM6jlBCToJgmMU7Hq7YohwAAVc7yvcsVOydW245s0wNXPKAHr3pQPl4+TscCAABAFWGt1Q97flBiSqJmrZmlrPwsRTeOVkJMgmI7xTKb6DxRDgEAqoxCW6hnlz6r+xffr8bBjTV92HRd0fIKp2MBAACgCjuafVTTVk1TYkqiVqevVrBfsEZ1GqWEbgmKbhztdLxqgXIIAFAl7Du+T+PeG6eF2xZqePvhmvTbSapTo47TsQAAAFBNWGv1/Z7vlZiSqLfXvK2s/Cx1a9JN8dHxiu0cq2C/YKcjVlmUQwAAx328+WONe2+cTuae1AsDXtCt0bfKGON0LAAAAFRTmdmZJbOJ1qSvUYhfiEZ3Hq34mHhFNY5yOl6VQzkEAHBMTn6O7vn8Hr34/Yvq0rCLZg6fqQ71OzgdCwAAAG7CWqtlu5cVzSZa+7ay87N1aZNLFR8Tr5GdRjKbqBjlEADAEesPrlfsnFitPLBSd3a/U0/1e0oBPgFOxwIAAICbOpJ1pGQ20dqDaxXiF6IxXcYoPiZekY0inY7nKMohAEClstYqOTVZd35yp4L8gjT5+ska3Haw07EAAADgIay1+m73d0pMSdTstbOVnZ+t7k27Kz66aDZRkF+Q0xErHeUQAKDSHMk6ovgP4/XuunfVN7yvpg6dqiYhTZyOBQAAAA91OOtwyWyidQfXqaZ/TY3pXDSbqGujrk7HqzSUQwCASvHNzm80eu5o7T2+V4/1eUx397xbXsbL6VgAAACArLVaumtpyWyinIIcXdb0MiXEJOh3HX/n9rOJKIcAABUqvzBfj3/1uB796lGF1Q7TzOEz1b1pd6djAQAAAKU6nHVYb618S4kpiVp/aL1q+tfU2C5jlRCToM4NOzsdr0JQDgEAKszOozs1eu5ofbPzG43pMkavDnpVNf1rOh0LAAAAOCdrrb7Z+Y2SViTpnbXvKKcgR5c3u7xkNlGgb6DTEcsN5RAAoEK8u+5d3Tr/VuUX5uv1617XmC5jnI4EAAAAXJCMUxmaunKqklYkacOhDarlX0v39bpP9/S6x+lo5eJs5RCLQAAALsipvFOKnx+vEe+MUETdCKUmpFIMAQAAoFoLDQzVn3r8SetuX6cvx3+pwW0HK9gv2OlYFc7H6QAAgOpn5f6Vip0Tqw2HNuienvfo0T6Pys/bz+lYAAAAQLkwxujKllfqypZXOh2lUlAOAQDKzFqrl394WXcvvFuhNUK1cOxC9W3V1+lYAAAAAC4C5RAAoEwOnjyoCe9P0EebP9J1Eddp8vWTVT+ovtOxAAAAAFwkyiEAwDl9vu1zjZ03VkeyjuilAS/pju53yBjjdCwAAAAA5YByCABwVrkFuXpw8YN6ZukzalevnT4b85m6NOzidCwAAAAA5YhyCABQqi2Htyh2TqyW712u+Oh4PT/geQX6BjodCwAAAEA5oxwCAJzhrZVv6faPb5ePl4/eHfGuhncY7nQkAAAAABWEcggAUOJYzjHd/tHtmr56uq5ocYWmDZumFrVaOB0LAAAAQAWiHAIASJK+3/29Rs0dpR2ZO/RI70f09yv+Lm8vb6djAQAAAKhglEMA4OEKbaGe/vZpPfjFg2oS0kRfjv9SvVr0cjoWAAAAgEpCOQQAHmzv8b26ed7NWrR9kUZ0GKHEwYmqU6OO07EAAAAAVCLKIQDwUPM3zteE9ycoKz9Lb/z2DcVFxckY43QsAAAAAJWMcggAPEx2frb+tvBvevmHlxXZKFIzh89Uu3rtnI4FAAAAwCGUQwDgQdYdXKfYObFadWCV7rrsLj15zZPy9/F3OhYAAAAAB1EOAYAHsNYqKSVJf/rsTwr2C9ZHoz7SoIhBTscCAAAAUAVQDgGAmzucdVi3zr9Vc9fPVb9W/fTmDW+qcUhjp2MBAAAAqCIohwDAjX3101caPXe0Dpw4oGf6PaM/9/izvIyX07EAAAAAVCGUQwDghvIL8/Xol4/q8a8fV6s6rbR04lJ1a9LN6VgAAAAAqiDKIQBwMz9l/qRRc0dp6a6lGtd1nF4e+LJC/EOcjgUAAACgiqIcAgA3MnvtbMXPj1ehLdT0YdM1qvMopyMBAAAAqOIohwDADZzMPak/fvpHJacm67Kml2nG8BlqVaeV07EAAAAAVAOUQwBQzaXuS1XsnFhtytik+3rdp0d6PyJfb1+nYwEAAACoJiiHAKCastbqxe9f1D2f36N6gfX0+c2f6+rwq52OBQAAAKCaoRwCgGoo/WS6xr83Xp9s+URDLhmi5CHJqhdYz+lYAAAAAKohyiEAqGYWbF2gm+fdrMzsTL0y8BXdfuntMsY4HQsAAABANUU5BADVRG5Brv6+6O/693f/Vsf6HbVw7EJ1btjZ6VgAAAAAqjnKIQCoBjZnbFbsnFil7EvR72N+r2f7P6tA30CnYwEAAABwA5RDAFCFWWs1deVU/eHjP8jP209zfzdXQ9sPdToWAAAAADdCOQQAVdTR7KO67aPbNHPNTF3V8ipNGzZNzWo2czoWAAAAADdDOQQAVdCy3cs0as4o7Ty6U//s80/d1+s+eXt5Ox0LAAAAgBvyOtcAY0xzY8wXxpj1xpi1xpg/Fj9f1xiz0BizufhrnbO8focxZrUxJs0Ys7y8dwAA3ElBYYGe+PoJ9XL1UqEt1FcTvtIDVz5AMQQAAACgwpRl5lC+pL9Ya1cYY0IkpRhjFkoaL2mRtfZJY8y9ku6VdM9Z3qOPtfZQuSQGADe159gejZk3Rkt2LNFNHW/Sfwb/R7UDajsdCwAAAICbO2c5ZK3dJ2lf8ePjxpj1kppKul5S7+Jhb0paorOXQwCAX/H+hvcV90GccvJz5Bri0vjI8TLGOB0LAAAAgAc452VlP2eMCZMUJel7SQ2Li6P/FkgNzvIyK2mBMSbFGBP/K+8db4xZboxZfvDgwfOJBQDVVlZelv7w0R90w9s3qGWtllqRsEIToiZQDAEAAACoNGVekNoYEyxpjqS7rLXHzuMHl57W2r3GmAaSFhpjNlhrv/rlIGttkqQkSerWrZst65sDQHW1Jn2NYufEak36Gv358j/rib5PyN/H3+lYAAAAADxMmWYOGWN8VVQMTbfWzi1++oAxpnHx9saS0kt7rbV2b/HXdEnzJHW/2NAAUJ1Za/X6j6/r0kmXKv1kuj4Z/Yme7f8sxRAAAAAAR5TlbmVGUrKk9dba53626QNJ44ofj5P0fimvDSpexFrGmCBJ10pac7GhAaC6yjiVoWGzh+n2j2/XVS2v0qrfr9KANgOcjgUAAADAg5XlsrKeksZKWm2MSSt+7n5JT0qabYyZKGmnpBGSZIxpIukNa+0gSQ0lzSu+BM1H0gxr7aflugcAUE0s2bFEY+aOUfrJdD177bO66/K75GXOa+k3AAAAACh3Zblb2TeSzrbAUN9Sxu+VNKj48TZJXS8mIABUd3kFeXrky0f0xNdPKCI0Qstilym6cbTTsQAAAABA0nksSA0AOH/bj2zXqLmjtGz3Mk2InKCXBr6kYL9gp2MBAAAAQAnKIQCoILPWzFLChwmSpJnDZ2pkp5EOJwIAAACAM1EOAUA5O5F7Qv/3yf9pStoU9WjWQ9OHTVd4nXCnYwEAAABAqSiHAKAcrdi3QiPfHakth7fogSse0EO9H5KPF3/UAgAAAKi6+IkFAMrBnmN7lJSSpH998y81CGqgxeMWq3dYb6djAQAAAMA5UQ4BwAXKLcjVh5s+VHJqsj7d8qkKbaFu7HCj/nPdfxQaGOp0PAAAAAAoE8ohADhPa9PXypXq0lur3tLBUwfVNKSp7ut1n8ZHjlebum2cjgcAAAAA54VyCADK4Gj2Ub299m0lpybrhz0/yNfLV0MuGaKJURN1betr5e3l7XREAAAAALgglEMAcBbWWn3101dKTk3Wu+veVVZ+ljo16KTn+z+v0Z1Hq35QfacjAgAAAMBFoxwCgF/Yc2yPpqRN0eS0ydp6ZKtq+tfUuK7jFBcVp25NuskY43REAAAAACg3lEMAoKLFpT/Y+IFcqS59tvUzFdpC9Qnro4d7P6xh7Ycp0DfQ6YgAAAAAUCEohwB4tNUHVsuV6tK01dN06NQhNavZTPf3ul/jI8erdd3WTscDAAAAgApHOQTA42RmZ2rWmllypbr0494f5evlqxva3aC4qDj1a9WPxaUBAAAAeBTKIQAeodAW6ssdX8qV5tK7695Vdn62OjforBf6v6DRXUarXmA9pyMCAAAAgCMohwC4tV1Hd+nNlW9qctpkbTuyTbX8a2lC5ARNjJqo6MbRLC4NAAAAwONRDgFwOzn5OUWLS6e59NmWz2RldXX41fpnn39qaLuhquFbw+mIAAAAAFBlUA4BcBurDqwqWlx61TRlZGWoec3meuDKBzQhcoLC64Q7HQ8AAAAAqiTKIQDVWmZ2pmaunqnk1GSl7EuRn7efbmh3gyZGTVTf8L4sLg0AAAAA50A5BKDaKbSFWrJjiZJTkzV3/Vxl52era8OuemnASxrVeZRCA0OdjggAAAAA1QblEIBqY+fRnZqSNkWT0yZrR+YO1Q6orYlRExUXFaeoRlEsLg0AAAAAF4ByCECVlpOfo/c3vq/k1GQt3LpQVlZ9w/vqiauf0A3tbmBxaQAAAAC4SJRDAKqklftXKjk1WdNXT9fhrMNqUauF/nHVPzQ+crzCaoc5HQ8AAAAA3AblEIAq40jWEc1YPUOuNJdW7FshP28/DWs/THGRcerbqq+8jJfTEQEAAADA7VAOAXBUoS3U4u2L5Up1ae76ucopyFFko0i9PPBljeo8SnVr1HU6IgAAAAC4NcohAI74KfOnksWlfzr6k+oE1NGt0bcWLS7dOMrpeAAAAADgMSiHAFSa7PxsvbfhPblSXfp82+eSpGtaXaMnr3lSN7S7QQE+AQ4nBAAAAADPQzkEoMKl7kuVK9Wl6aun60j2EbWs1VIPXfWQxkeOV8vaLZ2OBwAAAAAejXIIQIU4nHVYM1bPUHJqstL2p8nf279ocemoOF0dfjWLSwMAAABAFUE5BKDcFNpCLdq2SMmpyZq3YZ5yC3IV3Tharwx8RaM6j1KdGnWcjggAAAAA+AXKIQAXbUfmjpLFpXce3ak6AXWUEJOguKg4RTaKdDoeAAAAAOBXUA4BuCBZeVl6b8N7Sk5N1qLti2Rk1K91Pz3T7xkNuWQIi0sDAAAAQDVBOQSgzKy1St2fquQVyZqxZoYyszMVVjtMj/Z+VOMix6lFrRZORwQAAAAAnCfKIQDnlHEqQ9NXT5cr1aWVB1bK39tfwzsM18Soieod1pvFpQEAAACgGqMcAlCqgsICfb7tc7nSXHpvw3vKLchVtybd9Nqg1zSy00gWlwYAAAAAN0E5BOA0249s1+S0yZqSNkW7ju1S3Rp1dVu32zQhcoK6NurqdDwAAAAAQDmjHAKgrLwszV0/V640lxZvXywjo/5t+uvZa5/VkEuGyN/H3+mIAAAAAIAKQjkEeChrrVL2pciV6tKM1TN0NOeowmuH6599/qlxXcepea3mTkcEAAAAAFQCyiHAwxw6dUjTV02XK82lVQdWKcAnQDd2uFFxkXG6KuwqFpcGAAAAAA9DOQR4gILCAi3ctlCuVJfe3/i+cgtydWmTS/X6da9rZKeRqh1Q2+mIAAAAAACHUA4BbmzbkW2anDpZU1ZO0e5juxVaI1S3d7tdcVFx6tyws9PxAAAAAABVAOUQ4GZO5Z3S3PVzlZyarCU7lsjLeKl/6/56of8L+u0lv5Wft5/TEQEAAAAAVQjlEOAGrLVavne5klOTNXPNTB3LOaZWdVrpsT6PaVzkODWr2czpiAAAAACAKopyCKjGDp48qGmrpsmV5tKa9DWq4VNDN3a4UROjJuqKllewuDQAAAAA4Jwoh4BqpqCwQJ9t/UyuVJc+2PiB8grz1L1pdyUOTtRNHW9SrYBaTkcEAAAAAFQjlENANbHl8BZNTp2sN1e+qT3H96heYD3d0f0OxUXFqVODTk7HAwAAAABUU5RDQBV2Ku+U3l33rlypLn3505fyMl4a2GagXhr4kga3Hczi0gAAAACAi0Y5BFQx1lr9sOcHuVJdmrlmpo7nHlebum30xNVP6OauN6tpzaZORwQAAAAAuBHKIaCKSD+ZXrS4dKpLaw+uVaBvoEZ0GKG4qDhd0eIKGWOcjggAAAAAcEOUQ4CD8gvz9dmWz+RKK1pcOr8wX5c3u1xJg5N0U6ebVNO/ptMRAQAAAABujnIIcMDmjM2anFa0uPTe43tVP7C+/njZHzUhcoI6NujodDwAAAAAgAehHAIqycnck3p33btKTk3W1zu/lpfx0qCIQXpl4Cu6ru11LC4NAAAAAHAE5RBQgay1+n7P93KlujRrzSwdzz2uiLoR+lfff+nmrjerSUgTpyMCAAAAADwc5RBQAQ6cOFC0uHSaS+sOrlOgb6B+1/F3mhg1UT2b92RxaQAAAABAlUE5BJST/MJ8fbrlUyWnJuvDTR8qvzBfPZr10KTfTtJNHW9SiH+I0xEBAAAAADgD5RBwkTZlbJIr1aU3V76p/Sf2q0FQA9112V2Ki4pT+/rtnY4HAAAAAMCvohwCLsCJ3BN6Z+07cqW59M3Ob+RtvDUoYpAmRk3UoIhB8vX2dToiAAAAAABlQjkElJG1Vt/t/k6uVJfeXvu2TuSeUNvQtnrqmqc0tstYNQ5p7HREAAAAAADOG+UQcA77T+zXWyvfkivNpQ2HNijIN0g3dbxJcVFx+k3z37C4NAAAAACgWqMcAkqRV5CnT7Z8IleqSx9u+lAFtkC/af4bJQ9J1ogOI1hcGgAAAADgNiiHgJ/ZcGiDJqdO1tRVU7X/xH41DGqov/T4iyZETVC7eu2cjgcAAAAAQLmjHILHO55zXO+se0euVJe+3fWtvI23BrcdrLioOA1sM5DFpQEAAAAAbu2c5ZAxprmkqZIaSSqUlGStfdEYU1fS25LCJO2Q9Dtr7ZFSXj9A0ouSvCW9Ya19stzSAxfIWqulu5YqOTVZs9fO1sm8k7ok9BI9fc3TGtt1rBoFN3I6IgAAAAAAlaIsM4fyJf3FWrvCGBMiKcUYs1DSeEmLrLVPGmPulXSvpHt+/kJjjLekVyX1k7Rb0o/GmA+stevKcyeAstp/Yr+mrpwqV6pLGzM2KtgvWCM7jVRcVJx6NOvB4tIAAAAAAI9zznLIWrtP0r7ix8eNMeslNZV0vaTexcPelLREvyiHJHWXtMVau02SjDGzil9HOYRKk1eQp483f6zk1GR9vPljFdgC9WrRS/f0vEcjOo5QsF+w0xEBAAAAAHDMea05ZIwJkxQl6XtJDYuLI1lr9xljGpTykqaSdv3s+92SLjvLe8dLipekFi1anE8soFTrD66XK9WlqaumKv1kuhoFN9Jff/NXxUXFqW1oW6fjAQAAAABQJZS5HDLGBEuaI+kua+2xMl5+U9ogW9pAa22SpCRJ6tatW6ljgHM5nnNcs9fOVnJqsr7b/Z18vHyKFpeOjNPAiIHy8WINdgAAAAAAfq5MPykbY3xVVAxNt9bOLX76gDGmcfGsocaS0kt56W5JzX/2fTNJey8mMPBL1lp9s/MbudJcmr12tk7lnVL7eu31TL9nNLbLWDUMbuh0RAAAAAAAqqyy3K3MSEqWtN5a+9zPNn0gaZykJ4u/vl/Ky3+UFGGMCZe0R9JISaMuNjQgSfuO79ObK9+UK9WlzYc3K9gvWKM6jdLE6Im6rOllLC4NAAAAAEAZlGXmUE9JYyWtNsakFT93v4pKodnGmImSdkoaIUnGmCYqumX9IGttvjHmDkmfqehW9i5r7dpy3gd4kNyCXH206SO50lz6ZPMnKrAFuqLFFfr7FX/XjR1uVJBfkNMRAQAAAACoVoy1VW95n27dutnly5c7HQNVyLqD64oWl145VQdPHVTj4MYaHzle4yPHs7g0AAAAAABlYIxJsdZ2++XzrM6LKutYzjG9veZtudJcWrZ7mXy8fDTkkiGKi4xT/zb9WVwaAAAAAIBywE/XqFKstfp659dypbr0zrp3dCrvlDrU76Bnr31WY7qMUYOgBk5HBAAAAADArVAOoUrYc2yPpq6cKleaS1sOb1GIX4jGdB6juKg4dW/ancWlAQAAAACoIJRDcExuQa4+3PShklOT9emWT1VoC3VVy6v04JUPanj74SwuDQAAAABAJaAcQqVbm75WrlSX3lr1lg6eOqgmIU10b897NSFqgtrUbeN0PAAAAAAAPArlECrF0eyjmrVmllxpLv2w5wf5evkWLS4dFadrW1/L4tIAAAAAADiEn8hRYay1+uqnr5Scmqx3172rrPwsdazfUc9d+5zGdBmj+kH1nY4IAAAAAIDHoxxCudt9bLfeTHtTk9Mma+uRrarpX1M3d71ZcVFxurTJpSwuDQAAAABAFUI5hHKRW5CrDzZ+IFeqS59t/UyFtlC9w3rroase0vAOwxXoG+h0RAAAAAAAUArKIVyU1QdWy5Xq0rTV03To1CE1DWmq+3rdpwmRE9S6bmun4wEAAAAAgHOgHMJ5y8zOLFpcOtWlH/f+KF8vX13f7npNjJqofq36ydvL2+mIAAAAAACgjCiHUCaFtlBf7vhSrjSX3l33rrLzs9WpQSc93/95jekyRvUC6zkdEQAAAAAAXADKIfyqXUd36c2VRYtLbzuyTbX8a2lC5ATFRcUppnEMi0sDAAAAAFDNUQ7hDDn5Ofpg4wdKTk3Wgq0LZGXVJ6yPHu39qIa2H8ri0gAAAAAAuBHKIZRYdWBV0eLSq6YpIytDzWo20wNXPqDxkePVqk4rp+MBAAAAAIAKQDnk4TKzMzVz9UwlpyYrZV+K/Lz9dEO7GxQXGadrWl3D4tIAAAAAALg5yiEPVGgLtWTHEiWnJmvu+rnKzs9Wl4Zd9OKAFzW682iFBoY6HREAAAAAAFQSyiEPsvPoTk1Jm6LJaZO1I3OHavnXUlxknOKi4hTdOJrFpQEAAAAA8ECUQ24uJz9H7214T640lxZuXSgrq77hffX41Y9raLuhquFbw+mIAAAAAADAQZRDbiptf5pcqS5NXz1dh7MOq3nN5nrwygc1PnK8wuuEOx0PAAAAAABUEZRDbuRI1hHNWD1DrjSXVuxbIT9vPw1tN1RxUXHqG96XxaUBAAAAAMAZKIequUJbqMXbF8uV6tLc9XOVU5Cjrg276qUBL2l0l9GqW6Ou0xEBAAAAAEAVRjlUTf2U+VPJ4tI/Hf1JtQNq65boWzQxaqKiGkc5HQ8AAAAAAFQTlEPVSHZ+dtHi0qkufb7tc1lZXdPqGj15zZO6od0NCvAJcDoiAAAAAACoZiiHqoHUfalKTk3W9NXTlZmdqZa1Wuqhqx7SuMhxCqsd5nQ8AAAAAABQjVEOVVGHsw5rxuoZSk5NVtr+NPl7+2to+6GaGDVRV4dfLS/j5XREAAAAAADgBiiHqpBCW6hF2xYpOTVZ8zbMU25BrqIaRemVga8otnMsi0sDAAAAAIByRzlUBezI3KHJqZM1ZeUU7Ty6U3UC6ighJkETIiewuDQAAAAAAKhQlEMOycrL0nsb3lNyarIWbV8kI6N+rfvp6Wue1vXtrmdxaQAAAAAAUCkohyqRtVYr9q2QK9WlGWtmKDM7U2G1w/RI70c0rus4tazd0umIAAAAAADAw1AOVYKMUxmavnq6XKkurTywUv7e/hreYbjiIuPUJ7wPi0sDAAAAAADHUA5VkILCAn2+7XO50lx6b8N7yi3IVUzjGL066FXFdopVnRp1nI4IAAAAAABAOVRR/vnVP/XIl4+obo26+n3M7xUXFaeujbo6HQsAAAAAAOA0lEMVZGyXsepQv4Ouv+R6+fv4Ox0HAAAAAACgVJRDFaR13dZqXbe10zEAAAAAAAB+FSshAwAAAAAAeDDKIQAAAAAAAA9GOQQAAAAAAODBKIcAAAAAAAA8GOUQAAAAAACAB6McAgAAAAAA8GCUQwAAAAAAAB6McggAAAAAAMCDUQ4BAAAAAAB4MMohAAAAAAAAD0Y5BAAAAAAA4MEohwAAAAAAADwY5RAAAAAAAIAHoxwCAAAAAADwYJRDAAAAAAAAHoxyCAAAAAAAwINRDgEAAAAAAHgwyiEAAAAAAAAPRjkEAAAAAADgwSiHAAAAAAAAPBjlEAAAAAAAgAejHAIAAAAAAPBglEMAAAAAAAAejHIIAAAAAADAg1EOAQAAAAAAeDDKIQAAAAAAAA9GOQQAAAAAAODBzlkOGWNcxph0Y8yanz3X1RjznTFmtTFmvjGm5lleu6N4TJoxZnl5BgcAAAAAAMDFK8vMoSmSBvziuTck3Wut7SxpnqS7f+X1fay1kdbabhcWEQAAAAAAABXlnOWQtfYrSYd/8fQlkr4qfrxQ0vByzgUAAAAAAIBKcKFrDq2RNKT48QhJzc8yzkpaYIxJMcbE/9obGmPijTHLjTHLDx48eIGxAAAAAAAAcD4utByKk/QHY0yKpBBJuWcZ19NaGy1pYPH4K8/2htbaJGttN2ttt/r1619gLAAAAAAAAJyPCyqHrLUbrLXXWmtjJM2UtPUs4/YWf01X0dpE3S80KAAAAAAAAMrfBZVDxpgGxV+9JD0g6T+ljAkyxoT897Gka1V0ORoAAAAAAACqiLLcyn6mpO8kXWKM2W2MmSgp1hizSdIGSXslTS4e28QY83HxSxtK+sYYs1LSD5I+stZ+WhE7AQAAAAAAgAvjc64B1trYs2x6sZSxeyUNKn68TVLXi0oHAAAAAACACnWhC1IDAAAAAADADVAOAQAAAAAAeDDKIQAAAAAAAA9GOQQAAAAAAODBKIcAAAAAAAA8GOUQAAAAAACAB6McAgAAAAAA8GCUQwAAAAAAAB6McggAAAAAAMCDUQ4BAAAAAAB4MMohAAAAAAAAD0Y5BAAAAAAA4MEohwAAAAAAADwY5RAAAAAAAIAHoxwCAAAAAADwYJRDAAAAAAAAHoxyCAAAAAAAwINRDgEAAAAAAHgwyiEAAAAAAAAPRjkEAAAAAADgwSiHAKC8fPed9K9/FX0FAAAAgGrCx+kAAOAWvvtO6ttXys2V/PykRYukHj2cTgWgon33nbRkidS7N+c8AACotiiHAKA8LFlSVAwVFBR9XbKEHxQBd0cpDAAA3ASXlQFAeejdu+iHQ2/voq+9ezudCEBFK60UBgAAqIaYOVRRmGYOeJYePYpmDXDeA57jv6Xwf2cOUQoD7o/P+ADcFOVQRWCaOeCZevTgXAc8CaUw4Fn4jA94Jg8phSmHKgJrjwAA4BkohQHPwWd8wPN4UCnMmkMVgbVHAAAAAPfCZ3zA83jQ+oLMHKoITDMHAAAA3Auf8QHP40HrCxprrdMZztCtWze7fPlyp2MAAAAAAABP5mZrDhljUqy13X75PDOHAAAAAAAASuMh6wuy5hAAAAAAAIAHoxwCAAAAAADwYJRDAAAAAAAAHoxyCAAAAAAAwINRDgEAAAAAAHgwyiEAAAAAAAAPRjkEAAAAAADgwSiHAAAAAAAAPBjlEAAAAAAAgAejHAIAAAAAAPBglEMAAAAAAAAejHIIAAAAAADAg1EOAQAAAAAAeDBjrXU6wxmMMQcl/eR0jnJQT9Ihp0PAERx7z8Wx91wce8/FsfdMHHfPxbH3XBx7z+VOx76ltbb+L5+skuWQuzDGLLfWdnM6Byofx95zcew9F8fec3HsPRPH3XNx7D0Xx95zecKx57IyAAAAAAAAD0Y5BAAAAAAA4MEohypWktMB4BiOvefi2Hsujr3n4th7Jo675+LYey6Ovedy+2PPmkMAAAAAAAAejJlDAAAAAAAAHoxyCAAAAAAAwINRDpUDY8wAY8xGY8wWY8y9pWw3xpiXirevMsZEO5ET5a8Mx763MeaoMSat+Nc/nMiJ8mWMcRlj0o0xa86ynXPeTZXh2HPOuyFjTHNjzBfGmPXGmLXGmD+WMobz3g2V8dhz3rshY0yAMeYHY8zK4mP/SCljOO/dUBmPPee9mzLGeBtjUo0xH5ayza3PeR+nA1R3xhhvSa9K6idpt6QfjTEfWGvX/WzYQEkRxb8uk/R68VdUY2U89pL0tbV2cKUHREWaIukVSVPPsp1z3n1N0a8fe4lz3h3lS/qLtXaFMSZEUooxZiF/13uEshx7ifPeHeVIutpae8IY4yvpG2PMJ9baZT8bw3nvnspy7CXOe3f1R0nrJdUsZZtbn/PMHLp43SVtsdZus9bmSpol6fpfjLle0lRbZJmk2saYxpUdFOWuLMcebsha+5Wkw78yhHPeTZXh2MMNWWv3WWtXFD8+rqIPjU1/MYzz3g2V8djDDRWfyyeKv/Ut/vXLO/lw3ruhMh57uCFjTDNJ10l64yxD3Pqcpxy6eE0l7frZ97t15oeGsoxB9VPW49qjeFrqJ8aYjpUTDQ7jnPdsnPNuzBgTJilK0ve/2MR57+Z+5dhLnPduqfjykjRJ6ZIWWms57z1EGY69xHnvjl6Q9DdJhWfZ7tbnPOXQxTOlPPfLZrksY1D9lOW4rpDU0lrbVdLLkt6r6FCoEjjnPRfnvBszxgRLmiPpLmvtsV9uLuUlnPdu4hzHnvPeTVlrC6y1kZKaSepujOn0iyGc926qDMee897NGGMGS0q31qb82rBSnnObc55y6OLtltT8Z983k7T3Asag+jnncbXWHvvvtFRr7ceSfI0x9SovIhzCOe+hOOfdV/G6E3MkTbfWzi1lCOe9mzrXsee8d3/W2kxJSyQN+MUmzns3d7Zjz3nvlnpKGmKM2aGi5UKuNsZM+8UYtz7nKYcu3o+SIowx4cYYP0kjJX3wizEfSLq5eHXzyyUdtdbuq+ygKHfnPPbGmEbGGFP8uLuKzrmMSk+KysY576E4591T8TFNlrTeWvvcWYZx3ruhshx7znv3ZIypb4ypXfy4hqRrJG34xTDOezdUlmPPee9+rLX3WWubWWvDVPRz3WJr7ZhfDHPrc567lV0ka22+MeYOSZ9J8pbkstauNcb8vnj7fyR9LGmQpC2STkma4FRelJ8yHvsbJd1mjMmXlCVppLXWbaYeeipjzExJvSXVM8bslvSQihYr5Jx3c2U49pzz7qmnpLGSVhevQSFJ90tqIXHeu7myHHvOe/fUWNKbxXen9ZI021r7IZ/xPUJZjj3nvYfwpHPe8P8wAAAAAACA5+KyMgAAAAAAAA9GOQQAAAAAAODBKIcAAAAAAAA8GOUQAAAAAACAB6McAgAAAAAA8GCUQwAAAAAAAB6McggAAAAAAMCD/T+cfYV1HX3p1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred = np.array(model.predict(X_test))\n",
    "\n",
    "plt.plot(y_test_pred, '.r', label='predicted')\n",
    "plt.plot(np.array(y_test), 'g', label='true')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 - 0s - loss: 2.8540 - mae: 1.5305 - 14ms/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_mse: 2.85, test_mae: 1.53'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "test_mse, test_mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "\n",
    "print \n",
    "(f'test_mse: {round(test_mse, 2)}, test_mae: {round(test_mae,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guYTy52CTEPL"
   },
   "source": [
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    "Теперь, когда мы знаем как работает LSTM, давайте бегло взглянем на то, как работает GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XKvuvLiD3_B",
    "outputId": "671676be-ca95-481c-ad27-ac7a01c19d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 128)               51456     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51585 (201.50 KB)\n",
      "Trainable params: 51585 (201.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(128, input_shape=(10, 4)))\n",
    "model.add(Dense(1, activation='elu'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYH7T6caEBp5",
    "outputId": "6d18b822-fe93-4ff7-942c-9d21a0d6d5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "2/2 [==============================] - 1s 228ms/step - loss: 315.1051 - mae: 17.7036 - val_loss: 411.8324 - val_mae: 20.2805\n",
      "Epoch 2/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 308.1080 - mae: 17.5086 - val_loss: 398.3065 - val_mae: 19.9440\n",
      "Epoch 3/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 300.6981 - mae: 17.2989 - val_loss: 383.2193 - val_mae: 19.5619\n",
      "Epoch 4/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 292.2068 - mae: 17.0557 - val_loss: 365.3618 - val_mae: 19.0999\n",
      "Epoch 5/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 282.5379 - mae: 16.7725 - val_loss: 343.1857 - val_mae: 18.5102\n",
      "Epoch 6/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 270.1912 - mae: 16.4040 - val_loss: 313.9586 - val_mae: 17.7034\n",
      "Epoch 7/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 253.5419 - mae: 15.8937 - val_loss: 272.7861 - val_mae: 16.5003\n",
      "Epoch 8/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 230.0126 - mae: 15.1407 - val_loss: 215.1359 - val_mae: 14.6509\n",
      "Epoch 9/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 194.7208 - mae: 13.9265 - val_loss: 149.9734 - val_mae: 12.2282\n",
      "Epoch 10/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 145.2828 - mae: 12.0115 - val_loss: 102.0228 - val_mae: 10.0777\n",
      "Epoch 11/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 89.0860 - mae: 9.3851 - val_loss: 76.8667 - val_mae: 8.7387\n",
      "Epoch 12/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 45.9790 - mae: 6.7341 - val_loss: 62.8750 - val_mae: 7.8970\n",
      "Epoch 13/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 28.1287 - mae: 5.1802 - val_loss: 53.4136 - val_mae: 7.2732\n",
      "Epoch 14/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 20.4538 - mae: 4.3350 - val_loss: 46.2628 - val_mae: 6.7637\n",
      "Epoch 15/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 15.8718 - mae: 3.7633 - val_loss: 40.5505 - val_mae: 6.3274\n",
      "Epoch 16/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 12.6512 - mae: 3.3029 - val_loss: 35.7763 - val_mae: 5.9382\n",
      "Epoch 17/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 10.2093 - mae: 2.9018 - val_loss: 31.7166 - val_mae: 5.5859\n",
      "Epoch 18/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.2350 - mae: 2.5440 - val_loss: 28.2151 - val_mae: 5.2631\n",
      "Epoch 19/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.6967 - mae: 2.2316 - val_loss: 25.1528 - val_mae: 4.9637\n",
      "Epoch 20/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.4633 - mae: 1.9749 - val_loss: 22.4942 - val_mae: 4.6883\n",
      "Epoch 21/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.4954 - mae: 1.7566 - val_loss: 20.2135 - val_mae: 4.4384\n",
      "Epoch 22/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.7399 - mae: 1.5778 - val_loss: 18.2730 - val_mae: 4.2141\n",
      "Epoch 23/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.1630 - mae: 1.4519 - val_loss: 16.6125 - val_mae: 4.0123\n",
      "Epoch 24/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.7309 - mae: 1.3720 - val_loss: 15.1807 - val_mae: 3.8297\n",
      "Epoch 25/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4168 - mae: 1.3301 - val_loss: 13.9586 - val_mae: 3.6667\n",
      "Epoch 26/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1786 - mae: 1.3017 - val_loss: 12.9221 - val_mae: 3.5225\n",
      "Epoch 27/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0240 - mae: 1.2850 - val_loss: 12.0540 - val_mae: 3.3970\n",
      "Epoch 28/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9057 - mae: 1.2635 - val_loss: 11.3278 - val_mae: 3.2884\n",
      "Epoch 29/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8299 - mae: 1.2453 - val_loss: 10.6803 - val_mae: 3.1884\n",
      "Epoch 30/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7925 - mae: 1.2338 - val_loss: 10.1016 - val_mae: 3.0964\n",
      "Epoch 31/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7721 - mae: 1.2217 - val_loss: 9.6107 - val_mae: 3.0161\n",
      "Epoch 32/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7652 - mae: 1.2154 - val_loss: 9.1988 - val_mae: 2.9470\n",
      "Epoch 33/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7764 - mae: 1.2152 - val_loss: 8.8787 - val_mae: 2.8922\n",
      "Epoch 34/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7821 - mae: 1.2121 - val_loss: 8.6418 - val_mae: 2.8509\n",
      "Epoch 35/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7912 - mae: 1.2100 - val_loss: 8.4246 - val_mae: 2.8125\n",
      "Epoch 36/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8068 - mae: 1.2117 - val_loss: 8.2145 - val_mae: 2.7749\n",
      "Epoch 37/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8251 - mae: 1.2127 - val_loss: 8.0433 - val_mae: 2.7439\n",
      "Epoch 38/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8414 - mae: 1.2144 - val_loss: 7.9278 - val_mae: 2.7228\n",
      "Epoch 39/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8546 - mae: 1.2152 - val_loss: 7.8992 - val_mae: 2.7175\n",
      "Epoch 40/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8546 - mae: 1.2144 - val_loss: 7.9762 - val_mae: 2.7317\n",
      "Epoch 41/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8434 - mae: 1.2133 - val_loss: 8.1472 - val_mae: 2.7628\n",
      "Epoch 42/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8334 - mae: 1.2150 - val_loss: 8.3348 - val_mae: 2.7965\n",
      "Epoch 43/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8141 - mae: 1.2127 - val_loss: 8.4780 - val_mae: 2.8220\n",
      "Epoch 44/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8014 - mae: 1.2112 - val_loss: 8.6355 - val_mae: 2.8498\n",
      "Epoch 45/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7935 - mae: 1.2105 - val_loss: 8.8043 - val_mae: 2.8792\n",
      "Epoch 46/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7842 - mae: 1.2113 - val_loss: 8.9519 - val_mae: 2.9048\n",
      "Epoch 47/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7749 - mae: 1.2115 - val_loss: 9.1254 - val_mae: 2.9345\n",
      "Epoch 48/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7753 - mae: 1.2148 - val_loss: 9.2906 - val_mae: 2.9625\n",
      "Epoch 49/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7694 - mae: 1.2143 - val_loss: 9.3726 - val_mae: 2.9763\n",
      "Epoch 50/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7664 - mae: 1.2142 - val_loss: 9.4314 - val_mae: 2.9862\n",
      "Epoch 51/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7664 - mae: 1.2147 - val_loss: 9.4825 - val_mae: 2.9947\n",
      "Epoch 52/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7660 - mae: 1.2150 - val_loss: 9.4713 - val_mae: 2.9928\n",
      "Epoch 53/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7651 - mae: 1.2145 - val_loss: 9.4175 - val_mae: 2.9838\n",
      "Epoch 54/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7659 - mae: 1.2145 - val_loss: 9.3872 - val_mae: 2.9787\n",
      "Epoch 55/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7657 - mae: 1.2141 - val_loss: 9.3873 - val_mae: 2.9788\n",
      "Epoch 56/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7655 - mae: 1.2141 - val_loss: 9.3946 - val_mae: 2.9800\n",
      "Epoch 57/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7652 - mae: 1.2141 - val_loss: 9.4228 - val_mae: 2.9847\n",
      "Epoch 58/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7649 - mae: 1.2143 - val_loss: 9.4650 - val_mae: 2.9918\n",
      "Epoch 59/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7649 - mae: 1.2146 - val_loss: 9.4553 - val_mae: 2.9901\n",
      "Epoch 60/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7654 - mae: 1.2147 - val_loss: 9.4531 - val_mae: 2.9898\n",
      "Epoch 61/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7643 - mae: 1.2143 - val_loss: 9.4919 - val_mae: 2.9963\n",
      "Epoch 62/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7635 - mae: 1.2143 - val_loss: 9.5169 - val_mae: 3.0004\n",
      "Epoch 63/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7631 - mae: 1.2143 - val_loss: 9.5565 - val_mae: 3.0070\n",
      "Epoch 64/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7639 - mae: 1.2149 - val_loss: 9.5629 - val_mae: 3.0081\n",
      "Epoch 65/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7635 - mae: 1.2148 - val_loss: 9.5622 - val_mae: 3.0080\n",
      "Epoch 66/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7622 - mae: 1.2144 - val_loss: 9.6307 - val_mae: 3.0193\n",
      "Epoch 67/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7611 - mae: 1.2142 - val_loss: 9.7591 - val_mae: 3.0405\n",
      "Epoch 68/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7631 - mae: 1.2170 - val_loss: 9.9070 - val_mae: 3.0647\n",
      "Epoch 69/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7643 - mae: 1.2184 - val_loss: 10.0378 - val_mae: 3.0860\n",
      "Epoch 70/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7679 - mae: 1.2207 - val_loss: 10.1458 - val_mae: 3.1035\n",
      "Epoch 71/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7699 - mae: 1.2218 - val_loss: 10.2319 - val_mae: 3.1173\n",
      "Epoch 72/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7730 - mae: 1.2239 - val_loss: 10.3027 - val_mae: 3.1286\n",
      "Epoch 73/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7752 - mae: 1.2254 - val_loss: 10.3494 - val_mae: 3.1361\n",
      "Epoch 74/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7768 - mae: 1.2263 - val_loss: 10.3917 - val_mae: 3.1428\n",
      "Epoch 75/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7796 - mae: 1.2276 - val_loss: 10.3638 - val_mae: 3.1384\n",
      "Epoch 76/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7775 - mae: 1.2269 - val_loss: 10.2700 - val_mae: 3.1234\n",
      "Epoch 77/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7739 - mae: 1.2243 - val_loss: 10.1986 - val_mae: 3.1119\n",
      "Epoch 78/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7716 - mae: 1.2229 - val_loss: 10.1632 - val_mae: 3.1063\n",
      "Epoch 79/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7698 - mae: 1.2219 - val_loss: 10.1105 - val_mae: 3.0978\n",
      "Epoch 80/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7684 - mae: 1.2213 - val_loss: 10.0222 - val_mae: 3.0835\n",
      "Epoch 81/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7650 - mae: 1.2197 - val_loss: 9.9177 - val_mae: 3.0665\n",
      "Epoch 82/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7640 - mae: 1.2186 - val_loss: 9.8027 - val_mae: 3.0477\n",
      "Epoch 83/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7614 - mae: 1.2165 - val_loss: 9.7141 - val_mae: 3.0331\n",
      "Epoch 84/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7609 - mae: 1.2156 - val_loss: 9.6480 - val_mae: 3.0222\n",
      "Epoch 85/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7612 - mae: 1.2148 - val_loss: 9.6656 - val_mae: 3.0251\n",
      "Epoch 86/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7592 - mae: 1.2144 - val_loss: 9.7717 - val_mae: 3.0426\n",
      "Epoch 87/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7608 - mae: 1.2164 - val_loss: 9.8822 - val_mae: 3.0607\n",
      "Epoch 88/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7634 - mae: 1.2183 - val_loss: 9.9200 - val_mae: 3.0668\n",
      "Epoch 89/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7626 - mae: 1.2181 - val_loss: 9.9043 - val_mae: 3.0643\n",
      "Epoch 90/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7621 - mae: 1.2178 - val_loss: 9.8778 - val_mae: 3.0600\n",
      "Epoch 91/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7613 - mae: 1.2173 - val_loss: 9.8182 - val_mae: 3.0502\n",
      "Epoch 92/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7594 - mae: 1.2161 - val_loss: 9.6982 - val_mae: 3.0305\n",
      "Epoch 93/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7575 - mae: 1.2144 - val_loss: 9.5167 - val_mae: 3.0004\n",
      "Epoch 94/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7576 - mae: 1.2125 - val_loss: 9.3263 - val_mae: 2.9685\n",
      "Epoch 95/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7598 - mae: 1.2115 - val_loss: 9.1608 - val_mae: 2.9405\n",
      "Epoch 96/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7615 - mae: 1.2108 - val_loss: 9.0058 - val_mae: 2.9140\n",
      "Epoch 97/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7669 - mae: 1.2099 - val_loss: 8.8608 - val_mae: 2.8890\n",
      "Epoch 98/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7727 - mae: 1.2098 - val_loss: 8.7721 - val_mae: 2.8736\n",
      "Epoch 99/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7762 - mae: 1.2091 - val_loss: 8.7549 - val_mae: 2.8706\n",
      "Epoch 100/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7764 - mae: 1.2089 - val_loss: 8.7774 - val_mae: 2.8745\n",
      "Epoch 101/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7751 - mae: 1.2089 - val_loss: 8.8093 - val_mae: 2.8801\n",
      "Epoch 102/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7738 - mae: 1.2092 - val_loss: 8.8353 - val_mae: 2.8846\n",
      "Epoch 103/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7721 - mae: 1.2091 - val_loss: 8.8771 - val_mae: 2.8918\n",
      "Epoch 104/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7699 - mae: 1.2091 - val_loss: 8.9655 - val_mae: 2.9071\n",
      "Epoch 105/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7688 - mae: 1.2105 - val_loss: 9.0146 - val_mae: 2.9155\n",
      "Epoch 106/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7651 - mae: 1.2099 - val_loss: 8.9770 - val_mae: 2.9090\n",
      "Epoch 107/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7660 - mae: 1.2095 - val_loss: 8.9193 - val_mae: 2.8991\n",
      "Epoch 108/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7674 - mae: 1.2091 - val_loss: 8.8261 - val_mae: 2.8830\n",
      "Epoch 109/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7731 - mae: 1.2092 - val_loss: 8.7369 - val_mae: 2.8675\n",
      "Epoch 110/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7751 - mae: 1.2082 - val_loss: 8.6675 - val_mae: 2.8553\n",
      "Epoch 111/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7777 - mae: 1.2072 - val_loss: 8.5469 - val_mae: 2.8342\n",
      "Epoch 112/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7868 - mae: 1.2076 - val_loss: 8.4766 - val_mae: 2.8217\n",
      "Epoch 113/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7894 - mae: 1.2075 - val_loss: 8.5132 - val_mae: 2.8282\n",
      "Epoch 114/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7883 - mae: 1.2080 - val_loss: 8.5566 - val_mae: 2.8359\n",
      "Epoch 115/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7841 - mae: 1.2072 - val_loss: 8.6357 - val_mae: 2.8498\n",
      "Epoch 116/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7783 - mae: 1.2071 - val_loss: 8.8116 - val_mae: 2.8805\n",
      "Epoch 117/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7698 - mae: 1.2079 - val_loss: 8.9972 - val_mae: 2.9125\n",
      "Epoch 118/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7630 - mae: 1.2088 - val_loss: 9.1759 - val_mae: 2.9430\n",
      "Epoch 119/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7587 - mae: 1.2105 - val_loss: 9.3305 - val_mae: 2.9692\n",
      "Epoch 120/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7539 - mae: 1.2099 - val_loss: 9.5037 - val_mae: 2.9982\n",
      "Epoch 121/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7526 - mae: 1.2111 - val_loss: 9.7280 - val_mae: 3.0354\n",
      "Epoch 122/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7574 - mae: 1.2147 - val_loss: 9.9087 - val_mae: 3.0650\n",
      "Epoch 123/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7575 - mae: 1.2164 - val_loss: 10.0214 - val_mae: 3.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7610 - mae: 1.2184 - val_loss: 10.0856 - val_mae: 3.0937\n",
      "Epoch 125/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7618 - mae: 1.2191 - val_loss: 10.0862 - val_mae: 3.0938\n",
      "Epoch 126/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7615 - mae: 1.2190 - val_loss: 10.0306 - val_mae: 3.0848\n",
      "Epoch 127/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7593 - mae: 1.2180 - val_loss: 9.9110 - val_mae: 3.0654\n",
      "Epoch 128/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7568 - mae: 1.2168 - val_loss: 9.7675 - val_mae: 3.0419\n",
      "Epoch 129/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7554 - mae: 1.2141 - val_loss: 9.6574 - val_mae: 3.0237\n",
      "Epoch 130/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7532 - mae: 1.2127 - val_loss: 9.5721 - val_mae: 3.0096\n",
      "Epoch 131/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7526 - mae: 1.2114 - val_loss: 9.4717 - val_mae: 2.9929\n",
      "Epoch 132/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7525 - mae: 1.2107 - val_loss: 9.3636 - val_mae: 2.9747\n",
      "Epoch 133/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7531 - mae: 1.2106 - val_loss: 9.2579 - val_mae: 2.9569\n",
      "Epoch 134/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7549 - mae: 1.2100 - val_loss: 9.1805 - val_mae: 2.9438\n",
      "Epoch 135/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7565 - mae: 1.2095 - val_loss: 9.1818 - val_mae: 2.9440\n",
      "Epoch 136/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7562 - mae: 1.2095 - val_loss: 9.2076 - val_mae: 2.9484\n",
      "Epoch 137/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7550 - mae: 1.2094 - val_loss: 9.2405 - val_mae: 2.9540\n",
      "Epoch 138/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7539 - mae: 1.2093 - val_loss: 9.3240 - val_mae: 2.9681\n",
      "Epoch 139/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7541 - mae: 1.2106 - val_loss: 9.3596 - val_mae: 2.9741\n",
      "Epoch 140/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7526 - mae: 1.2100 - val_loss: 9.3845 - val_mae: 2.9782\n",
      "Epoch 141/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7520 - mae: 1.2102 - val_loss: 9.4500 - val_mae: 2.9892\n",
      "Epoch 142/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7518 - mae: 1.2105 - val_loss: 9.4711 - val_mae: 2.9928\n",
      "Epoch 143/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7511 - mae: 1.2104 - val_loss: 9.4376 - val_mae: 2.9872\n",
      "Epoch 144/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7517 - mae: 1.2103 - val_loss: 9.4266 - val_mae: 2.9853\n",
      "Epoch 145/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7506 - mae: 1.2099 - val_loss: 9.5240 - val_mae: 3.0016\n",
      "Epoch 146/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7511 - mae: 1.2109 - val_loss: 9.6603 - val_mae: 3.0242\n",
      "Epoch 147/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7526 - mae: 1.2130 - val_loss: 9.7007 - val_mae: 3.0309\n",
      "Epoch 148/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7509 - mae: 1.2127 - val_loss: 9.6322 - val_mae: 3.0196\n",
      "Epoch 149/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7537 - mae: 1.2126 - val_loss: 9.6239 - val_mae: 3.0182\n",
      "Epoch 150/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7500 - mae: 1.2114 - val_loss: 9.7275 - val_mae: 3.0353\n",
      "Epoch 151/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7536 - mae: 1.2138 - val_loss: 9.7406 - val_mae: 3.0375\n",
      "Epoch 152/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7496 - mae: 1.2127 - val_loss: 9.5803 - val_mae: 3.0110\n",
      "Epoch 153/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7485 - mae: 1.2110 - val_loss: 9.3473 - val_mae: 2.9720\n",
      "Epoch 154/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7501 - mae: 1.2098 - val_loss: 9.1465 - val_mae: 2.9380\n",
      "Epoch 155/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7524 - mae: 1.2078 - val_loss: 8.9830 - val_mae: 2.9101\n",
      "Epoch 156/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7580 - mae: 1.2077 - val_loss: 8.8770 - val_mae: 2.8918\n",
      "Epoch 157/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7605 - mae: 1.2067 - val_loss: 8.8412 - val_mae: 2.8856\n",
      "Epoch 158/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7615 - mae: 1.2066 - val_loss: 8.8026 - val_mae: 2.8789\n",
      "Epoch 159/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7641 - mae: 1.2068 - val_loss: 8.8068 - val_mae: 2.8796\n",
      "Epoch 160/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7631 - mae: 1.2065 - val_loss: 8.8667 - val_mae: 2.8900\n",
      "Epoch 161/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7602 - mae: 1.2067 - val_loss: 8.8968 - val_mae: 2.8952\n",
      "Epoch 162/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7586 - mae: 1.2067 - val_loss: 8.9408 - val_mae: 2.9028\n",
      "Epoch 163/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7583 - mae: 1.2075 - val_loss: 8.9573 - val_mae: 2.9057\n",
      "Epoch 164/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7561 - mae: 1.2068 - val_loss: 8.8761 - val_mae: 2.8916\n",
      "Epoch 165/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7597 - mae: 1.2067 - val_loss: 8.7882 - val_mae: 2.8764\n",
      "Epoch 166/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7627 - mae: 1.2061 - val_loss: 8.7842 - val_mae: 2.8757\n",
      "Epoch 167/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7633 - mae: 1.2064 - val_loss: 8.7723 - val_mae: 2.8736\n",
      "Epoch 168/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7634 - mae: 1.2060 - val_loss: 8.7557 - val_mae: 2.8707\n",
      "Epoch 169/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7627 - mae: 1.2056 - val_loss: 8.8394 - val_mae: 2.8853\n",
      "Epoch 170/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7599 - mae: 1.2064 - val_loss: 8.9537 - val_mae: 2.9050\n",
      "Epoch 171/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7559 - mae: 1.2068 - val_loss: 9.0292 - val_mae: 2.9180\n",
      "Epoch 172/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7526 - mae: 1.2068 - val_loss: 9.1077 - val_mae: 2.9314\n",
      "Epoch 173/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7515 - mae: 1.2075 - val_loss: 9.1899 - val_mae: 2.9454\n",
      "Epoch 174/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7493 - mae: 1.2078 - val_loss: 9.2257 - val_mae: 2.9515\n",
      "Epoch 175/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7485 - mae: 1.2078 - val_loss: 9.2212 - val_mae: 2.9507\n",
      "Epoch 176/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7484 - mae: 1.2077 - val_loss: 9.2154 - val_mae: 2.9497\n",
      "Epoch 177/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7482 - mae: 1.2077 - val_loss: 9.2293 - val_mae: 2.9521\n",
      "Epoch 178/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7480 - mae: 1.2077 - val_loss: 9.2091 - val_mae: 2.9487\n",
      "Epoch 179/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7477 - mae: 1.2072 - val_loss: 9.1347 - val_mae: 2.9360\n",
      "Epoch 180/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7484 - mae: 1.2069 - val_loss: 9.0150 - val_mae: 2.9156\n",
      "Epoch 181/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7512 - mae: 1.2061 - val_loss: 8.8706 - val_mae: 2.8907\n",
      "Epoch 182/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7556 - mae: 1.2054 - val_loss: 8.7262 - val_mae: 2.8656\n",
      "Epoch 183/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7636 - mae: 1.2053 - val_loss: 8.6449 - val_mae: 2.8514\n",
      "Epoch 184/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7658 - mae: 1.2045 - val_loss: 8.6528 - val_mae: 2.8528\n",
      "Epoch 185/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7658 - mae: 1.2049 - val_loss: 8.6472 - val_mae: 2.8518\n",
      "Epoch 186/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7653 - mae: 1.2043 - val_loss: 8.6145 - val_mae: 2.8461\n",
      "Epoch 187/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7671 - mae: 1.2043 - val_loss: 8.6501 - val_mae: 2.8523\n",
      "Epoch 188/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7630 - mae: 1.2037 - val_loss: 8.8247 - val_mae: 2.8828\n",
      "Epoch 189/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7561 - mae: 1.2046 - val_loss: 9.0826 - val_mae: 2.9271\n",
      "Epoch 190/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7455 - mae: 1.2047 - val_loss: 9.3725 - val_mae: 2.9763\n",
      "Epoch 191/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7481 - mae: 1.2086 - val_loss: 9.6322 - val_mae: 3.0196\n",
      "Epoch 192/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7455 - mae: 1.2107 - val_loss: 9.7761 - val_mae: 3.0433\n",
      "Epoch 193/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7466 - mae: 1.2125 - val_loss: 9.8593 - val_mae: 3.0569\n",
      "Epoch 194/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7487 - mae: 1.2135 - val_loss: 9.8560 - val_mae: 3.0564\n",
      "Epoch 195/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7481 - mae: 1.2135 - val_loss: 9.8079 - val_mae: 3.0485\n",
      "Epoch 196/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7465 - mae: 1.2126 - val_loss: 9.7739 - val_mae: 3.0429\n",
      "Epoch 197/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7463 - mae: 1.2122 - val_loss: 9.7574 - val_mae: 3.0402\n",
      "Epoch 198/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7455 - mae: 1.2119 - val_loss: 9.7729 - val_mae: 3.0428\n",
      "Epoch 199/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7456 - mae: 1.2120 - val_loss: 9.8013 - val_mae: 3.0474\n",
      "Epoch 200/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7459 - mae: 1.2123 - val_loss: 9.8534 - val_mae: 3.0560\n",
      "Epoch 201/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7466 - mae: 1.2130 - val_loss: 9.9235 - val_mae: 3.0674\n",
      "Epoch 202/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7475 - mae: 1.2139 - val_loss: 10.0550 - val_mae: 3.0888\n",
      "Epoch 203/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7522 - mae: 1.2166 - val_loss: 10.2070 - val_mae: 3.1133\n",
      "Epoch 204/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7567 - mae: 1.2199 - val_loss: 10.3180 - val_mae: 3.1311\n",
      "Epoch 205/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7618 - mae: 1.2224 - val_loss: 10.3907 - val_mae: 3.1426\n",
      "Epoch 206/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7654 - mae: 1.2241 - val_loss: 10.3412 - val_mae: 3.1348\n",
      "Epoch 207/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7647 - mae: 1.2238 - val_loss: 10.2659 - val_mae: 3.1227\n",
      "Epoch 208/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7594 - mae: 1.2210 - val_loss: 10.3189 - val_mae: 3.1312\n",
      "Epoch 209/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7612 - mae: 1.2223 - val_loss: 10.4090 - val_mae: 3.1456\n",
      "Epoch 210/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7657 - mae: 1.2243 - val_loss: 10.4304 - val_mae: 3.1490\n",
      "Epoch 211/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7661 - mae: 1.2245 - val_loss: 10.3703 - val_mae: 3.1394\n",
      "Epoch 212/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7639 - mae: 1.2235 - val_loss: 10.2989 - val_mae: 3.1280\n",
      "Epoch 213/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7596 - mae: 1.2215 - val_loss: 10.2048 - val_mae: 3.1129\n",
      "Epoch 214/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7563 - mae: 1.2197 - val_loss: 10.0699 - val_mae: 3.0912\n",
      "Epoch 215/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7498 - mae: 1.2155 - val_loss: 9.9020 - val_mae: 3.0639\n",
      "Epoch 216/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7436 - mae: 1.2119 - val_loss: 9.6417 - val_mae: 3.0211\n",
      "Epoch 217/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7453 - mae: 1.2103 - val_loss: 9.4184 - val_mae: 2.9839\n",
      "Epoch 218/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7412 - mae: 1.2072 - val_loss: 9.3123 - val_mae: 2.9661\n",
      "Epoch 219/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7407 - mae: 1.2062 - val_loss: 9.2231 - val_mae: 2.9510\n",
      "Epoch 220/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7427 - mae: 1.2062 - val_loss: 9.1610 - val_mae: 2.9405\n",
      "Epoch 221/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7428 - mae: 1.2056 - val_loss: 9.1914 - val_mae: 2.9457\n",
      "Epoch 222/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7412 - mae: 1.2052 - val_loss: 9.3189 - val_mae: 2.9672\n",
      "Epoch 223/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7415 - mae: 1.2067 - val_loss: 9.4603 - val_mae: 2.9910\n",
      "Epoch 224/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7400 - mae: 1.2069 - val_loss: 9.5360 - val_mae: 3.0036\n",
      "Epoch 225/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7397 - mae: 1.2077 - val_loss: 9.5890 - val_mae: 3.0124\n",
      "Epoch 226/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7406 - mae: 1.2086 - val_loss: 9.5916 - val_mae: 3.0128\n",
      "Epoch 227/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7401 - mae: 1.2086 - val_loss: 9.5626 - val_mae: 3.0080\n",
      "Epoch 228/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7395 - mae: 1.2080 - val_loss: 9.5250 - val_mae: 3.0018\n",
      "Epoch 229/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7381 - mae: 1.2070 - val_loss: 9.3801 - val_mae: 2.9775\n",
      "Epoch 230/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7350 - mae: 1.2048 - val_loss: 9.0988 - val_mae: 2.9299\n",
      "Epoch 231/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7450 - mae: 1.2055 - val_loss: 8.8287 - val_mae: 2.8834\n",
      "Epoch 232/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7483 - mae: 1.2029 - val_loss: 8.6513 - val_mae: 2.8525\n",
      "Epoch 233/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7559 - mae: 1.2018 - val_loss: 8.5113 - val_mae: 2.8279\n",
      "Epoch 234/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7624 - mae: 1.2010 - val_loss: 8.4457 - val_mae: 2.8163\n",
      "Epoch 235/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7635 - mae: 1.2002 - val_loss: 8.4703 - val_mae: 2.8207\n",
      "Epoch 236/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7570 - mae: 1.1990 - val_loss: 8.6270 - val_mae: 2.8484\n",
      "Epoch 237/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7505 - mae: 1.2014 - val_loss: 8.7742 - val_mae: 2.8741\n",
      "Epoch 238/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7414 - mae: 1.2004 - val_loss: 8.7930 - val_mae: 2.8773\n",
      "Epoch 239/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7401 - mae: 1.2003 - val_loss: 8.8775 - val_mae: 2.8920\n",
      "Epoch 240/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7381 - mae: 1.2011 - val_loss: 9.0023 - val_mae: 2.9135\n",
      "Epoch 241/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7341 - mae: 1.2015 - val_loss: 9.0492 - val_mae: 2.9215\n",
      "Epoch 242/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7329 - mae: 1.2017 - val_loss: 8.9682 - val_mae: 2.9076\n",
      "Epoch 243/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7316 - mae: 1.2000 - val_loss: 8.7899 - val_mae: 2.8768\n",
      "Epoch 244/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7362 - mae: 1.1992 - val_loss: 8.6793 - val_mae: 2.8575\n",
      "Epoch 245/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7391 - mae: 1.1981 - val_loss: 8.6836 - val_mae: 2.8583\n",
      "Epoch 246/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7368 - mae: 1.1975 - val_loss: 8.8630 - val_mae: 2.8895\n",
      "Epoch 247/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7363 - mae: 1.2009 - val_loss: 9.0608 - val_mae: 2.9235\n",
      "Epoch 248/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7253 - mae: 1.1992 - val_loss: 9.1557 - val_mae: 2.9397\n",
      "Epoch 249/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7256 - mae: 1.2007 - val_loss: 9.1891 - val_mae: 2.9454\n",
      "Epoch 250/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7225 - mae: 1.1996 - val_loss: 9.1255 - val_mae: 2.9346\n",
      "Epoch 251/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7222 - mae: 1.1990 - val_loss: 9.0335 - val_mae: 2.9189\n",
      "Epoch 252/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7266 - mae: 1.1994 - val_loss: 9.0566 - val_mae: 2.9228\n",
      "Epoch 253/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7205 - mae: 1.1971 - val_loss: 9.2724 - val_mae: 2.9595\n",
      "Epoch 254/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7226 - mae: 1.2004 - val_loss: 9.4487 - val_mae: 2.9892\n",
      "Epoch 255/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7201 - mae: 1.2011 - val_loss: 9.4680 - val_mae: 2.9924\n",
      "Epoch 256/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7184 - mae: 1.2009 - val_loss: 9.3804 - val_mae: 2.9777\n",
      "Epoch 257/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7166 - mae: 1.1993 - val_loss: 9.2135 - val_mae: 2.9496\n",
      "Epoch 258/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7159 - mae: 1.1978 - val_loss: 8.9924 - val_mae: 2.9118\n",
      "Epoch 259/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7195 - mae: 1.1965 - val_loss: 8.7639 - val_mae: 2.8723\n",
      "Epoch 260/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7278 - mae: 1.1956 - val_loss: 8.5876 - val_mae: 2.8414\n",
      "Epoch 261/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7359 - mae: 1.1956 - val_loss: 8.5068 - val_mae: 2.8272\n",
      "Epoch 262/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7392 - mae: 1.1949 - val_loss: 8.5561 - val_mae: 2.8359\n",
      "Epoch 263/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7372 - mae: 1.1960 - val_loss: 8.6307 - val_mae: 2.8490\n",
      "Epoch 264/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7304 - mae: 1.1948 - val_loss: 8.6323 - val_mae: 2.8493\n",
      "Epoch 265/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7299 - mae: 1.1947 - val_loss: 8.5279 - val_mae: 2.8309\n",
      "Epoch 266/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7367 - mae: 1.1943 - val_loss: 8.4260 - val_mae: 2.8129\n",
      "Epoch 267/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7377 - mae: 1.1930 - val_loss: 8.5644 - val_mae: 2.8374\n",
      "Epoch 268/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7288 - mae: 1.1941 - val_loss: 8.8376 - val_mae: 2.8852\n",
      "Epoch 269/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7179 - mae: 1.1953 - val_loss: 9.0957 - val_mae: 2.9296\n",
      "Epoch 270/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7120 - mae: 1.1954 - val_loss: 9.3437 - val_mae: 2.9716\n",
      "Epoch 271/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7125 - mae: 1.1982 - val_loss: 9.5594 - val_mae: 3.0077\n",
      "Epoch 272/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7141 - mae: 1.2012 - val_loss: 9.7175 - val_mae: 3.0338\n",
      "Epoch 273/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7171 - mae: 1.2028 - val_loss: 9.8337 - val_mae: 3.0529\n",
      "Epoch 274/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7210 - mae: 1.2054 - val_loss: 9.8513 - val_mae: 3.0558\n",
      "Epoch 275/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7193 - mae: 1.2049 - val_loss: 9.7336 - val_mae: 3.0365\n",
      "Epoch 276/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7145 - mae: 1.2023 - val_loss: 9.5396 - val_mae: 3.0044\n",
      "Epoch 277/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7087 - mae: 1.1990 - val_loss: 9.2981 - val_mae: 2.9639\n",
      "Epoch 278/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7085 - mae: 1.1949 - val_loss: 9.0810 - val_mae: 2.9271\n",
      "Epoch 279/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7062 - mae: 1.1938 - val_loss: 8.8802 - val_mae: 2.8925\n",
      "Epoch 280/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7142 - mae: 1.1949 - val_loss: 8.7235 - val_mae: 2.8653\n",
      "Epoch 281/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7157 - mae: 1.1921 - val_loss: 8.5973 - val_mae: 2.8432\n",
      "Epoch 282/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7202 - mae: 1.1913 - val_loss: 8.4096 - val_mae: 2.8100\n",
      "Epoch 283/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7297 - mae: 1.1904 - val_loss: 8.2315 - val_mae: 2.7781\n",
      "Epoch 284/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7464 - mae: 1.1916 - val_loss: 8.2033 - val_mae: 2.7730\n",
      "Epoch 285/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7425 - mae: 1.1904 - val_loss: 8.3344 - val_mae: 2.7966\n",
      "Epoch 286/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7303 - mae: 1.1892 - val_loss: 8.5098 - val_mae: 2.8278\n",
      "Epoch 287/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7229 - mae: 1.1906 - val_loss: 8.6798 - val_mae: 2.8577\n",
      "Epoch 288/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7131 - mae: 1.1910 - val_loss: 8.7614 - val_mae: 2.8720\n",
      "Epoch 289/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7092 - mae: 1.1908 - val_loss: 8.8204 - val_mae: 2.8822\n",
      "Epoch 290/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7074 - mae: 1.1910 - val_loss: 8.8675 - val_mae: 2.8904\n",
      "Epoch 291/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7058 - mae: 1.1914 - val_loss: 8.8733 - val_mae: 2.8914\n",
      "Epoch 292/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7051 - mae: 1.1913 - val_loss: 8.8854 - val_mae: 2.8935\n",
      "Epoch 293/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7054 - mae: 1.1917 - val_loss: 8.8516 - val_mae: 2.8877\n",
      "Epoch 294/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7086 - mae: 1.1918 - val_loss: 8.8968 - val_mae: 2.8955\n",
      "Epoch 295/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6989 - mae: 1.1894 - val_loss: 9.2052 - val_mae: 2.9483\n",
      "Epoch 296/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7013 - mae: 1.1934 - val_loss: 9.5443 - val_mae: 3.0052\n",
      "Epoch 297/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7010 - mae: 1.1965 - val_loss: 9.8099 - val_mae: 3.0491\n",
      "Epoch 298/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7114 - mae: 1.2021 - val_loss: 9.9742 - val_mae: 3.0759\n",
      "Epoch 299/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7137 - mae: 1.2051 - val_loss: 10.0813 - val_mae: 3.0933\n",
      "Epoch 300/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7191 - mae: 1.2079 - val_loss: 10.1677 - val_mae: 3.1072\n",
      "Epoch 301/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7213 - mae: 1.2093 - val_loss: 10.1280 - val_mae: 3.1008\n",
      "Epoch 302/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7180 - mae: 1.2078 - val_loss: 10.0151 - val_mae: 3.0826\n",
      "Epoch 303/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7107 - mae: 1.2041 - val_loss: 9.8222 - val_mae: 3.0511\n",
      "Epoch 304/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7058 - mae: 1.2008 - val_loss: 9.6349 - val_mae: 3.0202\n",
      "Epoch 305/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6977 - mae: 1.1961 - val_loss: 9.5095 - val_mae: 2.9994\n",
      "Epoch 306/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6941 - mae: 1.1942 - val_loss: 9.3433 - val_mae: 2.9715\n",
      "Epoch 307/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6936 - mae: 1.1925 - val_loss: 9.1659 - val_mae: 2.9415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6926 - mae: 1.1897 - val_loss: 9.0099 - val_mae: 2.9149\n",
      "Epoch 309/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6922 - mae: 1.1884 - val_loss: 8.7710 - val_mae: 2.8736\n",
      "Epoch 310/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6995 - mae: 1.1875 - val_loss: 8.4823 - val_mae: 2.8229\n",
      "Epoch 311/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7154 - mae: 1.1876 - val_loss: 8.3292 - val_mae: 2.7956\n",
      "Epoch 312/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7192 - mae: 1.1860 - val_loss: 8.3347 - val_mae: 2.7966\n",
      "Epoch 313/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7162 - mae: 1.1852 - val_loss: 8.4129 - val_mae: 2.8106\n",
      "Epoch 314/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7090 - mae: 1.1849 - val_loss: 8.5469 - val_mae: 2.8344\n",
      "Epoch 315/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6983 - mae: 1.1849 - val_loss: 8.8055 - val_mae: 2.8797\n",
      "Epoch 316/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6943 - mae: 1.1873 - val_loss: 9.1025 - val_mae: 2.9308\n",
      "Epoch 317/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6828 - mae: 1.1864 - val_loss: 9.4301 - val_mae: 2.9862\n",
      "Epoch 318/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.6931 - mae: 1.1931 - val_loss: 9.7720 - val_mae: 3.0429\n",
      "Epoch 319/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.6988 - mae: 1.1985 - val_loss: 9.9470 - val_mae: 3.0716\n",
      "Epoch 320/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7054 - mae: 1.2024 - val_loss: 9.9733 - val_mae: 3.0758\n",
      "Epoch 321/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7052 - mae: 1.2028 - val_loss: 9.9306 - val_mae: 3.0689\n",
      "Epoch 322/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7024 - mae: 1.2014 - val_loss: 9.9606 - val_mae: 3.0738\n",
      "Epoch 323/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7015 - mae: 1.2013 - val_loss: 10.0988 - val_mae: 3.0962\n",
      "Epoch 324/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7066 - mae: 1.2043 - val_loss: 10.2987 - val_mae: 3.1283\n",
      "Epoch 325/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7190 - mae: 1.2095 - val_loss: 10.4247 - val_mae: 3.1484\n",
      "Epoch 326/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7253 - mae: 1.2119 - val_loss: 10.3818 - val_mae: 3.1415\n",
      "Epoch 327/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7183 - mae: 1.2094 - val_loss: 10.1229 - val_mae: 3.1000\n",
      "Epoch 328/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.7055 - mae: 1.2028 - val_loss: 9.7830 - val_mae: 3.0447\n",
      "Epoch 329/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6841 - mae: 1.1935 - val_loss: 9.4302 - val_mae: 2.9861\n",
      "Epoch 330/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6770 - mae: 1.1880 - val_loss: 9.0164 - val_mae: 2.9160\n",
      "Epoch 331/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6767 - mae: 1.1839 - val_loss: 8.6151 - val_mae: 2.8463\n",
      "Epoch 332/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6889 - mae: 1.1826 - val_loss: 8.2320 - val_mae: 2.7782\n",
      "Epoch 333/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7149 - mae: 1.1827 - val_loss: 7.9314 - val_mae: 2.7235\n",
      "Epoch 334/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7419 - mae: 1.1857 - val_loss: 7.8224 - val_mae: 2.7034\n",
      "Epoch 335/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7463 - mae: 1.1843 - val_loss: 7.8339 - val_mae: 2.7056\n",
      "Epoch 336/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7406 - mae: 1.1829 - val_loss: 7.8494 - val_mae: 2.7085\n",
      "Epoch 337/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7341 - mae: 1.1813 - val_loss: 7.9340 - val_mae: 2.7241\n",
      "Epoch 338/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7248 - mae: 1.1811 - val_loss: 8.0220 - val_mae: 2.7402\n",
      "Epoch 339/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7110 - mae: 1.1780 - val_loss: 8.0499 - val_mae: 2.7453\n",
      "Epoch 340/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7051 - mae: 1.1767 - val_loss: 8.1356 - val_mae: 2.7609\n",
      "Epoch 341/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6938 - mae: 1.1758 - val_loss: 8.3717 - val_mae: 2.8034\n",
      "Epoch 342/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6756 - mae: 1.1741 - val_loss: 8.7661 - val_mae: 2.8729\n",
      "Epoch 343/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6661 - mae: 1.1792 - val_loss: 9.1819 - val_mae: 2.9444\n",
      "Epoch 344/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.6564 - mae: 1.1791 - val_loss: 9.6096 - val_mae: 3.0162\n",
      "Epoch 345/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6758 - mae: 1.1900 - val_loss: 9.9877 - val_mae: 3.0782\n",
      "Epoch 346/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6857 - mae: 1.1976 - val_loss: 10.2391 - val_mae: 3.1188\n",
      "Epoch 347/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7048 - mae: 1.2046 - val_loss: 10.3787 - val_mae: 3.1411\n",
      "Epoch 348/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7110 - mae: 1.2071 - val_loss: 10.3539 - val_mae: 3.1371\n",
      "Epoch 349/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7078 - mae: 1.2062 - val_loss: 10.2658 - val_mae: 3.1230\n",
      "Epoch 350/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7020 - mae: 1.2038 - val_loss: 10.2078 - val_mae: 3.1137\n",
      "Epoch 351/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6951 - mae: 1.2016 - val_loss: 10.2231 - val_mae: 3.1162\n",
      "Epoch 352/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6948 - mae: 1.2015 - val_loss: 10.1803 - val_mae: 3.1093\n",
      "Epoch 353/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6907 - mae: 1.2003 - val_loss: 10.0674 - val_mae: 3.0910\n",
      "Epoch 354/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6832 - mae: 1.1972 - val_loss: 9.9901 - val_mae: 3.0785\n",
      "Epoch 355/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6763 - mae: 1.1945 - val_loss: 9.8851 - val_mae: 3.0614\n",
      "Epoch 356/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6710 - mae: 1.1922 - val_loss: 9.7381 - val_mae: 3.0372\n",
      "Epoch 357/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6620 - mae: 1.1876 - val_loss: 9.5936 - val_mae: 3.0133\n",
      "Epoch 358/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6561 - mae: 1.1837 - val_loss: 9.4082 - val_mae: 2.9824\n",
      "Epoch 359/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6514 - mae: 1.1795 - val_loss: 9.2425 - val_mae: 2.9545\n",
      "Epoch 360/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6476 - mae: 1.1776 - val_loss: 9.1277 - val_mae: 2.9350\n",
      "Epoch 361/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6447 - mae: 1.1751 - val_loss: 9.0096 - val_mae: 2.9148\n",
      "Epoch 362/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6418 - mae: 1.1724 - val_loss: 8.7867 - val_mae: 2.8763\n",
      "Epoch 363/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6425 - mae: 1.1708 - val_loss: 8.4843 - val_mae: 2.8233\n",
      "Epoch 364/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6492 - mae: 1.1690 - val_loss: 8.1982 - val_mae: 2.7721\n",
      "Epoch 365/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6603 - mae: 1.1673 - val_loss: 7.9366 - val_mae: 2.7246\n",
      "Epoch 366/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6781 - mae: 1.1669 - val_loss: 7.7610 - val_mae: 2.6922\n",
      "Epoch 367/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6892 - mae: 1.1668 - val_loss: 7.7660 - val_mae: 2.6931\n",
      "Epoch 368/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6811 - mae: 1.1644 - val_loss: 7.9844 - val_mae: 2.7334\n",
      "Epoch 369/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6634 - mae: 1.1632 - val_loss: 8.3057 - val_mae: 2.7916\n",
      "Epoch 370/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6452 - mae: 1.1666 - val_loss: 8.5943 - val_mae: 2.8429\n",
      "Epoch 371/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6368 - mae: 1.1669 - val_loss: 8.8434 - val_mae: 2.8864\n",
      "Epoch 372/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6374 - mae: 1.1706 - val_loss: 8.9819 - val_mae: 2.9103\n",
      "Epoch 373/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6344 - mae: 1.1708 - val_loss: 9.0999 - val_mae: 2.9305\n",
      "Epoch 374/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6338 - mae: 1.1723 - val_loss: 9.3236 - val_mae: 2.9685\n",
      "Epoch 375/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6414 - mae: 1.1766 - val_loss: 9.4825 - val_mae: 2.9951\n",
      "Epoch 376/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6425 - mae: 1.1795 - val_loss: 9.6064 - val_mae: 3.0157\n",
      "Epoch 377/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6485 - mae: 1.1826 - val_loss: 9.6925 - val_mae: 3.0299\n",
      "Epoch 378/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6485 - mae: 1.1837 - val_loss: 9.6906 - val_mae: 3.0296\n",
      "Epoch 379/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6459 - mae: 1.1829 - val_loss: 9.8177 - val_mae: 3.0505\n",
      "Epoch 380/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6542 - mae: 1.1870 - val_loss: 9.9106 - val_mae: 3.0657\n",
      "Epoch 381/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6535 - mae: 1.1871 - val_loss: 9.8222 - val_mae: 3.0512\n",
      "Epoch 382/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6464 - mae: 1.1837 - val_loss: 9.7006 - val_mae: 3.0312\n",
      "Epoch 383/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6388 - mae: 1.1806 - val_loss: 9.5915 - val_mae: 3.0131\n",
      "Epoch 384/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6310 - mae: 1.1769 - val_loss: 9.4388 - val_mae: 2.9876\n",
      "Epoch 385/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6234 - mae: 1.1723 - val_loss: 9.1940 - val_mae: 2.9463\n",
      "Epoch 386/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6224 - mae: 1.1681 - val_loss: 9.0442 - val_mae: 2.9208\n",
      "Epoch 387/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6145 - mae: 1.1648 - val_loss: 8.9923 - val_mae: 2.9119\n",
      "Epoch 388/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6129 - mae: 1.1636 - val_loss: 8.9533 - val_mae: 2.9052\n",
      "Epoch 389/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6109 - mae: 1.1625 - val_loss: 8.8523 - val_mae: 2.8878\n",
      "Epoch 390/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6066 - mae: 1.1596 - val_loss: 8.6214 - val_mae: 2.8476\n",
      "Epoch 391/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6081 - mae: 1.1574 - val_loss: 8.4142 - val_mae: 2.8109\n",
      "Epoch 392/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6114 - mae: 1.1560 - val_loss: 8.2794 - val_mae: 2.7869\n",
      "Epoch 393/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6132 - mae: 1.1548 - val_loss: 8.1933 - val_mae: 2.7714\n",
      "Epoch 394/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6136 - mae: 1.1535 - val_loss: 8.1391 - val_mae: 2.7617\n",
      "Epoch 395/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6128 - mae: 1.1525 - val_loss: 8.0439 - val_mae: 2.7444\n",
      "Epoch 396/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6131 - mae: 1.1505 - val_loss: 7.9055 - val_mae: 2.7191\n",
      "Epoch 397/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6169 - mae: 1.1490 - val_loss: 7.7937 - val_mae: 2.6985\n",
      "Epoch 398/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6194 - mae: 1.1471 - val_loss: 7.6354 - val_mae: 2.6690\n",
      "Epoch 399/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6287 - mae: 1.1460 - val_loss: 7.5062 - val_mae: 2.6447\n",
      "Epoch 400/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6340 - mae: 1.1458 - val_loss: 7.4550 - val_mae: 2.6350\n",
      "Epoch 401/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6327 - mae: 1.1445 - val_loss: 7.5249 - val_mae: 2.6483\n",
      "Epoch 402/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6188 - mae: 1.1424 - val_loss: 7.7302 - val_mae: 2.6868\n",
      "Epoch 403/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5932 - mae: 1.1396 - val_loss: 7.9979 - val_mae: 2.7362\n",
      "Epoch 404/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5728 - mae: 1.1394 - val_loss: 8.3684 - val_mae: 2.8032\n",
      "Epoch 405/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5722 - mae: 1.1448 - val_loss: 8.5982 - val_mae: 2.8439\n",
      "Epoch 406/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5588 - mae: 1.1430 - val_loss: 8.6614 - val_mae: 2.8550\n",
      "Epoch 407/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5569 - mae: 1.1434 - val_loss: 8.7056 - val_mae: 2.8627\n",
      "Epoch 408/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5542 - mae: 1.1430 - val_loss: 8.5642 - val_mae: 2.8379\n",
      "Epoch 409/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5549 - mae: 1.1414 - val_loss: 8.4350 - val_mae: 2.8150\n",
      "Epoch 410/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5450 - mae: 1.1359 - val_loss: 8.5152 - val_mae: 2.8291\n",
      "Epoch 411/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5432 - mae: 1.1367 - val_loss: 8.6025 - val_mae: 2.8445\n",
      "Epoch 412/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5418 - mae: 1.1374 - val_loss: 8.5276 - val_mae: 2.8313\n",
      "Epoch 413/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5358 - mae: 1.1343 - val_loss: 8.2908 - val_mae: 2.7891\n",
      "Epoch 414/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5370 - mae: 1.1310 - val_loss: 8.0461 - val_mae: 2.7449\n",
      "Epoch 415/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5421 - mae: 1.1295 - val_loss: 7.8567 - val_mae: 2.7101\n",
      "Epoch 416/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5525 - mae: 1.1300 - val_loss: 7.8105 - val_mae: 2.7016\n",
      "Epoch 417/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5503 - mae: 1.1280 - val_loss: 7.8622 - val_mae: 2.7112\n",
      "Epoch 418/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5429 - mae: 1.1269 - val_loss: 7.8778 - val_mae: 2.7141\n",
      "Epoch 419/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5376 - mae: 1.1256 - val_loss: 7.9579 - val_mae: 2.7288\n",
      "Epoch 420/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5329 - mae: 1.1267 - val_loss: 8.0493 - val_mae: 2.7456\n",
      "Epoch 421/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5260 - mae: 1.1252 - val_loss: 7.9685 - val_mae: 2.7309\n",
      "Epoch 422/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5236 - mae: 1.1230 - val_loss: 7.7794 - val_mae: 2.6960\n",
      "Epoch 423/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5303 - mae: 1.1220 - val_loss: 7.6620 - val_mae: 2.6741\n",
      "Epoch 424/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5320 - mae: 1.1200 - val_loss: 7.6499 - val_mae: 2.6719\n",
      "Epoch 425/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5304 - mae: 1.1196 - val_loss: 7.6000 - val_mae: 2.6625\n",
      "Epoch 426/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5289 - mae: 1.1176 - val_loss: 7.5061 - val_mae: 2.6448\n",
      "Epoch 427/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5311 - mae: 1.1164 - val_loss: 7.3719 - val_mae: 2.6193\n",
      "Epoch 428/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5381 - mae: 1.1152 - val_loss: 7.2207 - val_mae: 2.5903\n",
      "Epoch 429/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5460 - mae: 1.1135 - val_loss: 7.1104 - val_mae: 2.5689\n",
      "Epoch 430/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5551 - mae: 1.1137 - val_loss: 7.0903 - val_mae: 2.5650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5511 - mae: 1.1127 - val_loss: 7.2030 - val_mae: 2.5869\n",
      "Epoch 432/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5388 - mae: 1.1117 - val_loss: 7.2295 - val_mae: 2.5920\n",
      "Epoch 433/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5300 - mae: 1.1092 - val_loss: 7.2402 - val_mae: 2.5941\n",
      "Epoch 434/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5238 - mae: 1.1079 - val_loss: 7.4040 - val_mae: 2.6255\n",
      "Epoch 435/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5088 - mae: 1.1078 - val_loss: 7.6718 - val_mae: 2.6761\n",
      "Epoch 436/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4952 - mae: 1.1108 - val_loss: 7.9514 - val_mae: 2.7279\n",
      "Epoch 437/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4833 - mae: 1.1109 - val_loss: 8.2642 - val_mae: 2.7847\n",
      "Epoch 438/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4908 - mae: 1.1182 - val_loss: 8.4744 - val_mae: 2.8222\n",
      "Epoch 439/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4849 - mae: 1.1181 - val_loss: 8.5499 - val_mae: 2.8355\n",
      "Epoch 440/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4808 - mae: 1.1181 - val_loss: 8.8122 - val_mae: 2.8814\n",
      "Epoch 441/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4979 - mae: 1.1281 - val_loss: 9.0022 - val_mae: 2.9142\n",
      "Epoch 442/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4945 - mae: 1.1284 - val_loss: 8.8886 - val_mae: 2.8945\n",
      "Epoch 443/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4811 - mae: 1.1224 - val_loss: 8.6879 - val_mae: 2.8596\n",
      "Epoch 444/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4651 - mae: 1.1141 - val_loss: 8.4459 - val_mae: 2.8169\n",
      "Epoch 445/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4551 - mae: 1.1061 - val_loss: 8.1932 - val_mae: 2.7716\n",
      "Epoch 446/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4536 - mae: 1.1013 - val_loss: 7.9761 - val_mae: 2.7321\n",
      "Epoch 447/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4609 - mae: 1.1016 - val_loss: 7.8657 - val_mae: 2.7118\n",
      "Epoch 448/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4620 - mae: 1.1004 - val_loss: 7.7843 - val_mae: 2.6967\n",
      "Epoch 449/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4596 - mae: 1.0980 - val_loss: 7.5784 - val_mae: 2.6583\n",
      "Epoch 450/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4665 - mae: 1.0951 - val_loss: 7.3030 - val_mae: 2.6060\n",
      "Epoch 451/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4812 - mae: 1.0933 - val_loss: 7.0061 - val_mae: 2.5484\n",
      "Epoch 452/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5065 - mae: 1.0950 - val_loss: 6.7318 - val_mae: 2.4940\n",
      "Epoch 453/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5317 - mae: 1.0956 - val_loss: 6.6083 - val_mae: 2.4692\n",
      "Epoch 454/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5288 - mae: 1.0916 - val_loss: 6.6391 - val_mae: 2.4755\n",
      "Epoch 455/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5049 - mae: 1.0851 - val_loss: 6.7456 - val_mae: 2.4971\n",
      "Epoch 456/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4785 - mae: 1.0825 - val_loss: 6.9208 - val_mae: 2.5321\n",
      "Epoch 457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.4558 - mae: 1.0801 - val_loss: 7.1349 - val_mae: 2.5741\n",
      "Epoch 458/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4410 - mae: 1.0818 - val_loss: 7.2757 - val_mae: 2.6014\n",
      "Epoch 459/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4305 - mae: 1.0824 - val_loss: 7.2809 - val_mae: 2.6024\n",
      "Epoch 460/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4254 - mae: 1.0808 - val_loss: 7.2282 - val_mae: 2.5923\n",
      "Epoch 461/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4215 - mae: 1.0784 - val_loss: 7.0809 - val_mae: 2.5636\n",
      "Epoch 462/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4196 - mae: 1.0735 - val_loss: 6.8461 - val_mae: 2.5172\n",
      "Epoch 463/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4288 - mae: 1.0687 - val_loss: 6.6733 - val_mae: 2.4825\n",
      "Epoch 464/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4395 - mae: 1.0670 - val_loss: 6.6235 - val_mae: 2.4724\n",
      "Epoch 465/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4381 - mae: 1.0658 - val_loss: 6.6880 - val_mae: 2.4854\n",
      "Epoch 466/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4231 - mae: 1.0624 - val_loss: 6.8616 - val_mae: 2.5202\n",
      "Epoch 467/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3952 - mae: 1.0585 - val_loss: 7.2712 - val_mae: 2.6003\n",
      "Epoch 468/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3880 - mae: 1.0695 - val_loss: 7.6944 - val_mae: 2.6806\n",
      "Epoch 469/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3746 - mae: 1.0709 - val_loss: 7.8393 - val_mae: 2.7075\n",
      "Epoch 470/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3704 - mae: 1.0717 - val_loss: 7.7634 - val_mae: 2.6934\n",
      "Epoch 471/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3550 - mae: 1.0644 - val_loss: 7.5392 - val_mae: 2.6513\n",
      "Epoch 472/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3423 - mae: 1.0550 - val_loss: 7.2910 - val_mae: 2.6039\n",
      "Epoch 473/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3484 - mae: 1.0526 - val_loss: 7.1313 - val_mae: 2.5730\n",
      "Epoch 474/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3528 - mae: 1.0501 - val_loss: 7.0757 - val_mae: 2.5622\n",
      "Epoch 475/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3525 - mae: 1.0484 - val_loss: 7.1017 - val_mae: 2.5673\n",
      "Epoch 476/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3456 - mae: 1.0474 - val_loss: 7.1307 - val_mae: 2.5730\n",
      "Epoch 477/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3318 - mae: 1.0431 - val_loss: 7.2347 - val_mae: 2.5932\n",
      "Epoch 478/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3162 - mae: 1.0407 - val_loss: 7.4886 - val_mae: 2.6419\n",
      "Epoch 479/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3077 - mae: 1.0433 - val_loss: 7.5372 - val_mae: 2.6511\n",
      "Epoch 480/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2965 - mae: 1.0397 - val_loss: 7.3113 - val_mae: 2.6081\n",
      "Epoch 481/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2894 - mae: 1.0313 - val_loss: 7.0170 - val_mae: 2.5509\n",
      "Epoch 482/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2977 - mae: 1.0287 - val_loss: 6.8859 - val_mae: 2.5250\n",
      "Epoch 483/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2969 - mae: 1.0252 - val_loss: 6.9587 - val_mae: 2.5394\n",
      "Epoch 484/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2805 - mae: 1.0216 - val_loss: 7.1577 - val_mae: 2.5784\n",
      "Epoch 485/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2656 - mae: 1.0215 - val_loss: 7.3580 - val_mae: 2.6171\n",
      "Epoch 486/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2568 - mae: 1.0228 - val_loss: 7.5347 - val_mae: 2.6508\n",
      "Epoch 487/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2591 - mae: 1.0272 - val_loss: 7.6200 - val_mae: 2.6669\n",
      "Epoch 488/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2527 - mae: 1.0274 - val_loss: 7.6411 - val_mae: 2.6708\n",
      "Epoch 489/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2424 - mae: 1.0238 - val_loss: 7.7138 - val_mae: 2.6843\n",
      "Epoch 490/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2351 - mae: 1.0221 - val_loss: 7.6754 - val_mae: 2.6771\n",
      "Epoch 491/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2207 - mae: 1.0153 - val_loss: 7.5882 - val_mae: 2.6606\n",
      "Epoch 492/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2065 - mae: 1.0070 - val_loss: 7.5706 - val_mae: 2.6573\n",
      "Epoch 493/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1966 - mae: 1.0023 - val_loss: 7.5372 - val_mae: 2.6510\n",
      "Epoch 494/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1853 - mae: 0.9971 - val_loss: 7.4047 - val_mae: 2.6258\n",
      "Epoch 495/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1760 - mae: 0.9896 - val_loss: 7.2648 - val_mae: 2.5990\n",
      "Epoch 496/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1677 - mae: 0.9845 - val_loss: 7.2346 - val_mae: 2.5932\n",
      "Epoch 497/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1524 - mae: 0.9783 - val_loss: 7.3426 - val_mae: 2.6140\n",
      "Epoch 498/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1391 - mae: 0.9757 - val_loss: 7.4799 - val_mae: 2.6403\n",
      "Epoch 499/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1418 - mae: 0.9820 - val_loss: 7.3536 - val_mae: 2.6163\n",
      "Epoch 500/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1229 - mae: 0.9721 - val_loss: 7.0983 - val_mae: 2.5669\n",
      "Epoch 501/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1061 - mae: 0.9569 - val_loss: 6.9663 - val_mae: 2.5410\n",
      "Epoch 502/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1017 - mae: 0.9529 - val_loss: 7.0220 - val_mae: 2.5520\n",
      "Epoch 503/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0761 - mae: 0.9443 - val_loss: 7.3646 - val_mae: 2.6185\n",
      "Epoch 504/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0838 - mae: 0.9571 - val_loss: 7.7668 - val_mae: 2.6945\n",
      "Epoch 505/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1280 - mae: 0.9753 - val_loss: 7.8176 - val_mae: 2.7038\n",
      "Epoch 506/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1146 - mae: 0.9684 - val_loss: 7.5926 - val_mae: 2.6616\n",
      "Epoch 507/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0594 - mae: 0.9462 - val_loss: 7.2982 - val_mae: 2.6055\n",
      "Epoch 508/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0325 - mae: 0.9296 - val_loss: 7.0097 - val_mae: 2.5494\n",
      "Epoch 509/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0422 - mae: 0.9291 - val_loss: 6.8403 - val_mae: 2.5160\n",
      "Epoch 510/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0339 - mae: 0.9230 - val_loss: 6.8451 - val_mae: 2.5170\n",
      "Epoch 511/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9880 - mae: 0.9037 - val_loss: 7.0865 - val_mae: 2.5647\n",
      "Epoch 512/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9867 - mae: 0.9096 - val_loss: 7.3821 - val_mae: 2.6220\n",
      "Epoch 513/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0286 - mae: 0.9282 - val_loss: 7.4541 - val_mae: 2.6359\n",
      "Epoch 514/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0482 - mae: 0.9334 - val_loss: 7.3786 - val_mae: 2.6214\n",
      "Epoch 515/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0140 - mae: 0.9175 - val_loss: 7.0492 - val_mae: 2.5575\n",
      "Epoch 516/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9333 - mae: 0.8845 - val_loss: 6.6138 - val_mae: 2.4707\n",
      "Epoch 517/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8993 - mae: 0.8583 - val_loss: 6.3195 - val_mae: 2.4103\n",
      "Epoch 518/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9141 - mae: 0.8623 - val_loss: 6.1225 - val_mae: 2.3690\n",
      "Epoch 519/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9244 - mae: 0.8621 - val_loss: 5.9011 - val_mae: 2.3218\n",
      "Epoch 520/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9260 - mae: 0.8583 - val_loss: 5.7563 - val_mae: 2.2905\n",
      "Epoch 521/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8755 - mae: 0.8295 - val_loss: 5.7956 - val_mae: 2.2992\n",
      "Epoch 522/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8072 - mae: 0.8024 - val_loss: 5.9880 - val_mae: 2.3411\n",
      "Epoch 523/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8189 - mae: 0.8234 - val_loss: 6.1718 - val_mae: 2.3804\n",
      "Epoch 524/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8646 - mae: 0.8458 - val_loss: 6.0171 - val_mae: 2.3475\n",
      "Epoch 525/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8219 - mae: 0.8238 - val_loss: 5.6439 - val_mae: 2.2662\n",
      "Epoch 526/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7505 - mae: 0.7774 - val_loss: 5.3830 - val_mae: 2.2077\n",
      "Epoch 527/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7293 - mae: 0.7519 - val_loss: 5.2828 - val_mae: 2.1848\n",
      "Epoch 528/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7212 - mae: 0.7441 - val_loss: 5.2532 - val_mae: 2.1781\n",
      "Epoch 529/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6907 - mae: 0.7279 - val_loss: 5.3051 - val_mae: 2.1901\n",
      "Epoch 530/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6598 - mae: 0.7159 - val_loss: 5.4306 - val_mae: 2.2187\n",
      "Epoch 531/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6700 - mae: 0.7337 - val_loss: 5.5357 - val_mae: 2.2425\n",
      "Epoch 532/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6996 - mae: 0.7508 - val_loss: 5.4107 - val_mae: 2.2143\n",
      "Epoch 533/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6441 - mae: 0.7184 - val_loss: 5.1648 - val_mae: 2.1579\n",
      "Epoch 534/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5841 - mae: 0.6685 - val_loss: 4.9922 - val_mae: 2.1174\n",
      "Epoch 535/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6255 - mae: 0.6911 - val_loss: 4.8992 - val_mae: 2.0953\n",
      "Epoch 536/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6401 - mae: 0.6981 - val_loss: 4.8839 - val_mae: 2.0918\n",
      "Epoch 537/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5716 - mae: 0.6544 - val_loss: 4.9501 - val_mae: 2.1077\n",
      "Epoch 538/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5268 - mae: 0.6321 - val_loss: 5.0035 - val_mae: 2.1205\n",
      "Epoch 539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5499 - mae: 0.6525 - val_loss: 4.9158 - val_mae: 2.0998\n",
      "Epoch 540/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5350 - mae: 0.6430 - val_loss: 4.7392 - val_mae: 2.0572\n",
      "Epoch 541/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4775 - mae: 0.5960 - val_loss: 4.5656 - val_mae: 2.0145\n",
      "Epoch 542/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5132 - mae: 0.6144 - val_loss: 4.5090 - val_mae: 2.0005\n",
      "Epoch 543/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5023 - mae: 0.6066 - val_loss: 4.5021 - val_mae: 1.9989\n",
      "Epoch 544/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4444 - mae: 0.5614 - val_loss: 4.4280 - val_mae: 1.9804\n",
      "Epoch 545/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4244 - mae: 0.5457 - val_loss: 4.3178 - val_mae: 1.9524\n",
      "Epoch 546/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4147 - mae: 0.5376 - val_loss: 4.1960 - val_mae: 1.9210\n",
      "Epoch 547/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4061 - mae: 0.5268 - val_loss: 4.0796 - val_mae: 1.8905\n",
      "Epoch 548/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3984 - mae: 0.5136 - val_loss: 4.0028 - val_mae: 1.8701\n",
      "Epoch 549/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3894 - mae: 0.5044 - val_loss: 3.9660 - val_mae: 1.8602\n",
      "Epoch 550/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3762 - mae: 0.4939 - val_loss: 3.9590 - val_mae: 1.8584\n",
      "Epoch 551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3622 - mae: 0.4836 - val_loss: 3.9464 - val_mae: 1.8551\n",
      "Epoch 552/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3498 - mae: 0.4722 - val_loss: 3.9592 - val_mae: 1.8585\n",
      "Epoch 553/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3334 - mae: 0.4635 - val_loss: 4.1082 - val_mae: 1.8983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3175 - mae: 0.4600 - val_loss: 4.2958 - val_mae: 1.9472\n",
      "Epoch 555/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3191 - mae: 0.4680 - val_loss: 4.3802 - val_mae: 1.9687\n",
      "Epoch 556/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2913 - mae: 0.4391 - val_loss: 4.3848 - val_mae: 1.9698\n",
      "Epoch 557/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2807 - mae: 0.4291 - val_loss: 4.3683 - val_mae: 1.9655\n",
      "Epoch 558/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2910 - mae: 0.4434 - val_loss: 4.3690 - val_mae: 1.9658\n",
      "Epoch 559/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2732 - mae: 0.4257 - val_loss: 4.4158 - val_mae: 1.9777\n",
      "Epoch 560/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2611 - mae: 0.4079 - val_loss: 4.4443 - val_mae: 1.9850\n",
      "Epoch 561/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2805 - mae: 0.4286 - val_loss: 4.3600 - val_mae: 1.9636\n",
      "Epoch 562/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2395 - mae: 0.3856 - val_loss: 4.2779 - val_mae: 1.9425\n",
      "Epoch 563/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2477 - mae: 0.4027 - val_loss: 4.2636 - val_mae: 1.9389\n",
      "Epoch 564/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2256 - mae: 0.3736 - val_loss: 4.2500 - val_mae: 1.9354\n",
      "Epoch 565/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2095 - mae: 0.3516 - val_loss: 4.1900 - val_mae: 1.9199\n",
      "Epoch 566/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2061 - mae: 0.3487 - val_loss: 4.1200 - val_mae: 1.9016\n",
      "Epoch 567/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1975 - mae: 0.3376 - val_loss: 4.0239 - val_mae: 1.8762\n",
      "Epoch 568/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1838 - mae: 0.3244 - val_loss: 3.8970 - val_mae: 1.8420\n",
      "Epoch 569/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1818 - mae: 0.3266 - val_loss: 3.7887 - val_mae: 1.8124\n",
      "Epoch 570/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1791 - mae: 0.3232 - val_loss: 3.7392 - val_mae: 1.7987\n",
      "Epoch 571/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1659 - mae: 0.3044 - val_loss: 3.7041 - val_mae: 1.7890\n",
      "Epoch 572/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1627 - mae: 0.2965 - val_loss: 3.6256 - val_mae: 1.7669\n",
      "Epoch 573/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1548 - mae: 0.2910 - val_loss: 3.5514 - val_mae: 1.7458\n",
      "Epoch 574/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1665 - mae: 0.3102 - val_loss: 3.5549 - val_mae: 1.7468\n",
      "Epoch 575/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1598 - mae: 0.3046 - val_loss: 3.6132 - val_mae: 1.7635\n",
      "Epoch 576/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1437 - mae: 0.2906 - val_loss: 3.6475 - val_mae: 1.7732\n",
      "Epoch 577/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1416 - mae: 0.2816 - val_loss: 3.6179 - val_mae: 1.7648\n",
      "Epoch 578/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1372 - mae: 0.2822 - val_loss: 3.5874 - val_mae: 1.7562\n",
      "Epoch 579/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1342 - mae: 0.2808 - val_loss: 3.5439 - val_mae: 1.7437\n",
      "Epoch 580/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1309 - mae: 0.2761 - val_loss: 3.4700 - val_mae: 1.7224\n",
      "Epoch 581/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1293 - mae: 0.2759 - val_loss: 3.4513 - val_mae: 1.7170\n",
      "Epoch 582/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1273 - mae: 0.2759 - val_loss: 3.4420 - val_mae: 1.7143\n",
      "Epoch 583/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1237 - mae: 0.2744 - val_loss: 3.4088 - val_mae: 1.7045\n",
      "Epoch 584/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1206 - mae: 0.2733 - val_loss: 3.4416 - val_mae: 1.7142\n",
      "Epoch 585/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1239 - mae: 0.2760 - val_loss: 3.4677 - val_mae: 1.7217\n",
      "Epoch 586/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1216 - mae: 0.2839 - val_loss: 3.4555 - val_mae: 1.7181\n",
      "Epoch 587/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1561 - mae: 0.3275 - val_loss: 3.4637 - val_mae: 1.7205\n",
      "Epoch 588/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1702 - mae: 0.3398 - val_loss: 3.4932 - val_mae: 1.7291\n",
      "Epoch 589/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1421 - mae: 0.3185 - val_loss: 3.5148 - val_mae: 1.7354\n",
      "Epoch 590/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1258 - mae: 0.2952 - val_loss: 3.4700 - val_mae: 1.7224\n",
      "Epoch 591/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1288 - mae: 0.2905 - val_loss: 3.3725 - val_mae: 1.6939\n",
      "Epoch 592/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1184 - mae: 0.2801 - val_loss: 3.2705 - val_mae: 1.6634\n",
      "Epoch 593/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1110 - mae: 0.2718 - val_loss: 3.1787 - val_mae: 1.6356\n",
      "Epoch 594/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1090 - mae: 0.2637 - val_loss: 3.1051 - val_mae: 1.6130\n",
      "Epoch 595/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1098 - mae: 0.2591 - val_loss: 3.0559 - val_mae: 1.5976\n",
      "Epoch 596/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1058 - mae: 0.2529 - val_loss: 3.0059 - val_mae: 1.5818\n",
      "Epoch 597/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1121 - mae: 0.2709 - val_loss: 2.9780 - val_mae: 1.5730\n",
      "Epoch 598/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1166 - mae: 0.2788 - val_loss: 3.0298 - val_mae: 1.5894\n",
      "Epoch 599/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1048 - mae: 0.2552 - val_loss: 3.1289 - val_mae: 1.6204\n",
      "Epoch 600/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1640 - mae: 0.3454 - val_loss: 3.1696 - val_mae: 1.6329\n",
      "Epoch 601/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1703 - mae: 0.3535 - val_loss: 3.1228 - val_mae: 1.6184\n",
      "Epoch 602/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1072 - mae: 0.2590 - val_loss: 3.0361 - val_mae: 1.5913\n",
      "Epoch 603/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1537 - mae: 0.3163 - val_loss: 3.0227 - val_mae: 1.5871\n",
      "Epoch 604/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1339 - mae: 0.3019 - val_loss: 3.0946 - val_mae: 1.6098\n",
      "Epoch 605/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1137 - mae: 0.2761 - val_loss: 3.1236 - val_mae: 1.6188\n",
      "Epoch 606/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1591 - mae: 0.3435 - val_loss: 3.0269 - val_mae: 1.5886\n",
      "Epoch 607/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1079 - mae: 0.2646 - val_loss: 2.8606 - val_mae: 1.5353\n",
      "Epoch 608/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1395 - mae: 0.3001 - val_loss: 2.7602 - val_mae: 1.5022\n",
      "Epoch 609/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1493 - mae: 0.3094 - val_loss: 2.7571 - val_mae: 1.5013\n",
      "Epoch 610/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1022 - mae: 0.2543 - val_loss: 2.7945 - val_mae: 1.5138\n",
      "Epoch 611/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1620 - mae: 0.3241 - val_loss: 2.7285 - val_mae: 1.4918\n",
      "Epoch 612/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1150 - mae: 0.2645 - val_loss: 2.6192 - val_mae: 1.4545\n",
      "Epoch 613/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1840 - mae: 0.3361 - val_loss: 2.6408 - val_mae: 1.4619\n",
      "Epoch 614/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1864 - mae: 0.3371 - val_loss: 2.7794 - val_mae: 1.5088\n",
      "Epoch 615/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1182 - mae: 0.2660 - val_loss: 2.9392 - val_mae: 1.5610\n",
      "Epoch 616/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1265 - mae: 0.2895 - val_loss: 3.0211 - val_mae: 1.5871\n",
      "Epoch 617/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1608 - mae: 0.3339 - val_loss: 3.0391 - val_mae: 1.5928\n",
      "Epoch 618/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1589 - mae: 0.3327 - val_loss: 3.0026 - val_mae: 1.5812\n",
      "Epoch 619/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1128 - mae: 0.2740 - val_loss: 2.9124 - val_mae: 1.5523\n",
      "Epoch 620/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1296 - mae: 0.2815 - val_loss: 2.8956 - val_mae: 1.5468\n",
      "Epoch 621/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1484 - mae: 0.3053 - val_loss: 2.9994 - val_mae: 1.5801\n",
      "Epoch 622/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1071 - mae: 0.2623 - val_loss: 3.1252 - val_mae: 1.6195\n",
      "Epoch 623/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1140 - mae: 0.2800 - val_loss: 3.2018 - val_mae: 1.6431\n",
      "Epoch 624/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1521 - mae: 0.3369 - val_loss: 3.2035 - val_mae: 1.6436\n",
      "Epoch 625/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1474 - mae: 0.3301 - val_loss: 3.1217 - val_mae: 1.6185\n",
      "Epoch 626/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1114 - mae: 0.2734 - val_loss: 3.0205 - val_mae: 1.5868\n",
      "Epoch 627/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1011 - mae: 0.2654 - val_loss: 2.9616 - val_mae: 1.5681\n",
      "Epoch 628/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1047 - mae: 0.2685 - val_loss: 2.9252 - val_mae: 1.5565\n",
      "Epoch 629/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1001 - mae: 0.2624 - val_loss: 2.9109 - val_mae: 1.5520\n",
      "Epoch 630/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0968 - mae: 0.2535 - val_loss: 2.8932 - val_mae: 1.5463\n",
      "Epoch 631/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0957 - mae: 0.2437 - val_loss: 2.8459 - val_mae: 1.5309\n",
      "Epoch 632/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0948 - mae: 0.2455 - val_loss: 2.8070 - val_mae: 1.5181\n",
      "Epoch 633/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0946 - mae: 0.2490 - val_loss: 2.8096 - val_mae: 1.5190\n",
      "Epoch 634/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0946 - mae: 0.2509 - val_loss: 2.8250 - val_mae: 1.5240\n",
      "Epoch 635/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0969 - mae: 0.2561 - val_loss: 2.8216 - val_mae: 1.5229\n",
      "Epoch 636/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1046 - mae: 0.2644 - val_loss: 2.8285 - val_mae: 1.5251\n",
      "Epoch 637/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1043 - mae: 0.2648 - val_loss: 2.8541 - val_mae: 1.5335\n",
      "Epoch 638/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0963 - mae: 0.2577 - val_loss: 2.8872 - val_mae: 1.5443\n",
      "Epoch 639/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0932 - mae: 0.2517 - val_loss: 2.9046 - val_mae: 1.5500\n",
      "Epoch 640/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0964 - mae: 0.2487 - val_loss: 2.8862 - val_mae: 1.5440\n",
      "Epoch 641/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0983 - mae: 0.2511 - val_loss: 2.8556 - val_mae: 1.5341\n",
      "Epoch 642/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0952 - mae: 0.2475 - val_loss: 2.8102 - val_mae: 1.5192\n",
      "Epoch 643/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0924 - mae: 0.2493 - val_loss: 2.7699 - val_mae: 1.5058\n",
      "Epoch 644/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0929 - mae: 0.2554 - val_loss: 2.7566 - val_mae: 1.5014\n",
      "Epoch 645/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0940 - mae: 0.2582 - val_loss: 2.7356 - val_mae: 1.4944\n",
      "Epoch 646/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0943 - mae: 0.2584 - val_loss: 2.7205 - val_mae: 1.4893\n",
      "Epoch 647/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0916 - mae: 0.2522 - val_loss: 2.7450 - val_mae: 1.4976\n",
      "Epoch 648/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0947 - mae: 0.2476 - val_loss: 2.7740 - val_mae: 1.5073\n",
      "Epoch 649/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1076 - mae: 0.2733 - val_loss: 2.7697 - val_mae: 1.5059\n",
      "Epoch 650/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1064 - mae: 0.2697 - val_loss: 2.7423 - val_mae: 1.4967\n",
      "Epoch 651/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0956 - mae: 0.2483 - val_loss: 2.7492 - val_mae: 1.4990\n",
      "Epoch 652/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0905 - mae: 0.2461 - val_loss: 2.7602 - val_mae: 1.5026\n",
      "Epoch 653/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0927 - mae: 0.2549 - val_loss: 2.7563 - val_mae: 1.5013\n",
      "Epoch 654/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1021 - mae: 0.2644 - val_loss: 2.8079 - val_mae: 1.5184\n",
      "Epoch 655/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0996 - mae: 0.2632 - val_loss: 2.8838 - val_mae: 1.5432\n",
      "Epoch 656/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0913 - mae: 0.2547 - val_loss: 2.9506 - val_mae: 1.5647\n",
      "Epoch 657/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0929 - mae: 0.2489 - val_loss: 2.9943 - val_mae: 1.5787\n",
      "Epoch 658/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1060 - mae: 0.2706 - val_loss: 2.9618 - val_mae: 1.5684\n",
      "Epoch 659/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1059 - mae: 0.2689 - val_loss: 2.8825 - val_mae: 1.5428\n",
      "Epoch 660/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0949 - mae: 0.2482 - val_loss: 2.8202 - val_mae: 1.5225\n",
      "Epoch 661/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0891 - mae: 0.2482 - val_loss: 2.7783 - val_mae: 1.5086\n",
      "Epoch 662/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0947 - mae: 0.2610 - val_loss: 2.7809 - val_mae: 1.5095\n",
      "Epoch 663/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0942 - mae: 0.2610 - val_loss: 2.8117 - val_mae: 1.5197\n",
      "Epoch 664/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0903 - mae: 0.2526 - val_loss: 2.8103 - val_mae: 1.5192\n",
      "Epoch 665/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0908 - mae: 0.2490 - val_loss: 2.7969 - val_mae: 1.5148\n",
      "Epoch 666/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0934 - mae: 0.2488 - val_loss: 2.7849 - val_mae: 1.5109\n",
      "Epoch 667/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0971 - mae: 0.2535 - val_loss: 2.7520 - val_mae: 1.4999\n",
      "Epoch 668/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0957 - mae: 0.2499 - val_loss: 2.7112 - val_mae: 1.4863\n",
      "Epoch 669/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0912 - mae: 0.2443 - val_loss: 2.6916 - val_mae: 1.4797\n",
      "Epoch 670/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0894 - mae: 0.2465 - val_loss: 2.6603 - val_mae: 1.4690\n",
      "Epoch 671/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0898 - mae: 0.2523 - val_loss: 2.6122 - val_mae: 1.4525\n",
      "Epoch 672/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0980 - mae: 0.2632 - val_loss: 2.5835 - val_mae: 1.4426\n",
      "Epoch 673/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0996 - mae: 0.2635 - val_loss: 2.6105 - val_mae: 1.4520\n",
      "Epoch 674/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2478 - val_loss: 2.6735 - val_mae: 1.4736\n",
      "Epoch 675/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1015 - mae: 0.2645 - val_loss: 2.7236 - val_mae: 1.4905\n",
      "Epoch 676/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1173 - mae: 0.2898 - val_loss: 2.7493 - val_mae: 1.4991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1024 - mae: 0.2669 - val_loss: 2.7596 - val_mae: 1.5025\n",
      "Epoch 678/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0882 - mae: 0.2478 - val_loss: 2.7480 - val_mae: 1.4985\n",
      "Epoch 679/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1004 - mae: 0.2690 - val_loss: 2.7483 - val_mae: 1.4986\n",
      "Epoch 680/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1168 - mae: 0.2888 - val_loss: 2.7887 - val_mae: 1.5120\n",
      "Epoch 681/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1149 - mae: 0.2883 - val_loss: 2.8337 - val_mae: 1.5269\n",
      "Epoch 682/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1023 - mae: 0.2735 - val_loss: 2.8858 - val_mae: 1.5439\n",
      "Epoch 683/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0927 - mae: 0.2612 - val_loss: 2.9260 - val_mae: 1.5569\n",
      "Epoch 684/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0900 - mae: 0.2527 - val_loss: 2.9252 - val_mae: 1.5567\n",
      "Epoch 685/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0899 - mae: 0.2483 - val_loss: 2.9087 - val_mae: 1.5514\n",
      "Epoch 686/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0894 - mae: 0.2447 - val_loss: 2.8743 - val_mae: 1.5403\n",
      "Epoch 687/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0869 - mae: 0.2428 - val_loss: 2.8031 - val_mae: 1.5170\n",
      "Epoch 688/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0870 - mae: 0.2474 - val_loss: 2.7289 - val_mae: 1.4923\n",
      "Epoch 689/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0923 - mae: 0.2517 - val_loss: 2.6874 - val_mae: 1.4784\n",
      "Epoch 690/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0949 - mae: 0.2542 - val_loss: 2.6737 - val_mae: 1.4738\n",
      "Epoch 691/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0940 - mae: 0.2520 - val_loss: 2.6787 - val_mae: 1.4755\n",
      "Epoch 692/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0890 - mae: 0.2429 - val_loss: 2.6866 - val_mae: 1.4782\n",
      "Epoch 693/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0878 - mae: 0.2374 - val_loss: 2.6813 - val_mae: 1.4764\n",
      "Epoch 694/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0899 - mae: 0.2448 - val_loss: 2.6619 - val_mae: 1.4698\n",
      "Epoch 695/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0872 - mae: 0.2396 - val_loss: 2.6542 - val_mae: 1.4671\n",
      "Epoch 696/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0870 - mae: 0.2445 - val_loss: 2.6624 - val_mae: 1.4699\n",
      "Epoch 697/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0873 - mae: 0.2460 - val_loss: 2.7025 - val_mae: 1.4835\n",
      "Epoch 698/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0859 - mae: 0.2405 - val_loss: 2.7576 - val_mae: 1.5020\n",
      "Epoch 699/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0877 - mae: 0.2417 - val_loss: 2.7743 - val_mae: 1.5076\n",
      "Epoch 700/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0889 - mae: 0.2436 - val_loss: 2.7875 - val_mae: 1.5119\n",
      "Epoch 701/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0883 - mae: 0.2417 - val_loss: 2.7976 - val_mae: 1.5152\n",
      "Epoch 702/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0867 - mae: 0.2411 - val_loss: 2.8058 - val_mae: 1.5179\n",
      "Epoch 703/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0853 - mae: 0.2451 - val_loss: 2.8264 - val_mae: 1.5247\n",
      "Epoch 704/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0856 - mae: 0.2487 - val_loss: 2.8433 - val_mae: 1.5302\n",
      "Epoch 705/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0865 - mae: 0.2518 - val_loss: 2.8500 - val_mae: 1.5324\n",
      "Epoch 706/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0876 - mae: 0.2541 - val_loss: 2.8732 - val_mae: 1.5400\n",
      "Epoch 707/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0872 - mae: 0.2505 - val_loss: 2.9112 - val_mae: 1.5523\n",
      "Epoch 708/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0878 - mae: 0.2451 - val_loss: 2.9183 - val_mae: 1.5546\n",
      "Epoch 709/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0876 - mae: 0.2468 - val_loss: 2.9150 - val_mae: 1.5535\n",
      "Epoch 710/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0873 - mae: 0.2453 - val_loss: 2.9111 - val_mae: 1.5523\n",
      "Epoch 711/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0873 - mae: 0.2482 - val_loss: 2.9055 - val_mae: 1.5505\n",
      "Epoch 712/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0865 - mae: 0.2481 - val_loss: 2.9344 - val_mae: 1.5598\n",
      "Epoch 713/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0888 - mae: 0.2450 - val_loss: 2.9627 - val_mae: 1.5689\n",
      "Epoch 714/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0928 - mae: 0.2470 - val_loss: 2.9468 - val_mae: 1.5638\n",
      "Epoch 715/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0897 - mae: 0.2437 - val_loss: 2.8718 - val_mae: 1.5396\n",
      "Epoch 716/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0855 - mae: 0.2490 - val_loss: 2.7854 - val_mae: 1.5113\n",
      "Epoch 717/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0887 - mae: 0.2518 - val_loss: 2.7347 - val_mae: 1.4944\n",
      "Epoch 718/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0937 - mae: 0.2538 - val_loss: 2.7086 - val_mae: 1.4858\n",
      "Epoch 719/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0929 - mae: 0.2513 - val_loss: 2.7128 - val_mae: 1.4873\n",
      "Epoch 720/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0877 - mae: 0.2422 - val_loss: 2.7173 - val_mae: 1.4889\n",
      "Epoch 721/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0852 - mae: 0.2321 - val_loss: 2.6977 - val_mae: 1.4823\n",
      "Epoch 722/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0855 - mae: 0.2305 - val_loss: 2.6533 - val_mae: 1.4671\n",
      "Epoch 723/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0858 - mae: 0.2343 - val_loss: 2.6061 - val_mae: 1.4508\n",
      "Epoch 724/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0871 - mae: 0.2389 - val_loss: 2.5714 - val_mae: 1.4388\n",
      "Epoch 725/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0883 - mae: 0.2422 - val_loss: 2.5608 - val_mae: 1.4350\n",
      "Epoch 726/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0889 - mae: 0.2444 - val_loss: 2.5709 - val_mae: 1.4385\n",
      "Epoch 727/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0871 - mae: 0.2419 - val_loss: 2.5940 - val_mae: 1.4465\n",
      "Epoch 728/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0838 - mae: 0.2365 - val_loss: 2.6528 - val_mae: 1.4668\n",
      "Epoch 729/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0871 - mae: 0.2426 - val_loss: 2.7013 - val_mae: 1.4832\n",
      "Epoch 730/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0892 - mae: 0.2448 - val_loss: 2.6935 - val_mae: 1.4804\n",
      "Epoch 731/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0844 - mae: 0.2423 - val_loss: 2.6851 - val_mae: 1.4775\n",
      "Epoch 732/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0851 - mae: 0.2500 - val_loss: 2.7040 - val_mae: 1.4839\n",
      "Epoch 733/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0854 - mae: 0.2506 - val_loss: 2.7257 - val_mae: 1.4912\n",
      "Epoch 734/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0859 - mae: 0.2441 - val_loss: 2.7546 - val_mae: 1.5009\n",
      "Epoch 735/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0915 - mae: 0.2469 - val_loss: 2.7383 - val_mae: 1.4955\n",
      "Epoch 736/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0828 - mae: 0.2389 - val_loss: 2.6698 - val_mae: 1.4723\n",
      "Epoch 737/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0900 - mae: 0.2544 - val_loss: 2.5986 - val_mae: 1.4479\n",
      "Epoch 738/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1261 - mae: 0.2892 - val_loss: 2.5739 - val_mae: 1.4394\n",
      "Epoch 739/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1322 - mae: 0.2922 - val_loss: 2.6327 - val_mae: 1.4600\n",
      "Epoch 740/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0905 - mae: 0.2431 - val_loss: 2.7545 - val_mae: 1.5017\n",
      "Epoch 741/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0995 - mae: 0.2619 - val_loss: 2.8636 - val_mae: 1.5381\n",
      "Epoch 742/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1480 - mae: 0.3160 - val_loss: 2.8605 - val_mae: 1.5372\n",
      "Epoch 743/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1467 - mae: 0.3119 - val_loss: 2.7494 - val_mae: 1.5002\n",
      "Epoch 744/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1031 - mae: 0.2627 - val_loss: 2.5944 - val_mae: 1.4471\n",
      "Epoch 745/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0984 - mae: 0.2470 - val_loss: 2.4976 - val_mae: 1.4129\n",
      "Epoch 746/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1258 - mae: 0.2832 - val_loss: 2.5279 - val_mae: 1.4236\n",
      "Epoch 747/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1069 - mae: 0.2603 - val_loss: 2.6335 - val_mae: 1.4604\n",
      "Epoch 748/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0861 - mae: 0.2367 - val_loss: 2.7329 - val_mae: 1.4941\n",
      "Epoch 749/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0909 - mae: 0.2525 - val_loss: 2.8077 - val_mae: 1.5189\n",
      "Epoch 750/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0961 - mae: 0.2600 - val_loss: 2.8129 - val_mae: 1.5205\n",
      "Epoch 751/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0811 - mae: 0.2329 - val_loss: 2.7506 - val_mae: 1.4997\n",
      "Epoch 752/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0948 - mae: 0.2590 - val_loss: 2.7205 - val_mae: 1.4895\n",
      "Epoch 753/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1076 - mae: 0.2735 - val_loss: 2.7477 - val_mae: 1.4987\n",
      "Epoch 754/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0902 - mae: 0.2549 - val_loss: 2.8137 - val_mae: 1.5207\n",
      "Epoch 755/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0801 - mae: 0.2370 - val_loss: 2.8791 - val_mae: 1.5422\n",
      "Epoch 756/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0875 - mae: 0.2459 - val_loss: 2.9039 - val_mae: 1.5503\n",
      "Epoch 757/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0894 - mae: 0.2492 - val_loss: 2.8648 - val_mae: 1.5376\n",
      "Epoch 758/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0822 - mae: 0.2341 - val_loss: 2.8266 - val_mae: 1.5250\n",
      "Epoch 759/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0826 - mae: 0.2407 - val_loss: 2.8071 - val_mae: 1.5185\n",
      "Epoch 760/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0904 - mae: 0.2508 - val_loss: 2.8023 - val_mae: 1.5170\n",
      "Epoch 761/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0868 - mae: 0.2461 - val_loss: 2.8435 - val_mae: 1.5306\n",
      "Epoch 762/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0803 - mae: 0.2345 - val_loss: 2.8774 - val_mae: 1.5417\n",
      "Epoch 763/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0828 - mae: 0.2362 - val_loss: 2.8543 - val_mae: 1.5341\n",
      "Epoch 764/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0817 - mae: 0.2342 - val_loss: 2.7745 - val_mae: 1.5078\n",
      "Epoch 765/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0799 - mae: 0.2328 - val_loss: 2.7002 - val_mae: 1.4829\n",
      "Epoch 766/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0786 - mae: 0.2300 - val_loss: 2.6550 - val_mae: 1.4676\n",
      "Epoch 767/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0815 - mae: 0.2343 - val_loss: 2.6249 - val_mae: 1.4573\n",
      "Epoch 768/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0850 - mae: 0.2428 - val_loss: 2.6022 - val_mae: 1.4494\n",
      "Epoch 769/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0852 - mae: 0.2432 - val_loss: 2.5791 - val_mae: 1.4414\n",
      "Epoch 770/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0827 - mae: 0.2369 - val_loss: 2.5491 - val_mae: 1.4309\n",
      "Epoch 771/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0813 - mae: 0.2355 - val_loss: 2.5333 - val_mae: 1.4253\n",
      "Epoch 772/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0827 - mae: 0.2419 - val_loss: 2.5693 - val_mae: 1.4379\n",
      "Epoch 773/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0814 - mae: 0.2424 - val_loss: 2.6399 - val_mae: 1.4622\n",
      "Epoch 774/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0805 - mae: 0.2379 - val_loss: 2.6907 - val_mae: 1.4796\n",
      "Epoch 775/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0821 - mae: 0.2378 - val_loss: 2.7170 - val_mae: 1.4884\n",
      "Epoch 776/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0831 - mae: 0.2377 - val_loss: 2.7406 - val_mae: 1.4963\n",
      "Epoch 777/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0835 - mae: 0.2377 - val_loss: 2.7629 - val_mae: 1.5038\n",
      "Epoch 778/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0822 - mae: 0.2380 - val_loss: 2.7703 - val_mae: 1.5062\n",
      "Epoch 779/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0804 - mae: 0.2400 - val_loss: 2.7620 - val_mae: 1.5034\n",
      "Epoch 780/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0803 - mae: 0.2445 - val_loss: 2.7535 - val_mae: 1.5006\n",
      "Epoch 781/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0797 - mae: 0.2430 - val_loss: 2.7732 - val_mae: 1.5073\n",
      "Epoch 782/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0797 - mae: 0.2324 - val_loss: 2.8005 - val_mae: 1.5164\n",
      "Epoch 783/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0930 - mae: 0.2543 - val_loss: 2.7610 - val_mae: 1.5033\n",
      "Epoch 784/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0881 - mae: 0.2447 - val_loss: 2.6664 - val_mae: 1.4714\n",
      "Epoch 785/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0795 - mae: 0.2333 - val_loss: 2.5950 - val_mae: 1.4469\n",
      "Epoch 786/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0831 - mae: 0.2411 - val_loss: 2.5882 - val_mae: 1.4445\n",
      "Epoch 787/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0817 - mae: 0.2369 - val_loss: 2.6034 - val_mae: 1.4499\n",
      "Epoch 788/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0797 - mae: 0.2278 - val_loss: 2.6004 - val_mae: 1.4489\n",
      "Epoch 789/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0801 - mae: 0.2267 - val_loss: 2.5983 - val_mae: 1.4481\n",
      "Epoch 790/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0797 - mae: 0.2266 - val_loss: 2.6151 - val_mae: 1.4539\n",
      "Epoch 791/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0788 - mae: 0.2271 - val_loss: 2.6603 - val_mae: 1.4694\n",
      "Epoch 792/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0779 - mae: 0.2270 - val_loss: 2.7184 - val_mae: 1.4891\n",
      "Epoch 793/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0782 - mae: 0.2274 - val_loss: 2.7548 - val_mae: 1.5013\n",
      "Epoch 794/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0775 - mae: 0.2266 - val_loss: 2.7498 - val_mae: 1.4996\n",
      "Epoch 795/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0766 - mae: 0.2289 - val_loss: 2.7086 - val_mae: 1.4858\n",
      "Epoch 796/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0802 - mae: 0.2345 - val_loss: 2.6902 - val_mae: 1.4796\n",
      "Epoch 797/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0796 - mae: 0.2302 - val_loss: 2.7225 - val_mae: 1.4906\n",
      "Epoch 798/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0772 - mae: 0.2208 - val_loss: 2.7798 - val_mae: 1.5098\n",
      "Epoch 799/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0857 - mae: 0.2430 - val_loss: 2.8409 - val_mae: 1.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1017 - mae: 0.2655 - val_loss: 2.8542 - val_mae: 1.5344\n",
      "Epoch 801/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0962 - mae: 0.2587 - val_loss: 2.7724 - val_mae: 1.5072\n",
      "Epoch 802/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0759 - mae: 0.2213 - val_loss: 2.6448 - val_mae: 1.4640\n",
      "Epoch 803/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1111 - mae: 0.2705 - val_loss: 2.5545 - val_mae: 1.4327\n",
      "Epoch 804/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1698 - mae: 0.3274 - val_loss: 2.5468 - val_mae: 1.4300\n",
      "Epoch 805/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1674 - mae: 0.3253 - val_loss: 2.6258 - val_mae: 1.4575\n",
      "Epoch 806/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1084 - mae: 0.2684 - val_loss: 2.7468 - val_mae: 1.4987\n",
      "Epoch 807/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0764 - mae: 0.2265 - val_loss: 2.8531 - val_mae: 1.5340\n",
      "Epoch 808/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1031 - mae: 0.2689 - val_loss: 2.9053 - val_mae: 1.5509\n",
      "Epoch 809/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1268 - mae: 0.2984 - val_loss: 2.9013 - val_mae: 1.5496\n",
      "Epoch 810/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1180 - mae: 0.2899 - val_loss: 2.8418 - val_mae: 1.5300\n",
      "Epoch 811/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0887 - mae: 0.2477 - val_loss: 2.7726 - val_mae: 1.5071\n",
      "Epoch 812/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0776 - mae: 0.2383 - val_loss: 2.7441 - val_mae: 1.4975\n",
      "Epoch 813/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0935 - mae: 0.2575 - val_loss: 2.7635 - val_mae: 1.5039\n",
      "Epoch 814/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0922 - mae: 0.2563 - val_loss: 2.8362 - val_mae: 1.5280\n",
      "Epoch 815/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0802 - mae: 0.2445 - val_loss: 2.9048 - val_mae: 1.5504\n",
      "Epoch 816/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0812 - mae: 0.2378 - val_loss: 2.9258 - val_mae: 1.5571\n",
      "Epoch 817/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0834 - mae: 0.2371 - val_loss: 2.9354 - val_mae: 1.5602\n",
      "Epoch 818/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0839 - mae: 0.2378 - val_loss: 2.9276 - val_mae: 1.5577\n",
      "Epoch 819/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0823 - mae: 0.2372 - val_loss: 2.8877 - val_mae: 1.5448\n",
      "Epoch 820/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0786 - mae: 0.2365 - val_loss: 2.8322 - val_mae: 1.5267\n",
      "Epoch 821/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0774 - mae: 0.2381 - val_loss: 2.7636 - val_mae: 1.5040\n",
      "Epoch 822/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0786 - mae: 0.2399 - val_loss: 2.7161 - val_mae: 1.4882\n",
      "Epoch 823/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0802 - mae: 0.2406 - val_loss: 2.6971 - val_mae: 1.4818\n",
      "Epoch 824/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0790 - mae: 0.2374 - val_loss: 2.7083 - val_mae: 1.4857\n",
      "Epoch 825/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0760 - mae: 0.2301 - val_loss: 2.7299 - val_mae: 1.4930\n",
      "Epoch 826/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0757 - mae: 0.2244 - val_loss: 2.7355 - val_mae: 1.4949\n",
      "Epoch 827/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0749 - mae: 0.2206 - val_loss: 2.7096 - val_mae: 1.4862\n",
      "Epoch 828/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0791 - mae: 0.2314 - val_loss: 2.6831 - val_mae: 1.4772\n",
      "Epoch 829/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0908 - mae: 0.2443 - val_loss: 2.7273 - val_mae: 1.4922\n",
      "Epoch 830/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0846 - mae: 0.2364 - val_loss: 2.8192 - val_mae: 1.5229\n",
      "Epoch 831/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0773 - mae: 0.2230 - val_loss: 2.8763 - val_mae: 1.5417\n",
      "Epoch 832/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0799 - mae: 0.2296 - val_loss: 2.8935 - val_mae: 1.5473\n",
      "Epoch 833/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0815 - mae: 0.2330 - val_loss: 2.8660 - val_mae: 1.5382\n",
      "Epoch 834/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0783 - mae: 0.2229 - val_loss: 2.8219 - val_mae: 1.5237\n",
      "Epoch 835/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0759 - mae: 0.2230 - val_loss: 2.8112 - val_mae: 1.5200\n",
      "Epoch 836/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0759 - mae: 0.2275 - val_loss: 2.8201 - val_mae: 1.5229\n",
      "Epoch 837/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0751 - mae: 0.2281 - val_loss: 2.8389 - val_mae: 1.5291\n",
      "Epoch 838/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0744 - mae: 0.2251 - val_loss: 2.8517 - val_mae: 1.5333\n",
      "Epoch 839/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0752 - mae: 0.2237 - val_loss: 2.8669 - val_mae: 1.5383\n",
      "Epoch 840/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0788 - mae: 0.2288 - val_loss: 2.8568 - val_mae: 1.5350\n",
      "Epoch 841/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0768 - mae: 0.2245 - val_loss: 2.7953 - val_mae: 1.5147\n",
      "Epoch 842/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0739 - mae: 0.2238 - val_loss: 2.7336 - val_mae: 1.4941\n",
      "Epoch 843/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0793 - mae: 0.2363 - val_loss: 2.6930 - val_mae: 1.4804\n",
      "Epoch 844/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0860 - mae: 0.2428 - val_loss: 2.7042 - val_mae: 1.4842\n",
      "Epoch 845/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0790 - mae: 0.2373 - val_loss: 2.7728 - val_mae: 1.5072\n",
      "Epoch 846/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0745 - mae: 0.2253 - val_loss: 2.8299 - val_mae: 1.5261\n",
      "Epoch 847/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0791 - mae: 0.2280 - val_loss: 2.8688 - val_mae: 1.5388\n",
      "Epoch 848/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0855 - mae: 0.2381 - val_loss: 2.8971 - val_mae: 1.5479\n",
      "Epoch 849/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0869 - mae: 0.2406 - val_loss: 2.8971 - val_mae: 1.5479\n",
      "Epoch 850/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0827 - mae: 0.2335 - val_loss: 2.8796 - val_mae: 1.5422\n",
      "Epoch 851/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0771 - mae: 0.2302 - val_loss: 2.8039 - val_mae: 1.5173\n",
      "Epoch 852/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0811 - mae: 0.2455 - val_loss: 2.7173 - val_mae: 1.4884\n",
      "Epoch 853/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1046 - mae: 0.2687 - val_loss: 2.7110 - val_mae: 1.4864\n",
      "Epoch 854/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0865 - mae: 0.2457 - val_loss: 2.7855 - val_mae: 1.5114\n",
      "Epoch 855/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0757 - mae: 0.2271 - val_loss: 2.8638 - val_mae: 1.5374\n",
      "Epoch 856/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1103 - mae: 0.2774 - val_loss: 2.8914 - val_mae: 1.5466\n",
      "Epoch 857/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1369 - mae: 0.3060 - val_loss: 2.8296 - val_mae: 1.5264\n",
      "Epoch 858/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1087 - mae: 0.2707 - val_loss: 2.6882 - val_mae: 1.4791\n",
      "Epoch 859/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0746 - mae: 0.2158 - val_loss: 2.5626 - val_mae: 1.4358\n",
      "Epoch 860/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0965 - mae: 0.2532 - val_loss: 2.4814 - val_mae: 1.4070\n",
      "Epoch 861/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1449 - mae: 0.3109 - val_loss: 2.4591 - val_mae: 1.3991\n",
      "Epoch 862/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1528 - mae: 0.3188 - val_loss: 2.5298 - val_mae: 1.4242\n",
      "Epoch 863/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1070 - mae: 0.2676 - val_loss: 2.6643 - val_mae: 1.4708\n",
      "Epoch 864/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0747 - mae: 0.2218 - val_loss: 2.7689 - val_mae: 1.5060\n",
      "Epoch 865/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0837 - mae: 0.2383 - val_loss: 2.8041 - val_mae: 1.5177\n",
      "Epoch 866/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0971 - mae: 0.2626 - val_loss: 2.7791 - val_mae: 1.5094\n",
      "Epoch 867/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0882 - mae: 0.2459 - val_loss: 2.7146 - val_mae: 1.4877\n",
      "Epoch 868/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0750 - mae: 0.2287 - val_loss: 2.6653 - val_mae: 1.4709\n",
      "Epoch 869/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0780 - mae: 0.2391 - val_loss: 2.6605 - val_mae: 1.4693\n",
      "Epoch 870/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0854 - mae: 0.2470 - val_loss: 2.6802 - val_mae: 1.4760\n",
      "Epoch 871/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0867 - mae: 0.2477 - val_loss: 2.7086 - val_mae: 1.4856\n",
      "Epoch 872/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0822 - mae: 0.2435 - val_loss: 2.7380 - val_mae: 1.4955\n",
      "Epoch 873/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0766 - mae: 0.2381 - val_loss: 2.7400 - val_mae: 1.4962\n",
      "Epoch 874/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0740 - mae: 0.2323 - val_loss: 2.7172 - val_mae: 1.4886\n",
      "Epoch 875/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0736 - mae: 0.2308 - val_loss: 2.6843 - val_mae: 1.4775\n",
      "Epoch 876/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0781 - mae: 0.2369 - val_loss: 2.6520 - val_mae: 1.4665\n",
      "Epoch 877/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0818 - mae: 0.2390 - val_loss: 2.6472 - val_mae: 1.4650\n",
      "Epoch 878/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0772 - mae: 0.2322 - val_loss: 2.6842 - val_mae: 1.4777\n",
      "Epoch 879/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0732 - mae: 0.2205 - val_loss: 2.7266 - val_mae: 1.4921\n",
      "Epoch 880/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0761 - mae: 0.2255 - val_loss: 2.7513 - val_mae: 1.5004\n",
      "Epoch 881/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0804 - mae: 0.2341 - val_loss: 2.7750 - val_mae: 1.5083\n",
      "Epoch 882/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0833 - mae: 0.2388 - val_loss: 2.7517 - val_mae: 1.5004\n",
      "Epoch 883/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0779 - mae: 0.2281 - val_loss: 2.6870 - val_mae: 1.4785\n",
      "Epoch 884/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0716 - mae: 0.2215 - val_loss: 2.6202 - val_mae: 1.4556\n",
      "Epoch 885/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0759 - mae: 0.2334 - val_loss: 2.5790 - val_mae: 1.4414\n",
      "Epoch 886/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0802 - mae: 0.2390 - val_loss: 2.5916 - val_mae: 1.4458\n",
      "Epoch 887/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0756 - mae: 0.2321 - val_loss: 2.6144 - val_mae: 1.4537\n",
      "Epoch 888/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0729 - mae: 0.2242 - val_loss: 2.6534 - val_mae: 1.4671\n",
      "Epoch 889/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0784 - mae: 0.2279 - val_loss: 2.6823 - val_mae: 1.4769\n",
      "Epoch 890/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0770 - mae: 0.2266 - val_loss: 2.6717 - val_mae: 1.4732\n",
      "Epoch 891/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0725 - mae: 0.2243 - val_loss: 2.6618 - val_mae: 1.4698\n",
      "Epoch 892/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0738 - mae: 0.2318 - val_loss: 2.6419 - val_mae: 1.4630\n",
      "Epoch 893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0807 - mae: 0.2404 - val_loss: 2.6582 - val_mae: 1.4686\n",
      "Epoch 894/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0809 - mae: 0.2392 - val_loss: 2.7098 - val_mae: 1.4861\n",
      "Epoch 895/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0741 - mae: 0.2293 - val_loss: 2.7616 - val_mae: 1.5036\n",
      "Epoch 896/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0709 - mae: 0.2202 - val_loss: 2.7974 - val_mae: 1.5156\n",
      "Epoch 897/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0712 - mae: 0.2157 - val_loss: 2.8144 - val_mae: 1.5212\n",
      "Epoch 898/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0726 - mae: 0.2145 - val_loss: 2.8050 - val_mae: 1.5181\n",
      "Epoch 899/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0724 - mae: 0.2147 - val_loss: 2.7896 - val_mae: 1.5130\n",
      "Epoch 900/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0730 - mae: 0.2176 - val_loss: 2.7895 - val_mae: 1.5130\n",
      "Epoch 901/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0742 - mae: 0.2215 - val_loss: 2.8175 - val_mae: 1.5222\n",
      "Epoch 902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0731 - mae: 0.2204 - val_loss: 2.8613 - val_mae: 1.5365\n",
      "Epoch 903/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0708 - mae: 0.2161 - val_loss: 2.9115 - val_mae: 1.5528\n",
      "Epoch 904/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0738 - mae: 0.2179 - val_loss: 2.9804 - val_mae: 1.5749\n",
      "Epoch 905/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0871 - mae: 0.2433 - val_loss: 3.0040 - val_mae: 1.5824\n",
      "Epoch 906/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0904 - mae: 0.2494 - val_loss: 2.9495 - val_mae: 1.5649\n",
      "Epoch 907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0779 - mae: 0.2241 - val_loss: 2.8687 - val_mae: 1.5387\n",
      "Epoch 908/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0728 - mae: 0.2279 - val_loss: 2.8151 - val_mae: 1.5212\n",
      "Epoch 909/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0730 - mae: 0.2280 - val_loss: 2.7839 - val_mae: 1.5109\n",
      "Epoch 910/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0724 - mae: 0.2270 - val_loss: 2.7697 - val_mae: 1.5062\n",
      "Epoch 911/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0710 - mae: 0.2231 - val_loss: 2.7786 - val_mae: 1.5091\n",
      "Epoch 912/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0704 - mae: 0.2193 - val_loss: 2.7845 - val_mae: 1.5111\n",
      "Epoch 913/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0723 - mae: 0.2195 - val_loss: 2.7610 - val_mae: 1.5033\n",
      "Epoch 914/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0708 - mae: 0.2180 - val_loss: 2.7238 - val_mae: 1.4908\n",
      "Epoch 915/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0705 - mae: 0.2216 - val_loss: 2.7035 - val_mae: 1.4840\n",
      "Epoch 916/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0727 - mae: 0.2269 - val_loss: 2.6970 - val_mae: 1.4817\n",
      "Epoch 917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0736 - mae: 0.2281 - val_loss: 2.7188 - val_mae: 1.4891\n",
      "Epoch 918/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0703 - mae: 0.2192 - val_loss: 2.7561 - val_mae: 1.5017\n",
      "Epoch 919/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0716 - mae: 0.2181 - val_loss: 2.7550 - val_mae: 1.5013\n",
      "Epoch 920/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0727 - mae: 0.2180 - val_loss: 2.7286 - val_mae: 1.4924\n",
      "Epoch 921/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0714 - mae: 0.2180 - val_loss: 2.6898 - val_mae: 1.4793\n",
      "Epoch 922/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0702 - mae: 0.2187 - val_loss: 2.6450 - val_mae: 1.4640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0707 - mae: 0.2204 - val_loss: 2.6448 - val_mae: 1.4640\n",
      "Epoch 924/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0702 - mae: 0.2192 - val_loss: 2.6712 - val_mae: 1.4730\n",
      "Epoch 925/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0706 - mae: 0.2185 - val_loss: 2.6722 - val_mae: 1.4733\n",
      "Epoch 926/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0699 - mae: 0.2175 - val_loss: 2.6801 - val_mae: 1.4760\n",
      "Epoch 927/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0714 - mae: 0.2242 - val_loss: 2.6948 - val_mae: 1.4809\n",
      "Epoch 928/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0742 - mae: 0.2281 - val_loss: 2.7004 - val_mae: 1.4828\n",
      "Epoch 929/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0727 - mae: 0.2239 - val_loss: 2.7446 - val_mae: 1.4978\n",
      "Epoch 930/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0729 - mae: 0.2170 - val_loss: 2.7692 - val_mae: 1.5062\n",
      "Epoch 931/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0752 - mae: 0.2220 - val_loss: 2.7378 - val_mae: 1.4957\n",
      "Epoch 932/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0757 - mae: 0.2193 - val_loss: 2.7222 - val_mae: 1.4905\n",
      "Epoch 933/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0745 - mae: 0.2161 - val_loss: 2.7152 - val_mae: 1.4881\n",
      "Epoch 934/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0732 - mae: 0.2114 - val_loss: 2.6988 - val_mae: 1.4825\n",
      "Epoch 935/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2120 - val_loss: 2.6897 - val_mae: 1.4793\n",
      "Epoch 936/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0710 - mae: 0.2127 - val_loss: 2.6753 - val_mae: 1.4744\n",
      "Epoch 937/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0714 - mae: 0.2175 - val_loss: 2.6693 - val_mae: 1.4723\n",
      "Epoch 938/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0727 - mae: 0.2228 - val_loss: 2.7022 - val_mae: 1.4834\n",
      "Epoch 939/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0715 - mae: 0.2231 - val_loss: 2.7569 - val_mae: 1.5017\n",
      "Epoch 940/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0696 - mae: 0.2202 - val_loss: 2.7941 - val_mae: 1.5141\n",
      "Epoch 941/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0713 - mae: 0.2206 - val_loss: 2.8044 - val_mae: 1.5175\n",
      "Epoch 942/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0722 - mae: 0.2223 - val_loss: 2.7947 - val_mae: 1.5143\n",
      "Epoch 943/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0714 - mae: 0.2231 - val_loss: 2.7930 - val_mae: 1.5137\n",
      "Epoch 944/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0714 - mae: 0.2211 - val_loss: 2.7922 - val_mae: 1.5135\n",
      "Epoch 945/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0734 - mae: 0.2214 - val_loss: 2.7819 - val_mae: 1.5101\n",
      "Epoch 946/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0738 - mae: 0.2215 - val_loss: 2.7847 - val_mae: 1.5110\n",
      "Epoch 947/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0725 - mae: 0.2195 - val_loss: 2.7619 - val_mae: 1.5034\n",
      "Epoch 948/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0688 - mae: 0.2174 - val_loss: 2.7302 - val_mae: 1.4927\n",
      "Epoch 949/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0753 - mae: 0.2290 - val_loss: 2.7409 - val_mae: 1.4963\n",
      "Epoch 950/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0803 - mae: 0.2336 - val_loss: 2.7768 - val_mae: 1.5083\n",
      "Epoch 951/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0778 - mae: 0.2307 - val_loss: 2.8207 - val_mae: 1.5228\n",
      "Epoch 952/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0733 - mae: 0.2225 - val_loss: 2.8439 - val_mae: 1.5305\n",
      "Epoch 953/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0707 - mae: 0.2161 - val_loss: 2.8536 - val_mae: 1.5337\n",
      "Epoch 954/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0702 - mae: 0.2110 - val_loss: 2.8592 - val_mae: 1.5355\n",
      "Epoch 955/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0707 - mae: 0.2109 - val_loss: 2.8503 - val_mae: 1.5326\n",
      "Epoch 956/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0700 - mae: 0.2108 - val_loss: 2.8401 - val_mae: 1.5292\n",
      "Epoch 957/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0697 - mae: 0.2131 - val_loss: 2.8283 - val_mae: 1.5253\n",
      "Epoch 958/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0705 - mae: 0.2169 - val_loss: 2.8356 - val_mae: 1.5277\n",
      "Epoch 959/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2182 - val_loss: 2.8551 - val_mae: 1.5340\n",
      "Epoch 960/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0700 - mae: 0.2198 - val_loss: 2.8531 - val_mae: 1.5334\n",
      "Epoch 961/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0704 - mae: 0.2219 - val_loss: 2.8734 - val_mae: 1.5400\n",
      "Epoch 962/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0706 - mae: 0.2219 - val_loss: 2.9122 - val_mae: 1.5526\n",
      "Epoch 963/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0748 - mae: 0.2246 - val_loss: 2.9153 - val_mae: 1.5536\n",
      "Epoch 964/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0772 - mae: 0.2268 - val_loss: 2.8854 - val_mae: 1.5439\n",
      "Epoch 965/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0733 - mae: 0.2214 - val_loss: 2.8160 - val_mae: 1.5212\n",
      "Epoch 966/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0695 - mae: 0.2183 - val_loss: 2.7442 - val_mae: 1.4974\n",
      "Epoch 967/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0695 - mae: 0.2206 - val_loss: 2.7107 - val_mae: 1.4862\n",
      "Epoch 968/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0680 - mae: 0.2140 - val_loss: 2.7021 - val_mae: 1.4834\n",
      "Epoch 969/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0692 - mae: 0.2107 - val_loss: 2.6787 - val_mae: 1.4755\n",
      "Epoch 970/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0704 - mae: 0.2106 - val_loss: 2.6399 - val_mae: 1.4623\n",
      "Epoch 971/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0707 - mae: 0.2092 - val_loss: 2.6012 - val_mae: 1.4490\n",
      "Epoch 972/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0723 - mae: 0.2134 - val_loss: 2.5633 - val_mae: 1.4358\n",
      "Epoch 973/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0746 - mae: 0.2187 - val_loss: 2.5510 - val_mae: 1.4315\n",
      "Epoch 974/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0748 - mae: 0.2195 - val_loss: 2.5764 - val_mae: 1.4404\n",
      "Epoch 975/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0723 - mae: 0.2154 - val_loss: 2.6276 - val_mae: 1.4581\n",
      "Epoch 976/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0702 - mae: 0.2098 - val_loss: 2.6686 - val_mae: 1.4721\n",
      "Epoch 977/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2093 - val_loss: 2.7149 - val_mae: 1.4877\n",
      "Epoch 978/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0676 - mae: 0.2100 - val_loss: 2.7940 - val_mae: 1.5141\n",
      "Epoch 979/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0701 - mae: 0.2173 - val_loss: 2.8495 - val_mae: 1.5322\n",
      "Epoch 980/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0714 - mae: 0.2219 - val_loss: 2.8395 - val_mae: 1.5289\n",
      "Epoch 981/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0715 - mae: 0.2276 - val_loss: 2.8108 - val_mae: 1.5194\n",
      "Epoch 982/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0737 - mae: 0.2344 - val_loss: 2.7655 - val_mae: 1.5044\n",
      "Epoch 983/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0800 - mae: 0.2391 - val_loss: 2.7077 - val_mae: 1.4850\n",
      "Epoch 984/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0763 - mae: 0.2353 - val_loss: 2.6809 - val_mae: 1.4761\n",
      "Epoch 985/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0682 - mae: 0.2179 - val_loss: 2.6658 - val_mae: 1.4710\n",
      "Epoch 986/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0683 - mae: 0.2134 - val_loss: 2.6406 - val_mae: 1.4625\n",
      "Epoch 987/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0708 - mae: 0.2142 - val_loss: 2.6219 - val_mae: 1.4561\n",
      "Epoch 988/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0723 - mae: 0.2177 - val_loss: 2.6248 - val_mae: 1.4572\n",
      "Epoch 989/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0738 - mae: 0.2213 - val_loss: 2.6198 - val_mae: 1.4554\n",
      "Epoch 990/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2130 - val_loss: 2.5905 - val_mae: 1.4452\n",
      "Epoch 991/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0683 - mae: 0.2108 - val_loss: 2.5833 - val_mae: 1.4426\n",
      "Epoch 992/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0722 - mae: 0.2231 - val_loss: 2.6149 - val_mae: 1.4534\n",
      "Epoch 993/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0779 - mae: 0.2319 - val_loss: 2.6609 - val_mae: 1.4692\n",
      "Epoch 994/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0754 - mae: 0.2298 - val_loss: 2.7092 - val_mae: 1.4856\n",
      "Epoch 995/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0692 - mae: 0.2213 - val_loss: 2.7588 - val_mae: 1.5023\n",
      "Epoch 996/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0670 - mae: 0.2139 - val_loss: 2.8087 - val_mae: 1.5189\n",
      "Epoch 997/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0687 - mae: 0.2146 - val_loss: 2.8443 - val_mae: 1.5306\n",
      "Epoch 998/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0751 - mae: 0.2240 - val_loss: 2.8835 - val_mae: 1.5435\n",
      "Epoch 999/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0837 - mae: 0.2382 - val_loss: 2.8908 - val_mae: 1.5458\n",
      "Epoch 1000/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0804 - mae: 0.2317 - val_loss: 2.8451 - val_mae: 1.5308\n",
      "Epoch 1001/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0692 - mae: 0.2158 - val_loss: 2.8036 - val_mae: 1.5171\n",
      "Epoch 1002/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0689 - mae: 0.2207 - val_loss: 2.8048 - val_mae: 1.5175\n",
      "Epoch 1003/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0716 - mae: 0.2232 - val_loss: 2.8524 - val_mae: 1.5331\n",
      "Epoch 1004/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0713 - mae: 0.2231 - val_loss: 2.9162 - val_mae: 1.5538\n",
      "Epoch 1005/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0692 - mae: 0.2186 - val_loss: 2.9698 - val_mae: 1.5710\n",
      "Epoch 1006/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0709 - mae: 0.2177 - val_loss: 2.9726 - val_mae: 1.5720\n",
      "Epoch 1007/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2147 - val_loss: 2.9062 - val_mae: 1.5506\n",
      "Epoch 1008/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0684 - mae: 0.2145 - val_loss: 2.8399 - val_mae: 1.5290\n",
      "Epoch 1009/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2141 - val_loss: 2.8059 - val_mae: 1.5179\n",
      "Epoch 1010/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0677 - mae: 0.2126 - val_loss: 2.7899 - val_mae: 1.5126\n",
      "Epoch 1011/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0669 - mae: 0.2111 - val_loss: 2.7693 - val_mae: 1.5058\n",
      "Epoch 1012/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0661 - mae: 0.2087 - val_loss: 2.7346 - val_mae: 1.4942\n",
      "Epoch 1013/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0662 - mae: 0.2086 - val_loss: 2.7040 - val_mae: 1.4839\n",
      "Epoch 1014/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0668 - mae: 0.2083 - val_loss: 2.7053 - val_mae: 1.4844\n",
      "Epoch 1015/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0667 - mae: 0.2074 - val_loss: 2.7489 - val_mae: 1.4991\n",
      "Epoch 1016/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0711 - mae: 0.2156 - val_loss: 2.7654 - val_mae: 1.5046\n",
      "Epoch 1017/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0739 - mae: 0.2221 - val_loss: 2.7360 - val_mae: 1.4947\n",
      "Epoch 1018/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0705 - mae: 0.2153 - val_loss: 2.7167 - val_mae: 1.4882\n",
      "Epoch 1019/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0675 - mae: 0.2140 - val_loss: 2.7122 - val_mae: 1.4866\n",
      "Epoch 1020/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0670 - mae: 0.2150 - val_loss: 2.6897 - val_mae: 1.4790\n",
      "Epoch 1021/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0670 - mae: 0.2177 - val_loss: 2.6322 - val_mae: 1.4594\n",
      "Epoch 1022/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0695 - mae: 0.2221 - val_loss: 2.5777 - val_mae: 1.4406\n",
      "Epoch 1023/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0742 - mae: 0.2266 - val_loss: 2.5718 - val_mae: 1.4385\n",
      "Epoch 1024/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2229 - val_loss: 2.5886 - val_mae: 1.4444\n",
      "Epoch 1025/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0677 - mae: 0.2166 - val_loss: 2.5982 - val_mae: 1.4477\n",
      "Epoch 1026/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0672 - mae: 0.2132 - val_loss: 2.6172 - val_mae: 1.4543\n",
      "Epoch 1027/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0667 - mae: 0.2126 - val_loss: 2.6497 - val_mae: 1.4654\n",
      "Epoch 1028/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0673 - mae: 0.2177 - val_loss: 2.6593 - val_mae: 1.4686\n",
      "Epoch 1029/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0691 - mae: 0.2219 - val_loss: 2.6681 - val_mae: 1.4716\n",
      "Epoch 1030/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0681 - mae: 0.2192 - val_loss: 2.7050 - val_mae: 1.4842\n",
      "Epoch 1031/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0655 - mae: 0.2109 - val_loss: 2.7555 - val_mae: 1.5012\n",
      "Epoch 1032/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0679 - mae: 0.2101 - val_loss: 2.7755 - val_mae: 1.5078\n",
      "Epoch 1033/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0682 - mae: 0.2092 - val_loss: 2.7181 - val_mae: 1.4886\n",
      "Epoch 1034/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0651 - mae: 0.2049 - val_loss: 2.6307 - val_mae: 1.4588\n",
      "Epoch 1035/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0697 - mae: 0.2183 - val_loss: 2.5537 - val_mae: 1.4321\n",
      "Epoch 1036/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0865 - mae: 0.2409 - val_loss: 2.5152 - val_mae: 1.4186\n",
      "Epoch 1037/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0892 - mae: 0.2435 - val_loss: 2.5521 - val_mae: 1.4317\n",
      "Epoch 1038/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0732 - mae: 0.2193 - val_loss: 2.6357 - val_mae: 1.4608\n",
      "Epoch 1039/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0729 - mae: 0.2178 - val_loss: 2.7141 - val_mae: 1.4875\n",
      "Epoch 1040/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0790 - mae: 0.2280 - val_loss: 2.7734 - val_mae: 1.5073\n",
      "Epoch 1041/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0780 - mae: 0.2286 - val_loss: 2.7942 - val_mae: 1.5140\n",
      "Epoch 1042/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0692 - mae: 0.2105 - val_loss: 2.7618 - val_mae: 1.5031\n",
      "Epoch 1043/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0670 - mae: 0.2133 - val_loss: 2.7343 - val_mae: 1.4938\n",
      "Epoch 1044/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0756 - mae: 0.2277 - val_loss: 2.7606 - val_mae: 1.5026\n",
      "Epoch 1045/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0743 - mae: 0.2265 - val_loss: 2.8106 - val_mae: 1.5192\n",
      "Epoch 1046/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0675 - mae: 0.2174 - val_loss: 2.8463 - val_mae: 1.5310\n",
      "Epoch 1047/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0655 - mae: 0.2091 - val_loss: 2.8936 - val_mae: 1.5464\n",
      "Epoch 1048/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0693 - mae: 0.2133 - val_loss: 2.9325 - val_mae: 1.5590\n",
      "Epoch 1049/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0747 - mae: 0.2218 - val_loss: 2.9146 - val_mae: 1.5532\n",
      "Epoch 1050/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0712 - mae: 0.2153 - val_loss: 2.8872 - val_mae: 1.5443\n",
      "Epoch 1051/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2104 - val_loss: 2.8727 - val_mae: 1.5395\n",
      "Epoch 1052/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0661 - mae: 0.2111 - val_loss: 2.8526 - val_mae: 1.5330\n",
      "Epoch 1053/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0657 - mae: 0.2098 - val_loss: 2.8167 - val_mae: 1.5212\n",
      "Epoch 1054/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2096 - val_loss: 2.7513 - val_mae: 1.4995\n",
      "Epoch 1055/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0722 - mae: 0.2241 - val_loss: 2.6973 - val_mae: 1.4813\n",
      "Epoch 1056/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0834 - mae: 0.2368 - val_loss: 2.6778 - val_mae: 1.4747\n",
      "Epoch 1057/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0828 - mae: 0.2356 - val_loss: 2.7146 - val_mae: 1.4873\n",
      "Epoch 1058/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.2189 - val_loss: 2.7865 - val_mae: 1.5114\n",
      "Epoch 1059/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0693 - mae: 0.2106 - val_loss: 2.8147 - val_mae: 1.5208\n",
      "Epoch 1060/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0748 - mae: 0.2242 - val_loss: 2.7704 - val_mae: 1.5060\n",
      "Epoch 1061/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0673 - mae: 0.2079 - val_loss: 2.6931 - val_mae: 1.4800\n",
      "Epoch 1062/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0660 - mae: 0.2118 - val_loss: 2.6433 - val_mae: 1.4630\n",
      "Epoch 1063/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0787 - mae: 0.2320 - val_loss: 2.6237 - val_mae: 1.4562\n",
      "Epoch 1064/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0903 - mae: 0.2461 - val_loss: 2.6259 - val_mae: 1.4569\n",
      "Epoch 1065/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0861 - mae: 0.2410 - val_loss: 2.7184 - val_mae: 1.4885\n",
      "Epoch 1066/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0712 - mae: 0.2277 - val_loss: 2.8355 - val_mae: 1.5277\n",
      "Epoch 1067/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1135 - mae: 0.2800 - val_loss: 2.8160 - val_mae: 1.5214\n",
      "Epoch 1068/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1120 - mae: 0.2764 - val_loss: 2.6825 - val_mae: 1.4767\n",
      "Epoch 1069/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0765 - mae: 0.2288 - val_loss: 2.5487 - val_mae: 1.4305\n",
      "Epoch 1070/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0681 - mae: 0.2133 - val_loss: 2.4775 - val_mae: 1.4052\n",
      "Epoch 1071/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0893 - mae: 0.2446 - val_loss: 2.4712 - val_mae: 1.4029\n",
      "Epoch 1072/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1013 - mae: 0.2566 - val_loss: 2.5544 - val_mae: 1.4323\n",
      "Epoch 1073/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0832 - mae: 0.2371 - val_loss: 2.6847 - val_mae: 1.4772\n",
      "Epoch 1074/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0659 - mae: 0.2130 - val_loss: 2.8067 - val_mae: 1.5181\n",
      "Epoch 1075/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0706 - mae: 0.2170 - val_loss: 2.8671 - val_mae: 1.5379\n",
      "Epoch 1076/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0798 - mae: 0.2280 - val_loss: 2.8391 - val_mae: 1.5287\n",
      "Epoch 1077/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0753 - mae: 0.2218 - val_loss: 2.7879 - val_mae: 1.5119\n",
      "Epoch 1078/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0664 - mae: 0.2126 - val_loss: 2.7515 - val_mae: 1.4998\n",
      "Epoch 1079/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2114 - val_loss: 2.7001 - val_mae: 1.4825\n",
      "Epoch 1080/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0695 - mae: 0.2199 - val_loss: 2.6619 - val_mae: 1.4695\n",
      "Epoch 1081/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0754 - mae: 0.2282 - val_loss: 2.6690 - val_mae: 1.4720\n",
      "Epoch 1082/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0702 - mae: 0.2203 - val_loss: 2.7103 - val_mae: 1.4861\n",
      "Epoch 1083/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0654 - mae: 0.2043 - val_loss: 2.7468 - val_mae: 1.4985\n",
      "Epoch 1084/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0711 - mae: 0.2143 - val_loss: 2.7599 - val_mae: 1.5029\n",
      "Epoch 1085/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0790 - mae: 0.2296 - val_loss: 2.7305 - val_mae: 1.4930\n",
      "Epoch 1086/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0739 - mae: 0.2192 - val_loss: 2.6953 - val_mae: 1.4810\n",
      "Epoch 1087/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0657 - mae: 0.2044 - val_loss: 2.6886 - val_mae: 1.4786\n",
      "Epoch 1088/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0651 - mae: 0.2104 - val_loss: 2.7112 - val_mae: 1.4862\n",
      "Epoch 1089/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0670 - mae: 0.2188 - val_loss: 2.7307 - val_mae: 1.4927\n",
      "Epoch 1090/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0673 - mae: 0.2207 - val_loss: 2.7503 - val_mae: 1.4992\n",
      "Epoch 1091/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0685 - mae: 0.2239 - val_loss: 2.7769 - val_mae: 1.5081\n",
      "Epoch 1092/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0685 - mae: 0.2225 - val_loss: 2.7792 - val_mae: 1.5089\n",
      "Epoch 1093/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2195 - val_loss: 2.7980 - val_mae: 1.5151\n",
      "Epoch 1094/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0677 - mae: 0.2155 - val_loss: 2.7926 - val_mae: 1.5134\n",
      "Epoch 1095/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2142 - val_loss: 2.7559 - val_mae: 1.5012\n",
      "Epoch 1096/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2106 - val_loss: 2.7308 - val_mae: 1.4929\n",
      "Epoch 1097/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0644 - mae: 0.2053 - val_loss: 2.7114 - val_mae: 1.4864\n",
      "Epoch 1098/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0643 - mae: 0.2035 - val_loss: 2.6833 - val_mae: 1.4769\n",
      "Epoch 1099/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0656 - mae: 0.2077 - val_loss: 2.6835 - val_mae: 1.4770\n",
      "Epoch 1100/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0669 - mae: 0.2103 - val_loss: 2.7161 - val_mae: 1.4880\n",
      "Epoch 1101/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0665 - mae: 0.2090 - val_loss: 2.7579 - val_mae: 1.5020\n",
      "Epoch 1102/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0663 - mae: 0.2092 - val_loss: 2.8007 - val_mae: 1.5161\n",
      "Epoch 1103/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0659 - mae: 0.2094 - val_loss: 2.8264 - val_mae: 1.5245\n",
      "Epoch 1104/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0659 - mae: 0.2108 - val_loss: 2.8405 - val_mae: 1.5291\n",
      "Epoch 1105/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0680 - mae: 0.2157 - val_loss: 2.8713 - val_mae: 1.5391\n",
      "Epoch 1106/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0704 - mae: 0.2191 - val_loss: 2.9138 - val_mae: 1.5529\n",
      "Epoch 1107/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.2176 - val_loss: 2.9536 - val_mae: 1.5656\n",
      "Epoch 1108/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0671 - mae: 0.2124 - val_loss: 3.0218 - val_mae: 1.5874\n",
      "Epoch 1109/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2171 - val_loss: 3.0456 - val_mae: 1.5949\n",
      "Epoch 1110/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0800 - mae: 0.2273 - val_loss: 2.9563 - val_mae: 1.5667\n",
      "Epoch 1111/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0733 - mae: 0.2148 - val_loss: 2.8423 - val_mae: 1.5298\n",
      "Epoch 1112/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0652 - mae: 0.2033 - val_loss: 2.7556 - val_mae: 1.5011\n",
      "Epoch 1113/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0652 - mae: 0.2046 - val_loss: 2.7122 - val_mae: 1.4866\n",
      "Epoch 1114/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.2073 - val_loss: 2.7051 - val_mae: 1.4842\n",
      "Epoch 1115/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0672 - mae: 0.2076 - val_loss: 2.7127 - val_mae: 1.4868\n",
      "Epoch 1116/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0668 - mae: 0.2052 - val_loss: 2.7293 - val_mae: 1.4924\n",
      "Epoch 1117/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0668 - mae: 0.2040 - val_loss: 2.7728 - val_mae: 1.5070\n",
      "Epoch 1118/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2115 - val_loss: 2.7936 - val_mae: 1.5138\n",
      "Epoch 1119/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0681 - mae: 0.2076 - val_loss: 2.7503 - val_mae: 1.4992\n",
      "Epoch 1120/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0621 - mae: 0.2004 - val_loss: 2.6970 - val_mae: 1.4812\n",
      "Epoch 1121/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.2183 - val_loss: 2.6429 - val_mae: 1.4626\n",
      "Epoch 1122/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0919 - mae: 0.2475 - val_loss: 2.6128 - val_mae: 1.4522\n",
      "Epoch 1123/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1003 - mae: 0.2582 - val_loss: 2.6763 - val_mae: 1.4741\n",
      "Epoch 1124/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0680 - mae: 0.2157 - val_loss: 2.8380 - val_mae: 1.5283\n",
      "Epoch 1125/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0736 - mae: 0.2184 - val_loss: 2.9741 - val_mae: 1.5725\n",
      "Epoch 1126/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1177 - mae: 0.2848 - val_loss: 2.9893 - val_mae: 1.5773\n",
      "Epoch 1127/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1181 - mae: 0.2857 - val_loss: 2.8924 - val_mae: 1.5460\n",
      "Epoch 1128/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0800 - mae: 0.2296 - val_loss: 2.7480 - val_mae: 1.4984\n",
      "Epoch 1129/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0636 - mae: 0.2086 - val_loss: 2.6313 - val_mae: 1.4588\n",
      "Epoch 1130/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0823 - mae: 0.2346 - val_loss: 2.5968 - val_mae: 1.4468\n",
      "Epoch 1131/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0978 - mae: 0.2542 - val_loss: 2.6428 - val_mae: 1.4627\n",
      "Epoch 1132/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0792 - mae: 0.2303 - val_loss: 2.7628 - val_mae: 1.5034\n",
      "Epoch 1133/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0619 - mae: 0.1985 - val_loss: 2.9084 - val_mae: 1.5514\n",
      "Epoch 1134/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0934 - mae: 0.2507 - val_loss: 2.9506 - val_mae: 1.5650\n",
      "Epoch 1135/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1080 - mae: 0.2732 - val_loss: 2.8932 - val_mae: 1.5465\n",
      "Epoch 1136/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0872 - mae: 0.2407 - val_loss: 2.8018 - val_mae: 1.5165\n",
      "Epoch 1137/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0652 - mae: 0.2051 - val_loss: 2.6704 - val_mae: 1.4724\n",
      "Epoch 1138/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0695 - mae: 0.2215 - val_loss: 2.5635 - val_mae: 1.4354\n",
      "Epoch 1139/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0982 - mae: 0.2541 - val_loss: 2.5756 - val_mae: 1.4397\n",
      "Epoch 1140/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0878 - mae: 0.2418 - val_loss: 2.6948 - val_mae: 1.4807\n",
      "Epoch 1141/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0643 - mae: 0.2059 - val_loss: 2.8134 - val_mae: 1.5205\n",
      "Epoch 1142/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0842 - mae: 0.2403 - val_loss: 2.8426 - val_mae: 1.5302\n",
      "Epoch 1143/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1016 - mae: 0.2629 - val_loss: 2.7895 - val_mae: 1.5127\n",
      "Epoch 1144/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0837 - mae: 0.2363 - val_loss: 2.6798 - val_mae: 1.4758\n",
      "Epoch 1145/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - mae: 0.2028 - val_loss: 2.5774 - val_mae: 1.4405\n",
      "Epoch 1146/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0738 - mae: 0.2258 - val_loss: 2.5460 - val_mae: 1.4295\n",
      "Epoch 1147/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0791 - mae: 0.2326 - val_loss: 2.5983 - val_mae: 1.4477\n",
      "Epoch 1148/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0668 - mae: 0.2145 - val_loss: 2.6996 - val_mae: 1.4824\n",
      "Epoch 1149/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2036 - val_loss: 2.7916 - val_mae: 1.5132\n",
      "Epoch 1150/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0792 - mae: 0.2298 - val_loss: 2.8337 - val_mae: 1.5271\n",
      "Epoch 1151/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0856 - mae: 0.2393 - val_loss: 2.7983 - val_mae: 1.5154\n",
      "Epoch 1152/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0745 - mae: 0.2198 - val_loss: 2.7133 - val_mae: 1.4870\n",
      "Epoch 1153/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0643 - mae: 0.2077 - val_loss: 2.6473 - val_mae: 1.4645\n",
      "Epoch 1154/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.2100 - val_loss: 2.6138 - val_mae: 1.4529\n",
      "Epoch 1155/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0736 - mae: 0.2259 - val_loss: 2.6188 - val_mae: 1.4546\n",
      "Epoch 1156/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0771 - mae: 0.2283 - val_loss: 2.6884 - val_mae: 1.4784\n",
      "Epoch 1157/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0654 - mae: 0.2127 - val_loss: 2.7998 - val_mae: 1.5158\n",
      "Epoch 1158/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0638 - mae: 0.2052 - val_loss: 2.9145 - val_mae: 1.5534\n",
      "Epoch 1159/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0808 - mae: 0.2270 - val_loss: 2.9813 - val_mae: 1.5749\n",
      "Epoch 1160/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0945 - mae: 0.2525 - val_loss: 2.9517 - val_mae: 1.5654\n",
      "Epoch 1161/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0835 - mae: 0.2339 - val_loss: 2.8468 - val_mae: 1.5314\n",
      "Epoch 1162/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0657 - mae: 0.2045 - val_loss: 2.7412 - val_mae: 1.4964\n",
      "Epoch 1163/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2074 - val_loss: 2.6610 - val_mae: 1.4693\n",
      "Epoch 1164/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0714 - mae: 0.2208 - val_loss: 2.6304 - val_mae: 1.4589\n",
      "Epoch 1165/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0713 - mae: 0.2190 - val_loss: 2.6659 - val_mae: 1.4711\n",
      "Epoch 1166/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0673 - mae: 0.2051 - val_loss: 2.7091 - val_mae: 1.4859\n",
      "Epoch 1167/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0700 - mae: 0.2086 - val_loss: 2.6988 - val_mae: 1.4825\n",
      "Epoch 1168/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0735 - mae: 0.2145 - val_loss: 2.6461 - val_mae: 1.4645\n",
      "Epoch 1169/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0721 - mae: 0.2128 - val_loss: 2.6216 - val_mae: 1.4560\n",
      "Epoch 1170/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2059 - val_loss: 2.6588 - val_mae: 1.4687\n",
      "Epoch 1171/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0668 - mae: 0.2025 - val_loss: 2.6954 - val_mae: 1.4810\n",
      "Epoch 1172/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0651 - mae: 0.2015 - val_loss: 2.7365 - val_mae: 1.4948\n",
      "Epoch 1173/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0638 - mae: 0.2015 - val_loss: 2.8407 - val_mae: 1.5292\n",
      "Epoch 1174/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0643 - mae: 0.1989 - val_loss: 2.9483 - val_mae: 1.5640\n",
      "Epoch 1175/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0667 - mae: 0.2009 - val_loss: 2.9899 - val_mae: 1.5772\n",
      "Epoch 1176/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0664 - mae: 0.2018 - val_loss: 2.9774 - val_mae: 1.5731\n",
      "Epoch 1177/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0650 - mae: 0.2008 - val_loss: 2.9571 - val_mae: 1.5665\n",
      "Epoch 1178/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2032 - val_loss: 2.9473 - val_mae: 1.5633\n",
      "Epoch 1179/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.2048 - val_loss: 2.9430 - val_mae: 1.5619\n",
      "Epoch 1180/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0643 - mae: 0.2061 - val_loss: 2.9075 - val_mae: 1.5505\n",
      "Epoch 1181/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0634 - mae: 0.2043 - val_loss: 2.8597 - val_mae: 1.5349\n",
      "Epoch 1182/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0635 - mae: 0.2074 - val_loss: 2.8332 - val_mae: 1.5262\n",
      "Epoch 1183/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0644 - mae: 0.2093 - val_loss: 2.7804 - val_mae: 1.5087\n",
      "Epoch 1184/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0671 - mae: 0.2146 - val_loss: 2.7153 - val_mae: 1.4869\n",
      "Epoch 1185/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0772 - mae: 0.2292 - val_loss: 2.7048 - val_mae: 1.4833\n",
      "Epoch 1186/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0749 - mae: 0.2260 - val_loss: 2.7498 - val_mae: 1.4985\n",
      "Epoch 1187/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0648 - mae: 0.2098 - val_loss: 2.7844 - val_mae: 1.5101\n",
      "Epoch 1188/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0623 - mae: 0.1998 - val_loss: 2.8172 - val_mae: 1.5210\n",
      "Epoch 1189/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0658 - mae: 0.2034 - val_loss: 2.8483 - val_mae: 1.5312\n",
      "Epoch 1190/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0680 - mae: 0.2061 - val_loss: 2.8558 - val_mae: 1.5336\n",
      "Epoch 1191/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0672 - mae: 0.2057 - val_loss: 2.8746 - val_mae: 1.5397\n",
      "Epoch 1192/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2074 - val_loss: 2.8800 - val_mae: 1.5414\n",
      "Epoch 1193/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0651 - mae: 0.2061 - val_loss: 2.8398 - val_mae: 1.5281\n",
      "Epoch 1194/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0642 - mae: 0.2116 - val_loss: 2.8037 - val_mae: 1.5161\n",
      "Epoch 1195/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0689 - mae: 0.2190 - val_loss: 2.8072 - val_mae: 1.5173\n",
      "Epoch 1196/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0705 - mae: 0.2209 - val_loss: 2.8029 - val_mae: 1.5158\n",
      "Epoch 1197/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0691 - mae: 0.2194 - val_loss: 2.7936 - val_mae: 1.5128\n",
      "Epoch 1198/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.2121 - val_loss: 2.8377 - val_mae: 1.5274\n",
      "Epoch 1199/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0620 - mae: 0.1977 - val_loss: 2.8838 - val_mae: 1.5426\n",
      "Epoch 1200/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0674 - mae: 0.2034 - val_loss: 2.8291 - val_mae: 1.5248\n",
      "Epoch 1201/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0677 - mae: 0.2049 - val_loss: 2.7101 - val_mae: 1.4852\n",
      "Epoch 1202/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0653 - mae: 0.2015 - val_loss: 2.5823 - val_mae: 1.4415\n",
      "Epoch 1203/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0732 - mae: 0.2227 - val_loss: 2.5094 - val_mae: 1.4159\n",
      "Epoch 1204/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0796 - mae: 0.2347 - val_loss: 2.5393 - val_mae: 1.4265\n",
      "Epoch 1205/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2183 - val_loss: 2.6472 - val_mae: 1.4640\n",
      "Epoch 1206/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0667 - mae: 0.2022 - val_loss: 2.7632 - val_mae: 1.5032\n",
      "Epoch 1207/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0763 - mae: 0.2205 - val_loss: 2.8097 - val_mae: 1.5185\n",
      "Epoch 1208/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0796 - mae: 0.2288 - val_loss: 2.7867 - val_mae: 1.5108\n",
      "Epoch 1209/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0696 - mae: 0.2087 - val_loss: 2.7193 - val_mae: 1.4881\n",
      "Epoch 1210/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0631 - mae: 0.2038 - val_loss: 2.6595 - val_mae: 1.4678\n",
      "Epoch 1211/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0665 - mae: 0.2152 - val_loss: 2.6725 - val_mae: 1.4722\n",
      "Epoch 1212/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0640 - mae: 0.2101 - val_loss: 2.7041 - val_mae: 1.4830\n",
      "Epoch 1213/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0628 - mae: 0.2023 - val_loss: 2.6946 - val_mae: 1.4798\n",
      "Epoch 1214/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0637 - mae: 0.2001 - val_loss: 2.6365 - val_mae: 1.4600\n",
      "Epoch 1215/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0642 - mae: 0.2014 - val_loss: 2.5632 - val_mae: 1.4347\n",
      "Epoch 1216/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0667 - mae: 0.2081 - val_loss: 2.5333 - val_mae: 1.4242\n",
      "Epoch 1217/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0697 - mae: 0.2149 - val_loss: 2.5630 - val_mae: 1.4346\n",
      "Epoch 1218/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0691 - mae: 0.2130 - val_loss: 2.6315 - val_mae: 1.4583\n",
      "Epoch 1219/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0660 - mae: 0.2046 - val_loss: 2.7052 - val_mae: 1.4834\n",
      "Epoch 1220/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0652 - mae: 0.1998 - val_loss: 2.7629 - val_mae: 1.5027\n",
      "Epoch 1221/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0651 - mae: 0.1987 - val_loss: 2.8003 - val_mae: 1.5151\n",
      "Epoch 1222/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0637 - mae: 0.1989 - val_loss: 2.8015 - val_mae: 1.5154\n",
      "Epoch 1223/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0612 - mae: 0.1984 - val_loss: 2.7576 - val_mae: 1.5007\n",
      "Epoch 1224/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2089 - val_loss: 2.7496 - val_mae: 1.4980\n",
      "Epoch 1225/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0672 - mae: 0.2165 - val_loss: 2.8526 - val_mae: 1.5318\n",
      "Epoch 1226/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0638 - mae: 0.2105 - val_loss: 3.0104 - val_mae: 1.5823\n",
      "Epoch 1227/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0608 - mae: 0.1994 - val_loss: 3.1962 - val_mae: 1.6398\n",
      "Epoch 1228/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0743 - mae: 0.2132 - val_loss: 3.3255 - val_mae: 1.6788\n",
      "Epoch 1229/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0920 - mae: 0.2409 - val_loss: 3.2999 - val_mae: 1.6712\n",
      "Epoch 1230/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0893 - mae: 0.2369 - val_loss: 3.1375 - val_mae: 1.6220\n",
      "Epoch 1231/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0675 - mae: 0.2028 - val_loss: 2.8860 - val_mae: 1.5429\n",
      "Epoch 1232/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0676 - mae: 0.2173 - val_loss: 2.7065 - val_mae: 1.4840\n",
      "Epoch 1233/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0949 - mae: 0.2554 - val_loss: 2.6565 - val_mae: 1.4672\n",
      "Epoch 1234/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0933 - mae: 0.2530 - val_loss: 2.7163 - val_mae: 1.4874\n",
      "Epoch 1235/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2171 - val_loss: 2.8479 - val_mae: 1.5310\n",
      "Epoch 1236/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0632 - mae: 0.1990 - val_loss: 2.9555 - val_mae: 1.5658\n",
      "Epoch 1237/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0743 - mae: 0.2162 - val_loss: 2.9889 - val_mae: 1.5765\n",
      "Epoch 1238/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0783 - mae: 0.2220 - val_loss: 2.9447 - val_mae: 1.5624\n",
      "Epoch 1239/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0702 - mae: 0.2066 - val_loss: 2.8566 - val_mae: 1.5339\n",
      "Epoch 1240/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0631 - mae: 0.1994 - val_loss: 2.7571 - val_mae: 1.5011\n",
      "Epoch 1241/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0678 - mae: 0.2163 - val_loss: 2.6617 - val_mae: 1.4689\n",
      "Epoch 1242/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0791 - mae: 0.2378 - val_loss: 2.6376 - val_mae: 1.4606\n",
      "Epoch 1243/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0801 - mae: 0.2383 - val_loss: 2.6879 - val_mae: 1.4777\n",
      "Epoch 1244/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.2213 - val_loss: 2.7578 - val_mae: 1.5011\n",
      "Epoch 1245/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0612 - mae: 0.2013 - val_loss: 2.8149 - val_mae: 1.5200\n",
      "Epoch 1246/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0622 - mae: 0.2004 - val_loss: 2.8573 - val_mae: 1.5339\n",
      "Epoch 1247/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0677 - mae: 0.2057 - val_loss: 2.8741 - val_mae: 1.5394\n",
      "Epoch 1248/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0723 - mae: 0.2137 - val_loss: 2.8763 - val_mae: 1.5401\n",
      "Epoch 1249/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2138 - val_loss: 2.8318 - val_mae: 1.5255\n",
      "Epoch 1250/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.2064 - val_loss: 2.7447 - val_mae: 1.4968\n",
      "Epoch 1251/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0688 - mae: 0.2197 - val_loss: 2.6847 - val_mae: 1.4767\n",
      "Epoch 1252/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0888 - mae: 0.2440 - val_loss: 2.6491 - val_mae: 1.4645\n",
      "Epoch 1253/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0914 - mae: 0.2467 - val_loss: 2.6541 - val_mae: 1.4661\n",
      "Epoch 1254/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0720 - mae: 0.2231 - val_loss: 2.7174 - val_mae: 1.4876\n",
      "Epoch 1255/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0617 - mae: 0.2038 - val_loss: 2.7723 - val_mae: 1.5060\n",
      "Epoch 1256/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0689 - mae: 0.2076 - val_loss: 2.7648 - val_mae: 1.5036\n",
      "Epoch 1257/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0740 - mae: 0.2185 - val_loss: 2.7186 - val_mae: 1.4882\n",
      "Epoch 1258/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0696 - mae: 0.2094 - val_loss: 2.6276 - val_mae: 1.4572\n",
      "Epoch 1259/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0624 - mae: 0.1972 - val_loss: 2.5083 - val_mae: 1.4155\n",
      "Epoch 1260/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0719 - mae: 0.2248 - val_loss: 2.4396 - val_mae: 1.3910\n",
      "Epoch 1261/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0876 - mae: 0.2493 - val_loss: 2.4701 - val_mae: 1.4019\n",
      "Epoch 1262/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0804 - mae: 0.2362 - val_loss: 2.5755 - val_mae: 1.4392\n",
      "Epoch 1263/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0656 - mae: 0.2056 - val_loss: 2.6819 - val_mae: 1.4759\n",
      "Epoch 1264/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0642 - mae: 0.1981 - val_loss: 2.7353 - val_mae: 1.4939\n",
      "Epoch 1265/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2047 - val_loss: 2.7589 - val_mae: 1.5017\n",
      "Epoch 1266/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0671 - mae: 0.2032 - val_loss: 2.7606 - val_mae: 1.5022\n",
      "Epoch 1267/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.2006 - val_loss: 2.7393 - val_mae: 1.4950\n",
      "Epoch 1268/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.1983 - val_loss: 2.7360 - val_mae: 1.4938\n",
      "Epoch 1269/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.2011 - val_loss: 2.7248 - val_mae: 1.4900\n",
      "Epoch 1270/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0614 - mae: 0.2055 - val_loss: 2.6754 - val_mae: 1.4732\n",
      "Epoch 1271/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0660 - mae: 0.2154 - val_loss: 2.6544 - val_mae: 1.4661\n",
      "Epoch 1272/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0626 - mae: 0.2091 - val_loss: 2.6974 - val_mae: 1.4808\n",
      "Epoch 1273/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0612 - mae: 0.1989 - val_loss: 2.7317 - val_mae: 1.4925\n",
      "Epoch 1274/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0681 - mae: 0.2064 - val_loss: 2.7232 - val_mae: 1.4898\n",
      "Epoch 1275/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0717 - mae: 0.2136 - val_loss: 2.6851 - val_mae: 1.4769\n",
      "Epoch 1276/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0694 - mae: 0.2080 - val_loss: 2.6352 - val_mae: 1.4599\n",
      "Epoch 1277/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0661 - mae: 0.2008 - val_loss: 2.5726 - val_mae: 1.4382\n",
      "Epoch 1278/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0651 - mae: 0.2006 - val_loss: 2.5201 - val_mae: 1.4198\n",
      "Epoch 1279/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0663 - mae: 0.2063 - val_loss: 2.4912 - val_mae: 1.4095\n",
      "Epoch 1280/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0684 - mae: 0.2122 - val_loss: 2.5046 - val_mae: 1.4143\n",
      "Epoch 1281/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0656 - mae: 0.2045 - val_loss: 2.5719 - val_mae: 1.4379\n",
      "Epoch 1282/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0636 - mae: 0.1967 - val_loss: 2.6583 - val_mae: 1.4677\n",
      "Epoch 1283/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0685 - mae: 0.2063 - val_loss: 2.7469 - val_mae: 1.4977\n",
      "Epoch 1284/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0802 - mae: 0.2289 - val_loss: 2.8092 - val_mae: 1.5183\n",
      "Epoch 1285/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0887 - mae: 0.2437 - val_loss: 2.7717 - val_mae: 1.5058\n",
      "Epoch 1286/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0703 - mae: 0.2084 - val_loss: 2.6564 - val_mae: 1.4669\n",
      "Epoch 1287/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.2049 - val_loss: 2.5731 - val_mae: 1.4381\n",
      "Epoch 1288/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0825 - mae: 0.2375 - val_loss: 2.5552 - val_mae: 1.4319\n",
      "Epoch 1289/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0978 - mae: 0.2596 - val_loss: 2.6002 - val_mae: 1.4477\n",
      "Epoch 1290/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0816 - mae: 0.2353 - val_loss: 2.7077 - val_mae: 1.4846\n",
      "Epoch 1291/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0619 - mae: 0.2067 - val_loss: 2.8277 - val_mae: 1.5247\n",
      "Epoch 1292/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0653 - mae: 0.1993 - val_loss: 2.8882 - val_mae: 1.5446\n",
      "Epoch 1293/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0773 - mae: 0.2207 - val_loss: 2.8727 - val_mae: 1.5396\n",
      "Epoch 1294/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0811 - mae: 0.2276 - val_loss: 2.8022 - val_mae: 1.5164\n",
      "Epoch 1295/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0726 - mae: 0.2153 - val_loss: 2.7148 - val_mae: 1.4871\n",
      "Epoch 1296/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0628 - mae: 0.1962 - val_loss: 2.6467 - val_mae: 1.4639\n",
      "Epoch 1297/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0618 - mae: 0.2000 - val_loss: 2.6336 - val_mae: 1.4594\n",
      "Epoch 1298/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0624 - mae: 0.2051 - val_loss: 2.6579 - val_mae: 1.4677\n",
      "Epoch 1299/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.2046 - val_loss: 2.6936 - val_mae: 1.4798\n",
      "Epoch 1300/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0609 - mae: 0.2027 - val_loss: 2.7048 - val_mae: 1.4836\n",
      "Epoch 1301/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0600 - mae: 0.2013 - val_loss: 2.6657 - val_mae: 1.4702\n",
      "Epoch 1302/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0616 - mae: 0.2070 - val_loss: 2.6380 - val_mae: 1.4607\n",
      "Epoch 1303/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0628 - mae: 0.2099 - val_loss: 2.6397 - val_mae: 1.4612\n",
      "Epoch 1304/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0628 - mae: 0.2089 - val_loss: 2.6887 - val_mae: 1.4779\n",
      "Epoch 1305/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0623 - mae: 0.2072 - val_loss: 2.7658 - val_mae: 1.5039\n",
      "Epoch 1306/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0643 - mae: 0.2090 - val_loss: 2.8217 - val_mae: 1.5224\n",
      "Epoch 1307/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0663 - mae: 0.2096 - val_loss: 2.8512 - val_mae: 1.5321\n",
      "Epoch 1308/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0653 - mae: 0.2082 - val_loss: 2.8593 - val_mae: 1.5348\n",
      "Epoch 1309/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0632 - mae: 0.2046 - val_loss: 2.8771 - val_mae: 1.5406\n",
      "Epoch 1310/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.1987 - val_loss: 2.8787 - val_mae: 1.5412\n",
      "Epoch 1311/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0634 - mae: 0.1986 - val_loss: 2.8403 - val_mae: 1.5287\n",
      "Epoch 1312/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0618 - mae: 0.1953 - val_loss: 2.8083 - val_mae: 1.5182\n",
      "Epoch 1313/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0606 - mae: 0.1937 - val_loss: 2.7723 - val_mae: 1.5064\n",
      "Epoch 1314/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0649 - mae: 0.2042 - val_loss: 2.7326 - val_mae: 1.4932\n",
      "Epoch 1315/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0693 - mae: 0.2149 - val_loss: 2.7362 - val_mae: 1.4944\n",
      "Epoch 1316/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0706 - mae: 0.2169 - val_loss: 2.7591 - val_mae: 1.5021\n",
      "Epoch 1317/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0699 - mae: 0.2147 - val_loss: 2.7786 - val_mae: 1.5085\n",
      "Epoch 1318/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2102 - val_loss: 2.8227 - val_mae: 1.5231\n",
      "Epoch 1319/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.2007 - val_loss: 2.8850 - val_mae: 1.5434\n",
      "Epoch 1320/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0635 - mae: 0.1950 - val_loss: 2.9517 - val_mae: 1.5648\n",
      "Epoch 1321/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0663 - mae: 0.1988 - val_loss: 2.9911 - val_mae: 1.5773\n",
      "Epoch 1322/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0688 - mae: 0.2014 - val_loss: 3.0092 - val_mae: 1.5831\n",
      "Epoch 1323/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.1995 - val_loss: 3.0001 - val_mae: 1.5803\n",
      "Epoch 1324/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0643 - mae: 0.2059 - val_loss: 2.9817 - val_mae: 1.5746\n",
      "Epoch 1325/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - mae: 0.2103 - val_loss: 2.9714 - val_mae: 1.5714\n",
      "Epoch 1326/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0708 - mae: 0.2159 - val_loss: 2.9476 - val_mae: 1.5638\n",
      "Epoch 1327/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0724 - mae: 0.2183 - val_loss: 2.9399 - val_mae: 1.5613\n",
      "Epoch 1328/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0697 - mae: 0.2156 - val_loss: 2.9491 - val_mae: 1.5641\n",
      "Epoch 1329/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0663 - mae: 0.2141 - val_loss: 2.9836 - val_mae: 1.5749\n",
      "Epoch 1330/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0676 - mae: 0.2135 - val_loss: 2.9783 - val_mae: 1.5732\n",
      "Epoch 1331/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0640 - mae: 0.2082 - val_loss: 2.8752 - val_mae: 1.5401\n",
      "Epoch 1332/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0679 - mae: 0.2173 - val_loss: 2.7856 - val_mae: 1.5108\n",
      "Epoch 1333/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0856 - mae: 0.2393 - val_loss: 2.7563 - val_mae: 1.5010\n",
      "Epoch 1334/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0884 - mae: 0.2447 - val_loss: 2.7980 - val_mae: 1.5148\n",
      "Epoch 1335/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0706 - mae: 0.2205 - val_loss: 2.9050 - val_mae: 1.5497\n",
      "Epoch 1336/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0623 - mae: 0.2018 - val_loss: 2.9560 - val_mae: 1.5661\n",
      "Epoch 1337/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0625 - mae: 0.1951 - val_loss: 2.9823 - val_mae: 1.5746\n",
      "Epoch 1338/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0635 - mae: 0.1950 - val_loss: 3.0038 - val_mae: 1.5815\n",
      "Epoch 1339/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0645 - mae: 0.1956 - val_loss: 2.9924 - val_mae: 1.5779\n",
      "Epoch 1340/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0640 - mae: 0.1963 - val_loss: 3.0060 - val_mae: 1.5823\n",
      "Epoch 1341/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0636 - mae: 0.1960 - val_loss: 3.0334 - val_mae: 1.5910\n",
      "Epoch 1342/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0639 - mae: 0.1976 - val_loss: 3.0374 - val_mae: 1.5923\n",
      "Epoch 1343/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0637 - mae: 0.1994 - val_loss: 3.0233 - val_mae: 1.5878\n",
      "Epoch 1344/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0636 - mae: 0.2014 - val_loss: 3.0213 - val_mae: 1.5872\n",
      "Epoch 1345/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0625 - mae: 0.2003 - val_loss: 3.0303 - val_mae: 1.5900\n",
      "Epoch 1346/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.1955 - val_loss: 2.9947 - val_mae: 1.5786\n",
      "Epoch 1347/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0638 - mae: 0.1977 - val_loss: 2.8935 - val_mae: 1.5461\n",
      "Epoch 1348/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0608 - mae: 0.1972 - val_loss: 2.7819 - val_mae: 1.5095\n",
      "Epoch 1349/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.1992 - val_loss: 2.6836 - val_mae: 1.4765\n",
      "Epoch 1350/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0638 - mae: 0.2141 - val_loss: 2.6204 - val_mae: 1.4550\n",
      "Epoch 1351/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0724 - mae: 0.2243 - val_loss: 2.6434 - val_mae: 1.4628\n",
      "Epoch 1352/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0631 - mae: 0.2117 - val_loss: 2.7508 - val_mae: 1.4989\n",
      "Epoch 1353/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0610 - mae: 0.1979 - val_loss: 2.8622 - val_mae: 1.5356\n",
      "Epoch 1354/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0771 - mae: 0.2208 - val_loss: 2.8900 - val_mae: 1.5447\n",
      "Epoch 1355/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0841 - mae: 0.2340 - val_loss: 2.7900 - val_mae: 1.5119\n",
      "Epoch 1356/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0674 - mae: 0.2045 - val_loss: 2.6221 - val_mae: 1.4552\n",
      "Epoch 1357/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0618 - mae: 0.2028 - val_loss: 2.4995 - val_mae: 1.4124\n",
      "Epoch 1358/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0771 - mae: 0.2350 - val_loss: 2.4397 - val_mae: 1.3910\n",
      "Epoch 1359/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0877 - mae: 0.2512 - val_loss: 2.4675 - val_mae: 1.4010\n",
      "Epoch 1360/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0761 - mae: 0.2345 - val_loss: 2.5538 - val_mae: 1.4315\n",
      "Epoch 1361/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0609 - mae: 0.1983 - val_loss: 2.6815 - val_mae: 1.4755\n",
      "Epoch 1362/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0658 - mae: 0.2007 - val_loss: 2.8301 - val_mae: 1.5252\n",
      "Epoch 1363/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0863 - mae: 0.2374 - val_loss: 2.9354 - val_mae: 1.5594\n",
      "Epoch 1364/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0950 - mae: 0.2510 - val_loss: 2.9716 - val_mae: 1.5709\n",
      "Epoch 1365/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0803 - mae: 0.2243 - val_loss: 2.9158 - val_mae: 1.5529\n",
      "Epoch 1366/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.1958 - val_loss: 2.8218 - val_mae: 1.5224\n",
      "Epoch 1367/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0624 - mae: 0.2079 - val_loss: 2.7597 - val_mae: 1.5018\n",
      "Epoch 1368/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0747 - mae: 0.2270 - val_loss: 2.7692 - val_mae: 1.5050\n",
      "Epoch 1369/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0702 - mae: 0.2197 - val_loss: 2.8570 - val_mae: 1.5339\n",
      "Epoch 1370/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0612 - mae: 0.2016 - val_loss: 2.9151 - val_mae: 1.5528\n",
      "Epoch 1371/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0622 - mae: 0.1952 - val_loss: 2.8997 - val_mae: 1.5478\n",
      "Epoch 1372/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0657 - mae: 0.1987 - val_loss: 2.8272 - val_mae: 1.5242\n",
      "Epoch 1373/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.1972 - val_loss: 2.7140 - val_mae: 1.4865\n",
      "Epoch 1374/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0590 - mae: 0.1944 - val_loss: 2.6040 - val_mae: 1.4490\n",
      "Epoch 1375/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0602 - mae: 0.2026 - val_loss: 2.5154 - val_mae: 1.4180\n",
      "Epoch 1376/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0658 - mae: 0.2137 - val_loss: 2.4845 - val_mae: 1.4071\n",
      "Epoch 1377/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0672 - mae: 0.2161 - val_loss: 2.5162 - val_mae: 1.4183\n",
      "Epoch 1378/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0627 - mae: 0.2066 - val_loss: 2.5780 - val_mae: 1.4399\n",
      "Epoch 1379/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0607 - mae: 0.1989 - val_loss: 2.6336 - val_mae: 1.4591\n",
      "Epoch 1380/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0630 - mae: 0.2020 - val_loss: 2.6690 - val_mae: 1.4712\n",
      "Epoch 1381/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0658 - mae: 0.2065 - val_loss: 2.6554 - val_mae: 1.4665\n",
      "Epoch 1382/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0645 - mae: 0.2064 - val_loss: 2.5819 - val_mae: 1.4412\n",
      "Epoch 1383/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0636 - mae: 0.2082 - val_loss: 2.5140 - val_mae: 1.4175\n",
      "Epoch 1384/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0681 - mae: 0.2177 - val_loss: 2.5094 - val_mae: 1.4159\n",
      "Epoch 1385/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0667 - mae: 0.2145 - val_loss: 2.5422 - val_mae: 1.4273\n",
      "Epoch 1386/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0631 - mae: 0.2075 - val_loss: 2.5699 - val_mae: 1.4370\n",
      "Epoch 1387/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0663 - mae: 0.2071 - val_loss: 2.5364 - val_mae: 1.4253\n",
      "Epoch 1388/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0624 - mae: 0.2015 - val_loss: 2.4615 - val_mae: 1.3987\n",
      "Epoch 1389/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0652 - mae: 0.2084 - val_loss: 2.4509 - val_mae: 1.3950\n",
      "Epoch 1390/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0689 - mae: 0.2186 - val_loss: 2.5219 - val_mae: 1.4202\n",
      "Epoch 1391/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0643 - mae: 0.2089 - val_loss: 2.6147 - val_mae: 1.4526\n",
      "Epoch 1392/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.1973 - val_loss: 2.7181 - val_mae: 1.4878\n",
      "Epoch 1393/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0640 - mae: 0.1970 - val_loss: 2.8084 - val_mae: 1.5179\n",
      "Epoch 1394/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.2013 - val_loss: 2.8654 - val_mae: 1.5366\n",
      "Epoch 1395/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0645 - mae: 0.1980 - val_loss: 2.9378 - val_mae: 1.5601\n",
      "Epoch 1396/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0642 - mae: 0.1952 - val_loss: 2.9999 - val_mae: 1.5799\n",
      "Epoch 1397/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0646 - mae: 0.1941 - val_loss: 3.0339 - val_mae: 1.5906\n",
      "Epoch 1398/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0638 - mae: 0.1942 - val_loss: 3.0290 - val_mae: 1.5891\n",
      "Epoch 1399/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0615 - mae: 0.1936 - val_loss: 2.9589 - val_mae: 1.5669\n",
      "Epoch 1400/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0610 - mae: 0.2027 - val_loss: 2.8375 - val_mae: 1.5277\n",
      "Epoch 1401/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0754 - mae: 0.2288 - val_loss: 2.7723 - val_mae: 1.5062\n",
      "Epoch 1402/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0735 - mae: 0.2278 - val_loss: 2.8032 - val_mae: 1.5163\n",
      "Epoch 1403/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0575 - mae: 0.1964 - val_loss: 2.8855 - val_mae: 1.5431\n",
      "Epoch 1404/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0696 - mae: 0.2060 - val_loss: 2.9679 - val_mae: 1.5696\n",
      "Epoch 1405/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1015 - mae: 0.2623 - val_loss: 2.9420 - val_mae: 1.5613\n",
      "Epoch 1406/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1028 - mae: 0.2628 - val_loss: 2.8354 - val_mae: 1.5267\n",
      "Epoch 1407/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0742 - mae: 0.2154 - val_loss: 2.7027 - val_mae: 1.4826\n",
      "Epoch 1408/5000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0587 - mae: 0.1921 - val_loss: 2.5745 - val_mae: 1.4387\n",
      "Epoch 1409/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0711 - mae: 0.2257 - val_loss: 2.5353 - val_mae: 1.4251\n",
      "Epoch 1410/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0748 - mae: 0.2327 - val_loss: 2.6130 - val_mae: 1.4520\n",
      "Epoch 1411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1960 - val_loss: 2.7516 - val_mae: 1.4989\n",
      "Epoch 1412/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0682 - mae: 0.2028 - val_loss: 2.8236 - val_mae: 1.5228\n",
      "Epoch 1413/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0860 - mae: 0.2371 - val_loss: 2.7603 - val_mae: 1.5019\n",
      "Epoch 1414/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0769 - mae: 0.2208 - val_loss: 2.6036 - val_mae: 1.4487\n",
      "Epoch 1415/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0620 - mae: 0.1995 - val_loss: 2.4569 - val_mae: 1.3971\n",
      "Epoch 1416/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0698 - mae: 0.2175 - val_loss: 2.3798 - val_mae: 1.3693\n",
      "Epoch 1417/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0824 - mae: 0.2402 - val_loss: 2.3823 - val_mae: 1.3702\n",
      "Epoch 1418/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0803 - mae: 0.2361 - val_loss: 2.4761 - val_mae: 1.4040\n",
      "Epoch 1419/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0679 - mae: 0.2131 - val_loss: 2.6330 - val_mae: 1.4589\n",
      "Epoch 1420/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0666 - mae: 0.2031 - val_loss: 2.7355 - val_mae: 1.4936\n",
      "Epoch 1421/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0707 - mae: 0.2113 - val_loss: 2.7750 - val_mae: 1.5068\n",
      "Epoch 1422/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0734 - mae: 0.2165 - val_loss: 2.7891 - val_mae: 1.5115\n",
      "Epoch 1423/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0672 - mae: 0.2050 - val_loss: 2.7338 - val_mae: 1.4932\n",
      "Epoch 1424/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0607 - mae: 0.1989 - val_loss: 2.6951 - val_mae: 1.4803\n",
      "Epoch 1425/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0634 - mae: 0.2108 - val_loss: 2.7501 - val_mae: 1.4988\n",
      "Epoch 1426/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0625 - mae: 0.2095 - val_loss: 2.8331 - val_mae: 1.5262\n",
      "Epoch 1427/5000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0587 - mae: 0.1978 - val_loss: 2.8897 - val_mae: 1.5446\n",
      "Epoch 1428/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0591 - mae: 0.1938 - val_loss: 2.9403 - val_mae: 1.5608\n",
      "Epoch 1429/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0626 - mae: 0.1973 - val_loss: 2.9665 - val_mae: 1.5692\n",
      "Epoch 1430/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0655 - mae: 0.1983 - val_loss: 2.9618 - val_mae: 1.5676\n",
      "Epoch 1431/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0627 - mae: 0.1960 - val_loss: 2.9341 - val_mae: 1.5588\n",
      "Epoch 1432/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0597 - mae: 0.1951 - val_loss: 2.9069 - val_mae: 1.5501\n",
      "Epoch 1433/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0596 - mae: 0.1996 - val_loss: 2.8753 - val_mae: 1.5398\n",
      "Epoch 1434/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.2053 - val_loss: 2.8489 - val_mae: 1.5312\n",
      "Epoch 1435/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0616 - mae: 0.2072 - val_loss: 2.8822 - val_mae: 1.5421\n",
      "Epoch 1436/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0606 - mae: 0.2013 - val_loss: 2.9383 - val_mae: 1.5602\n",
      "Epoch 1437/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0597 - mae: 0.1977 - val_loss: 3.0054 - val_mae: 1.5816\n",
      "Epoch 1438/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.1981 - val_loss: 3.1087 - val_mae: 1.6140\n",
      "Epoch 1439/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.1972 - val_loss: 3.1828 - val_mae: 1.6369\n",
      "Epoch 1440/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0647 - mae: 0.1968 - val_loss: 3.1674 - val_mae: 1.6322\n",
      "Epoch 1441/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.1966 - val_loss: 3.0747 - val_mae: 1.6036\n",
      "Epoch 1442/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0630 - mae: 0.2041 - val_loss: 2.9867 - val_mae: 1.5759\n",
      "Epoch 1443/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0619 - mae: 0.2043 - val_loss: 2.9245 - val_mae: 1.5560\n",
      "Epoch 1444/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.2016 - val_loss: 2.8196 - val_mae: 1.5219\n",
      "Epoch 1445/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0641 - mae: 0.2086 - val_loss: 2.7187 - val_mae: 1.4883\n",
      "Epoch 1446/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0672 - mae: 0.2154 - val_loss: 2.6707 - val_mae: 1.4721\n",
      "Epoch 1447/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0670 - mae: 0.2137 - val_loss: 2.6674 - val_mae: 1.4709\n",
      "Epoch 1448/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0656 - mae: 0.2057 - val_loss: 2.6733 - val_mae: 1.4729\n",
      "Epoch 1449/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0651 - mae: 0.2002 - val_loss: 2.6638 - val_mae: 1.4697\n",
      "Epoch 1450/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0664 - mae: 0.2015 - val_loss: 2.6507 - val_mae: 1.4652\n",
      "Epoch 1451/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0677 - mae: 0.2040 - val_loss: 2.6340 - val_mae: 1.4595\n",
      "Epoch 1452/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0681 - mae: 0.2062 - val_loss: 2.6416 - val_mae: 1.4622\n",
      "Epoch 1453/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0674 - mae: 0.2047 - val_loss: 2.6497 - val_mae: 1.4650\n",
      "Epoch 1454/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0664 - mae: 0.2024 - val_loss: 2.6738 - val_mae: 1.4734\n",
      "Epoch 1455/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0640 - mae: 0.2022 - val_loss: 2.7422 - val_mae: 1.4965\n",
      "Epoch 1456/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0624 - mae: 0.2018 - val_loss: 2.7682 - val_mae: 1.5053\n",
      "Epoch 1457/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2023 - val_loss: 2.7676 - val_mae: 1.5052\n",
      "Epoch 1458/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0637 - mae: 0.2113 - val_loss: 2.7963 - val_mae: 1.5148\n",
      "Epoch 1459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0673 - mae: 0.2169 - val_loss: 2.8821 - val_mae: 1.5428\n",
      "Epoch 1460/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2140 - val_loss: 2.9916 - val_mae: 1.5779\n",
      "Epoch 1461/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0623 - mae: 0.2059 - val_loss: 3.0777 - val_mae: 1.6050\n",
      "Epoch 1462/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0624 - mae: 0.2031 - val_loss: 3.1422 - val_mae: 1.6249\n",
      "Epoch 1463/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0637 - mae: 0.2001 - val_loss: 3.1590 - val_mae: 1.6301\n",
      "Epoch 1464/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.1988 - val_loss: 3.1355 - val_mae: 1.6229\n",
      "Epoch 1465/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0640 - mae: 0.2039 - val_loss: 3.1337 - val_mae: 1.6223\n",
      "Epoch 1466/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0629 - mae: 0.2008 - val_loss: 3.1406 - val_mae: 1.6243\n",
      "Epoch 1467/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0624 - mae: 0.1952 - val_loss: 3.1214 - val_mae: 1.6183\n",
      "Epoch 1468/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0631 - mae: 0.1934 - val_loss: 3.0842 - val_mae: 1.6068\n",
      "Epoch 1469/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0632 - mae: 0.1940 - val_loss: 3.0094 - val_mae: 1.5833\n",
      "Epoch 1470/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0614 - mae: 0.1942 - val_loss: 2.9387 - val_mae: 1.5609\n",
      "Epoch 1471/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0589 - mae: 0.1915 - val_loss: 2.8749 - val_mae: 1.5403\n",
      "Epoch 1472/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0585 - mae: 0.1933 - val_loss: 2.8069 - val_mae: 1.5182\n",
      "Epoch 1473/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0590 - mae: 0.1984 - val_loss: 2.7839 - val_mae: 1.5106\n",
      "Epoch 1474/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0601 - mae: 0.2034 - val_loss: 2.7940 - val_mae: 1.5139\n",
      "Epoch 1475/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0592 - mae: 0.1999 - val_loss: 2.8466 - val_mae: 1.5311\n",
      "Epoch 1476/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0600 - mae: 0.1943 - val_loss: 2.9196 - val_mae: 1.5548\n",
      "Epoch 1477/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0605 - mae: 0.1940 - val_loss: 3.0089 - val_mae: 1.5833\n",
      "Epoch 1478/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0625 - mae: 0.1960 - val_loss: 3.0602 - val_mae: 1.5996\n",
      "Epoch 1479/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0613 - mae: 0.1944 - val_loss: 3.0239 - val_mae: 1.5884\n",
      "Epoch 1480/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0590 - mae: 0.1977 - val_loss: 2.9850 - val_mae: 1.5763\n",
      "Epoch 1481/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0650 - mae: 0.2108 - val_loss: 3.0105 - val_mae: 1.5843\n",
      "Epoch 1482/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0610 - mae: 0.2015 - val_loss: 3.0668 - val_mae: 1.6017\n",
      "Epoch 1483/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0611 - mae: 0.1934 - val_loss: 3.0691 - val_mae: 1.6021\n",
      "Epoch 1484/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0683 - mae: 0.2016 - val_loss: 3.0356 - val_mae: 1.5914\n",
      "Epoch 1485/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0713 - mae: 0.2041 - val_loss: 2.9720 - val_mae: 1.5712\n",
      "Epoch 1486/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0667 - mae: 0.1991 - val_loss: 2.8584 - val_mae: 1.5345\n",
      "Epoch 1487/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0604 - mae: 0.1937 - val_loss: 2.7354 - val_mae: 1.4939\n",
      "Epoch 1488/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0615 - mae: 0.2048 - val_loss: 2.6589 - val_mae: 1.4680\n",
      "Epoch 1489/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0663 - mae: 0.2191 - val_loss: 2.6343 - val_mae: 1.4596\n",
      "Epoch 1490/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0642 - mae: 0.2133 - val_loss: 2.6788 - val_mae: 1.4747\n",
      "Epoch 1491/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0589 - mae: 0.1941 - val_loss: 2.7787 - val_mae: 1.5081\n",
      "Epoch 1492/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0628 - mae: 0.1966 - val_loss: 2.8997 - val_mae: 1.5477\n",
      "Epoch 1493/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0784 - mae: 0.2190 - val_loss: 2.9332 - val_mae: 1.5585\n",
      "Epoch 1494/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0728 - mae: 0.2109 - val_loss: 2.8439 - val_mae: 1.5295\n",
      "Epoch 1495/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0580 - mae: 0.1950 - val_loss: 2.7482 - val_mae: 1.4979\n",
      "Epoch 1496/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0641 - mae: 0.2125 - val_loss: 2.7032 - val_mae: 1.4828\n",
      "Epoch 1497/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0789 - mae: 0.2338 - val_loss: 2.7434 - val_mae: 1.4964\n",
      "Epoch 1498/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0707 - mae: 0.2231 - val_loss: 2.8453 - val_mae: 1.5300\n",
      "Epoch 1499/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0569 - mae: 0.1970 - val_loss: 2.9258 - val_mae: 1.5560\n",
      "Epoch 1500/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0662 - mae: 0.1992 - val_loss: 2.9275 - val_mae: 1.5566\n",
      "Epoch 1501/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0783 - mae: 0.2201 - val_loss: 2.8774 - val_mae: 1.5405\n",
      "Epoch 1502/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0793 - mae: 0.2220 - val_loss: 2.8280 - val_mae: 1.5243\n",
      "Epoch 1503/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0723 - mae: 0.2115 - val_loss: 2.7922 - val_mae: 1.5125\n",
      "Epoch 1504/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0639 - mae: 0.1933 - val_loss: 2.7809 - val_mae: 1.5088\n",
      "Epoch 1505/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0597 - mae: 0.1913 - val_loss: 2.7448 - val_mae: 1.4968\n",
      "Epoch 1506/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0601 - mae: 0.1993 - val_loss: 2.6859 - val_mae: 1.4770\n",
      "Epoch 1507/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0646 - mae: 0.2160 - val_loss: 2.6483 - val_mae: 1.4642\n",
      "Epoch 1508/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0674 - mae: 0.2218 - val_loss: 2.6536 - val_mae: 1.4660\n",
      "Epoch 1509/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0647 - mae: 0.2162 - val_loss: 2.6811 - val_mae: 1.4754\n",
      "Epoch 1510/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0608 - mae: 0.2067 - val_loss: 2.7181 - val_mae: 1.4879\n",
      "Epoch 1511/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0584 - mae: 0.1990 - val_loss: 2.7606 - val_mae: 1.5021\n",
      "Epoch 1512/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0605 - mae: 0.1983 - val_loss: 2.7393 - val_mae: 1.4950\n",
      "Epoch 1513/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0581 - mae: 0.1975 - val_loss: 2.6801 - val_mae: 1.4751\n",
      "Epoch 1514/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0638 - mae: 0.2106 - val_loss: 2.6551 - val_mae: 1.4667\n",
      "Epoch 1515/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0824 - mae: 0.2367 - val_loss: 2.6806 - val_mae: 1.4754\n",
      "Epoch 1516/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0891 - mae: 0.2454 - val_loss: 2.7366 - val_mae: 1.4942\n",
      "Epoch 1517/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0796 - mae: 0.2300 - val_loss: 2.7949 - val_mae: 1.5136\n",
      "Epoch 1518/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0656 - mae: 0.2113 - val_loss: 2.8808 - val_mae: 1.5417\n",
      "Epoch 1519/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.1959 - val_loss: 2.9441 - val_mae: 1.5620\n",
      "Epoch 1520/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0687 - mae: 0.2034 - val_loss: 2.9197 - val_mae: 1.5542\n",
      "Epoch 1521/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0742 - mae: 0.2130 - val_loss: 2.8229 - val_mae: 1.5227\n",
      "Epoch 1522/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2016 - val_loss: 2.7239 - val_mae: 1.4898\n",
      "Epoch 1523/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0610 - mae: 0.1908 - val_loss: 2.6592 - val_mae: 1.4679\n",
      "Epoch 1524/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0608 - mae: 0.1960 - val_loss: 2.5994 - val_mae: 1.4473\n",
      "Epoch 1525/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0648 - mae: 0.2108 - val_loss: 2.5612 - val_mae: 1.4340\n",
      "Epoch 1526/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0691 - mae: 0.2195 - val_loss: 2.5364 - val_mae: 1.4253\n",
      "Epoch 1527/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0739 - mae: 0.2309 - val_loss: 2.5612 - val_mae: 1.4340\n",
      "Epoch 1528/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0713 - mae: 0.2283 - val_loss: 2.6728 - val_mae: 1.4724\n",
      "Epoch 1529/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.2032 - val_loss: 2.7625 - val_mae: 1.5026\n",
      "Epoch 1530/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1921 - val_loss: 2.8253 - val_mae: 1.5233\n",
      "Epoch 1531/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0615 - mae: 0.1957 - val_loss: 2.9261 - val_mae: 1.5561\n",
      "Epoch 1532/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0692 - mae: 0.2073 - val_loss: 2.9876 - val_mae: 1.5757\n",
      "Epoch 1533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0688 - mae: 0.2076 - val_loss: 2.9322 - val_mae: 1.5581\n",
      "Epoch 1534/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0604 - mae: 0.2006 - val_loss: 2.8607 - val_mae: 1.5350\n",
      "Epoch 1535/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0717 - mae: 0.2189 - val_loss: 2.8597 - val_mae: 1.5347\n",
      "Epoch 1536/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0884 - mae: 0.2437 - val_loss: 2.9236 - val_mae: 1.5554\n",
      "Epoch 1537/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0757 - mae: 0.2257 - val_loss: 3.0302 - val_mae: 1.5893\n",
      "Epoch 1538/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0630 - mae: 0.2037 - val_loss: 3.0851 - val_mae: 1.6065\n",
      "Epoch 1539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.1970 - val_loss: 3.0596 - val_mae: 1.5985\n",
      "Epoch 1540/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0636 - mae: 0.1945 - val_loss: 3.0006 - val_mae: 1.5800\n",
      "Epoch 1541/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0605 - mae: 0.1906 - val_loss: 2.8885 - val_mae: 1.5441\n",
      "Epoch 1542/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.1958 - val_loss: 2.7446 - val_mae: 1.4968\n",
      "Epoch 1543/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0660 - mae: 0.2131 - val_loss: 2.6743 - val_mae: 1.4731\n",
      "Epoch 1544/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0654 - mae: 0.2119 - val_loss: 2.6765 - val_mae: 1.4738\n",
      "Epoch 1545/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.1984 - val_loss: 2.6833 - val_mae: 1.4762\n",
      "Epoch 1546/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.1924 - val_loss: 2.6846 - val_mae: 1.4766\n",
      "Epoch 1547/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.1956 - val_loss: 2.6830 - val_mae: 1.4761\n",
      "Epoch 1548/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0658 - mae: 0.1992 - val_loss: 2.6734 - val_mae: 1.4728\n",
      "Epoch 1549/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0652 - mae: 0.1984 - val_loss: 2.6188 - val_mae: 1.4541\n",
      "Epoch 1550/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.1935 - val_loss: 2.5431 - val_mae: 1.4278\n",
      "Epoch 1551/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0625 - mae: 0.2013 - val_loss: 2.5234 - val_mae: 1.4209\n",
      "Epoch 1552/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0630 - mae: 0.2036 - val_loss: 2.5157 - val_mae: 1.4181\n",
      "Epoch 1553/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0627 - mae: 0.2029 - val_loss: 2.4928 - val_mae: 1.4100\n",
      "Epoch 1554/5000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0635 - mae: 0.2045 - val_loss: 2.5147 - val_mae: 1.4177\n",
      "Epoch 1555/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.1998 - val_loss: 2.5906 - val_mae: 1.4442\n",
      "Epoch 1556/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.1949 - val_loss: 2.6663 - val_mae: 1.4702\n",
      "Epoch 1557/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0604 - mae: 0.1924 - val_loss: 2.6945 - val_mae: 1.4798\n",
      "Epoch 1558/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1905 - val_loss: 2.6992 - val_mae: 1.4813\n",
      "Epoch 1559/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0582 - mae: 0.1916 - val_loss: 2.6920 - val_mae: 1.4789\n",
      "Epoch 1560/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0575 - mae: 0.1927 - val_loss: 2.6998 - val_mae: 1.4815\n",
      "Epoch 1561/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.1942 - val_loss: 2.7323 - val_mae: 1.4924\n",
      "Epoch 1562/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0574 - mae: 0.1949 - val_loss: 2.7310 - val_mae: 1.4920\n",
      "Epoch 1563/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1952 - val_loss: 2.6844 - val_mae: 1.4763\n",
      "Epoch 1564/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.2015 - val_loss: 2.6382 - val_mae: 1.4605\n",
      "Epoch 1565/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2098 - val_loss: 2.6365 - val_mae: 1.4600\n",
      "Epoch 1566/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0601 - mae: 0.2046 - val_loss: 2.6906 - val_mae: 1.4784\n",
      "Epoch 1567/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.1974 - val_loss: 2.7140 - val_mae: 1.4863\n",
      "Epoch 1568/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0582 - mae: 0.1954 - val_loss: 2.7085 - val_mae: 1.4845\n",
      "Epoch 1569/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1937 - val_loss: 2.7056 - val_mae: 1.4835\n",
      "Epoch 1570/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1921 - val_loss: 2.7067 - val_mae: 1.4838\n",
      "Epoch 1571/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1909 - val_loss: 2.7147 - val_mae: 1.4865\n",
      "Epoch 1572/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1887 - val_loss: 2.6928 - val_mae: 1.4792\n",
      "Epoch 1573/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1918 - val_loss: 2.6685 - val_mae: 1.4709\n",
      "Epoch 1574/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1968 - val_loss: 2.6690 - val_mae: 1.4711\n",
      "Epoch 1575/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0599 - mae: 0.1981 - val_loss: 2.6807 - val_mae: 1.4751\n",
      "Epoch 1576/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0603 - mae: 0.1972 - val_loss: 2.6874 - val_mae: 1.4774\n",
      "Epoch 1577/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1958 - val_loss: 2.7084 - val_mae: 1.4845\n",
      "Epoch 1578/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0601 - mae: 0.1928 - val_loss: 2.7414 - val_mae: 1.4956\n",
      "Epoch 1579/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.1910 - val_loss: 2.7149 - val_mae: 1.4866\n",
      "Epoch 1580/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.1990 - val_loss: 2.6663 - val_mae: 1.4701\n",
      "Epoch 1581/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0639 - mae: 0.2142 - val_loss: 2.7072 - val_mae: 1.4840\n",
      "Epoch 1582/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.2136 - val_loss: 2.8231 - val_mae: 1.5225\n",
      "Epoch 1583/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0578 - mae: 0.1979 - val_loss: 2.9503 - val_mae: 1.5638\n",
      "Epoch 1584/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1920 - val_loss: 3.0454 - val_mae: 1.5940\n",
      "Epoch 1585/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0653 - mae: 0.1990 - val_loss: 3.0952 - val_mae: 1.6096\n",
      "Epoch 1586/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0673 - mae: 0.2027 - val_loss: 3.0746 - val_mae: 1.6031\n",
      "Epoch 1587/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0629 - mae: 0.2007 - val_loss: 3.0382 - val_mae: 1.5917\n",
      "Epoch 1588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1984 - val_loss: 2.9917 - val_mae: 1.5771\n",
      "Epoch 1589/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2081 - val_loss: 2.9341 - val_mae: 1.5587\n",
      "Epoch 1590/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0634 - mae: 0.2095 - val_loss: 2.9017 - val_mae: 1.5483\n",
      "Epoch 1591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1988 - val_loss: 2.8420 - val_mae: 1.5289\n",
      "Epoch 1592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1912 - val_loss: 2.7920 - val_mae: 1.5125\n",
      "Epoch 1593/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0576 - mae: 0.1893 - val_loss: 2.7733 - val_mae: 1.5063\n",
      "Epoch 1594/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.1886 - val_loss: 2.7398 - val_mae: 1.4952\n",
      "Epoch 1595/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0626 - mae: 0.1920 - val_loss: 2.6984 - val_mae: 1.4813\n",
      "Epoch 1596/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0631 - mae: 0.1935 - val_loss: 2.6591 - val_mae: 1.4680\n",
      "Epoch 1597/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.1915 - val_loss: 2.6116 - val_mae: 1.4518\n",
      "Epoch 1598/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0592 - mae: 0.1939 - val_loss: 2.5938 - val_mae: 1.4457\n",
      "Epoch 1599/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0586 - mae: 0.1950 - val_loss: 2.6043 - val_mae: 1.4494\n",
      "Epoch 1600/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.1960 - val_loss: 2.6113 - val_mae: 1.4519\n",
      "Epoch 1601/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1968 - val_loss: 2.6003 - val_mae: 1.4481\n",
      "Epoch 1602/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0586 - mae: 0.1970 - val_loss: 2.6070 - val_mae: 1.4504\n",
      "Epoch 1603/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0593 - mae: 0.1962 - val_loss: 2.6338 - val_mae: 1.4596\n",
      "Epoch 1604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1982 - val_loss: 2.6528 - val_mae: 1.4661\n",
      "Epoch 1605/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.1993 - val_loss: 2.6185 - val_mae: 1.4544\n",
      "Epoch 1606/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2016 - val_loss: 2.5663 - val_mae: 1.4363\n",
      "Epoch 1607/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0654 - mae: 0.2146 - val_loss: 2.5994 - val_mae: 1.4478\n",
      "Epoch 1608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0680 - mae: 0.2184 - val_loss: 2.7281 - val_mae: 1.4915\n",
      "Epoch 1609/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0611 - mae: 0.2038 - val_loss: 2.8697 - val_mae: 1.5382\n",
      "Epoch 1610/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0598 - mae: 0.1977 - val_loss: 2.9081 - val_mae: 1.5506\n",
      "Epoch 1611/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0623 - mae: 0.1980 - val_loss: 2.8808 - val_mae: 1.5417\n",
      "Epoch 1612/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1939 - val_loss: 2.8227 - val_mae: 1.5227\n",
      "Epoch 1613/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.1877 - val_loss: 2.7702 - val_mae: 1.5053\n",
      "Epoch 1614/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1917 - val_loss: 2.7312 - val_mae: 1.4922\n",
      "Epoch 1615/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2076 - val_loss: 2.6852 - val_mae: 1.4767\n",
      "Epoch 1616/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0693 - mae: 0.2242 - val_loss: 2.7015 - val_mae: 1.4822\n",
      "Epoch 1617/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0674 - mae: 0.2205 - val_loss: 2.7979 - val_mae: 1.5144\n",
      "Epoch 1618/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.2046 - val_loss: 2.8658 - val_mae: 1.5367\n",
      "Epoch 1619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1887 - val_loss: 2.8649 - val_mae: 1.5364\n",
      "Epoch 1620/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0577 - mae: 0.1884 - val_loss: 2.8462 - val_mae: 1.5303\n",
      "Epoch 1621/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1878 - val_loss: 2.8319 - val_mae: 1.5256\n",
      "Epoch 1622/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1883 - val_loss: 2.8126 - val_mae: 1.5193\n",
      "Epoch 1623/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1884 - val_loss: 2.8075 - val_mae: 1.5176\n",
      "Epoch 1624/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1911 - val_loss: 2.8200 - val_mae: 1.5217\n",
      "Epoch 1625/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0576 - mae: 0.1976 - val_loss: 2.8164 - val_mae: 1.5206\n",
      "Epoch 1626/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0601 - mae: 0.2061 - val_loss: 2.8371 - val_mae: 1.5274\n",
      "Epoch 1627/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2093 - val_loss: 2.9193 - val_mae: 1.5541\n",
      "Epoch 1628/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1988 - val_loss: 3.0389 - val_mae: 1.5922\n",
      "Epoch 1629/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0595 - mae: 0.1919 - val_loss: 3.1435 - val_mae: 1.6247\n",
      "Epoch 1630/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0698 - mae: 0.2032 - val_loss: 3.1661 - val_mae: 1.6317\n",
      "Epoch 1631/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0739 - mae: 0.2091 - val_loss: 3.1105 - val_mae: 1.6146\n",
      "Epoch 1632/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0673 - mae: 0.2011 - val_loss: 3.0487 - val_mae: 1.5954\n",
      "Epoch 1633/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0598 - mae: 0.1954 - val_loss: 3.0012 - val_mae: 1.5805\n",
      "Epoch 1634/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1970 - val_loss: 2.9436 - val_mae: 1.5622\n",
      "Epoch 1635/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2039 - val_loss: 2.8944 - val_mae: 1.5463\n",
      "Epoch 1636/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.2005 - val_loss: 2.8511 - val_mae: 1.5322\n",
      "Epoch 1637/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1913 - val_loss: 2.8489 - val_mae: 1.5315\n",
      "Epoch 1638/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0573 - mae: 0.1877 - val_loss: 2.9012 - val_mae: 1.5485\n",
      "Epoch 1639/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0618 - mae: 0.1917 - val_loss: 2.9589 - val_mae: 1.5670\n",
      "Epoch 1640/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0686 - mae: 0.2010 - val_loss: 2.9868 - val_mae: 1.5760\n",
      "Epoch 1641/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0725 - mae: 0.2079 - val_loss: 2.9285 - val_mae: 1.5574\n",
      "Epoch 1642/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.1997 - val_loss: 2.8360 - val_mae: 1.5275\n",
      "Epoch 1643/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1906 - val_loss: 2.8082 - val_mae: 1.5184\n",
      "Epoch 1644/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1921 - val_loss: 2.7814 - val_mae: 1.5096\n",
      "Epoch 1645/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0591 - mae: 0.2047 - val_loss: 2.7433 - val_mae: 1.4970\n",
      "Epoch 1646/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0685 - mae: 0.2212 - val_loss: 2.7864 - val_mae: 1.5115\n",
      "Epoch 1647/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0676 - mae: 0.2156 - val_loss: 2.9137 - val_mae: 1.5530\n",
      "Epoch 1648/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.2043 - val_loss: 3.1180 - val_mae: 1.6174\n",
      "Epoch 1649/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0684 - mae: 0.2126 - val_loss: 3.3072 - val_mae: 1.6747\n",
      "Epoch 1650/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0816 - mae: 0.2243 - val_loss: 3.2924 - val_mae: 1.6703\n",
      "Epoch 1651/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0707 - mae: 0.2066 - val_loss: 3.0796 - val_mae: 1.6055\n",
      "Epoch 1652/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0584 - mae: 0.1925 - val_loss: 2.8216 - val_mae: 1.5232\n",
      "Epoch 1653/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0707 - mae: 0.2272 - val_loss: 2.6848 - val_mae: 1.4775\n",
      "Epoch 1654/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2320 - val_loss: 2.6737 - val_mae: 1.4735\n",
      "Epoch 1655/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.2119 - val_loss: 2.6877 - val_mae: 1.4781\n",
      "Epoch 1656/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1953 - val_loss: 2.7135 - val_mae: 1.4867\n",
      "Epoch 1657/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1901 - val_loss: 2.7639 - val_mae: 1.5035\n",
      "Epoch 1658/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0663 - mae: 0.1994 - val_loss: 2.7919 - val_mae: 1.5128\n",
      "Epoch 1659/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0701 - mae: 0.2081 - val_loss: 2.7830 - val_mae: 1.5098\n",
      "Epoch 1660/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0680 - mae: 0.2042 - val_loss: 2.6985 - val_mae: 1.4816\n",
      "Epoch 1661/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0588 - mae: 0.1865 - val_loss: 2.5443 - val_mae: 1.4287\n",
      "Epoch 1662/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0658 - mae: 0.2150 - val_loss: 2.4816 - val_mae: 1.4066\n",
      "Epoch 1663/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0745 - mae: 0.2334 - val_loss: 2.5433 - val_mae: 1.4285\n",
      "Epoch 1664/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0665 - mae: 0.2218 - val_loss: 2.6667 - val_mae: 1.4711\n",
      "Epoch 1665/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1965 - val_loss: 2.8338 - val_mae: 1.5269\n",
      "Epoch 1666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1974 - val_loss: 2.9462 - val_mae: 1.5633\n",
      "Epoch 1667/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0659 - mae: 0.2020 - val_loss: 2.9768 - val_mae: 1.5731\n",
      "Epoch 1668/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.1948 - val_loss: 2.9736 - val_mae: 1.5723\n",
      "Epoch 1669/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1910 - val_loss: 2.9516 - val_mae: 1.5654\n",
      "Epoch 1670/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1986 - val_loss: 2.8965 - val_mae: 1.5479\n",
      "Epoch 1671/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0720 - mae: 0.2254 - val_loss: 2.8344 - val_mae: 1.5278\n",
      "Epoch 1672/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0883 - mae: 0.2480 - val_loss: 2.8300 - val_mae: 1.5263\n",
      "Epoch 1673/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0823 - mae: 0.2397 - val_loss: 2.8939 - val_mae: 1.5470\n",
      "Epoch 1674/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0656 - mae: 0.2123 - val_loss: 2.9505 - val_mae: 1.5650\n",
      "Epoch 1675/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1970 - val_loss: 2.9977 - val_mae: 1.5799\n",
      "Epoch 1676/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1958 - val_loss: 2.9821 - val_mae: 1.5747\n",
      "Epoch 1677/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0630 - mae: 0.1970 - val_loss: 2.8746 - val_mae: 1.5401\n",
      "Epoch 1678/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0598 - mae: 0.1914 - val_loss: 2.7887 - val_mae: 1.5118\n",
      "Epoch 1679/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1889 - val_loss: 2.7070 - val_mae: 1.4844\n",
      "Epoch 1680/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1921 - val_loss: 2.6131 - val_mae: 1.4523\n",
      "Epoch 1681/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0597 - mae: 0.2026 - val_loss: 2.5690 - val_mae: 1.4370\n",
      "Epoch 1682/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.2033 - val_loss: 2.5609 - val_mae: 1.4341\n",
      "Epoch 1683/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2004 - val_loss: 2.5837 - val_mae: 1.4420\n",
      "Epoch 1684/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0589 - mae: 0.2002 - val_loss: 2.6588 - val_mae: 1.4678\n",
      "Epoch 1685/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1929 - val_loss: 2.7283 - val_mae: 1.4913\n",
      "Epoch 1686/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1892 - val_loss: 2.7630 - val_mae: 1.5029\n",
      "Epoch 1687/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1901 - val_loss: 2.7994 - val_mae: 1.5149\n",
      "Epoch 1688/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0560 - mae: 0.1892 - val_loss: 2.8632 - val_mae: 1.5359\n",
      "Epoch 1689/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1870 - val_loss: 2.8946 - val_mae: 1.5460\n",
      "Epoch 1690/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0574 - mae: 0.1864 - val_loss: 2.8358 - val_mae: 1.5269\n",
      "Epoch 1691/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1911 - val_loss: 2.7573 - val_mae: 1.5009\n",
      "Epoch 1692/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1978 - val_loss: 2.7135 - val_mae: 1.4863\n",
      "Epoch 1693/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1989 - val_loss: 2.6876 - val_mae: 1.4776\n",
      "Epoch 1694/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1979 - val_loss: 2.6853 - val_mae: 1.4769\n",
      "Epoch 1695/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1958 - val_loss: 2.7110 - val_mae: 1.4856\n",
      "Epoch 1696/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0568 - mae: 0.1916 - val_loss: 2.7580 - val_mae: 1.5014\n",
      "Epoch 1697/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.1986 - val_loss: 2.7822 - val_mae: 1.5094\n",
      "Epoch 1698/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0660 - mae: 0.2068 - val_loss: 2.7255 - val_mae: 1.4905\n",
      "Epoch 1699/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.1997 - val_loss: 2.6143 - val_mae: 1.4527\n",
      "Epoch 1700/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0698 - mae: 0.2183 - val_loss: 2.5998 - val_mae: 1.4477\n",
      "Epoch 1701/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0699 - mae: 0.2198 - val_loss: 2.7050 - val_mae: 1.4836\n",
      "Epoch 1702/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.2027 - val_loss: 2.8303 - val_mae: 1.5252\n",
      "Epoch 1703/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0617 - mae: 0.2019 - val_loss: 2.9274 - val_mae: 1.5567\n",
      "Epoch 1704/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.2034 - val_loss: 2.9810 - val_mae: 1.5738\n",
      "Epoch 1705/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0639 - mae: 0.1995 - val_loss: 2.9687 - val_mae: 1.5698\n",
      "Epoch 1706/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1921 - val_loss: 2.9370 - val_mae: 1.5597\n",
      "Epoch 1707/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0580 - mae: 0.1987 - val_loss: 2.9157 - val_mae: 1.5529\n",
      "Epoch 1708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2060 - val_loss: 2.8995 - val_mae: 1.5476\n",
      "Epoch 1709/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.2039 - val_loss: 2.9164 - val_mae: 1.5530\n",
      "Epoch 1710/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.1977 - val_loss: 2.9010 - val_mae: 1.5481\n",
      "Epoch 1711/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0583 - mae: 0.1999 - val_loss: 2.8788 - val_mae: 1.5409\n",
      "Epoch 1712/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0613 - mae: 0.2097 - val_loss: 2.9020 - val_mae: 1.5485\n",
      "Epoch 1713/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0618 - mae: 0.2099 - val_loss: 2.9725 - val_mae: 1.5711\n",
      "Epoch 1714/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0588 - mae: 0.1978 - val_loss: 3.0371 - val_mae: 1.5915\n",
      "Epoch 1715/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0586 - mae: 0.1864 - val_loss: 3.0513 - val_mae: 1.5960\n",
      "Epoch 1716/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0605 - mae: 0.1873 - val_loss: 3.0708 - val_mae: 1.6021\n",
      "Epoch 1717/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0651 - mae: 0.1931 - val_loss: 3.0442 - val_mae: 1.5939\n",
      "Epoch 1718/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0638 - mae: 0.1909 - val_loss: 2.9699 - val_mae: 1.5705\n",
      "Epoch 1719/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1882 - val_loss: 2.9192 - val_mae: 1.5543\n",
      "Epoch 1720/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1925 - val_loss: 2.8978 - val_mae: 1.5474\n",
      "Epoch 1721/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0560 - mae: 0.1908 - val_loss: 2.9280 - val_mae: 1.5572\n",
      "Epoch 1722/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1864 - val_loss: 2.9699 - val_mae: 1.5706\n",
      "Epoch 1723/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.1889 - val_loss: 2.9702 - val_mae: 1.5708\n",
      "Epoch 1724/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1887 - val_loss: 2.9263 - val_mae: 1.5568\n",
      "Epoch 1725/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1883 - val_loss: 2.8852 - val_mae: 1.5436\n",
      "Epoch 1726/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1920 - val_loss: 2.8517 - val_mae: 1.5328\n",
      "Epoch 1727/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.2047 - val_loss: 2.8380 - val_mae: 1.5284\n",
      "Epoch 1728/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.2101 - val_loss: 2.8295 - val_mae: 1.5256\n",
      "Epoch 1729/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.2051 - val_loss: 2.8496 - val_mae: 1.5321\n",
      "Epoch 1730/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1974 - val_loss: 2.9160 - val_mae: 1.5536\n",
      "Epoch 1731/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1901 - val_loss: 2.9387 - val_mae: 1.5609\n",
      "Epoch 1732/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0570 - mae: 0.1867 - val_loss: 2.9250 - val_mae: 1.5565\n",
      "Epoch 1733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1869 - val_loss: 2.9651 - val_mae: 1.5694\n",
      "Epoch 1734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.1879 - val_loss: 2.9972 - val_mae: 1.5796\n",
      "Epoch 1735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1879 - val_loss: 2.9567 - val_mae: 1.5668\n",
      "Epoch 1736/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1861 - val_loss: 2.8998 - val_mae: 1.5486\n",
      "Epoch 1737/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1909 - val_loss: 2.8545 - val_mae: 1.5339\n",
      "Epoch 1738/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1935 - val_loss: 2.7943 - val_mae: 1.5142\n",
      "Epoch 1739/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1984 - val_loss: 2.7281 - val_mae: 1.4922\n",
      "Epoch 1740/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2027 - val_loss: 2.7360 - val_mae: 1.4949\n",
      "Epoch 1741/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1951 - val_loss: 2.7931 - val_mae: 1.5138\n",
      "Epoch 1742/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0574 - mae: 0.1900 - val_loss: 2.8394 - val_mae: 1.5291\n",
      "Epoch 1743/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0589 - mae: 0.1910 - val_loss: 2.8760 - val_mae: 1.5410\n",
      "Epoch 1744/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0592 - mae: 0.1906 - val_loss: 2.9025 - val_mae: 1.5496\n",
      "Epoch 1745/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1899 - val_loss: 2.9053 - val_mae: 1.5505\n",
      "Epoch 1746/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1874 - val_loss: 2.9422 - val_mae: 1.5624\n",
      "Epoch 1747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1877 - val_loss: 3.0014 - val_mae: 1.5813\n",
      "Epoch 1748/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.1883 - val_loss: 3.0154 - val_mae: 1.5857\n",
      "Epoch 1749/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.1899 - val_loss: 3.0322 - val_mae: 1.5910\n",
      "Epoch 1750/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1883 - val_loss: 3.0811 - val_mae: 1.6063\n",
      "Epoch 1751/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1882 - val_loss: 3.0690 - val_mae: 1.6025\n",
      "Epoch 1752/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0584 - mae: 0.1927 - val_loss: 3.0432 - val_mae: 1.5945\n",
      "Epoch 1753/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1935 - val_loss: 2.9833 - val_mae: 1.5755\n",
      "Epoch 1754/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1986 - val_loss: 2.9285 - val_mae: 1.5579\n",
      "Epoch 1755/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1963 - val_loss: 2.9474 - val_mae: 1.5638\n",
      "Epoch 1756/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1885 - val_loss: 2.9971 - val_mae: 1.5795\n",
      "Epoch 1757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.1897 - val_loss: 3.0461 - val_mae: 1.5949\n",
      "Epoch 1758/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0694 - mae: 0.1996 - val_loss: 3.0237 - val_mae: 1.5879\n",
      "Epoch 1759/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0682 - mae: 0.1987 - val_loss: 2.9086 - val_mae: 1.5513\n",
      "Epoch 1760/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1876 - val_loss: 2.7562 - val_mae: 1.5014\n",
      "Epoch 1761/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.1962 - val_loss: 2.6520 - val_mae: 1.4663\n",
      "Epoch 1762/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.2107 - val_loss: 2.6414 - val_mae: 1.4627\n",
      "Epoch 1763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.2022 - val_loss: 2.7059 - val_mae: 1.4845\n",
      "Epoch 1764/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1893 - val_loss: 2.7989 - val_mae: 1.5155\n",
      "Epoch 1765/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.2002 - val_loss: 2.8757 - val_mae: 1.5407\n",
      "Epoch 1766/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.2014 - val_loss: 2.8724 - val_mae: 1.5396\n",
      "Epoch 1767/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0576 - mae: 0.1932 - val_loss: 2.8417 - val_mae: 1.5297\n",
      "Epoch 1768/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1964 - val_loss: 2.8414 - val_mae: 1.5295\n",
      "Epoch 1769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.2006 - val_loss: 2.8962 - val_mae: 1.5472\n",
      "Epoch 1770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1886 - val_loss: 2.9979 - val_mae: 1.5796\n",
      "Epoch 1771/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1881 - val_loss: 3.0952 - val_mae: 1.6100\n",
      "Epoch 1772/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0739 - mae: 0.2081 - val_loss: 3.1293 - val_mae: 1.6206\n",
      "Epoch 1773/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0782 - mae: 0.2160 - val_loss: 3.0692 - val_mae: 1.6019\n",
      "Epoch 1774/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0688 - mae: 0.1957 - val_loss: 2.9623 - val_mae: 1.5682\n",
      "Epoch 1775/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1883 - val_loss: 2.8959 - val_mae: 1.5468\n",
      "Epoch 1776/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1959 - val_loss: 2.8944 - val_mae: 1.5464\n",
      "Epoch 1777/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1961 - val_loss: 2.9465 - val_mae: 1.5631\n",
      "Epoch 1778/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1906 - val_loss: 3.0009 - val_mae: 1.5804\n",
      "Epoch 1779/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0580 - mae: 0.1882 - val_loss: 3.0218 - val_mae: 1.5870\n",
      "Epoch 1780/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0581 - mae: 0.1876 - val_loss: 2.9953 - val_mae: 1.5787\n",
      "Epoch 1781/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1960 - val_loss: 2.9452 - val_mae: 1.5628\n",
      "Epoch 1782/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0606 - mae: 0.2083 - val_loss: 2.9228 - val_mae: 1.5557\n",
      "Epoch 1783/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2067 - val_loss: 2.9404 - val_mae: 1.5613\n",
      "Epoch 1784/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1919 - val_loss: 2.9623 - val_mae: 1.5682\n",
      "Epoch 1785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1862 - val_loss: 2.9471 - val_mae: 1.5633\n",
      "Epoch 1786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.1900 - val_loss: 2.8730 - val_mae: 1.5393\n",
      "Epoch 1787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1861 - val_loss: 2.7430 - val_mae: 1.4964\n",
      "Epoch 1788/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1874 - val_loss: 2.6076 - val_mae: 1.4504\n",
      "Epoch 1789/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0610 - mae: 0.2028 - val_loss: 2.5545 - val_mae: 1.4319\n",
      "Epoch 1790/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0612 - mae: 0.2034 - val_loss: 2.5472 - val_mae: 1.4293\n",
      "Epoch 1791/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1955 - val_loss: 2.4937 - val_mae: 1.4105\n",
      "Epoch 1792/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.1955 - val_loss: 2.4495 - val_mae: 1.3947\n",
      "Epoch 1793/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1960 - val_loss: 2.4381 - val_mae: 1.3905\n",
      "Epoch 1794/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0615 - mae: 0.1957 - val_loss: 2.4294 - val_mae: 1.3873\n",
      "Epoch 1795/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.1962 - val_loss: 2.4006 - val_mae: 1.3768\n",
      "Epoch 1796/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0647 - mae: 0.2094 - val_loss: 2.4067 - val_mae: 1.3790\n",
      "Epoch 1797/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.2189 - val_loss: 2.4961 - val_mae: 1.4110\n",
      "Epoch 1798/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.2091 - val_loss: 2.6489 - val_mae: 1.4642\n",
      "Epoch 1799/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0579 - mae: 0.1932 - val_loss: 2.7614 - val_mae: 1.5021\n",
      "Epoch 1800/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1844 - val_loss: 2.7524 - val_mae: 1.4991\n",
      "Epoch 1801/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1950 - val_loss: 2.7610 - val_mae: 1.5019\n",
      "Epoch 1802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2077 - val_loss: 2.8796 - val_mae: 1.5409\n",
      "Epoch 1803/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.2016 - val_loss: 3.0171 - val_mae: 1.5849\n",
      "Epoch 1804/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0616 - mae: 0.1917 - val_loss: 3.0580 - val_mae: 1.5978\n",
      "Epoch 1805/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1886 - val_loss: 3.0256 - val_mae: 1.5876\n",
      "Epoch 1806/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0607 - mae: 0.1987 - val_loss: 2.9579 - val_mae: 1.5661\n",
      "Epoch 1807/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0658 - mae: 0.2135 - val_loss: 2.8991 - val_mae: 1.5472\n",
      "Epoch 1808/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0670 - mae: 0.2160 - val_loss: 2.9063 - val_mae: 1.5495\n",
      "Epoch 1809/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0601 - mae: 0.2027 - val_loss: 2.9503 - val_mae: 1.5637\n",
      "Epoch 1810/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1887 - val_loss: 2.9448 - val_mae: 1.5620\n",
      "Epoch 1811/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0580 - mae: 0.1939 - val_loss: 2.8843 - val_mae: 1.5426\n",
      "Epoch 1812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1969 - val_loss: 2.8104 - val_mae: 1.5185\n",
      "Epoch 1813/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.1982 - val_loss: 2.7390 - val_mae: 1.4948\n",
      "Epoch 1814/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2002 - val_loss: 2.6828 - val_mae: 1.4759\n",
      "Epoch 1815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1988 - val_loss: 2.5879 - val_mae: 1.4434\n",
      "Epoch 1816/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0606 - mae: 0.1983 - val_loss: 2.4887 - val_mae: 1.4086\n",
      "Epoch 1817/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1994 - val_loss: 2.4357 - val_mae: 1.3897\n",
      "Epoch 1818/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0623 - mae: 0.1994 - val_loss: 2.4107 - val_mae: 1.3807\n",
      "Epoch 1819/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.1989 - val_loss: 2.3870 - val_mae: 1.3720\n",
      "Epoch 1820/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0681 - mae: 0.2174 - val_loss: 2.4184 - val_mae: 1.3834\n",
      "Epoch 1821/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0682 - mae: 0.2190 - val_loss: 2.5254 - val_mae: 1.4215\n",
      "Epoch 1822/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.2039 - val_loss: 2.6352 - val_mae: 1.4596\n",
      "Epoch 1823/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1889 - val_loss: 2.7271 - val_mae: 1.4907\n",
      "Epoch 1824/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1855 - val_loss: 2.7944 - val_mae: 1.5131\n",
      "Epoch 1825/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1840 - val_loss: 2.8486 - val_mae: 1.5309\n",
      "Epoch 1826/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1840 - val_loss: 2.8449 - val_mae: 1.5297\n",
      "Epoch 1827/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1857 - val_loss: 2.7711 - val_mae: 1.5054\n",
      "Epoch 1828/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0609 - mae: 0.2093 - val_loss: 2.7420 - val_mae: 1.4957\n",
      "Epoch 1829/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0706 - mae: 0.2259 - val_loss: 2.8119 - val_mae: 1.5189\n",
      "Epoch 1830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0646 - mae: 0.2161 - val_loss: 2.9132 - val_mae: 1.5520\n",
      "Epoch 1831/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1948 - val_loss: 2.9474 - val_mae: 1.5630\n",
      "Epoch 1832/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1839 - val_loss: 2.9216 - val_mae: 1.5547\n",
      "Epoch 1833/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.1860 - val_loss: 2.8446 - val_mae: 1.5298\n",
      "Epoch 1834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1874 - val_loss: 2.7436 - val_mae: 1.4964\n",
      "Epoch 1835/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1884 - val_loss: 2.6837 - val_mae: 1.4763\n",
      "Epoch 1836/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1898 - val_loss: 2.6314 - val_mae: 1.4585\n",
      "Epoch 1837/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0561 - mae: 0.1937 - val_loss: 2.5673 - val_mae: 1.4364\n",
      "Epoch 1838/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0588 - mae: 0.2026 - val_loss: 2.5192 - val_mae: 1.4195\n",
      "Epoch 1839/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0651 - mae: 0.2169 - val_loss: 2.5279 - val_mae: 1.4226\n",
      "Epoch 1840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0630 - mae: 0.2133 - val_loss: 2.6025 - val_mae: 1.4486\n",
      "Epoch 1841/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1927 - val_loss: 2.6647 - val_mae: 1.4699\n",
      "Epoch 1842/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1889 - val_loss: 2.6886 - val_mae: 1.4780\n",
      "Epoch 1843/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1923 - val_loss: 2.6979 - val_mae: 1.4812\n",
      "Epoch 1844/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1890 - val_loss: 2.6855 - val_mae: 1.4769\n",
      "Epoch 1845/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1875 - val_loss: 2.6673 - val_mae: 1.4707\n",
      "Epoch 1846/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1946 - val_loss: 2.6806 - val_mae: 1.4752\n",
      "Epoch 1847/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0579 - mae: 0.1985 - val_loss: 2.7491 - val_mae: 1.4982\n",
      "Epoch 1848/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1889 - val_loss: 2.8486 - val_mae: 1.5310\n",
      "Epoch 1849/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0610 - mae: 0.1888 - val_loss: 2.8695 - val_mae: 1.5378\n",
      "Epoch 1850/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1850 - val_loss: 2.7908 - val_mae: 1.5120\n",
      "Epoch 1851/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2065 - val_loss: 2.7706 - val_mae: 1.5054\n",
      "Epoch 1852/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0783 - mae: 0.2366 - val_loss: 2.8265 - val_mae: 1.5239\n",
      "Epoch 1853/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0852 - mae: 0.2439 - val_loss: 2.9474 - val_mae: 1.5631\n",
      "Epoch 1854/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0685 - mae: 0.2159 - val_loss: 3.1380 - val_mae: 1.6229\n",
      "Epoch 1855/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.1942 - val_loss: 3.2631 - val_mae: 1.6610\n",
      "Epoch 1856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0708 - mae: 0.2013 - val_loss: 3.2715 - val_mae: 1.6635\n",
      "Epoch 1857/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0740 - mae: 0.2060 - val_loss: 3.2151 - val_mae: 1.6464\n",
      "Epoch 1858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0675 - mae: 0.1947 - val_loss: 3.1193 - val_mae: 1.6171\n",
      "Epoch 1859/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0600 - mae: 0.1871 - val_loss: 3.0168 - val_mae: 1.5852\n",
      "Epoch 1860/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1962 - val_loss: 2.9632 - val_mae: 1.5682\n",
      "Epoch 1861/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1964 - val_loss: 2.9527 - val_mae: 1.5648\n",
      "Epoch 1862/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1905 - val_loss: 2.9479 - val_mae: 1.5633\n",
      "Epoch 1863/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0565 - mae: 0.1891 - val_loss: 2.9906 - val_mae: 1.5770\n",
      "Epoch 1864/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1896 - val_loss: 3.0561 - val_mae: 1.5978\n",
      "Epoch 1865/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1935 - val_loss: 3.0960 - val_mae: 1.6103\n",
      "Epoch 1866/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0620 - mae: 0.1977 - val_loss: 3.0806 - val_mae: 1.6055\n",
      "Epoch 1867/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0630 - mae: 0.1999 - val_loss: 2.9920 - val_mae: 1.5777\n",
      "Epoch 1868/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0630 - mae: 0.2034 - val_loss: 2.9024 - val_mae: 1.5490\n",
      "Epoch 1869/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0617 - mae: 0.2046 - val_loss: 2.8428 - val_mae: 1.5296\n",
      "Epoch 1870/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.2011 - val_loss: 2.8554 - val_mae: 1.5337\n",
      "Epoch 1871/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0560 - mae: 0.1921 - val_loss: 2.8583 - val_mae: 1.5346\n",
      "Epoch 1872/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1845 - val_loss: 2.7918 - val_mae: 1.5127\n",
      "Epoch 1873/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0557 - mae: 0.1855 - val_loss: 2.7631 - val_mae: 1.5031\n",
      "Epoch 1874/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0561 - mae: 0.1854 - val_loss: 2.7795 - val_mae: 1.5085\n",
      "Epoch 1875/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1859 - val_loss: 2.7681 - val_mae: 1.5047\n",
      "Epoch 1876/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0572 - mae: 0.1866 - val_loss: 2.7461 - val_mae: 1.4974\n",
      "Epoch 1877/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1852 - val_loss: 2.7262 - val_mae: 1.4908\n",
      "Epoch 1878/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1862 - val_loss: 2.6682 - val_mae: 1.4712\n",
      "Epoch 1879/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1922 - val_loss: 2.6186 - val_mae: 1.4543\n",
      "Epoch 1880/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1979 - val_loss: 2.6265 - val_mae: 1.4570\n",
      "Epoch 1881/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0556 - mae: 0.1903 - val_loss: 2.6652 - val_mae: 1.4703\n",
      "Epoch 1882/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1928 - val_loss: 2.6870 - val_mae: 1.4777\n",
      "Epoch 1883/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.2007 - val_loss: 2.6482 - val_mae: 1.4646\n",
      "Epoch 1884/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1982 - val_loss: 2.5195 - val_mae: 1.4200\n",
      "Epoch 1885/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0595 - mae: 0.2017 - val_loss: 2.3852 - val_mae: 1.3720\n",
      "Epoch 1886/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0984 - mae: 0.2577 - val_loss: 2.3975 - val_mae: 1.3764\n",
      "Epoch 1887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0997 - mae: 0.2584 - val_loss: 2.6071 - val_mae: 1.4505\n",
      "Epoch 1888/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.2023 - val_loss: 2.8871 - val_mae: 1.5440\n",
      "Epoch 1889/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0679 - mae: 0.2059 - val_loss: 3.0629 - val_mae: 1.5999\n",
      "Epoch 1890/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0976 - mae: 0.2553 - val_loss: 3.0560 - val_mae: 1.5977\n",
      "Epoch 1891/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0861 - mae: 0.2366 - val_loss: 2.9394 - val_mae: 1.5608\n",
      "Epoch 1892/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0593 - mae: 0.1944 - val_loss: 2.7958 - val_mae: 1.5140\n",
      "Epoch 1893/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0597 - mae: 0.2022 - val_loss: 2.7077 - val_mae: 1.4846\n",
      "Epoch 1894/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0682 - mae: 0.2214 - val_loss: 2.7259 - val_mae: 1.4906\n",
      "Epoch 1895/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0612 - mae: 0.2103 - val_loss: 2.7871 - val_mae: 1.5109\n",
      "Epoch 1896/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1933 - val_loss: 2.8038 - val_mae: 1.5164\n",
      "Epoch 1897/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1854 - val_loss: 2.7521 - val_mae: 1.4992\n",
      "Epoch 1898/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1913 - val_loss: 2.7043 - val_mae: 1.4832\n",
      "Epoch 1899/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1947 - val_loss: 2.7092 - val_mae: 1.4848\n",
      "Epoch 1900/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1911 - val_loss: 2.6901 - val_mae: 1.4783\n",
      "Epoch 1901/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1912 - val_loss: 2.6601 - val_mae: 1.4681\n",
      "Epoch 1902/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1934 - val_loss: 2.6676 - val_mae: 1.4707\n",
      "Epoch 1903/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1908 - val_loss: 2.7098 - val_mae: 1.4850\n",
      "Epoch 1904/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0559 - mae: 0.1843 - val_loss: 2.7872 - val_mae: 1.5109\n",
      "Epoch 1905/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1849 - val_loss: 2.8597 - val_mae: 1.5347\n",
      "Epoch 1906/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0657 - mae: 0.1973 - val_loss: 2.8848 - val_mae: 1.5428\n",
      "Epoch 1907/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0661 - mae: 0.1985 - val_loss: 2.8440 - val_mae: 1.5295\n",
      "Epoch 1908/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0587 - mae: 0.1865 - val_loss: 2.7678 - val_mae: 1.5044\n",
      "Epoch 1909/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0535 - mae: 0.1858 - val_loss: 2.6885 - val_mae: 1.4778\n",
      "Epoch 1910/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0615 - mae: 0.2123 - val_loss: 2.6796 - val_mae: 1.4748\n",
      "Epoch 1911/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0699 - mae: 0.2235 - val_loss: 2.7853 - val_mae: 1.5102\n",
      "Epoch 1912/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.2081 - val_loss: 2.9469 - val_mae: 1.5628\n",
      "Epoch 1913/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0582 - mae: 0.1917 - val_loss: 3.0356 - val_mae: 1.5909\n",
      "Epoch 1914/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1986 - val_loss: 3.0240 - val_mae: 1.5873\n",
      "Epoch 1915/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1988 - val_loss: 3.0083 - val_mae: 1.5823\n",
      "Epoch 1916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1979 - val_loss: 2.9806 - val_mae: 1.5735\n",
      "Epoch 1917/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0584 - mae: 0.1963 - val_loss: 2.9332 - val_mae: 1.5584\n",
      "Epoch 1918/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0584 - mae: 0.1962 - val_loss: 2.9606 - val_mae: 1.5671\n",
      "Epoch 1919/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1922 - val_loss: 3.0410 - val_mae: 1.5926\n",
      "Epoch 1920/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0664 - mae: 0.1979 - val_loss: 3.0005 - val_mae: 1.5798\n",
      "Epoch 1921/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1839 - val_loss: 2.8359 - val_mae: 1.5268\n",
      "Epoch 1922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.2098 - val_loss: 2.7266 - val_mae: 1.4907\n",
      "Epoch 1923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0829 - mae: 0.2450 - val_loss: 2.7391 - val_mae: 1.4949\n",
      "Epoch 1924/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0816 - mae: 0.2436 - val_loss: 2.8421 - val_mae: 1.5290\n",
      "Epoch 1925/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.2057 - val_loss: 3.0067 - val_mae: 1.5820\n",
      "Epoch 1926/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0600 - mae: 0.1901 - val_loss: 3.1040 - val_mae: 1.6125\n",
      "Epoch 1927/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0759 - mae: 0.2141 - val_loss: 3.0359 - val_mae: 1.5912\n",
      "Epoch 1928/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0668 - mae: 0.1971 - val_loss: 2.8367 - val_mae: 1.5273\n",
      "Epoch 1929/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1871 - val_loss: 2.6433 - val_mae: 1.4626\n",
      "Epoch 1930/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0686 - mae: 0.2254 - val_loss: 2.6095 - val_mae: 1.4511\n",
      "Epoch 1931/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.2249 - val_loss: 2.7405 - val_mae: 1.4955\n",
      "Epoch 1932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1884 - val_loss: 2.9314 - val_mae: 1.5581\n",
      "Epoch 1933/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0757 - mae: 0.2096 - val_loss: 2.9611 - val_mae: 1.5676\n",
      "Epoch 1934/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0702 - mae: 0.2002 - val_loss: 2.8208 - val_mae: 1.5223\n",
      "Epoch 1935/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0566 - mae: 0.1866 - val_loss: 2.7438 - val_mae: 1.4968\n",
      "Epoch 1936/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0595 - mae: 0.2083 - val_loss: 2.7788 - val_mae: 1.5085\n",
      "Epoch 1937/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.2082 - val_loss: 2.9009 - val_mae: 1.5484\n",
      "Epoch 1938/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0545 - mae: 0.1901 - val_loss: 3.0770 - val_mae: 1.6043\n",
      "Epoch 1939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0623 - mae: 0.1928 - val_loss: 3.1850 - val_mae: 1.6376\n",
      "Epoch 1940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0724 - mae: 0.2072 - val_loss: 3.1087 - val_mae: 1.6142\n",
      "Epoch 1941/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0641 - mae: 0.1960 - val_loss: 2.9250 - val_mae: 1.5562\n",
      "Epoch 1942/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1891 - val_loss: 2.7730 - val_mae: 1.5067\n",
      "Epoch 1943/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0577 - mae: 0.2038 - val_loss: 2.6937 - val_mae: 1.4801\n",
      "Epoch 1944/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0587 - mae: 0.2056 - val_loss: 2.7100 - val_mae: 1.4856\n",
      "Epoch 1945/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0559 - mae: 0.1922 - val_loss: 2.7854 - val_mae: 1.5107\n",
      "Epoch 1946/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1873 - val_loss: 2.7800 - val_mae: 1.5089\n",
      "Epoch 1947/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1868 - val_loss: 2.7146 - val_mae: 1.4871\n",
      "Epoch 1948/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1882 - val_loss: 2.6960 - val_mae: 1.4809\n",
      "Epoch 1949/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0557 - mae: 0.1876 - val_loss: 2.7084 - val_mae: 1.4851\n",
      "Epoch 1950/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1864 - val_loss: 2.7201 - val_mae: 1.4890\n",
      "Epoch 1951/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0555 - mae: 0.1860 - val_loss: 2.7126 - val_mae: 1.4865\n",
      "Epoch 1952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1880 - val_loss: 2.7097 - val_mae: 1.4855\n",
      "Epoch 1953/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1908 - val_loss: 2.7595 - val_mae: 1.5021\n",
      "Epoch 1954/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1861 - val_loss: 2.8042 - val_mae: 1.5169\n",
      "Epoch 1955/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1842 - val_loss: 2.7830 - val_mae: 1.5099\n",
      "Epoch 1956/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0556 - mae: 0.1853 - val_loss: 2.7605 - val_mae: 1.5025\n",
      "Epoch 1957/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1863 - val_loss: 2.7689 - val_mae: 1.5054\n",
      "Epoch 1958/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0567 - mae: 0.1994 - val_loss: 2.8332 - val_mae: 1.5266\n",
      "Epoch 1959/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1983 - val_loss: 2.9172 - val_mae: 1.5539\n",
      "Epoch 1960/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1893 - val_loss: 2.9409 - val_mae: 1.5616\n",
      "Epoch 1961/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1866 - val_loss: 2.8917 - val_mae: 1.5458\n",
      "Epoch 1962/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1895 - val_loss: 2.8113 - val_mae: 1.5196\n",
      "Epoch 1963/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0554 - mae: 0.1940 - val_loss: 2.7858 - val_mae: 1.5112\n",
      "Epoch 1964/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1918 - val_loss: 2.8039 - val_mae: 1.5171\n",
      "Epoch 1965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1869 - val_loss: 2.7980 - val_mae: 1.5152\n",
      "Epoch 1966/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1857 - val_loss: 2.7682 - val_mae: 1.5054\n",
      "Epoch 1967/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1858 - val_loss: 2.7871 - val_mae: 1.5116\n",
      "Epoch 1968/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1876 - val_loss: 2.8477 - val_mae: 1.5315\n",
      "Epoch 1969/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0591 - mae: 0.1890 - val_loss: 2.8509 - val_mae: 1.5326\n",
      "Epoch 1970/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.1853 - val_loss: 2.8241 - val_mae: 1.5238\n",
      "Epoch 1971/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0550 - mae: 0.1839 - val_loss: 2.7935 - val_mae: 1.5138\n",
      "Epoch 1972/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0553 - mae: 0.1872 - val_loss: 2.7488 - val_mae: 1.4989\n",
      "Epoch 1973/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0561 - mae: 0.1916 - val_loss: 2.7125 - val_mae: 1.4867\n",
      "Epoch 1974/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0564 - mae: 0.1931 - val_loss: 2.6327 - val_mae: 1.4596\n",
      "Epoch 1975/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0586 - mae: 0.2012 - val_loss: 2.5781 - val_mae: 1.4409\n",
      "Epoch 1976/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0587 - mae: 0.2029 - val_loss: 2.6336 - val_mae: 1.4600\n",
      "Epoch 1977/5000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0554 - mae: 0.1894 - val_loss: 2.7195 - val_mae: 1.4892\n",
      "Epoch 1978/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0564 - mae: 0.1848 - val_loss: 2.8047 - val_mae: 1.5175\n",
      "Epoch 1979/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0630 - mae: 0.1978 - val_loss: 2.8627 - val_mae: 1.5365\n",
      "Epoch 1980/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0673 - mae: 0.2046 - val_loss: 2.8057 - val_mae: 1.5178\n",
      "Epoch 1981/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0556 - mae: 0.1864 - val_loss: 2.6485 - val_mae: 1.4651\n",
      "Epoch 1982/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0618 - mae: 0.2117 - val_loss: 2.5382 - val_mae: 1.4270\n",
      "Epoch 1983/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0854 - mae: 0.2444 - val_loss: 2.5462 - val_mae: 1.4297\n",
      "Epoch 1984/5000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0798 - mae: 0.2363 - val_loss: 2.7018 - val_mae: 1.4830\n",
      "Epoch 1985/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0571 - mae: 0.1996 - val_loss: 2.8781 - val_mae: 1.5412\n",
      "Epoch 1986/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0691 - mae: 0.2101 - val_loss: 2.9135 - val_mae: 1.5525\n",
      "Epoch 1987/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0829 - mae: 0.2334 - val_loss: 2.8528 - val_mae: 1.5327\n",
      "Epoch 1988/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0726 - mae: 0.2143 - val_loss: 2.6982 - val_mae: 1.4813\n",
      "Epoch 1989/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0566 - mae: 0.1822 - val_loss: 2.4991 - val_mae: 1.4124\n",
      "Epoch 1990/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0637 - mae: 0.2136 - val_loss: 2.3632 - val_mae: 1.3634\n",
      "Epoch 1991/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0913 - mae: 0.2591 - val_loss: 2.3664 - val_mae: 1.3646\n",
      "Epoch 1992/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0865 - mae: 0.2504 - val_loss: 2.5296 - val_mae: 1.4231\n",
      "Epoch 1993/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0626 - mae: 0.2051 - val_loss: 2.6959 - val_mae: 1.4804\n",
      "Epoch 1994/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0615 - mae: 0.1863 - val_loss: 2.7535 - val_mae: 1.4997\n",
      "Epoch 1995/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0636 - mae: 0.1929 - val_loss: 2.7641 - val_mae: 1.5032\n",
      "Epoch 1996/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0593 - mae: 0.1841 - val_loss: 2.7478 - val_mae: 1.4978\n",
      "Epoch 1997/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0555 - mae: 0.1829 - val_loss: 2.7116 - val_mae: 1.4856\n",
      "Epoch 1998/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0560 - mae: 0.1956 - val_loss: 2.7208 - val_mae: 1.4887\n",
      "Epoch 1999/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0577 - mae: 0.2017 - val_loss: 2.7838 - val_mae: 1.5097\n",
      "Epoch 2000/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0564 - mae: 0.1952 - val_loss: 2.8475 - val_mae: 1.5306\n",
      "Epoch 2001/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0551 - mae: 0.1874 - val_loss: 2.8604 - val_mae: 1.5349\n",
      "Epoch 2002/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0556 - mae: 0.1876 - val_loss: 2.8613 - val_mae: 1.5352\n",
      "Epoch 2003/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0574 - mae: 0.1929 - val_loss: 2.8710 - val_mae: 1.5383\n",
      "Epoch 2004/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0600 - mae: 0.1964 - val_loss: 2.8682 - val_mae: 1.5373\n",
      "Epoch 2005/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0598 - mae: 0.1960 - val_loss: 2.8324 - val_mae: 1.5256\n",
      "Epoch 2006/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0564 - mae: 0.1915 - val_loss: 2.7518 - val_mae: 1.4990\n",
      "Epoch 2007/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0541 - mae: 0.1890 - val_loss: 2.6608 - val_mae: 1.4683\n",
      "Epoch 2008/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0602 - mae: 0.2083 - val_loss: 2.6608 - val_mae: 1.4682\n",
      "Epoch 2009/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0597 - mae: 0.2044 - val_loss: 2.7264 - val_mae: 1.4904\n",
      "Epoch 2010/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0551 - mae: 0.1863 - val_loss: 2.7912 - val_mae: 1.5120\n",
      "Epoch 2011/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1835 - val_loss: 2.8414 - val_mae: 1.5285\n",
      "Epoch 2012/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0598 - mae: 0.1846 - val_loss: 2.8472 - val_mae: 1.5305\n",
      "Epoch 2013/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - mae: 0.1890 - val_loss: 2.8112 - val_mae: 1.5186\n",
      "Epoch 2014/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1831 - val_loss: 2.7136 - val_mae: 1.4861\n",
      "Epoch 2015/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1857 - val_loss: 2.6272 - val_mae: 1.4568\n",
      "Epoch 2016/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1989 - val_loss: 2.6066 - val_mae: 1.4497\n",
      "Epoch 2017/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.2025 - val_loss: 2.6324 - val_mae: 1.4586\n",
      "Epoch 2018/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0560 - mae: 0.1963 - val_loss: 2.6785 - val_mae: 1.4743\n",
      "Epoch 2019/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0544 - mae: 0.1857 - val_loss: 2.7425 - val_mae: 1.4959\n",
      "Epoch 2020/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1816 - val_loss: 2.8195 - val_mae: 1.5214\n",
      "Epoch 2021/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0595 - mae: 0.1885 - val_loss: 2.8811 - val_mae: 1.5415\n",
      "Epoch 2022/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0622 - mae: 0.1921 - val_loss: 2.9025 - val_mae: 1.5485\n",
      "Epoch 2023/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0601 - mae: 0.1889 - val_loss: 2.8439 - val_mae: 1.5295\n",
      "Epoch 2024/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0550 - mae: 0.1818 - val_loss: 2.7437 - val_mae: 1.4963\n",
      "Epoch 2025/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1986 - val_loss: 2.6958 - val_mae: 1.4802\n",
      "Epoch 2026/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0603 - mae: 0.2099 - val_loss: 2.7259 - val_mae: 1.4904\n",
      "Epoch 2027/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.2022 - val_loss: 2.7871 - val_mae: 1.5108\n",
      "Epoch 2028/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0541 - mae: 0.1858 - val_loss: 2.7765 - val_mae: 1.5074\n",
      "Epoch 2029/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0542 - mae: 0.1825 - val_loss: 2.6832 - val_mae: 1.4761\n",
      "Epoch 2030/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1854 - val_loss: 2.5764 - val_mae: 1.4395\n",
      "Epoch 2031/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0564 - mae: 0.1919 - val_loss: 2.5237 - val_mae: 1.4211\n",
      "Epoch 2032/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1933 - val_loss: 2.5077 - val_mae: 1.4155\n",
      "Epoch 2033/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1916 - val_loss: 2.4976 - val_mae: 1.4120\n",
      "Epoch 2034/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0586 - mae: 0.1916 - val_loss: 2.4877 - val_mae: 1.4085\n",
      "Epoch 2035/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1918 - val_loss: 2.4743 - val_mae: 1.4037\n",
      "Epoch 2036/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1923 - val_loss: 2.4489 - val_mae: 1.3946\n",
      "Epoch 2037/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0604 - mae: 0.1925 - val_loss: 2.4112 - val_mae: 1.3811\n",
      "Epoch 2038/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.1971 - val_loss: 2.3996 - val_mae: 1.3769\n",
      "Epoch 2039/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0626 - mae: 0.1987 - val_loss: 2.4364 - val_mae: 1.3902\n",
      "Epoch 2040/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1959 - val_loss: 2.4700 - val_mae: 1.4023\n",
      "Epoch 2041/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0603 - mae: 0.1926 - val_loss: 2.5594 - val_mae: 1.4338\n",
      "Epoch 2042/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.1960 - val_loss: 2.7617 - val_mae: 1.5027\n",
      "Epoch 2043/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0721 - mae: 0.2135 - val_loss: 2.9481 - val_mae: 1.5636\n",
      "Epoch 2044/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0850 - mae: 0.2344 - val_loss: 3.0197 - val_mae: 1.5864\n",
      "Epoch 2045/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0760 - mae: 0.2170 - val_loss: 2.9744 - val_mae: 1.5721\n",
      "Epoch 2046/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1872 - val_loss: 2.8510 - val_mae: 1.5324\n",
      "Epoch 2047/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.2085 - val_loss: 2.7597 - val_mae: 1.5023\n",
      "Epoch 2048/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0691 - mae: 0.2243 - val_loss: 2.8261 - val_mae: 1.5242\n",
      "Epoch 2049/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0573 - mae: 0.1997 - val_loss: 3.0141 - val_mae: 1.5846\n",
      "Epoch 2050/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0614 - mae: 0.1847 - val_loss: 3.1317 - val_mae: 1.6212\n",
      "Epoch 2051/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0795 - mae: 0.2172 - val_loss: 3.0835 - val_mae: 1.6062\n",
      "Epoch 2052/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0808 - mae: 0.2191 - val_loss: 2.8988 - val_mae: 1.5476\n",
      "Epoch 2053/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0659 - mae: 0.1990 - val_loss: 2.6547 - val_mae: 1.4666\n",
      "Epoch 2054/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.2003 - val_loss: 2.4735 - val_mae: 1.4035\n",
      "Epoch 2055/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0697 - mae: 0.2211 - val_loss: 2.4722 - val_mae: 1.4030\n",
      "Epoch 2056/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.2128 - val_loss: 2.5586 - val_mae: 1.4334\n",
      "Epoch 2057/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0585 - mae: 0.1904 - val_loss: 2.6689 - val_mae: 1.4714\n",
      "Epoch 2058/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0594 - mae: 0.1894 - val_loss: 2.7996 - val_mae: 1.5152\n",
      "Epoch 2059/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0640 - mae: 0.1975 - val_loss: 2.8684 - val_mae: 1.5377\n",
      "Epoch 2060/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0627 - mae: 0.1977 - val_loss: 2.9060 - val_mae: 1.5499\n",
      "Epoch 2061/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1907 - val_loss: 2.9070 - val_mae: 1.5502\n",
      "Epoch 2062/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1927 - val_loss: 2.8929 - val_mae: 1.5457\n",
      "Epoch 2063/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.2006 - val_loss: 2.9564 - val_mae: 1.5661\n",
      "Epoch 2064/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0579 - mae: 0.1975 - val_loss: 3.0310 - val_mae: 1.5897\n",
      "Epoch 2065/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1899 - val_loss: 3.0381 - val_mae: 1.5918\n",
      "Epoch 2066/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.1855 - val_loss: 2.9631 - val_mae: 1.5680\n",
      "Epoch 2067/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1834 - val_loss: 2.8143 - val_mae: 1.5198\n",
      "Epoch 2068/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0581 - mae: 0.2032 - val_loss: 2.7225 - val_mae: 1.4893\n",
      "Epoch 2069/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0595 - mae: 0.2075 - val_loss: 2.7043 - val_mae: 1.4832\n",
      "Epoch 2070/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1983 - val_loss: 2.6854 - val_mae: 1.4768\n",
      "Epoch 2071/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1872 - val_loss: 2.7096 - val_mae: 1.4850\n",
      "Epoch 2072/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.1871 - val_loss: 2.7640 - val_mae: 1.5033\n",
      "Epoch 2073/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.2026 - val_loss: 2.7757 - val_mae: 1.5072\n",
      "Epoch 2074/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0665 - mae: 0.2060 - val_loss: 2.6671 - val_mae: 1.4707\n",
      "Epoch 2075/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0598 - mae: 0.1964 - val_loss: 2.5246 - val_mae: 1.4213\n",
      "Epoch 2076/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1930 - val_loss: 2.4544 - val_mae: 1.3964\n",
      "Epoch 2077/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0608 - mae: 0.2004 - val_loss: 2.4783 - val_mae: 1.4049\n",
      "Epoch 2078/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.1950 - val_loss: 2.5833 - val_mae: 1.4418\n",
      "Epoch 2079/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0564 - mae: 0.1880 - val_loss: 2.6911 - val_mae: 1.4786\n",
      "Epoch 2080/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1870 - val_loss: 2.7751 - val_mae: 1.5068\n",
      "Epoch 2081/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0603 - mae: 0.1908 - val_loss: 2.7445 - val_mae: 1.4965\n",
      "Epoch 2082/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1833 - val_loss: 2.6300 - val_mae: 1.4578\n",
      "Epoch 2083/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.2087 - val_loss: 2.5717 - val_mae: 1.4376\n",
      "Epoch 2084/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0712 - mae: 0.2275 - val_loss: 2.5756 - val_mae: 1.4390\n",
      "Epoch 2085/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0719 - mae: 0.2280 - val_loss: 2.6245 - val_mae: 1.4559\n",
      "Epoch 2086/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0629 - mae: 0.2144 - val_loss: 2.7184 - val_mae: 1.4878\n",
      "Epoch 2087/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0537 - mae: 0.1905 - val_loss: 2.8624 - val_mae: 1.5355\n",
      "Epoch 2088/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1869 - val_loss: 3.0051 - val_mae: 1.5813\n",
      "Epoch 2089/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0723 - mae: 0.2105 - val_loss: 3.0859 - val_mae: 1.6066\n",
      "Epoch 2090/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0804 - mae: 0.2240 - val_loss: 3.1003 - val_mae: 1.6111\n",
      "Epoch 2091/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2090 - val_loss: 3.0191 - val_mae: 1.5857\n",
      "Epoch 2092/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1905 - val_loss: 2.9125 - val_mae: 1.5518\n",
      "Epoch 2093/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0642 - mae: 0.2124 - val_loss: 2.9064 - val_mae: 1.5499\n",
      "Epoch 2094/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0689 - mae: 0.2193 - val_loss: 3.0133 - val_mae: 1.5840\n",
      "Epoch 2095/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.1997 - val_loss: 3.0967 - val_mae: 1.6101\n",
      "Epoch 2096/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1927 - val_loss: 3.0076 - val_mae: 1.5822\n",
      "Epoch 2097/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0590 - mae: 0.1911 - val_loss: 2.8851 - val_mae: 1.5431\n",
      "Epoch 2098/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1874 - val_loss: 2.8742 - val_mae: 1.5395\n",
      "Epoch 2099/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1855 - val_loss: 2.8769 - val_mae: 1.5404\n",
      "Epoch 2100/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1835 - val_loss: 2.8629 - val_mae: 1.5359\n",
      "Epoch 2101/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1819 - val_loss: 2.8312 - val_mae: 1.5256\n",
      "Epoch 2102/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1823 - val_loss: 2.7774 - val_mae: 1.5079\n",
      "Epoch 2103/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1875 - val_loss: 2.7891 - val_mae: 1.5117\n",
      "Epoch 2104/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0545 - mae: 0.1898 - val_loss: 2.8659 - val_mae: 1.5369\n",
      "Epoch 2105/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1911 - val_loss: 2.9834 - val_mae: 1.5747\n",
      "Epoch 2106/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1885 - val_loss: 3.1341 - val_mae: 1.6218\n",
      "Epoch 2107/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0597 - mae: 0.1842 - val_loss: 3.2165 - val_mae: 1.6470\n",
      "Epoch 2108/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0628 - mae: 0.1868 - val_loss: 3.2376 - val_mae: 1.6534\n",
      "Epoch 2109/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0634 - mae: 0.1874 - val_loss: 3.2350 - val_mae: 1.6526\n",
      "Epoch 2110/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.1872 - val_loss: 3.1377 - val_mae: 1.6229\n",
      "Epoch 2111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1876 - val_loss: 2.9839 - val_mae: 1.5749\n",
      "Epoch 2112/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0585 - mae: 0.2006 - val_loss: 2.8801 - val_mae: 1.5416\n",
      "Epoch 2113/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0604 - mae: 0.2080 - val_loss: 2.8108 - val_mae: 1.5190\n",
      "Epoch 2114/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0625 - mae: 0.2128 - val_loss: 2.7705 - val_mae: 1.5057\n",
      "Epoch 2115/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.2095 - val_loss: 2.7930 - val_mae: 1.5131\n",
      "Epoch 2116/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1917 - val_loss: 2.8614 - val_mae: 1.5355\n",
      "Epoch 2117/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1805 - val_loss: 2.8820 - val_mae: 1.5422\n",
      "Epoch 2118/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.1887 - val_loss: 2.8424 - val_mae: 1.5293\n",
      "Epoch 2119/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.1949 - val_loss: 2.7742 - val_mae: 1.5068\n",
      "Epoch 2120/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0593 - mae: 0.1911 - val_loss: 2.6546 - val_mae: 1.4666\n",
      "Epoch 2121/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1865 - val_loss: 2.5312 - val_mae: 1.4239\n",
      "Epoch 2122/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.2046 - val_loss: 2.4642 - val_mae: 1.4001\n",
      "Epoch 2123/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0641 - mae: 0.2127 - val_loss: 2.4548 - val_mae: 1.3968\n",
      "Epoch 2124/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0642 - mae: 0.2107 - val_loss: 2.4277 - val_mae: 1.3870\n",
      "Epoch 2125/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0649 - mae: 0.2106 - val_loss: 2.3698 - val_mae: 1.3659\n",
      "Epoch 2126/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0724 - mae: 0.2225 - val_loss: 2.3816 - val_mae: 1.3702\n",
      "Epoch 2127/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0686 - mae: 0.2155 - val_loss: 2.4805 - val_mae: 1.4058\n",
      "Epoch 2128/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0587 - mae: 0.1984 - val_loss: 2.5987 - val_mae: 1.4473\n",
      "Epoch 2129/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0667 - mae: 0.2086 - val_loss: 2.6643 - val_mae: 1.4697\n",
      "Epoch 2130/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0742 - mae: 0.2162 - val_loss: 2.6012 - val_mae: 1.4480\n",
      "Epoch 2131/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0632 - mae: 0.1960 - val_loss: 2.4804 - val_mae: 1.4056\n",
      "Epoch 2132/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0581 - mae: 0.1880 - val_loss: 2.4092 - val_mae: 1.3800\n",
      "Epoch 2133/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0623 - mae: 0.2031 - val_loss: 2.4371 - val_mae: 1.3901\n",
      "Epoch 2134/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0613 - mae: 0.2021 - val_loss: 2.5002 - val_mae: 1.4126\n",
      "Epoch 2135/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0578 - mae: 0.1912 - val_loss: 2.5637 - val_mae: 1.4350\n",
      "Epoch 2136/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1862 - val_loss: 2.6598 - val_mae: 1.4681\n",
      "Epoch 2137/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1830 - val_loss: 2.7240 - val_mae: 1.4898\n",
      "Epoch 2138/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0575 - mae: 0.1815 - val_loss: 2.7173 - val_mae: 1.4876\n",
      "Epoch 2139/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0550 - mae: 0.1818 - val_loss: 2.6239 - val_mae: 1.4559\n",
      "Epoch 2140/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0537 - mae: 0.1909 - val_loss: 2.4708 - val_mae: 1.4024\n",
      "Epoch 2141/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0771 - mae: 0.2357 - val_loss: 2.4181 - val_mae: 1.3835\n",
      "Epoch 2142/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0863 - mae: 0.2421 - val_loss: 2.5595 - val_mae: 1.4338\n",
      "Epoch 2143/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0621 - mae: 0.2108 - val_loss: 2.7927 - val_mae: 1.5130\n",
      "Epoch 2144/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.2005 - val_loss: 2.9205 - val_mae: 1.5547\n",
      "Epoch 2145/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0654 - mae: 0.2095 - val_loss: 2.9292 - val_mae: 1.5575\n",
      "Epoch 2146/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0624 - mae: 0.2088 - val_loss: 2.8847 - val_mae: 1.5432\n",
      "Epoch 2147/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0642 - mae: 0.2148 - val_loss: 2.8533 - val_mae: 1.5331\n",
      "Epoch 2148/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0637 - mae: 0.2108 - val_loss: 2.9002 - val_mae: 1.5482\n",
      "Epoch 2149/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.2083 - val_loss: 2.8763 - val_mae: 1.5404\n",
      "Epoch 2150/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.2021 - val_loss: 2.7995 - val_mae: 1.5153\n",
      "Epoch 2151/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1958 - val_loss: 2.7856 - val_mae: 1.5107\n",
      "Epoch 2152/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0542 - mae: 0.1907 - val_loss: 2.8260 - val_mae: 1.5240\n",
      "Epoch 2153/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1881 - val_loss: 2.8443 - val_mae: 1.5300\n",
      "Epoch 2154/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1854 - val_loss: 2.8169 - val_mae: 1.5210\n",
      "Epoch 2155/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0541 - mae: 0.1844 - val_loss: 2.8086 - val_mae: 1.5183\n",
      "Epoch 2156/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1874 - val_loss: 2.8042 - val_mae: 1.5168\n",
      "Epoch 2157/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1902 - val_loss: 2.7650 - val_mae: 1.5039\n",
      "Epoch 2158/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1959 - val_loss: 2.7450 - val_mae: 1.4972\n",
      "Epoch 2159/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1934 - val_loss: 2.7467 - val_mae: 1.4978\n",
      "Epoch 2160/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1880 - val_loss: 2.7451 - val_mae: 1.4973\n",
      "Epoch 2161/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1874 - val_loss: 2.7961 - val_mae: 1.5143\n",
      "Epoch 2162/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1843 - val_loss: 2.8213 - val_mae: 1.5227\n",
      "Epoch 2163/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1853 - val_loss: 2.7775 - val_mae: 1.5084\n",
      "Epoch 2164/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1863 - val_loss: 2.7545 - val_mae: 1.5008\n",
      "Epoch 2165/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1869 - val_loss: 2.7811 - val_mae: 1.5097\n",
      "Epoch 2166/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0537 - mae: 0.1860 - val_loss: 2.8005 - val_mae: 1.5161\n",
      "Epoch 2167/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1874 - val_loss: 2.7867 - val_mae: 1.5117\n",
      "Epoch 2168/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0568 - mae: 0.1983 - val_loss: 2.8271 - val_mae: 1.5250\n",
      "Epoch 2169/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0587 - mae: 0.2018 - val_loss: 2.9367 - val_mae: 1.5605\n",
      "Epoch 2170/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1875 - val_loss: 3.0806 - val_mae: 1.6058\n",
      "Epoch 2171/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1965 - val_loss: 3.1029 - val_mae: 1.6127\n",
      "Epoch 2172/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0679 - mae: 0.1992 - val_loss: 2.9802 - val_mae: 1.5741\n",
      "Epoch 2173/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1839 - val_loss: 2.8307 - val_mae: 1.5259\n",
      "Epoch 2174/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1951 - val_loss: 2.7135 - val_mae: 1.4870\n",
      "Epoch 2175/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.2027 - val_loss: 2.7338 - val_mae: 1.4938\n",
      "Epoch 2176/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1838 - val_loss: 2.8163 - val_mae: 1.5212\n",
      "Epoch 2177/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0605 - mae: 0.1870 - val_loss: 2.8930 - val_mae: 1.5462\n",
      "Epoch 2178/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0791 - mae: 0.2222 - val_loss: 2.8451 - val_mae: 1.5307\n",
      "Epoch 2179/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.2015 - val_loss: 2.6044 - val_mae: 1.4500\n",
      "Epoch 2180/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0580 - mae: 0.2007 - val_loss: 2.4012 - val_mae: 1.3782\n",
      "Epoch 2181/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0936 - mae: 0.2590 - val_loss: 2.4286 - val_mae: 1.3881\n",
      "Epoch 2182/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0877 - mae: 0.2511 - val_loss: 2.6647 - val_mae: 1.4705\n",
      "Epoch 2183/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0594 - mae: 0.2043 - val_loss: 2.9093 - val_mae: 1.5515\n",
      "Epoch 2184/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.1827 - val_loss: 3.0736 - val_mae: 1.6036\n",
      "Epoch 2185/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0667 - mae: 0.1968 - val_loss: 3.1641 - val_mae: 1.6316\n",
      "Epoch 2186/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0677 - mae: 0.1973 - val_loss: 3.1365 - val_mae: 1.6231\n",
      "Epoch 2187/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.1829 - val_loss: 3.0599 - val_mae: 1.5995\n",
      "Epoch 2188/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1905 - val_loss: 3.0151 - val_mae: 1.5856\n",
      "Epoch 2189/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.2021 - val_loss: 2.9811 - val_mae: 1.5750\n",
      "Epoch 2190/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0633 - mae: 0.2095 - val_loss: 2.9254 - val_mae: 1.5573\n",
      "Epoch 2191/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0662 - mae: 0.2150 - val_loss: 2.8994 - val_mae: 1.5490\n",
      "Epoch 2192/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.2098 - val_loss: 2.9492 - val_mae: 1.5650\n",
      "Epoch 2193/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1956 - val_loss: 3.0110 - val_mae: 1.5846\n",
      "Epoch 2194/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0581 - mae: 0.1953 - val_loss: 2.9792 - val_mae: 1.5744\n",
      "Epoch 2195/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.1945 - val_loss: 2.8908 - val_mae: 1.5459\n",
      "Epoch 2196/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1858 - val_loss: 2.7847 - val_mae: 1.5110\n",
      "Epoch 2197/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0539 - mae: 0.1832 - val_loss: 2.6989 - val_mae: 1.4822\n",
      "Epoch 2198/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1875 - val_loss: 2.6695 - val_mae: 1.4721\n",
      "Epoch 2199/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1888 - val_loss: 2.6592 - val_mae: 1.4685\n",
      "Epoch 2200/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1895 - val_loss: 2.6763 - val_mae: 1.4743\n",
      "Epoch 2201/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1874 - val_loss: 2.7235 - val_mae: 1.4901\n",
      "Epoch 2202/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1837 - val_loss: 2.7667 - val_mae: 1.5046\n",
      "Epoch 2203/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1818 - val_loss: 2.7665 - val_mae: 1.5046\n",
      "Epoch 2204/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1819 - val_loss: 2.7271 - val_mae: 1.4915\n",
      "Epoch 2205/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1919 - val_loss: 2.7330 - val_mae: 1.4936\n",
      "Epoch 2206/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1960 - val_loss: 2.7714 - val_mae: 1.5064\n",
      "Epoch 2207/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1959 - val_loss: 2.8046 - val_mae: 1.5175\n",
      "Epoch 2208/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0585 - mae: 0.2006 - val_loss: 2.9064 - val_mae: 1.5507\n",
      "Epoch 2209/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1987 - val_loss: 3.0467 - val_mae: 1.5952\n",
      "Epoch 2210/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0671 - mae: 0.2078 - val_loss: 3.0596 - val_mae: 1.5992\n",
      "Epoch 2211/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0684 - mae: 0.2075 - val_loss: 2.9599 - val_mae: 1.5676\n",
      "Epoch 2212/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0578 - mae: 0.1900 - val_loss: 2.8762 - val_mae: 1.5406\n",
      "Epoch 2213/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0535 - mae: 0.1847 - val_loss: 2.8277 - val_mae: 1.5247\n",
      "Epoch 2214/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1888 - val_loss: 2.8343 - val_mae: 1.5268\n",
      "Epoch 2215/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1835 - val_loss: 2.9017 - val_mae: 1.5487\n",
      "Epoch 2216/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1836 - val_loss: 2.9699 - val_mae: 1.5705\n",
      "Epoch 2217/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1928 - val_loss: 2.9614 - val_mae: 1.5678\n",
      "Epoch 2218/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.1927 - val_loss: 2.9004 - val_mae: 1.5483\n",
      "Epoch 2219/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1851 - val_loss: 2.8423 - val_mae: 1.5294\n",
      "Epoch 2220/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1851 - val_loss: 2.8046 - val_mae: 1.5171\n",
      "Epoch 2221/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1868 - val_loss: 2.7950 - val_mae: 1.5139\n",
      "Epoch 2222/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0541 - mae: 0.1890 - val_loss: 2.8192 - val_mae: 1.5219\n",
      "Epoch 2223/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1867 - val_loss: 2.8123 - val_mae: 1.5197\n",
      "Epoch 2224/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0539 - mae: 0.1839 - val_loss: 2.7511 - val_mae: 1.4994\n",
      "Epoch 2225/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0536 - mae: 0.1855 - val_loss: 2.7187 - val_mae: 1.4885\n",
      "Epoch 2226/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0538 - mae: 0.1879 - val_loss: 2.7062 - val_mae: 1.4843\n",
      "Epoch 2227/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1895 - val_loss: 2.6594 - val_mae: 1.4684\n",
      "Epoch 2228/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0567 - mae: 0.1993 - val_loss: 2.6088 - val_mae: 1.4511\n",
      "Epoch 2229/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0652 - mae: 0.2169 - val_loss: 2.6188 - val_mae: 1.4545\n",
      "Epoch 2230/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0657 - mae: 0.2168 - val_loss: 2.7369 - val_mae: 1.4945\n",
      "Epoch 2231/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1985 - val_loss: 2.9057 - val_mae: 1.5498\n",
      "Epoch 2232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1898 - val_loss: 2.9983 - val_mae: 1.5793\n",
      "Epoch 2233/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1927 - val_loss: 3.0230 - val_mae: 1.5870\n",
      "Epoch 2234/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0589 - mae: 0.1914 - val_loss: 3.0110 - val_mae: 1.5832\n",
      "Epoch 2235/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.1860 - val_loss: 3.0000 - val_mae: 1.5796\n",
      "Epoch 2236/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1827 - val_loss: 2.9595 - val_mae: 1.5667\n",
      "Epoch 2237/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0539 - mae: 0.1859 - val_loss: 2.8892 - val_mae: 1.5441\n",
      "Epoch 2238/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1979 - val_loss: 2.8509 - val_mae: 1.5317\n",
      "Epoch 2239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.2030 - val_loss: 2.9103 - val_mae: 1.5510\n",
      "Epoch 2240/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1959 - val_loss: 2.9367 - val_mae: 1.5595\n",
      "Epoch 2241/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0544 - mae: 0.1898 - val_loss: 2.8806 - val_mae: 1.5414\n",
      "Epoch 2242/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0531 - mae: 0.1872 - val_loss: 2.8835 - val_mae: 1.5423\n",
      "Epoch 2243/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1820 - val_loss: 2.8921 - val_mae: 1.5451\n",
      "Epoch 2244/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0580 - mae: 0.1858 - val_loss: 2.8354 - val_mae: 1.5267\n",
      "Epoch 2245/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0571 - mae: 0.1839 - val_loss: 2.7439 - val_mae: 1.4964\n",
      "Epoch 2246/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0542 - mae: 0.1803 - val_loss: 2.6403 - val_mae: 1.4613\n",
      "Epoch 2247/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1865 - val_loss: 2.5425 - val_mae: 1.4275\n",
      "Epoch 2248/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1966 - val_loss: 2.5268 - val_mae: 1.4220\n",
      "Epoch 2249/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1937 - val_loss: 2.6164 - val_mae: 1.4532\n",
      "Epoch 2250/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0562 - mae: 0.1862 - val_loss: 2.6825 - val_mae: 1.4758\n",
      "Epoch 2251/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1862 - val_loss: 2.7147 - val_mae: 1.4867\n",
      "Epoch 2252/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1862 - val_loss: 2.7996 - val_mae: 1.5150\n",
      "Epoch 2253/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1870 - val_loss: 2.8820 - val_mae: 1.5420\n",
      "Epoch 2254/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0538 - mae: 0.1870 - val_loss: 2.9354 - val_mae: 1.5592\n",
      "Epoch 2255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1876 - val_loss: 2.9511 - val_mae: 1.5643\n",
      "Epoch 2256/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1867 - val_loss: 2.9131 - val_mae: 1.5521\n",
      "Epoch 2257/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1892 - val_loss: 2.8380 - val_mae: 1.5277\n",
      "Epoch 2258/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1984 - val_loss: 2.7410 - val_mae: 1.4957\n",
      "Epoch 2259/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2061 - val_loss: 2.6879 - val_mae: 1.4778\n",
      "Epoch 2260/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.2013 - val_loss: 2.7239 - val_mae: 1.4901\n",
      "Epoch 2261/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0541 - mae: 0.1869 - val_loss: 2.7984 - val_mae: 1.5149\n",
      "Epoch 2262/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1978 - val_loss: 2.8499 - val_mae: 1.5318\n",
      "Epoch 2263/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0683 - mae: 0.2110 - val_loss: 2.8863 - val_mae: 1.5436\n",
      "Epoch 2264/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0691 - mae: 0.2117 - val_loss: 2.9283 - val_mae: 1.5572\n",
      "Epoch 2265/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0642 - mae: 0.2023 - val_loss: 2.9314 - val_mae: 1.5582\n",
      "Epoch 2266/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1910 - val_loss: 2.8540 - val_mae: 1.5331\n",
      "Epoch 2267/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0531 - mae: 0.1896 - val_loss: 2.7566 - val_mae: 1.5010\n",
      "Epoch 2268/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.2015 - val_loss: 2.7492 - val_mae: 1.4986\n",
      "Epoch 2269/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1961 - val_loss: 2.8374 - val_mae: 1.5277\n",
      "Epoch 2270/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1847 - val_loss: 2.8626 - val_mae: 1.5360\n",
      "Epoch 2271/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1840 - val_loss: 2.7663 - val_mae: 1.5044\n",
      "Epoch 2272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1873 - val_loss: 2.7104 - val_mae: 1.4857\n",
      "Epoch 2273/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1909 - val_loss: 2.7944 - val_mae: 1.5138\n",
      "Epoch 2274/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1859 - val_loss: 2.9435 - val_mae: 1.5623\n",
      "Epoch 2275/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1790 - val_loss: 3.0994 - val_mae: 1.6115\n",
      "Epoch 2276/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0619 - mae: 0.1896 - val_loss: 3.1602 - val_mae: 1.6304\n",
      "Epoch 2277/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1864 - val_loss: 3.1237 - val_mae: 1.6193\n",
      "Epoch 2278/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0617 - mae: 0.1978 - val_loss: 3.1068 - val_mae: 1.6142\n",
      "Epoch 2279/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0792 - mae: 0.2251 - val_loss: 3.2230 - val_mae: 1.6498\n",
      "Epoch 2280/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0648 - mae: 0.1964 - val_loss: 3.4465 - val_mae: 1.7161\n",
      "Epoch 2281/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0772 - mae: 0.2079 - val_loss: 3.5756 - val_mae: 1.7533\n",
      "Epoch 2282/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1072 - mae: 0.2633 - val_loss: 3.4856 - val_mae: 1.7274\n",
      "Epoch 2283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0940 - mae: 0.2382 - val_loss: 3.1905 - val_mae: 1.6399\n",
      "Epoch 2284/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0645 - mae: 0.1900 - val_loss: 2.9238 - val_mae: 1.5565\n",
      "Epoch 2285/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.2110 - val_loss: 2.8131 - val_mae: 1.5206\n",
      "Epoch 2286/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0683 - mae: 0.2278 - val_loss: 2.8200 - val_mae: 1.5229\n",
      "Epoch 2287/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0624 - mae: 0.2146 - val_loss: 2.8864 - val_mae: 1.5445\n",
      "Epoch 2288/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1894 - val_loss: 2.8968 - val_mae: 1.5480\n",
      "Epoch 2289/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0557 - mae: 0.1842 - val_loss: 2.8076 - val_mae: 1.5190\n",
      "Epoch 2290/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1889 - val_loss: 2.6944 - val_mae: 1.4815\n",
      "Epoch 2291/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0606 - mae: 0.2106 - val_loss: 2.7335 - val_mae: 1.4948\n",
      "Epoch 2292/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1981 - val_loss: 2.8974 - val_mae: 1.5487\n",
      "Epoch 2293/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1879 - val_loss: 3.0237 - val_mae: 1.5889\n",
      "Epoch 2294/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.1985 - val_loss: 3.0731 - val_mae: 1.6045\n",
      "Epoch 2295/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0685 - mae: 0.2058 - val_loss: 3.0670 - val_mae: 1.6027\n",
      "Epoch 2296/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.1945 - val_loss: 2.9672 - val_mae: 1.5713\n",
      "Epoch 2297/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1909 - val_loss: 2.8282 - val_mae: 1.5265\n",
      "Epoch 2298/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.2104 - val_loss: 2.8170 - val_mae: 1.5228\n",
      "Epoch 2299/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1917 - val_loss: 2.9198 - val_mae: 1.5559\n",
      "Epoch 2300/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1835 - val_loss: 3.0235 - val_mae: 1.5888\n",
      "Epoch 2301/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0800 - mae: 0.2226 - val_loss: 3.0021 - val_mae: 1.5819\n",
      "Epoch 2302/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0867 - mae: 0.2320 - val_loss: 2.7860 - val_mae: 1.5120\n",
      "Epoch 2303/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0671 - mae: 0.2014 - val_loss: 2.5479 - val_mae: 1.4310\n",
      "Epoch 2304/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - mae: 0.1993 - val_loss: 2.4215 - val_mae: 1.3861\n",
      "Epoch 2305/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0711 - mae: 0.2220 - val_loss: 2.4089 - val_mae: 1.3815\n",
      "Epoch 2306/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0708 - mae: 0.2208 - val_loss: 2.5205 - val_mae: 1.4212\n",
      "Epoch 2307/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0611 - mae: 0.1966 - val_loss: 2.6969 - val_mae: 1.4818\n",
      "Epoch 2308/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.1898 - val_loss: 2.8423 - val_mae: 1.5300\n",
      "Epoch 2309/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0716 - mae: 0.2085 - val_loss: 2.9254 - val_mae: 1.5569\n",
      "Epoch 2310/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0766 - mae: 0.2179 - val_loss: 2.8835 - val_mae: 1.5433\n",
      "Epoch 2311/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0661 - mae: 0.1956 - val_loss: 2.7807 - val_mae: 1.5096\n",
      "Epoch 2312/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0552 - mae: 0.1829 - val_loss: 2.6691 - val_mae: 1.4721\n",
      "Epoch 2313/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2016 - val_loss: 2.5856 - val_mae: 1.4434\n",
      "Epoch 2314/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0670 - mae: 0.2236 - val_loss: 2.6035 - val_mae: 1.4496\n",
      "Epoch 2315/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.2198 - val_loss: 2.6763 - val_mae: 1.4745\n",
      "Epoch 2316/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.2023 - val_loss: 2.7559 - val_mae: 1.5012\n",
      "Epoch 2317/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0536 - mae: 0.1901 - val_loss: 2.8411 - val_mae: 1.5294\n",
      "Epoch 2318/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1874 - val_loss: 2.9178 - val_mae: 1.5543\n",
      "Epoch 2319/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.1943 - val_loss: 2.9273 - val_mae: 1.5574\n",
      "Epoch 2320/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.1986 - val_loss: 2.9038 - val_mae: 1.5498\n",
      "Epoch 2321/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1970 - val_loss: 2.8626 - val_mae: 1.5364\n",
      "Epoch 2322/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1931 - val_loss: 2.7665 - val_mae: 1.5048\n",
      "Epoch 2323/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1905 - val_loss: 2.6846 - val_mae: 1.4773\n",
      "Epoch 2324/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0541 - mae: 0.1924 - val_loss: 2.6913 - val_mae: 1.4794\n",
      "Epoch 2325/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0539 - mae: 0.1871 - val_loss: 2.6988 - val_mae: 1.4819\n",
      "Epoch 2326/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0546 - mae: 0.1822 - val_loss: 2.6686 - val_mae: 1.4716\n",
      "Epoch 2327/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1825 - val_loss: 2.6766 - val_mae: 1.4743\n",
      "Epoch 2328/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0617 - mae: 0.1884 - val_loss: 2.6845 - val_mae: 1.4770\n",
      "Epoch 2329/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0658 - mae: 0.1974 - val_loss: 2.6166 - val_mae: 1.4538\n",
      "Epoch 2330/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.1927 - val_loss: 2.5390 - val_mae: 1.4268\n",
      "Epoch 2331/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1861 - val_loss: 2.4927 - val_mae: 1.4105\n",
      "Epoch 2332/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0586 - mae: 0.1908 - val_loss: 2.4346 - val_mae: 1.3897\n",
      "Epoch 2333/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1978 - val_loss: 2.4418 - val_mae: 1.3923\n",
      "Epoch 2334/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.1949 - val_loss: 2.5216 - val_mae: 1.4206\n",
      "Epoch 2335/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1857 - val_loss: 2.6260 - val_mae: 1.4569\n",
      "Epoch 2336/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0576 - mae: 0.1851 - val_loss: 2.6856 - val_mae: 1.4772\n",
      "Epoch 2337/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0592 - mae: 0.1890 - val_loss: 2.6989 - val_mae: 1.4816\n",
      "Epoch 2338/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1867 - val_loss: 2.7082 - val_mae: 1.4847\n",
      "Epoch 2339/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1838 - val_loss: 2.7302 - val_mae: 1.4921\n",
      "Epoch 2340/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1810 - val_loss: 2.7624 - val_mae: 1.5028\n",
      "Epoch 2341/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0526 - mae: 0.1793 - val_loss: 2.7228 - val_mae: 1.4895\n",
      "Epoch 2342/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0526 - mae: 0.1885 - val_loss: 2.6425 - val_mae: 1.4622\n",
      "Epoch 2343/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0700 - mae: 0.2221 - val_loss: 2.6018 - val_mae: 1.4481\n",
      "Epoch 2344/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0900 - mae: 0.2517 - val_loss: 2.7400 - val_mae: 1.4951\n",
      "Epoch 2345/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0638 - mae: 0.2096 - val_loss: 3.0066 - val_mae: 1.5819\n",
      "Epoch 2346/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1893 - val_loss: 3.1369 - val_mae: 1.6227\n",
      "Epoch 2347/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0820 - mae: 0.2272 - val_loss: 3.0618 - val_mae: 1.5994\n",
      "Epoch 2348/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0762 - mae: 0.2145 - val_loss: 2.8312 - val_mae: 1.5255\n",
      "Epoch 2349/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0603 - mae: 0.1890 - val_loss: 2.6184 - val_mae: 1.4540\n",
      "Epoch 2350/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1886 - val_loss: 2.4993 - val_mae: 1.4124\n",
      "Epoch 2351/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.2073 - val_loss: 2.5102 - val_mae: 1.4162\n",
      "Epoch 2352/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0620 - mae: 0.2027 - val_loss: 2.6214 - val_mae: 1.4550\n",
      "Epoch 2353/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1870 - val_loss: 2.7331 - val_mae: 1.4929\n",
      "Epoch 2354/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0568 - mae: 0.1810 - val_loss: 2.8360 - val_mae: 1.5270\n",
      "Epoch 2355/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1805 - val_loss: 2.9038 - val_mae: 1.5489\n",
      "Epoch 2356/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1805 - val_loss: 2.9600 - val_mae: 1.5670\n",
      "Epoch 2357/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1860 - val_loss: 2.9766 - val_mae: 1.5722\n",
      "Epoch 2358/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.1930 - val_loss: 2.9825 - val_mae: 1.5741\n",
      "Epoch 2359/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0565 - mae: 0.1911 - val_loss: 2.9874 - val_mae: 1.5757\n",
      "Epoch 2360/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1868 - val_loss: 2.9155 - val_mae: 1.5527\n",
      "Epoch 2361/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0535 - mae: 0.1842 - val_loss: 2.8437 - val_mae: 1.5294\n",
      "Epoch 2362/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0529 - mae: 0.1803 - val_loss: 2.7944 - val_mae: 1.5133\n",
      "Epoch 2363/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0552 - mae: 0.1812 - val_loss: 2.7197 - val_mae: 1.4884\n",
      "Epoch 2364/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1839 - val_loss: 2.6320 - val_mae: 1.4587\n",
      "Epoch 2365/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0595 - mae: 0.1849 - val_loss: 2.5330 - val_mae: 1.4243\n",
      "Epoch 2366/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1841 - val_loss: 2.4442 - val_mae: 1.3928\n",
      "Epoch 2367/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0591 - mae: 0.1894 - val_loss: 2.3957 - val_mae: 1.3752\n",
      "Epoch 2368/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0613 - mae: 0.1967 - val_loss: 2.3649 - val_mae: 1.3639\n",
      "Epoch 2369/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0654 - mae: 0.2093 - val_loss: 2.3992 - val_mae: 1.3764\n",
      "Epoch 2370/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.2078 - val_loss: 2.5074 - val_mae: 1.4152\n",
      "Epoch 2371/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1911 - val_loss: 2.6308 - val_mae: 1.4581\n",
      "Epoch 2372/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1824 - val_loss: 2.7279 - val_mae: 1.4911\n",
      "Epoch 2373/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1905 - val_loss: 2.7887 - val_mae: 1.5113\n",
      "Epoch 2374/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0617 - mae: 0.1976 - val_loss: 2.8141 - val_mae: 1.5197\n",
      "Epoch 2375/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0613 - mae: 0.1974 - val_loss: 2.7636 - val_mae: 1.5029\n",
      "Epoch 2376/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0569 - mae: 0.1943 - val_loss: 2.7422 - val_mae: 1.4957\n",
      "Epoch 2377/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1933 - val_loss: 2.8814 - val_mae: 1.5416\n",
      "Epoch 2378/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1943 - val_loss: 3.0528 - val_mae: 1.5962\n",
      "Epoch 2379/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0602 - mae: 0.1947 - val_loss: 3.1170 - val_mae: 1.6162\n",
      "Epoch 2380/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0619 - mae: 0.1936 - val_loss: 3.0746 - val_mae: 1.6031\n",
      "Epoch 2381/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1854 - val_loss: 2.9074 - val_mae: 1.5500\n",
      "Epoch 2382/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1836 - val_loss: 2.7058 - val_mae: 1.4836\n",
      "Epoch 2383/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0578 - mae: 0.2024 - val_loss: 2.6021 - val_mae: 1.4482\n",
      "Epoch 2384/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0670 - mae: 0.2231 - val_loss: 2.6589 - val_mae: 1.4677\n",
      "Epoch 2385/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0627 - mae: 0.2142 - val_loss: 2.8247 - val_mae: 1.5232\n",
      "Epoch 2386/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0539 - mae: 0.1890 - val_loss: 2.9641 - val_mae: 1.5683\n",
      "Epoch 2387/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1788 - val_loss: 3.0504 - val_mae: 1.5956\n",
      "Epoch 2388/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0608 - mae: 0.1826 - val_loss: 3.1301 - val_mae: 1.6204\n",
      "Epoch 2389/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0675 - mae: 0.1949 - val_loss: 3.0925 - val_mae: 1.6088\n",
      "Epoch 2390/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1807 - val_loss: 2.9466 - val_mae: 1.5627\n",
      "Epoch 2391/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1872 - val_loss: 2.8735 - val_mae: 1.5392\n",
      "Epoch 2392/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0563 - mae: 0.1962 - val_loss: 2.8276 - val_mae: 1.5242\n",
      "Epoch 2393/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0583 - mae: 0.2033 - val_loss: 2.8218 - val_mae: 1.5224\n",
      "Epoch 2394/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0561 - mae: 0.2000 - val_loss: 2.8933 - val_mae: 1.5457\n",
      "Epoch 2395/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1814 - val_loss: 2.9672 - val_mae: 1.5695\n",
      "Epoch 2396/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1812 - val_loss: 2.9930 - val_mae: 1.5777\n",
      "Epoch 2397/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0626 - mae: 0.1899 - val_loss: 2.9430 - val_mae: 1.5619\n",
      "Epoch 2398/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.1879 - val_loss: 2.7757 - val_mae: 1.5074\n",
      "Epoch 2399/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1788 - val_loss: 2.5616 - val_mae: 1.4346\n",
      "Epoch 2400/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0614 - mae: 0.2087 - val_loss: 2.4611 - val_mae: 1.3991\n",
      "Epoch 2401/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0714 - mae: 0.2275 - val_loss: 2.5134 - val_mae: 1.4177\n",
      "Epoch 2402/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0641 - mae: 0.2143 - val_loss: 2.6332 - val_mae: 1.4594\n",
      "Epoch 2403/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1904 - val_loss: 2.7376 - val_mae: 1.4948\n",
      "Epoch 2404/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1819 - val_loss: 2.8167 - val_mae: 1.5211\n",
      "Epoch 2405/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0590 - mae: 0.1912 - val_loss: 2.8432 - val_mae: 1.5297\n",
      "Epoch 2406/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.1932 - val_loss: 2.7479 - val_mae: 1.4982\n",
      "Epoch 2407/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1865 - val_loss: 2.6362 - val_mae: 1.4605\n",
      "Epoch 2408/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0550 - mae: 0.1933 - val_loss: 2.6404 - val_mae: 1.4620\n",
      "Epoch 2409/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1890 - val_loss: 2.6842 - val_mae: 1.4769\n",
      "Epoch 2410/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1831 - val_loss: 2.6749 - val_mae: 1.4737\n",
      "Epoch 2411/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0553 - mae: 0.1844 - val_loss: 2.6729 - val_mae: 1.4730\n",
      "Epoch 2412/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1829 - val_loss: 2.7278 - val_mae: 1.4914\n",
      "Epoch 2413/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0559 - mae: 0.1828 - val_loss: 2.8079 - val_mae: 1.5180\n",
      "Epoch 2414/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1843 - val_loss: 2.8068 - val_mae: 1.5175\n",
      "Epoch 2415/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1803 - val_loss: 2.6985 - val_mae: 1.4813\n",
      "Epoch 2416/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1952 - val_loss: 2.6318 - val_mae: 1.4586\n",
      "Epoch 2417/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2096 - val_loss: 2.6515 - val_mae: 1.4654\n",
      "Epoch 2418/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0601 - mae: 0.2070 - val_loss: 2.7615 - val_mae: 1.5025\n",
      "Epoch 2419/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0532 - mae: 0.1872 - val_loss: 2.9301 - val_mae: 1.5576\n",
      "Epoch 2420/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0588 - mae: 0.1964 - val_loss: 3.0609 - val_mae: 1.5991\n",
      "Epoch 2421/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0803 - mae: 0.2266 - val_loss: 3.1216 - val_mae: 1.6180\n",
      "Epoch 2422/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0910 - mae: 0.2432 - val_loss: 3.0504 - val_mae: 1.5958\n",
      "Epoch 2423/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0709 - mae: 0.2072 - val_loss: 2.8282 - val_mae: 1.5246\n",
      "Epoch 2424/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1933 - val_loss: 2.6190 - val_mae: 1.4543\n",
      "Epoch 2425/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0694 - mae: 0.2204 - val_loss: 2.5422 - val_mae: 1.4276\n",
      "Epoch 2426/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0796 - mae: 0.2347 - val_loss: 2.6186 - val_mae: 1.4542\n",
      "Epoch 2427/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.2140 - val_loss: 2.7991 - val_mae: 1.5150\n",
      "Epoch 2428/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0512 - mae: 0.1826 - val_loss: 2.9775 - val_mae: 1.5728\n",
      "Epoch 2429/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.1916 - val_loss: 2.9867 - val_mae: 1.5758\n",
      "Epoch 2430/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1927 - val_loss: 2.8147 - val_mae: 1.5202\n",
      "Epoch 2431/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1851 - val_loss: 2.6587 - val_mae: 1.4680\n",
      "Epoch 2432/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.2034 - val_loss: 2.6176 - val_mae: 1.4539\n",
      "Epoch 2433/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.2052 - val_loss: 2.6311 - val_mae: 1.4586\n",
      "Epoch 2434/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0545 - mae: 0.1938 - val_loss: 2.6607 - val_mae: 1.4687\n",
      "Epoch 2435/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0532 - mae: 0.1889 - val_loss: 2.7246 - val_mae: 1.4903\n",
      "Epoch 2436/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1886 - val_loss: 2.7712 - val_mae: 1.5059\n",
      "Epoch 2437/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1918 - val_loss: 2.8001 - val_mae: 1.5154\n",
      "Epoch 2438/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0555 - mae: 0.1964 - val_loss: 2.7947 - val_mae: 1.5137\n",
      "Epoch 2439/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0592 - mae: 0.2009 - val_loss: 2.8144 - val_mae: 1.5201\n",
      "Epoch 2440/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1968 - val_loss: 2.9249 - val_mae: 1.5561\n",
      "Epoch 2441/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1957 - val_loss: 2.9682 - val_mae: 1.5699\n",
      "Epoch 2442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1922 - val_loss: 2.8988 - val_mae: 1.5476\n",
      "Epoch 2443/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1810 - val_loss: 2.7952 - val_mae: 1.5137\n",
      "Epoch 2444/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1815 - val_loss: 2.6654 - val_mae: 1.4702\n",
      "Epoch 2445/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.2020 - val_loss: 2.6184 - val_mae: 1.4540\n",
      "Epoch 2446/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2102 - val_loss: 2.6664 - val_mae: 1.4705\n",
      "Epoch 2447/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1934 - val_loss: 2.7180 - val_mae: 1.4879\n",
      "Epoch 2448/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1802 - val_loss: 2.7212 - val_mae: 1.4891\n",
      "Epoch 2449/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1820 - val_loss: 2.7158 - val_mae: 1.4872\n",
      "Epoch 2450/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1834 - val_loss: 2.7228 - val_mae: 1.4896\n",
      "Epoch 2451/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0611 - mae: 0.1878 - val_loss: 2.7085 - val_mae: 1.4848\n",
      "Epoch 2452/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0600 - mae: 0.1876 - val_loss: 2.6473 - val_mae: 1.4640\n",
      "Epoch 2453/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1839 - val_loss: 2.5765 - val_mae: 1.4396\n",
      "Epoch 2454/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1849 - val_loss: 2.5878 - val_mae: 1.4435\n",
      "Epoch 2455/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1882 - val_loss: 2.6647 - val_mae: 1.4698\n",
      "Epoch 2456/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1869 - val_loss: 2.7489 - val_mae: 1.4982\n",
      "Epoch 2457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1840 - val_loss: 2.8141 - val_mae: 1.5197\n",
      "Epoch 2458/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1824 - val_loss: 2.8128 - val_mae: 1.5193\n",
      "Epoch 2459/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0519 - mae: 0.1850 - val_loss: 2.7837 - val_mae: 1.5096\n",
      "Epoch 2460/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1890 - val_loss: 2.8233 - val_mae: 1.5227\n",
      "Epoch 2461/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0526 - mae: 0.1863 - val_loss: 2.9636 - val_mae: 1.5681\n",
      "Epoch 2462/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1797 - val_loss: 3.0735 - val_mae: 1.6027\n",
      "Epoch 2463/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0620 - mae: 0.1855 - val_loss: 3.0714 - val_mae: 1.6021\n",
      "Epoch 2464/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.1860 - val_loss: 3.0880 - val_mae: 1.6072\n",
      "Epoch 2465/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0605 - mae: 0.1813 - val_loss: 3.0786 - val_mae: 1.6043\n",
      "Epoch 2466/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1786 - val_loss: 2.9449 - val_mae: 1.5621\n",
      "Epoch 2467/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0539 - mae: 0.1896 - val_loss: 2.7669 - val_mae: 1.5040\n",
      "Epoch 2468/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0660 - mae: 0.2199 - val_loss: 2.6943 - val_mae: 1.4797\n",
      "Epoch 2469/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0659 - mae: 0.2197 - val_loss: 2.7791 - val_mae: 1.5081\n",
      "Epoch 2470/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1893 - val_loss: 2.8903 - val_mae: 1.5446\n",
      "Epoch 2471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1787 - val_loss: 2.9302 - val_mae: 1.5575\n",
      "Epoch 2472/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0654 - mae: 0.1978 - val_loss: 2.8416 - val_mae: 1.5289\n",
      "Epoch 2473/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0621 - mae: 0.1931 - val_loss: 2.6960 - val_mae: 1.4805\n",
      "Epoch 2474/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1780 - val_loss: 2.5798 - val_mae: 1.4407\n",
      "Epoch 2475/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1909 - val_loss: 2.4907 - val_mae: 1.4094\n",
      "Epoch 2476/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0628 - mae: 0.2108 - val_loss: 2.5070 - val_mae: 1.4152\n",
      "Epoch 2477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.2055 - val_loss: 2.6041 - val_mae: 1.4492\n",
      "Epoch 2478/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0531 - mae: 0.1856 - val_loss: 2.6997 - val_mae: 1.4819\n",
      "Epoch 2479/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1925 - val_loss: 2.7174 - val_mae: 1.4879\n",
      "Epoch 2480/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0605 - mae: 0.1962 - val_loss: 2.6325 - val_mae: 1.4590\n",
      "Epoch 2481/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1858 - val_loss: 2.5121 - val_mae: 1.4171\n",
      "Epoch 2482/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0554 - mae: 0.1901 - val_loss: 2.4110 - val_mae: 1.3810\n",
      "Epoch 2483/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0629 - mae: 0.2076 - val_loss: 2.3914 - val_mae: 1.3738\n",
      "Epoch 2484/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0656 - mae: 0.2125 - val_loss: 2.4572 - val_mae: 1.3976\n",
      "Epoch 2485/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0595 - mae: 0.2015 - val_loss: 2.6032 - val_mae: 1.4489\n",
      "Epoch 2486/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0543 - mae: 0.1843 - val_loss: 2.7585 - val_mae: 1.5015\n",
      "Epoch 2487/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1779 - val_loss: 2.9048 - val_mae: 1.5495\n",
      "Epoch 2488/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0617 - mae: 0.1893 - val_loss: 2.9778 - val_mae: 1.5729\n",
      "Epoch 2489/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0610 - mae: 0.1855 - val_loss: 2.8799 - val_mae: 1.5414\n",
      "Epoch 2490/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0541 - mae: 0.1811 - val_loss: 2.7909 - val_mae: 1.5122\n",
      "Epoch 2491/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0524 - mae: 0.1875 - val_loss: 2.7672 - val_mae: 1.5044\n",
      "Epoch 2492/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0530 - mae: 0.1898 - val_loss: 2.8114 - val_mae: 1.5190\n",
      "Epoch 2493/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0512 - mae: 0.1827 - val_loss: 2.9577 - val_mae: 1.5665\n",
      "Epoch 2494/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0542 - mae: 0.1777 - val_loss: 3.0448 - val_mae: 1.5941\n",
      "Epoch 2495/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0575 - mae: 0.1788 - val_loss: 2.9585 - val_mae: 1.5668\n",
      "Epoch 2496/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0537 - mae: 0.1792 - val_loss: 2.8216 - val_mae: 1.5224\n",
      "Epoch 2497/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0523 - mae: 0.1859 - val_loss: 2.7742 - val_mae: 1.5068\n",
      "Epoch 2498/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0521 - mae: 0.1857 - val_loss: 2.8105 - val_mae: 1.5188\n",
      "Epoch 2499/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0516 - mae: 0.1801 - val_loss: 2.9037 - val_mae: 1.5492\n",
      "Epoch 2500/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0548 - mae: 0.1768 - val_loss: 2.9933 - val_mae: 1.5778\n",
      "Epoch 2501/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0604 - mae: 0.1838 - val_loss: 2.9627 - val_mae: 1.5681\n",
      "Epoch 2502/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0550 - mae: 0.1789 - val_loss: 2.8792 - val_mae: 1.5412\n",
      "Epoch 2503/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0532 - mae: 0.1889 - val_loss: 2.8260 - val_mae: 1.5239\n",
      "Epoch 2504/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0602 - mae: 0.2041 - val_loss: 2.8222 - val_mae: 1.5226\n",
      "Epoch 2505/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0613 - mae: 0.2049 - val_loss: 2.9179 - val_mae: 1.5537\n",
      "Epoch 2506/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0565 - mae: 0.1936 - val_loss: 2.9710 - val_mae: 1.5707\n",
      "Epoch 2507/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0538 - mae: 0.1837 - val_loss: 2.8505 - val_mae: 1.5318\n",
      "Epoch 2508/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0519 - mae: 0.1844 - val_loss: 2.6990 - val_mae: 1.4815\n",
      "Epoch 2509/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0542 - mae: 0.1948 - val_loss: 2.6121 - val_mae: 1.4518\n",
      "Epoch 2510/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0569 - mae: 0.2009 - val_loss: 2.5985 - val_mae: 1.4471\n",
      "Epoch 2511/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0563 - mae: 0.1949 - val_loss: 2.6457 - val_mae: 1.4633\n",
      "Epoch 2512/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0536 - mae: 0.1828 - val_loss: 2.6957 - val_mae: 1.4803\n",
      "Epoch 2513/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0528 - mae: 0.1776 - val_loss: 2.7532 - val_mae: 1.4996\n",
      "Epoch 2514/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0533 - mae: 0.1756 - val_loss: 2.8099 - val_mae: 1.5184\n",
      "Epoch 2515/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0540 - mae: 0.1750 - val_loss: 2.8467 - val_mae: 1.5305\n",
      "Epoch 2516/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0541 - mae: 0.1757 - val_loss: 2.8350 - val_mae: 1.5267\n",
      "Epoch 2517/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0527 - mae: 0.1758 - val_loss: 2.7508 - val_mae: 1.4988\n",
      "Epoch 2518/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0516 - mae: 0.1796 - val_loss: 2.6774 - val_mae: 1.4742\n",
      "Epoch 2519/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1832 - val_loss: 2.6677 - val_mae: 1.4709\n",
      "Epoch 2520/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1858 - val_loss: 2.6768 - val_mae: 1.4740\n",
      "Epoch 2521/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1878 - val_loss: 2.7204 - val_mae: 1.4887\n",
      "Epoch 2522/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1884 - val_loss: 2.7564 - val_mae: 1.5008\n",
      "Epoch 2523/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1854 - val_loss: 2.7359 - val_mae: 1.4939\n",
      "Epoch 2524/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0513 - mae: 0.1812 - val_loss: 2.6741 - val_mae: 1.4730\n",
      "Epoch 2525/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1855 - val_loss: 2.5890 - val_mae: 1.4438\n",
      "Epoch 2526/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1948 - val_loss: 2.5533 - val_mae: 1.4315\n",
      "Epoch 2527/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1900 - val_loss: 2.5887 - val_mae: 1.4438\n",
      "Epoch 2528/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1820 - val_loss: 2.6773 - val_mae: 1.4742\n",
      "Epoch 2529/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1830 - val_loss: 2.7162 - val_mae: 1.4874\n",
      "Epoch 2530/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1843 - val_loss: 2.6203 - val_mae: 1.4548\n",
      "Epoch 2531/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1847 - val_loss: 2.5094 - val_mae: 1.4162\n",
      "Epoch 2532/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1989 - val_loss: 2.4367 - val_mae: 1.3903\n",
      "Epoch 2533/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0646 - mae: 0.2126 - val_loss: 2.4112 - val_mae: 1.3811\n",
      "Epoch 2534/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0669 - mae: 0.2160 - val_loss: 2.4726 - val_mae: 1.4031\n",
      "Epoch 2535/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.2026 - val_loss: 2.5414 - val_mae: 1.4275\n",
      "Epoch 2536/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1864 - val_loss: 2.5728 - val_mae: 1.4385\n",
      "Epoch 2537/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1839 - val_loss: 2.5973 - val_mae: 1.4469\n",
      "Epoch 2538/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1849 - val_loss: 2.6697 - val_mae: 1.4718\n",
      "Epoch 2539/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1828 - val_loss: 2.7383 - val_mae: 1.4949\n",
      "Epoch 2540/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0524 - mae: 0.1797 - val_loss: 2.7396 - val_mae: 1.4953\n",
      "Epoch 2541/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0517 - mae: 0.1800 - val_loss: 2.7289 - val_mae: 1.4917\n",
      "Epoch 2542/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1798 - val_loss: 2.7180 - val_mae: 1.4880\n",
      "Epoch 2543/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1823 - val_loss: 2.6893 - val_mae: 1.4783\n",
      "Epoch 2544/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1895 - val_loss: 2.6586 - val_mae: 1.4678\n",
      "Epoch 2545/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1958 - val_loss: 2.7071 - val_mae: 1.4842\n",
      "Epoch 2546/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1861 - val_loss: 2.8042 - val_mae: 1.5166\n",
      "Epoch 2547/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1788 - val_loss: 2.8551 - val_mae: 1.5333\n",
      "Epoch 2548/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1789 - val_loss: 2.8757 - val_mae: 1.5400\n",
      "Epoch 2549/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0548 - mae: 0.1775 - val_loss: 2.8435 - val_mae: 1.5295\n",
      "Epoch 2550/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1750 - val_loss: 2.8141 - val_mae: 1.5198\n",
      "Epoch 2551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1762 - val_loss: 2.8297 - val_mae: 1.5249\n",
      "Epoch 2552/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1772 - val_loss: 2.9106 - val_mae: 1.5512\n",
      "Epoch 2553/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1753 - val_loss: 3.0930 - val_mae: 1.6089\n",
      "Epoch 2554/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0598 - mae: 0.1831 - val_loss: 3.2355 - val_mae: 1.6527\n",
      "Epoch 2555/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0674 - mae: 0.1947 - val_loss: 3.1300 - val_mae: 1.6204\n",
      "Epoch 2556/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0581 - mae: 0.1845 - val_loss: 2.9379 - val_mae: 1.5599\n",
      "Epoch 2557/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1909 - val_loss: 2.8244 - val_mae: 1.5231\n",
      "Epoch 2558/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.2064 - val_loss: 2.7922 - val_mae: 1.5125\n",
      "Epoch 2559/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0616 - mae: 0.2079 - val_loss: 2.8164 - val_mae: 1.5205\n",
      "Epoch 2560/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1953 - val_loss: 2.8722 - val_mae: 1.5388\n",
      "Epoch 2561/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0524 - mae: 0.1876 - val_loss: 2.9189 - val_mae: 1.5540\n",
      "Epoch 2562/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1866 - val_loss: 2.8267 - val_mae: 1.5240\n",
      "Epoch 2563/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1807 - val_loss: 2.6848 - val_mae: 1.4767\n",
      "Epoch 2564/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0518 - mae: 0.1824 - val_loss: 2.5791 - val_mae: 1.4404\n",
      "Epoch 2565/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0573 - mae: 0.1994 - val_loss: 2.5541 - val_mae: 1.4317\n",
      "Epoch 2566/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1976 - val_loss: 2.6184 - val_mae: 1.4540\n",
      "Epoch 2567/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1860 - val_loss: 2.6985 - val_mae: 1.4813\n",
      "Epoch 2568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1785 - val_loss: 2.7932 - val_mae: 1.5129\n",
      "Epoch 2569/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1760 - val_loss: 2.8931 - val_mae: 1.5455\n",
      "Epoch 2570/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1819 - val_loss: 2.9735 - val_mae: 1.5713\n",
      "Epoch 2571/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1866 - val_loss: 2.9737 - val_mae: 1.5712\n",
      "Epoch 2572/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0537 - mae: 0.1854 - val_loss: 2.9480 - val_mae: 1.5630\n",
      "Epoch 2573/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1857 - val_loss: 2.9780 - val_mae: 1.5725\n",
      "Epoch 2574/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1862 - val_loss: 3.0152 - val_mae: 1.5842\n",
      "Epoch 2575/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1843 - val_loss: 3.0416 - val_mae: 1.5925\n",
      "Epoch 2576/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1815 - val_loss: 3.0430 - val_mae: 1.5929\n",
      "Epoch 2577/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0529 - mae: 0.1789 - val_loss: 2.9972 - val_mae: 1.5784\n",
      "Epoch 2578/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1798 - val_loss: 2.9614 - val_mae: 1.5670\n",
      "Epoch 2579/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0512 - mae: 0.1775 - val_loss: 3.0267 - val_mae: 1.5877\n",
      "Epoch 2580/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1754 - val_loss: 3.0274 - val_mae: 1.5879\n",
      "Epoch 2581/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.1802 - val_loss: 2.8591 - val_mae: 1.5339\n",
      "Epoch 2582/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1825 - val_loss: 2.6737 - val_mae: 1.4722\n",
      "Epoch 2583/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0668 - mae: 0.2184 - val_loss: 2.6112 - val_mae: 1.4509\n",
      "Epoch 2584/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0696 - mae: 0.2202 - val_loss: 2.7627 - val_mae: 1.5023\n",
      "Epoch 2585/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1841 - val_loss: 3.0611 - val_mae: 1.5987\n",
      "Epoch 2586/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0720 - mae: 0.2133 - val_loss: 3.2350 - val_mae: 1.6522\n",
      "Epoch 2587/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0934 - mae: 0.2477 - val_loss: 3.1766 - val_mae: 1.6345\n",
      "Epoch 2588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2067 - val_loss: 2.9791 - val_mae: 1.5730\n",
      "Epoch 2589/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1772 - val_loss: 2.7612 - val_mae: 1.5025\n",
      "Epoch 2590/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2184 - val_loss: 2.6560 - val_mae: 1.4675\n",
      "Epoch 2591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0893 - mae: 0.2560 - val_loss: 2.7451 - val_mae: 1.4975\n",
      "Epoch 2592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0703 - mae: 0.2260 - val_loss: 2.9748 - val_mae: 1.5722\n",
      "Epoch 2593/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0551 - mae: 0.1898 - val_loss: 3.0929 - val_mae: 1.6094\n",
      "Epoch 2594/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1947 - val_loss: 3.0289 - val_mae: 1.5896\n",
      "Epoch 2595/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1997 - val_loss: 2.9071 - val_mae: 1.5506\n",
      "Epoch 2596/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2023 - val_loss: 2.7655 - val_mae: 1.5040\n",
      "Epoch 2597/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.2046 - val_loss: 2.6052 - val_mae: 1.4495\n",
      "Epoch 2598/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0725 - mae: 0.2218 - val_loss: 2.5802 - val_mae: 1.4406\n",
      "Epoch 2599/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.2047 - val_loss: 2.6689 - val_mae: 1.4711\n",
      "Epoch 2600/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1775 - val_loss: 2.7396 - val_mae: 1.4950\n",
      "Epoch 2601/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0684 - mae: 0.2009 - val_loss: 2.7254 - val_mae: 1.4903\n",
      "Epoch 2602/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0664 - mae: 0.1981 - val_loss: 2.6136 - val_mae: 1.4522\n",
      "Epoch 2603/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1864 - val_loss: 2.6097 - val_mae: 1.4508\n",
      "Epoch 2604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1854 - val_loss: 2.6879 - val_mae: 1.4775\n",
      "Epoch 2605/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1847 - val_loss: 2.7851 - val_mae: 1.5101\n",
      "Epoch 2606/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1765 - val_loss: 2.9546 - val_mae: 1.5652\n",
      "Epoch 2607/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1739 - val_loss: 3.1229 - val_mae: 1.6182\n",
      "Epoch 2608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0692 - mae: 0.2012 - val_loss: 3.1567 - val_mae: 1.6286\n",
      "Epoch 2609/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0669 - mae: 0.2013 - val_loss: 3.0649 - val_mae: 1.6001\n",
      "Epoch 2610/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1957 - val_loss: 3.0104 - val_mae: 1.5830\n",
      "Epoch 2611/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1987 - val_loss: 2.9962 - val_mae: 1.5784\n",
      "Epoch 2612/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0605 - mae: 0.2029 - val_loss: 2.9734 - val_mae: 1.5712\n",
      "Epoch 2613/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0561 - mae: 0.1967 - val_loss: 2.8969 - val_mae: 1.5466\n",
      "Epoch 2614/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1881 - val_loss: 2.7085 - val_mae: 1.4843\n",
      "Epoch 2615/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0528 - mae: 0.1910 - val_loss: 2.5705 - val_mae: 1.4370\n",
      "Epoch 2616/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1984 - val_loss: 2.5918 - val_mae: 1.4444\n",
      "Epoch 2617/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0525 - mae: 0.1850 - val_loss: 2.7114 - val_mae: 1.4852\n",
      "Epoch 2618/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1842 - val_loss: 2.7880 - val_mae: 1.5108\n",
      "Epoch 2619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1919 - val_loss: 2.8139 - val_mae: 1.5193\n",
      "Epoch 2620/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.1902 - val_loss: 2.8517 - val_mae: 1.5317\n",
      "Epoch 2621/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.1853 - val_loss: 2.8583 - val_mae: 1.5338\n",
      "Epoch 2622/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1770 - val_loss: 2.8756 - val_mae: 1.5394\n",
      "Epoch 2623/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1758 - val_loss: 2.8558 - val_mae: 1.5329\n",
      "Epoch 2624/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0513 - mae: 0.1833 - val_loss: 2.8211 - val_mae: 1.5216\n",
      "Epoch 2625/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1926 - val_loss: 2.9040 - val_mae: 1.5486\n",
      "Epoch 2626/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1888 - val_loss: 3.0281 - val_mae: 1.5882\n",
      "Epoch 2627/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1821 - val_loss: 3.0258 - val_mae: 1.5875\n",
      "Epoch 2628/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0525 - mae: 0.1804 - val_loss: 2.9137 - val_mae: 1.5517\n",
      "Epoch 2629/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0518 - mae: 0.1847 - val_loss: 2.8019 - val_mae: 1.5152\n",
      "Epoch 2630/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1904 - val_loss: 2.6946 - val_mae: 1.4794\n",
      "Epoch 2631/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1965 - val_loss: 2.6626 - val_mae: 1.4686\n",
      "Epoch 2632/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1910 - val_loss: 2.6877 - val_mae: 1.4771\n",
      "Epoch 2633/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1817 - val_loss: 2.7550 - val_mae: 1.4997\n",
      "Epoch 2634/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1764 - val_loss: 2.9010 - val_mae: 1.5477\n",
      "Epoch 2635/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0637 - mae: 0.1945 - val_loss: 2.9311 - val_mae: 1.5575\n",
      "Epoch 2636/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0634 - mae: 0.1966 - val_loss: 2.8494 - val_mae: 1.5311\n",
      "Epoch 2637/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1804 - val_loss: 2.7817 - val_mae: 1.5091\n",
      "Epoch 2638/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0511 - mae: 0.1873 - val_loss: 2.7749 - val_mae: 1.5071\n",
      "Epoch 2639/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1935 - val_loss: 2.8695 - val_mae: 1.5383\n",
      "Epoch 2640/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1908 - val_loss: 2.9892 - val_mae: 1.5768\n",
      "Epoch 2641/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1837 - val_loss: 3.0494 - val_mae: 1.5957\n",
      "Epoch 2642/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1817 - val_loss: 3.0037 - val_mae: 1.5815\n",
      "Epoch 2643/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1822 - val_loss: 2.9177 - val_mae: 1.5542\n",
      "Epoch 2644/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1973 - val_loss: 2.8948 - val_mae: 1.5467\n",
      "Epoch 2645/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.2039 - val_loss: 2.9273 - val_mae: 1.5569\n",
      "Epoch 2646/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1957 - val_loss: 3.0385 - val_mae: 1.5919\n",
      "Epoch 2647/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1814 - val_loss: 3.0897 - val_mae: 1.6076\n",
      "Epoch 2648/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0568 - mae: 0.1819 - val_loss: 2.9573 - val_mae: 1.5657\n",
      "Epoch 2649/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1810 - val_loss: 2.7877 - val_mae: 1.5104\n",
      "Epoch 2650/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0519 - mae: 0.1882 - val_loss: 2.6778 - val_mae: 1.4735\n",
      "Epoch 2651/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0573 - mae: 0.2021 - val_loss: 2.6814 - val_mae: 1.4747\n",
      "Epoch 2652/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1924 - val_loss: 2.7960 - val_mae: 1.5131\n",
      "Epoch 2653/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1801 - val_loss: 2.8524 - val_mae: 1.5317\n",
      "Epoch 2654/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1799 - val_loss: 2.8226 - val_mae: 1.5219\n",
      "Epoch 2655/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1800 - val_loss: 2.7908 - val_mae: 1.5114\n",
      "Epoch 2656/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1789 - val_loss: 2.7772 - val_mae: 1.5069\n",
      "Epoch 2657/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1781 - val_loss: 2.7215 - val_mae: 1.4883\n",
      "Epoch 2658/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1830 - val_loss: 2.7481 - val_mae: 1.4972\n",
      "Epoch 2659/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1830 - val_loss: 2.8914 - val_mae: 1.5443\n",
      "Epoch 2660/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1824 - val_loss: 2.9920 - val_mae: 1.5766\n",
      "Epoch 2661/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0527 - mae: 0.1827 - val_loss: 2.9977 - val_mae: 1.5784\n",
      "Epoch 2662/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1826 - val_loss: 2.9546 - val_mae: 1.5647\n",
      "Epoch 2663/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1814 - val_loss: 2.9629 - val_mae: 1.5674\n",
      "Epoch 2664/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1784 - val_loss: 2.9709 - val_mae: 1.5699\n",
      "Epoch 2665/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1771 - val_loss: 2.9560 - val_mae: 1.5652\n",
      "Epoch 2666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1782 - val_loss: 2.9421 - val_mae: 1.5608\n",
      "Epoch 2667/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1776 - val_loss: 2.8837 - val_mae: 1.5420\n",
      "Epoch 2668/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1726 - val_loss: 2.8311 - val_mae: 1.5248\n",
      "Epoch 2669/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0505 - mae: 0.1767 - val_loss: 2.7757 - val_mae: 1.5065\n",
      "Epoch 2670/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.2008 - val_loss: 2.7630 - val_mae: 1.5023\n",
      "Epoch 2671/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0589 - mae: 0.2065 - val_loss: 2.8886 - val_mae: 1.5436\n",
      "Epoch 2672/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0511 - mae: 0.1845 - val_loss: 3.0245 - val_mae: 1.5871\n",
      "Epoch 2673/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0532 - mae: 0.1796 - val_loss: 3.0167 - val_mae: 1.5846\n",
      "Epoch 2674/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0546 - mae: 0.1808 - val_loss: 2.8694 - val_mae: 1.5375\n",
      "Epoch 2675/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489 - mae: 0.1805 - val_loss: 2.6849 - val_mae: 1.4763\n",
      "Epoch 2676/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0599 - mae: 0.2071 - val_loss: 2.6031 - val_mae: 1.4484\n",
      "Epoch 2677/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0653 - mae: 0.2125 - val_loss: 2.6540 - val_mae: 1.4658\n",
      "Epoch 2678/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1985 - val_loss: 2.6704 - val_mae: 1.4713\n",
      "Epoch 2679/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0525 - mae: 0.1924 - val_loss: 2.6306 - val_mae: 1.4577\n",
      "Epoch 2680/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1917 - val_loss: 2.5902 - val_mae: 1.4438\n",
      "Epoch 2681/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1903 - val_loss: 2.5938 - val_mae: 1.4450\n",
      "Epoch 2682/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1854 - val_loss: 2.6251 - val_mae: 1.4557\n",
      "Epoch 2683/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1812 - val_loss: 2.6638 - val_mae: 1.4689\n",
      "Epoch 2684/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1769 - val_loss: 2.7342 - val_mae: 1.4926\n",
      "Epoch 2685/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1763 - val_loss: 2.8109 - val_mae: 1.5180\n",
      "Epoch 2686/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0542 - mae: 0.1773 - val_loss: 2.8832 - val_mae: 1.5416\n",
      "Epoch 2687/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1779 - val_loss: 2.8918 - val_mae: 1.5444\n",
      "Epoch 2688/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0541 - mae: 0.1765 - val_loss: 2.7643 - val_mae: 1.5025\n",
      "Epoch 2689/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0516 - mae: 0.1778 - val_loss: 2.6216 - val_mae: 1.4541\n",
      "Epoch 2690/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1981 - val_loss: 2.5854 - val_mae: 1.4416\n",
      "Epoch 2691/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.2100 - val_loss: 2.6611 - val_mae: 1.4676\n",
      "Epoch 2692/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.2010 - val_loss: 2.8238 - val_mae: 1.5220\n",
      "Epoch 2693/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1850 - val_loss: 2.9996 - val_mae: 1.5787\n",
      "Epoch 2694/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0557 - mae: 0.1909 - val_loss: 3.0498 - val_mae: 1.5946\n",
      "Epoch 2695/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1990 - val_loss: 2.9133 - val_mae: 1.5512\n",
      "Epoch 2696/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0569 - mae: 0.2002 - val_loss: 2.7248 - val_mae: 1.4891\n",
      "Epoch 2697/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1957 - val_loss: 2.5789 - val_mae: 1.4393\n",
      "Epoch 2698/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2014 - val_loss: 2.5249 - val_mae: 1.4204\n",
      "Epoch 2699/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.2001 - val_loss: 2.5302 - val_mae: 1.4223\n",
      "Epoch 2700/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1882 - val_loss: 2.5044 - val_mae: 1.4133\n",
      "Epoch 2701/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0532 - mae: 0.1823 - val_loss: 2.4785 - val_mae: 1.4042\n",
      "Epoch 2702/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1807 - val_loss: 2.4676 - val_mae: 1.4004\n",
      "Epoch 2703/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1815 - val_loss: 2.4739 - val_mae: 1.4026\n",
      "Epoch 2704/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1831 - val_loss: 2.4597 - val_mae: 1.3975\n",
      "Epoch 2705/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1836 - val_loss: 2.4655 - val_mae: 1.3995\n",
      "Epoch 2706/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0559 - mae: 0.1847 - val_loss: 2.5731 - val_mae: 1.4374\n",
      "Epoch 2707/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1811 - val_loss: 2.6910 - val_mae: 1.4779\n",
      "Epoch 2708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1739 - val_loss: 2.8134 - val_mae: 1.5187\n",
      "Epoch 2709/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1758 - val_loss: 2.9014 - val_mae: 1.5474\n",
      "Epoch 2710/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0556 - mae: 0.1815 - val_loss: 2.9481 - val_mae: 1.5624\n",
      "Epoch 2711/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1846 - val_loss: 2.9422 - val_mae: 1.5605\n",
      "Epoch 2712/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1831 - val_loss: 2.8407 - val_mae: 1.5276\n",
      "Epoch 2713/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0534 - mae: 0.1878 - val_loss: 2.7811 - val_mae: 1.5080\n",
      "Epoch 2714/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1992 - val_loss: 2.8397 - val_mae: 1.5274\n",
      "Epoch 2715/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1880 - val_loss: 2.9406 - val_mae: 1.5602\n",
      "Epoch 2716/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0508 - mae: 0.1789 - val_loss: 2.9849 - val_mae: 1.5743\n",
      "Epoch 2717/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1798 - val_loss: 2.9626 - val_mae: 1.5673\n",
      "Epoch 2718/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1807 - val_loss: 2.8111 - val_mae: 1.5181\n",
      "Epoch 2719/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1746 - val_loss: 2.5996 - val_mae: 1.4467\n",
      "Epoch 2720/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0650 - mae: 0.2170 - val_loss: 2.5638 - val_mae: 1.4343\n",
      "Epoch 2721/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - mae: 0.2152 - val_loss: 2.7252 - val_mae: 1.4896\n",
      "Epoch 2722/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0485 - mae: 0.1754 - val_loss: 2.9571 - val_mae: 1.5657\n",
      "Epoch 2723/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0635 - mae: 0.1926 - val_loss: 3.0795 - val_mae: 1.6044\n",
      "Epoch 2724/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0777 - mae: 0.2205 - val_loss: 3.0030 - val_mae: 1.5804\n",
      "Epoch 2725/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0649 - mae: 0.1962 - val_loss: 2.8638 - val_mae: 1.5357\n",
      "Epoch 2726/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1738 - val_loss: 2.7375 - val_mae: 1.4940\n",
      "Epoch 2727/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1898 - val_loss: 2.7034 - val_mae: 1.4826\n",
      "Epoch 2728/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0539 - mae: 0.1937 - val_loss: 2.7990 - val_mae: 1.5146\n",
      "Epoch 2729/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1801 - val_loss: 2.9328 - val_mae: 1.5582\n",
      "Epoch 2730/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1739 - val_loss: 2.9568 - val_mae: 1.5659\n",
      "Epoch 2731/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1741 - val_loss: 2.8478 - val_mae: 1.5307\n",
      "Epoch 2732/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0493 - mae: 0.1784 - val_loss: 2.7278 - val_mae: 1.4911\n",
      "Epoch 2733/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1962 - val_loss: 2.6970 - val_mae: 1.4808\n",
      "Epoch 2734/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.2002 - val_loss: 2.7740 - val_mae: 1.5066\n",
      "Epoch 2735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1851 - val_loss: 2.9104 - val_mae: 1.5513\n",
      "Epoch 2736/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1783 - val_loss: 2.9837 - val_mae: 1.5748\n",
      "Epoch 2737/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1800 - val_loss: 2.9585 - val_mae: 1.5670\n",
      "Epoch 2738/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1794 - val_loss: 2.8673 - val_mae: 1.5378\n",
      "Epoch 2739/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1860 - val_loss: 2.8083 - val_mae: 1.5186\n",
      "Epoch 2740/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1888 - val_loss: 2.8317 - val_mae: 1.5263\n",
      "Epoch 2741/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0503 - mae: 0.1859 - val_loss: 2.8956 - val_mae: 1.5471\n",
      "Epoch 2742/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1817 - val_loss: 2.9666 - val_mae: 1.5699\n",
      "Epoch 2743/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1815 - val_loss: 2.9329 - val_mae: 1.5592\n",
      "Epoch 2744/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0509 - mae: 0.1807 - val_loss: 2.8232 - val_mae: 1.5235\n",
      "Epoch 2745/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1815 - val_loss: 2.7501 - val_mae: 1.4992\n",
      "Epoch 2746/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1834 - val_loss: 2.7439 - val_mae: 1.4970\n",
      "Epoch 2747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1794 - val_loss: 2.7928 - val_mae: 1.5133\n",
      "Epoch 2748/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0528 - mae: 0.1787 - val_loss: 2.8032 - val_mae: 1.5166\n",
      "Epoch 2749/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1788 - val_loss: 2.7468 - val_mae: 1.4978\n",
      "Epoch 2750/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1774 - val_loss: 2.6454 - val_mae: 1.4635\n",
      "Epoch 2751/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1834 - val_loss: 2.6002 - val_mae: 1.4478\n",
      "Epoch 2752/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0529 - mae: 0.1857 - val_loss: 2.6552 - val_mae: 1.4666\n",
      "Epoch 2753/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1818 - val_loss: 2.6865 - val_mae: 1.4772\n",
      "Epoch 2754/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0505 - mae: 0.1809 - val_loss: 2.7366 - val_mae: 1.4941\n",
      "Epoch 2755/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1804 - val_loss: 2.8140 - val_mae: 1.5197\n",
      "Epoch 2756/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1781 - val_loss: 2.8814 - val_mae: 1.5417\n",
      "Epoch 2757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1776 - val_loss: 2.9344 - val_mae: 1.5588\n",
      "Epoch 2758/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0509 - mae: 0.1771 - val_loss: 2.9738 - val_mae: 1.5713\n",
      "Epoch 2759/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1762 - val_loss: 3.0212 - val_mae: 1.5863\n",
      "Epoch 2760/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1763 - val_loss: 3.0724 - val_mae: 1.6024\n",
      "Epoch 2761/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0542 - mae: 0.1759 - val_loss: 3.0725 - val_mae: 1.6024\n",
      "Epoch 2762/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1757 - val_loss: 3.0120 - val_mae: 1.5833\n",
      "Epoch 2763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1733 - val_loss: 2.9388 - val_mae: 1.5600\n",
      "Epoch 2764/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0497 - mae: 0.1772 - val_loss: 2.8743 - val_mae: 1.5391\n",
      "Epoch 2765/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1829 - val_loss: 2.8717 - val_mae: 1.5382\n",
      "Epoch 2766/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0494 - mae: 0.1799 - val_loss: 2.9515 - val_mae: 1.5639\n",
      "Epoch 2767/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1777 - val_loss: 2.9890 - val_mae: 1.5759\n",
      "Epoch 2768/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1768 - val_loss: 2.8702 - val_mae: 1.5377\n",
      "Epoch 2769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1767 - val_loss: 2.7106 - val_mae: 1.4848\n",
      "Epoch 2770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1936 - val_loss: 2.6762 - val_mae: 1.4731\n",
      "Epoch 2771/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1971 - val_loss: 2.7966 - val_mae: 1.5134\n",
      "Epoch 2772/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0488 - mae: 0.1758 - val_loss: 2.9783 - val_mae: 1.5724\n",
      "Epoch 2773/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1799 - val_loss: 3.0204 - val_mae: 1.5857\n",
      "Epoch 2774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1824 - val_loss: 2.9453 - val_mae: 1.5618\n",
      "Epoch 2775/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0543 - mae: 0.1774 - val_loss: 2.9517 - val_mae: 1.5638\n",
      "Epoch 2776/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1733 - val_loss: 2.9630 - val_mae: 1.5674\n",
      "Epoch 2777/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1732 - val_loss: 2.9047 - val_mae: 1.5488\n",
      "Epoch 2778/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1763 - val_loss: 2.8399 - val_mae: 1.5277\n",
      "Epoch 2779/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0492 - mae: 0.1802 - val_loss: 2.7719 - val_mae: 1.5052\n",
      "Epoch 2780/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1919 - val_loss: 2.7199 - val_mae: 1.4879\n",
      "Epoch 2781/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.2020 - val_loss: 2.7344 - val_mae: 1.4927\n",
      "Epoch 2782/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1976 - val_loss: 2.8480 - val_mae: 1.5302\n",
      "Epoch 2783/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1805 - val_loss: 3.0295 - val_mae: 1.5885\n",
      "Epoch 2784/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0543 - mae: 0.1781 - val_loss: 3.1104 - val_mae: 1.6138\n",
      "Epoch 2785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.1844 - val_loss: 2.9976 - val_mae: 1.5785\n",
      "Epoch 2786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1810 - val_loss: 2.8399 - val_mae: 1.5277\n",
      "Epoch 2787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1897 - val_loss: 2.8154 - val_mae: 1.5197\n",
      "Epoch 2788/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0525 - mae: 0.1917 - val_loss: 2.8905 - val_mae: 1.5441\n",
      "Epoch 2789/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0495 - mae: 0.1821 - val_loss: 2.9881 - val_mae: 1.5754\n",
      "Epoch 2790/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1777 - val_loss: 3.0497 - val_mae: 1.5948\n",
      "Epoch 2791/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1767 - val_loss: 3.0456 - val_mae: 1.5935\n",
      "Epoch 2792/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0530 - mae: 0.1758 - val_loss: 3.0514 - val_mae: 1.5954\n",
      "Epoch 2793/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1745 - val_loss: 3.0618 - val_mae: 1.5986\n",
      "Epoch 2794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1731 - val_loss: 3.0137 - val_mae: 1.5835\n",
      "Epoch 2795/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1703 - val_loss: 2.9049 - val_mae: 1.5488\n",
      "Epoch 2796/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0499 - mae: 0.1782 - val_loss: 2.7788 - val_mae: 1.5075\n",
      "Epoch 2797/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1960 - val_loss: 2.7057 - val_mae: 1.4831\n",
      "Epoch 2798/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0574 - mae: 0.2072 - val_loss: 2.7148 - val_mae: 1.4862\n",
      "Epoch 2799/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.2052 - val_loss: 2.7949 - val_mae: 1.5129\n",
      "Epoch 2800/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0552 - mae: 0.1990 - val_loss: 2.9410 - val_mae: 1.5605\n",
      "Epoch 2801/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0523 - mae: 0.1876 - val_loss: 3.0389 - val_mae: 1.5916\n",
      "Epoch 2802/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1799 - val_loss: 2.9804 - val_mae: 1.5730\n",
      "Epoch 2803/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1805 - val_loss: 2.9177 - val_mae: 1.5530\n",
      "Epoch 2804/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1774 - val_loss: 2.9292 - val_mae: 1.5566\n",
      "Epoch 2805/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1742 - val_loss: 2.9549 - val_mae: 1.5649\n",
      "Epoch 2806/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1729 - val_loss: 2.9804 - val_mae: 1.5731\n",
      "Epoch 2807/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0525 - mae: 0.1735 - val_loss: 3.0243 - val_mae: 1.5870\n",
      "Epoch 2808/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - mae: 0.1750 - val_loss: 3.0139 - val_mae: 1.5837\n",
      "Epoch 2809/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1729 - val_loss: 2.9207 - val_mae: 1.5540\n",
      "Epoch 2810/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0492 - mae: 0.1743 - val_loss: 2.8185 - val_mae: 1.5207\n",
      "Epoch 2811/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1798 - val_loss: 2.7077 - val_mae: 1.4837\n",
      "Epoch 2812/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1909 - val_loss: 2.6856 - val_mae: 1.4762\n",
      "Epoch 2813/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1853 - val_loss: 2.7196 - val_mae: 1.4877\n",
      "Epoch 2814/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1749 - val_loss: 2.6903 - val_mae: 1.4778\n",
      "Epoch 2815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1725 - val_loss: 2.6461 - val_mae: 1.4628\n",
      "Epoch 2816/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1735 - val_loss: 2.6086 - val_mae: 1.4499\n",
      "Epoch 2817/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0536 - mae: 0.1759 - val_loss: 2.6247 - val_mae: 1.4555\n",
      "Epoch 2818/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1778 - val_loss: 2.6866 - val_mae: 1.4766\n",
      "Epoch 2819/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1776 - val_loss: 2.7212 - val_mae: 1.4882\n",
      "Epoch 2820/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0532 - mae: 0.1733 - val_loss: 2.7380 - val_mae: 1.4938\n",
      "Epoch 2821/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1723 - val_loss: 2.7994 - val_mae: 1.5142\n",
      "Epoch 2822/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1709 - val_loss: 2.8973 - val_mae: 1.5462\n",
      "Epoch 2823/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1759 - val_loss: 2.9457 - val_mae: 1.5617\n",
      "Epoch 2824/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1866 - val_loss: 3.0172 - val_mae: 1.5845\n",
      "Epoch 2825/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0604 - mae: 0.1954 - val_loss: 3.0917 - val_mae: 1.6079\n",
      "Epoch 2826/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0621 - mae: 0.1988 - val_loss: 3.0696 - val_mae: 1.6010\n",
      "Epoch 2827/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.1967 - val_loss: 2.9334 - val_mae: 1.5578\n",
      "Epoch 2828/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0559 - mae: 0.1932 - val_loss: 2.7041 - val_mae: 1.4824\n",
      "Epoch 2829/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0618 - mae: 0.2059 - val_loss: 2.5224 - val_mae: 1.4197\n",
      "Epoch 2830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0647 - mae: 0.2119 - val_loss: 2.5040 - val_mae: 1.4133\n",
      "Epoch 2831/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1929 - val_loss: 2.5656 - val_mae: 1.4349\n",
      "Epoch 2832/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1772 - val_loss: 2.6746 - val_mae: 1.4725\n",
      "Epoch 2833/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0609 - mae: 0.1902 - val_loss: 2.7878 - val_mae: 1.5105\n",
      "Epoch 2834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0727 - mae: 0.2119 - val_loss: 2.7831 - val_mae: 1.5090\n",
      "Epoch 2835/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0690 - mae: 0.2040 - val_loss: 2.6764 - val_mae: 1.4731\n",
      "Epoch 2836/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1788 - val_loss: 2.5110 - val_mae: 1.4158\n",
      "Epoch 2837/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0579 - mae: 0.1912 - val_loss: 2.4066 - val_mae: 1.3784\n",
      "Epoch 2838/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0652 - mae: 0.2131 - val_loss: 2.4267 - val_mae: 1.3857\n",
      "Epoch 2839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.2018 - val_loss: 2.5331 - val_mae: 1.4236\n",
      "Epoch 2840/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1796 - val_loss: 2.7212 - val_mae: 1.4883\n",
      "Epoch 2841/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.1892 - val_loss: 2.7489 - val_mae: 1.4976\n",
      "Epoch 2842/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1837 - val_loss: 2.5808 - val_mae: 1.4403\n",
      "Epoch 2843/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1969 - val_loss: 2.5081 - val_mae: 1.4149\n",
      "Epoch 2844/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0854 - mae: 0.2371 - val_loss: 2.5866 - val_mae: 1.4424\n",
      "Epoch 2845/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0810 - mae: 0.2305 - val_loss: 2.7739 - val_mae: 1.5060\n",
      "Epoch 2846/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.2021 - val_loss: 2.9644 - val_mae: 1.5681\n",
      "Epoch 2847/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1937 - val_loss: 2.9427 - val_mae: 1.5612\n",
      "Epoch 2848/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1845 - val_loss: 2.7655 - val_mae: 1.5033\n",
      "Epoch 2849/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0499 - mae: 0.1758 - val_loss: 2.6609 - val_mae: 1.4682\n",
      "Epoch 2850/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1805 - val_loss: 2.6689 - val_mae: 1.4709\n",
      "Epoch 2851/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1778 - val_loss: 2.7005 - val_mae: 1.4817\n",
      "Epoch 2852/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1781 - val_loss: 2.6784 - val_mae: 1.4742\n",
      "Epoch 2853/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1807 - val_loss: 2.6594 - val_mae: 1.4677\n",
      "Epoch 2854/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1809 - val_loss: 2.6620 - val_mae: 1.4686\n",
      "Epoch 2855/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0546 - mae: 0.1797 - val_loss: 2.6003 - val_mae: 1.4475\n",
      "Epoch 2856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0565 - mae: 0.1973 - val_loss: 2.6132 - val_mae: 1.4520\n",
      "Epoch 2857/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.2045 - val_loss: 2.7010 - val_mae: 1.4820\n",
      "Epoch 2858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1963 - val_loss: 2.8029 - val_mae: 1.5161\n",
      "Epoch 2859/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0531 - mae: 0.1883 - val_loss: 2.9650 - val_mae: 1.5687\n",
      "Epoch 2860/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1832 - val_loss: 3.0555 - val_mae: 1.5974\n",
      "Epoch 2861/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0613 - mae: 0.1949 - val_loss: 3.0100 - val_mae: 1.5830\n",
      "Epoch 2862/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1904 - val_loss: 2.8769 - val_mae: 1.5404\n",
      "Epoch 2863/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1905 - val_loss: 2.7785 - val_mae: 1.5082\n",
      "Epoch 2864/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0593 - mae: 0.2004 - val_loss: 2.7654 - val_mae: 1.5039\n",
      "Epoch 2865/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.1980 - val_loss: 2.8730 - val_mae: 1.5393\n",
      "Epoch 2866/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1877 - val_loss: 2.9696 - val_mae: 1.5704\n",
      "Epoch 2867/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1869 - val_loss: 2.9513 - val_mae: 1.5646\n",
      "Epoch 2868/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0519 - mae: 0.1827 - val_loss: 2.8594 - val_mae: 1.5350\n",
      "Epoch 2869/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1818 - val_loss: 2.7569 - val_mae: 1.5012\n",
      "Epoch 2870/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1877 - val_loss: 2.7043 - val_mae: 1.4836\n",
      "Epoch 2871/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1892 - val_loss: 2.7318 - val_mae: 1.4929\n",
      "Epoch 2872/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1878 - val_loss: 2.8250 - val_mae: 1.5238\n",
      "Epoch 2873/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1797 - val_loss: 2.9193 - val_mae: 1.5544\n",
      "Epoch 2874/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0499 - mae: 0.1787 - val_loss: 2.9964 - val_mae: 1.5790\n",
      "Epoch 2875/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1809 - val_loss: 3.0331 - val_mae: 1.5905\n",
      "Epoch 2876/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0582 - mae: 0.1869 - val_loss: 3.0036 - val_mae: 1.5812\n",
      "Epoch 2877/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1811 - val_loss: 2.9224 - val_mae: 1.5552\n",
      "Epoch 2878/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1723 - val_loss: 2.8328 - val_mae: 1.5261\n",
      "Epoch 2879/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0495 - mae: 0.1793 - val_loss: 2.7910 - val_mae: 1.5123\n",
      "Epoch 2880/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0500 - mae: 0.1830 - val_loss: 2.8630 - val_mae: 1.5359\n",
      "Epoch 2881/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1758 - val_loss: 2.9614 - val_mae: 1.5676\n",
      "Epoch 2882/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1702 - val_loss: 3.0152 - val_mae: 1.5846\n",
      "Epoch 2883/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1702 - val_loss: 3.0376 - val_mae: 1.5916\n",
      "Epoch 2884/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1697 - val_loss: 2.9449 - val_mae: 1.5622\n",
      "Epoch 2885/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1801 - val_loss: 2.8738 - val_mae: 1.5393\n",
      "Epoch 2886/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0622 - mae: 0.2125 - val_loss: 3.0437 - val_mae: 1.5938\n",
      "Epoch 2887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0614 - mae: 0.2028 - val_loss: 3.3408 - val_mae: 1.6845\n",
      "Epoch 2888/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1863 - val_loss: 3.5752 - val_mae: 1.7527\n",
      "Epoch 2889/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0769 - mae: 0.2115 - val_loss: 3.5865 - val_mae: 1.7559\n",
      "Epoch 2890/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0793 - mae: 0.2121 - val_loss: 3.3066 - val_mae: 1.6742\n",
      "Epoch 2891/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1767 - val_loss: 2.9300 - val_mae: 1.5575\n",
      "Epoch 2892/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.2097 - val_loss: 2.6705 - val_mae: 1.4716\n",
      "Epoch 2893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0731 - mae: 0.2396 - val_loss: 2.6360 - val_mae: 1.4596\n",
      "Epoch 2894/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0629 - mae: 0.2179 - val_loss: 2.7884 - val_mae: 1.5109\n",
      "Epoch 2895/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1750 - val_loss: 2.9476 - val_mae: 1.5627\n",
      "Epoch 2896/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0674 - mae: 0.1993 - val_loss: 2.9828 - val_mae: 1.5739\n",
      "Epoch 2897/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0767 - mae: 0.2176 - val_loss: 2.9256 - val_mae: 1.5556\n",
      "Epoch 2898/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0701 - mae: 0.2056 - val_loss: 2.8775 - val_mae: 1.5401\n",
      "Epoch 2899/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.1867 - val_loss: 2.8222 - val_mae: 1.5220\n",
      "Epoch 2900/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1774 - val_loss: 2.7278 - val_mae: 1.4907\n",
      "Epoch 2901/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1940 - val_loss: 2.6855 - val_mae: 1.4765\n",
      "Epoch 2902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mae: 0.1997 - val_loss: 2.6801 - val_mae: 1.4746\n",
      "Epoch 2903/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0535 - mae: 0.1929 - val_loss: 2.6825 - val_mae: 1.4754\n",
      "Epoch 2904/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0533 - mae: 0.1865 - val_loss: 2.6632 - val_mae: 1.4689\n",
      "Epoch 2905/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0534 - mae: 0.1927 - val_loss: 2.6237 - val_mae: 1.4554\n",
      "Epoch 2906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.2063 - val_loss: 2.6678 - val_mae: 1.4706\n",
      "Epoch 2907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.2014 - val_loss: 2.8539 - val_mae: 1.5326\n",
      "Epoch 2908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1863 - val_loss: 3.0535 - val_mae: 1.5964\n",
      "Epoch 2909/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0662 - mae: 0.2023 - val_loss: 3.0358 - val_mae: 1.5909\n",
      "Epoch 2910/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0668 - mae: 0.2002 - val_loss: 2.8785 - val_mae: 1.5407\n",
      "Epoch 2911/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0554 - mae: 0.1815 - val_loss: 2.7862 - val_mae: 1.5105\n",
      "Epoch 2912/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1729 - val_loss: 2.7622 - val_mae: 1.5026\n",
      "Epoch 2913/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0500 - mae: 0.1804 - val_loss: 2.7659 - val_mae: 1.5038\n",
      "Epoch 2914/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1814 - val_loss: 2.8773 - val_mae: 1.5405\n",
      "Epoch 2915/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0500 - mae: 0.1768 - val_loss: 2.9900 - val_mae: 1.5767\n",
      "Epoch 2916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1726 - val_loss: 3.0913 - val_mae: 1.6086\n",
      "Epoch 2917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1743 - val_loss: 3.2190 - val_mae: 1.6479\n",
      "Epoch 2918/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0611 - mae: 0.1825 - val_loss: 3.2708 - val_mae: 1.6636\n",
      "Epoch 2919/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0608 - mae: 0.1790 - val_loss: 3.2118 - val_mae: 1.6458\n",
      "Epoch 2920/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1779 - val_loss: 3.0867 - val_mae: 1.6074\n",
      "Epoch 2921/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1858 - val_loss: 3.0170 - val_mae: 1.5856\n",
      "Epoch 2922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1917 - val_loss: 2.9929 - val_mae: 1.5780\n",
      "Epoch 2923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1887 - val_loss: 3.0031 - val_mae: 1.5811\n",
      "Epoch 2924/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1800 - val_loss: 3.0537 - val_mae: 1.5970\n",
      "Epoch 2925/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0513 - mae: 0.1731 - val_loss: 3.0825 - val_mae: 1.6060\n",
      "Epoch 2926/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0564 - mae: 0.1811 - val_loss: 3.0572 - val_mae: 1.5980\n",
      "Epoch 2927/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1849 - val_loss: 3.0346 - val_mae: 1.5910\n",
      "Epoch 2928/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0553 - mae: 0.1805 - val_loss: 2.9312 - val_mae: 1.5581\n",
      "Epoch 2929/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1772 - val_loss: 2.7737 - val_mae: 1.5067\n",
      "Epoch 2930/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1847 - val_loss: 2.6936 - val_mae: 1.4798\n",
      "Epoch 2931/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0522 - mae: 0.1916 - val_loss: 2.6324 - val_mae: 1.4589\n",
      "Epoch 2932/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0556 - mae: 0.1987 - val_loss: 2.6339 - val_mae: 1.4594\n",
      "Epoch 2933/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0564 - mae: 0.1983 - val_loss: 2.7034 - val_mae: 1.4829\n",
      "Epoch 2934/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1902 - val_loss: 2.7302 - val_mae: 1.4918\n",
      "Epoch 2935/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1864 - val_loss: 2.7548 - val_mae: 1.4999\n",
      "Epoch 2936/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0507 - mae: 0.1835 - val_loss: 2.8036 - val_mae: 1.5160\n",
      "Epoch 2937/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0535 - mae: 0.1836 - val_loss: 2.7618 - val_mae: 1.5021\n",
      "Epoch 2938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1812 - val_loss: 2.6353 - val_mae: 1.4593\n",
      "Epoch 2939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1847 - val_loss: 2.5380 - val_mae: 1.4256\n",
      "Epoch 2940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1955 - val_loss: 2.5583 - val_mae: 1.4326\n",
      "Epoch 2941/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1913 - val_loss: 2.7169 - val_mae: 1.4870\n",
      "Epoch 2942/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1776 - val_loss: 2.9376 - val_mae: 1.5594\n",
      "Epoch 2943/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1822 - val_loss: 3.0699 - val_mae: 1.6013\n",
      "Epoch 2944/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0642 - mae: 0.1945 - val_loss: 3.0657 - val_mae: 1.5999\n",
      "Epoch 2945/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1830 - val_loss: 2.9844 - val_mae: 1.5743\n",
      "Epoch 2946/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1708 - val_loss: 2.8672 - val_mae: 1.5365\n",
      "Epoch 2947/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1770 - val_loss: 2.7767 - val_mae: 1.5068\n",
      "Epoch 2948/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0528 - mae: 0.1914 - val_loss: 2.8283 - val_mae: 1.5238\n",
      "Epoch 2949/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0531 - mae: 0.1903 - val_loss: 2.9885 - val_mae: 1.5755\n",
      "Epoch 2950/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0517 - mae: 0.1797 - val_loss: 3.0735 - val_mae: 1.6023\n",
      "Epoch 2951/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0522 - mae: 0.1794 - val_loss: 3.0331 - val_mae: 1.5896\n",
      "Epoch 2952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1812 - val_loss: 2.9808 - val_mae: 1.5731\n",
      "Epoch 2953/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1828 - val_loss: 2.9073 - val_mae: 1.5496\n",
      "Epoch 2954/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1846 - val_loss: 2.7877 - val_mae: 1.5106\n",
      "Epoch 2955/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1929 - val_loss: 2.7678 - val_mae: 1.5040\n",
      "Epoch 2956/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1781 - val_loss: 2.9108 - val_mae: 1.5509\n",
      "Epoch 2957/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1745 - val_loss: 3.0492 - val_mae: 1.5949\n",
      "Epoch 2958/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0737 - mae: 0.2125 - val_loss: 3.0130 - val_mae: 1.5836\n",
      "Epoch 2959/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0713 - mae: 0.2084 - val_loss: 2.9035 - val_mae: 1.5486\n",
      "Epoch 2960/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1776 - val_loss: 2.7639 - val_mae: 1.5028\n",
      "Epoch 2961/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1782 - val_loss: 2.7184 - val_mae: 1.4876\n",
      "Epoch 2962/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1972 - val_loss: 2.8233 - val_mae: 1.5226\n",
      "Epoch 2963/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0545 - mae: 0.1988 - val_loss: 2.9887 - val_mae: 1.5761\n",
      "Epoch 2964/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0527 - mae: 0.1871 - val_loss: 3.2071 - val_mae: 1.6440\n",
      "Epoch 2965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1798 - val_loss: 3.3458 - val_mae: 1.6857\n",
      "Epoch 2966/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.1854 - val_loss: 3.3796 - val_mae: 1.6957\n",
      "Epoch 2967/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0629 - mae: 0.1896 - val_loss: 3.2509 - val_mae: 1.6573\n",
      "Epoch 2968/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0547 - mae: 0.1817 - val_loss: 2.9337 - val_mae: 1.5586\n",
      "Epoch 2969/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1850 - val_loss: 2.6753 - val_mae: 1.4733\n",
      "Epoch 2970/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.2006 - val_loss: 2.5590 - val_mae: 1.4332\n",
      "Epoch 2971/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0590 - mae: 0.2023 - val_loss: 2.5024 - val_mae: 1.4133\n",
      "Epoch 2972/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.1994 - val_loss: 2.5166 - val_mae: 1.4183\n",
      "Epoch 2973/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0563 - mae: 0.1938 - val_loss: 2.6640 - val_mae: 1.4694\n",
      "Epoch 2974/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1872 - val_loss: 2.7983 - val_mae: 1.5144\n",
      "Epoch 2975/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0520 - mae: 0.1834 - val_loss: 2.8056 - val_mae: 1.5168\n",
      "Epoch 2976/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1868 - val_loss: 2.7691 - val_mae: 1.5047\n",
      "Epoch 2977/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0591 - mae: 0.2003 - val_loss: 2.8187 - val_mae: 1.5211\n",
      "Epoch 2978/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0485 - mae: 0.1810 - val_loss: 3.0018 - val_mae: 1.5801\n",
      "Epoch 2979/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0602 - mae: 0.1900 - val_loss: 3.0685 - val_mae: 1.6011\n",
      "Epoch 2980/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0771 - mae: 0.2184 - val_loss: 2.9227 - val_mae: 1.5549\n",
      "Epoch 2981/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1849 - val_loss: 2.6656 - val_mae: 1.4699\n",
      "Epoch 2982/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1838 - val_loss: 2.4737 - val_mae: 1.4030\n",
      "Epoch 2983/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0723 - mae: 0.2337 - val_loss: 2.4989 - val_mae: 1.4120\n",
      "Epoch 2984/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0669 - mae: 0.2246 - val_loss: 2.7164 - val_mae: 1.4871\n",
      "Epoch 2985/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1812 - val_loss: 2.9502 - val_mae: 1.5638\n",
      "Epoch 2986/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0605 - mae: 0.1832 - val_loss: 2.9599 - val_mae: 1.5670\n",
      "Epoch 2987/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.1805 - val_loss: 2.8188 - val_mae: 1.5213\n",
      "Epoch 2988/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1723 - val_loss: 2.7308 - val_mae: 1.4921\n",
      "Epoch 2989/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0503 - mae: 0.1815 - val_loss: 2.7388 - val_mae: 1.4948\n",
      "Epoch 2990/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0495 - mae: 0.1803 - val_loss: 2.7534 - val_mae: 1.4997\n",
      "Epoch 2991/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0480 - mae: 0.1765 - val_loss: 2.7478 - val_mae: 1.4979\n",
      "Epoch 2992/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0478 - mae: 0.1775 - val_loss: 2.8084 - val_mae: 1.5180\n",
      "Epoch 2993/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0495 - mae: 0.1790 - val_loss: 2.8461 - val_mae: 1.5303\n",
      "Epoch 2994/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0504 - mae: 0.1805 - val_loss: 2.8373 - val_mae: 1.5274\n",
      "Epoch 2995/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0491 - mae: 0.1769 - val_loss: 2.8456 - val_mae: 1.5300\n",
      "Epoch 2996/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0482 - mae: 0.1739 - val_loss: 2.8232 - val_mae: 1.5227\n",
      "Epoch 2997/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0473 - mae: 0.1713 - val_loss: 2.8035 - val_mae: 1.5162\n",
      "Epoch 2998/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0486 - mae: 0.1788 - val_loss: 2.8022 - val_mae: 1.5157\n",
      "Epoch 2999/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0494 - mae: 0.1809 - val_loss: 2.7880 - val_mae: 1.5110\n",
      "Epoch 3000/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0497 - mae: 0.1810 - val_loss: 2.7501 - val_mae: 1.4984\n",
      "Epoch 3001/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0513 - mae: 0.1902 - val_loss: 2.7207 - val_mae: 1.4885\n",
      "Epoch 3002/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0537 - mae: 0.1972 - val_loss: 2.7237 - val_mae: 1.4895\n",
      "Epoch 3003/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0512 - mae: 0.1886 - val_loss: 2.8154 - val_mae: 1.5200\n",
      "Epoch 3004/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0486 - mae: 0.1717 - val_loss: 2.9414 - val_mae: 1.5609\n",
      "Epoch 3005/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0496 - mae: 0.1725 - val_loss: 2.9296 - val_mae: 1.5571\n",
      "Epoch 3006/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489 - mae: 0.1769 - val_loss: 2.8514 - val_mae: 1.5318\n",
      "Epoch 3007/5000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0499 - mae: 0.1811 - val_loss: 2.8428 - val_mae: 1.5290\n",
      "Epoch 3008/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0496 - mae: 0.1808 - val_loss: 2.9607 - val_mae: 1.5671\n",
      "Epoch 3009/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0508 - mae: 0.1753 - val_loss: 3.0721 - val_mae: 1.6023\n",
      "Epoch 3010/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0637 - mae: 0.1935 - val_loss: 3.0001 - val_mae: 1.5797\n",
      "Epoch 3011/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1814 - val_loss: 2.8028 - val_mae: 1.5159\n",
      "Epoch 3012/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0484 - mae: 0.1692 - val_loss: 2.6414 - val_mae: 1.4617\n",
      "Epoch 3013/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0554 - mae: 0.2026 - val_loss: 2.5903 - val_mae: 1.4441\n",
      "Epoch 3014/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0618 - mae: 0.2174 - val_loss: 2.6282 - val_mae: 1.4572\n",
      "Epoch 3015/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.2073 - val_loss: 2.6884 - val_mae: 1.4778\n",
      "Epoch 3016/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0515 - mae: 0.1858 - val_loss: 2.7811 - val_mae: 1.5089\n",
      "Epoch 3017/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0523 - mae: 0.1698 - val_loss: 2.8149 - val_mae: 1.5201\n",
      "Epoch 3018/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0488 - mae: 0.1652 - val_loss: 2.7432 - val_mae: 1.4963\n",
      "Epoch 3019/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0482 - mae: 0.1781 - val_loss: 2.6904 - val_mae: 1.4786\n",
      "Epoch 3020/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0569 - mae: 0.1975 - val_loss: 2.7160 - val_mae: 1.4873\n",
      "Epoch 3021/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0569 - mae: 0.1958 - val_loss: 2.8315 - val_mae: 1.5257\n",
      "Epoch 3022/5000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0506 - mae: 0.1843 - val_loss: 2.9750 - val_mae: 1.5721\n",
      "Epoch 3023/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0549 - mae: 0.1839 - val_loss: 3.0012 - val_mae: 1.5805\n",
      "Epoch 3024/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0546 - mae: 0.1819 - val_loss: 2.8607 - val_mae: 1.5355\n",
      "Epoch 3025/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0499 - mae: 0.1811 - val_loss: 2.7441 - val_mae: 1.4971\n",
      "Epoch 3026/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0543 - mae: 0.1910 - val_loss: 2.7710 - val_mae: 1.5062\n",
      "Epoch 3027/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0522 - mae: 0.1859 - val_loss: 2.8292 - val_mae: 1.5255\n",
      "Epoch 3028/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0484 - mae: 0.1752 - val_loss: 2.7694 - val_mae: 1.5058\n",
      "Epoch 3029/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0484 - mae: 0.1785 - val_loss: 2.6590 - val_mae: 1.4687\n",
      "Epoch 3030/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1871 - val_loss: 2.6301 - val_mae: 1.4588\n",
      "Epoch 3031/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0499 - mae: 0.1800 - val_loss: 2.6637 - val_mae: 1.4702\n",
      "Epoch 3032/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0512 - mae: 0.1721 - val_loss: 2.7078 - val_mae: 1.4851\n",
      "Epoch 3033/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0583 - mae: 0.1822 - val_loss: 2.7544 - val_mae: 1.5008\n",
      "Epoch 3034/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0635 - mae: 0.1923 - val_loss: 2.7080 - val_mae: 1.4853\n",
      "Epoch 3035/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1790 - val_loss: 2.6694 - val_mae: 1.4724\n",
      "Epoch 3036/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0496 - mae: 0.1736 - val_loss: 2.7122 - val_mae: 1.4871\n",
      "Epoch 3037/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1821 - val_loss: 2.7420 - val_mae: 1.4972\n",
      "Epoch 3038/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1852 - val_loss: 2.8001 - val_mae: 1.5166\n",
      "Epoch 3039/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1819 - val_loss: 2.8784 - val_mae: 1.5422\n",
      "Epoch 3040/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0489 - mae: 0.1803 - val_loss: 2.9298 - val_mae: 1.5588\n",
      "Epoch 3041/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0498 - mae: 0.1844 - val_loss: 2.8884 - val_mae: 1.5454\n",
      "Epoch 3042/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0502 - mae: 0.1877 - val_loss: 2.7691 - val_mae: 1.5061\n",
      "Epoch 3043/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1906 - val_loss: 2.6591 - val_mae: 1.4689\n",
      "Epoch 3044/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0531 - mae: 0.1938 - val_loss: 2.6221 - val_mae: 1.4560\n",
      "Epoch 3045/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0513 - mae: 0.1881 - val_loss: 2.7004 - val_mae: 1.4825\n",
      "Epoch 3046/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0495 - mae: 0.1826 - val_loss: 2.7648 - val_mae: 1.5039\n",
      "Epoch 3047/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0521 - mae: 0.1781 - val_loss: 2.7371 - val_mae: 1.4945\n",
      "Epoch 3048/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1779 - val_loss: 2.6343 - val_mae: 1.4596\n",
      "Epoch 3049/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1744 - val_loss: 2.4993 - val_mae: 1.4125\n",
      "Epoch 3050/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1830 - val_loss: 2.5558 - val_mae: 1.4323\n",
      "Epoch 3051/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0502 - mae: 0.1753 - val_loss: 2.7985 - val_mae: 1.5146\n",
      "Epoch 3052/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1692 - val_loss: 3.0981 - val_mae: 1.6105\n",
      "Epoch 3053/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0683 - mae: 0.2001 - val_loss: 3.2631 - val_mae: 1.6609\n",
      "Epoch 3054/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0738 - mae: 0.2075 - val_loss: 3.1861 - val_mae: 1.6375\n",
      "Epoch 3055/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0561 - mae: 0.1741 - val_loss: 2.9545 - val_mae: 1.5651\n",
      "Epoch 3056/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1763 - val_loss: 2.6778 - val_mae: 1.4739\n",
      "Epoch 3057/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0724 - mae: 0.2302 - val_loss: 2.5605 - val_mae: 1.4335\n",
      "Epoch 3058/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0839 - mae: 0.2462 - val_loss: 2.6981 - val_mae: 1.4807\n",
      "Epoch 3059/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1990 - val_loss: 2.9594 - val_mae: 1.5665\n",
      "Epoch 3060/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1776 - val_loss: 3.0648 - val_mae: 1.5999\n",
      "Epoch 3061/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0639 - mae: 0.1972 - val_loss: 3.0029 - val_mae: 1.5804\n",
      "Epoch 3062/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0615 - mae: 0.1926 - val_loss: 2.8734 - val_mae: 1.5388\n",
      "Epoch 3063/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1710 - val_loss: 2.6349 - val_mae: 1.4592\n",
      "Epoch 3064/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1821 - val_loss: 2.3781 - val_mae: 1.3683\n",
      "Epoch 3065/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0965 - mae: 0.2579 - val_loss: 2.3603 - val_mae: 1.3618\n",
      "Epoch 3066/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0795 - mae: 0.2355 - val_loss: 2.5458 - val_mae: 1.4284\n",
      "Epoch 3067/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1826 - val_loss: 2.6796 - val_mae: 1.4746\n",
      "Epoch 3068/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0588 - mae: 0.1907 - val_loss: 2.6616 - val_mae: 1.4685\n",
      "Epoch 3069/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1869 - val_loss: 2.5663 - val_mae: 1.4356\n",
      "Epoch 3070/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1807 - val_loss: 2.4933 - val_mae: 1.4099\n",
      "Epoch 3071/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1816 - val_loss: 2.4688 - val_mae: 1.4012\n",
      "Epoch 3072/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1816 - val_loss: 2.5055 - val_mae: 1.4142\n",
      "Epoch 3073/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0504 - mae: 0.1763 - val_loss: 2.6191 - val_mae: 1.4539\n",
      "Epoch 3074/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0498 - mae: 0.1716 - val_loss: 2.7638 - val_mae: 1.5029\n",
      "Epoch 3075/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1809 - val_loss: 2.8018 - val_mae: 1.5155\n",
      "Epoch 3076/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1814 - val_loss: 2.7233 - val_mae: 1.4893\n",
      "Epoch 3077/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1680 - val_loss: 2.6125 - val_mae: 1.4516\n",
      "Epoch 3078/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0489 - mae: 0.1768 - val_loss: 2.5199 - val_mae: 1.4193\n",
      "Epoch 3079/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1887 - val_loss: 2.4567 - val_mae: 1.3969\n",
      "Epoch 3080/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0561 - mae: 0.1957 - val_loss: 2.4483 - val_mae: 1.3939\n",
      "Epoch 3081/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0544 - mae: 0.1886 - val_loss: 2.5839 - val_mae: 1.4417\n",
      "Epoch 3082/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1795 - val_loss: 2.7781 - val_mae: 1.5076\n",
      "Epoch 3083/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0509 - mae: 0.1793 - val_loss: 2.8269 - val_mae: 1.5237\n",
      "Epoch 3084/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1791 - val_loss: 2.7539 - val_mae: 1.4995\n",
      "Epoch 3085/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0527 - mae: 0.1858 - val_loss: 2.7060 - val_mae: 1.4834\n",
      "Epoch 3086/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1885 - val_loss: 2.7833 - val_mae: 1.5093\n",
      "Epoch 3087/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1805 - val_loss: 2.9177 - val_mae: 1.5532\n",
      "Epoch 3088/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1769 - val_loss: 3.0317 - val_mae: 1.5895\n",
      "Epoch 3089/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1801 - val_loss: 3.1248 - val_mae: 1.6186\n",
      "Epoch 3090/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0589 - mae: 0.1838 - val_loss: 3.1404 - val_mae: 1.6234\n",
      "Epoch 3091/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0577 - mae: 0.1789 - val_loss: 3.0624 - val_mae: 1.5992\n",
      "Epoch 3092/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1751 - val_loss: 2.9536 - val_mae: 1.5648\n",
      "Epoch 3093/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0500 - mae: 0.1770 - val_loss: 2.8652 - val_mae: 1.5363\n",
      "Epoch 3094/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1802 - val_loss: 2.8948 - val_mae: 1.5460\n",
      "Epoch 3095/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1713 - val_loss: 2.9666 - val_mae: 1.5691\n",
      "Epoch 3096/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1665 - val_loss: 2.9274 - val_mae: 1.5566\n",
      "Epoch 3097/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1671 - val_loss: 2.7973 - val_mae: 1.5142\n",
      "Epoch 3098/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1668 - val_loss: 2.6246 - val_mae: 1.4561\n",
      "Epoch 3099/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1803 - val_loss: 2.5043 - val_mae: 1.4142\n",
      "Epoch 3100/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0557 - mae: 0.1943 - val_loss: 2.4886 - val_mae: 1.4087\n",
      "Epoch 3101/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1894 - val_loss: 2.5993 - val_mae: 1.4474\n",
      "Epoch 3102/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0507 - mae: 0.1793 - val_loss: 2.7236 - val_mae: 1.4897\n",
      "Epoch 3103/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1760 - val_loss: 2.8382 - val_mae: 1.5277\n",
      "Epoch 3104/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1769 - val_loss: 2.9307 - val_mae: 1.5577\n",
      "Epoch 3105/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1710 - val_loss: 2.9312 - val_mae: 1.5579\n",
      "Epoch 3106/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1703 - val_loss: 2.9599 - val_mae: 1.5671\n",
      "Epoch 3107/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0483 - mae: 0.1745 - val_loss: 3.0373 - val_mae: 1.5917\n",
      "Epoch 3108/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0489 - mae: 0.1752 - val_loss: 3.1432 - val_mae: 1.6247\n",
      "Epoch 3109/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1721 - val_loss: 3.2763 - val_mae: 1.6653\n",
      "Epoch 3110/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0546 - mae: 0.1755 - val_loss: 3.3461 - val_mae: 1.6862\n",
      "Epoch 3111/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0580 - mae: 0.1800 - val_loss: 3.3290 - val_mae: 1.6811\n",
      "Epoch 3112/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1786 - val_loss: 3.2226 - val_mae: 1.6492\n",
      "Epoch 3113/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1777 - val_loss: 3.0338 - val_mae: 1.5909\n",
      "Epoch 3114/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1916 - val_loss: 2.8285 - val_mae: 1.5249\n",
      "Epoch 3115/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0681 - mae: 0.2184 - val_loss: 2.7072 - val_mae: 1.4845\n",
      "Epoch 3116/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mae: 0.2111 - val_loss: 2.7777 - val_mae: 1.5080\n",
      "Epoch 3117/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0484 - mae: 0.1819 - val_loss: 2.9578 - val_mae: 1.5665\n",
      "Epoch 3118/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0824 - mae: 0.2358 - val_loss: 2.9955 - val_mae: 1.5785\n",
      "Epoch 3119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1050 - mae: 0.2701 - val_loss: 2.8087 - val_mae: 1.5181\n",
      "Epoch 3120/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0737 - mae: 0.2123 - val_loss: 2.5565 - val_mae: 1.4326\n",
      "Epoch 3121/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0569 - mae: 0.1804 - val_loss: 2.4003 - val_mae: 1.3769\n",
      "Epoch 3122/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0724 - mae: 0.2250 - val_loss: 2.4068 - val_mae: 1.3792\n",
      "Epoch 3123/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0757 - mae: 0.2305 - val_loss: 2.5839 - val_mae: 1.4420\n",
      "Epoch 3124/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0656 - mae: 0.2102 - val_loss: 2.8025 - val_mae: 1.5159\n",
      "Epoch 3125/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.1921 - val_loss: 2.9783 - val_mae: 1.5728\n",
      "Epoch 3126/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0650 - mae: 0.1910 - val_loss: 3.0085 - val_mae: 1.5824\n",
      "Epoch 3127/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0579 - mae: 0.1814 - val_loss: 2.9515 - val_mae: 1.5642\n",
      "Epoch 3128/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1891 - val_loss: 2.9934 - val_mae: 1.5776\n",
      "Epoch 3129/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1978 - val_loss: 3.0877 - val_mae: 1.6072\n",
      "Epoch 3130/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1860 - val_loss: 3.2327 - val_mae: 1.6518\n",
      "Epoch 3131/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1749 - val_loss: 3.3329 - val_mae: 1.6818\n",
      "Epoch 3132/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0596 - mae: 0.1810 - val_loss: 3.2139 - val_mae: 1.6460\n",
      "Epoch 3133/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0536 - mae: 0.1800 - val_loss: 2.9744 - val_mae: 1.5716\n",
      "Epoch 3134/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0686 - mae: 0.2104 - val_loss: 2.8617 - val_mae: 1.5353\n",
      "Epoch 3135/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0728 - mae: 0.2222 - val_loss: 3.0102 - val_mae: 1.5830\n",
      "Epoch 3136/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0545 - mae: 0.1869 - val_loss: 3.1674 - val_mae: 1.6321\n",
      "Epoch 3137/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0630 - mae: 0.1877 - val_loss: 3.0904 - val_mae: 1.6084\n",
      "Epoch 3138/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0635 - mae: 0.1905 - val_loss: 2.8973 - val_mae: 1.5473\n",
      "Epoch 3139/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1688 - val_loss: 2.6506 - val_mae: 1.4654\n",
      "Epoch 3140/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1796 - val_loss: 2.4855 - val_mae: 1.4080\n",
      "Epoch 3141/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0567 - mae: 0.2014 - val_loss: 2.5242 - val_mae: 1.4217\n",
      "Epoch 3142/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1876 - val_loss: 2.6463 - val_mae: 1.4642\n",
      "Epoch 3143/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0476 - mae: 0.1727 - val_loss: 2.7687 - val_mae: 1.5055\n",
      "Epoch 3144/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1719 - val_loss: 2.8686 - val_mae: 1.5383\n",
      "Epoch 3145/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0502 - mae: 0.1811 - val_loss: 2.9029 - val_mae: 1.5495\n",
      "Epoch 3146/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1843 - val_loss: 2.9039 - val_mae: 1.5499\n",
      "Epoch 3147/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1843 - val_loss: 2.8334 - val_mae: 1.5269\n",
      "Epoch 3148/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1884 - val_loss: 2.7890 - val_mae: 1.5123\n",
      "Epoch 3149/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0526 - mae: 0.1844 - val_loss: 2.8236 - val_mae: 1.5237\n",
      "Epoch 3150/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0482 - mae: 0.1751 - val_loss: 2.8226 - val_mae: 1.5234\n",
      "Epoch 3151/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0482 - mae: 0.1731 - val_loss: 2.8205 - val_mae: 1.5226\n",
      "Epoch 3152/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1734 - val_loss: 2.7559 - val_mae: 1.5012\n",
      "Epoch 3153/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0498 - mae: 0.1708 - val_loss: 2.6063 - val_mae: 1.4505\n",
      "Epoch 3154/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1705 - val_loss: 2.4923 - val_mae: 1.4106\n",
      "Epoch 3155/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1783 - val_loss: 2.4457 - val_mae: 1.3940\n",
      "Epoch 3156/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0528 - mae: 0.1806 - val_loss: 2.4381 - val_mae: 1.3912\n",
      "Epoch 3157/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1766 - val_loss: 2.4343 - val_mae: 1.3898\n",
      "Epoch 3158/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1764 - val_loss: 2.4090 - val_mae: 1.3807\n",
      "Epoch 3159/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1785 - val_loss: 2.4129 - val_mae: 1.3821\n",
      "Epoch 3160/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1790 - val_loss: 2.5533 - val_mae: 1.4320\n",
      "Epoch 3161/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1715 - val_loss: 2.8331 - val_mae: 1.5266\n",
      "Epoch 3162/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1847 - val_loss: 3.0944 - val_mae: 1.6100\n",
      "Epoch 3163/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0737 - mae: 0.2138 - val_loss: 3.1184 - val_mae: 1.6174\n",
      "Epoch 3164/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0632 - mae: 0.1917 - val_loss: 2.9496 - val_mae: 1.5642\n",
      "Epoch 3165/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1726 - val_loss: 2.8045 - val_mae: 1.5171\n",
      "Epoch 3166/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1944 - val_loss: 2.8374 - val_mae: 1.5279\n",
      "Epoch 3167/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1841 - val_loss: 2.9323 - val_mae: 1.5586\n",
      "Epoch 3168/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1717 - val_loss: 2.9266 - val_mae: 1.5568\n",
      "Epoch 3169/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1769 - val_loss: 2.8687 - val_mae: 1.5382\n",
      "Epoch 3170/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0566 - mae: 0.1786 - val_loss: 2.7354 - val_mae: 1.4941\n",
      "Epoch 3171/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1744 - val_loss: 2.5889 - val_mae: 1.4442\n",
      "Epoch 3172/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.2119 - val_loss: 2.5554 - val_mae: 1.4325\n",
      "Epoch 3173/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0740 - mae: 0.2324 - val_loss: 2.6521 - val_mae: 1.4659\n",
      "Epoch 3174/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0651 - mae: 0.2124 - val_loss: 2.8460 - val_mae: 1.5306\n",
      "Epoch 3175/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0509 - mae: 0.1820 - val_loss: 3.0839 - val_mae: 1.6066\n",
      "Epoch 3176/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640 - mae: 0.2008 - val_loss: 3.1505 - val_mae: 1.6272\n",
      "Epoch 3177/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0696 - mae: 0.2121 - val_loss: 2.9965 - val_mae: 1.5792\n",
      "Epoch 3178/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0554 - mae: 0.1916 - val_loss: 2.7949 - val_mae: 1.5140\n",
      "Epoch 3179/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1859 - val_loss: 2.5949 - val_mae: 1.4465\n",
      "Epoch 3180/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0655 - mae: 0.2101 - val_loss: 2.5008 - val_mae: 1.4136\n",
      "Epoch 3181/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0719 - mae: 0.2229 - val_loss: 2.6231 - val_mae: 1.4563\n",
      "Epoch 3182/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1864 - val_loss: 2.9196 - val_mae: 1.5550\n",
      "Epoch 3183/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1738 - val_loss: 3.0380 - val_mae: 1.5927\n",
      "Epoch 3184/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0660 - mae: 0.1994 - val_loss: 2.8775 - val_mae: 1.5414\n",
      "Epoch 3185/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1823 - val_loss: 2.7021 - val_mae: 1.4835\n",
      "Epoch 3186/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1719 - val_loss: 2.6168 - val_mae: 1.4545\n",
      "Epoch 3187/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1833 - val_loss: 2.5525 - val_mae: 1.4322\n",
      "Epoch 3188/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0569 - mae: 0.2009 - val_loss: 2.5236 - val_mae: 1.4221\n",
      "Epoch 3189/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0587 - mae: 0.2056 - val_loss: 2.6035 - val_mae: 1.4499\n",
      "Epoch 3190/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1900 - val_loss: 2.6722 - val_mae: 1.4734\n",
      "Epoch 3191/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1724 - val_loss: 2.6789 - val_mae: 1.4756\n",
      "Epoch 3192/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1692 - val_loss: 2.7348 - val_mae: 1.4944\n",
      "Epoch 3193/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1766 - val_loss: 2.7515 - val_mae: 1.5000\n",
      "Epoch 3194/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1732 - val_loss: 2.6597 - val_mae: 1.4690\n",
      "Epoch 3195/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1788 - val_loss: 2.5959 - val_mae: 1.4471\n",
      "Epoch 3196/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0578 - mae: 0.2021 - val_loss: 2.6520 - val_mae: 1.4664\n",
      "Epoch 3197/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0593 - mae: 0.2040 - val_loss: 2.7264 - val_mae: 1.4916\n",
      "Epoch 3198/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1916 - val_loss: 2.8023 - val_mae: 1.5169\n",
      "Epoch 3199/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0496 - mae: 0.1801 - val_loss: 2.9158 - val_mae: 1.5539\n",
      "Epoch 3200/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1771 - val_loss: 2.9660 - val_mae: 1.5699\n",
      "Epoch 3201/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0498 - mae: 0.1743 - val_loss: 2.9190 - val_mae: 1.5549\n",
      "Epoch 3202/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1729 - val_loss: 2.8466 - val_mae: 1.5314\n",
      "Epoch 3203/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0485 - mae: 0.1775 - val_loss: 2.7986 - val_mae: 1.5155\n",
      "Epoch 3204/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0488 - mae: 0.1790 - val_loss: 2.8299 - val_mae: 1.5258\n",
      "Epoch 3205/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1763 - val_loss: 2.8375 - val_mae: 1.5283\n",
      "Epoch 3206/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0474 - mae: 0.1760 - val_loss: 2.8201 - val_mae: 1.5225\n",
      "Epoch 3207/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0481 - mae: 0.1773 - val_loss: 2.8081 - val_mae: 1.5185\n",
      "Epoch 3208/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0476 - mae: 0.1768 - val_loss: 2.7339 - val_mae: 1.4938\n",
      "Epoch 3209/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1810 - val_loss: 2.7148 - val_mae: 1.4874\n",
      "Epoch 3210/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0468 - mae: 0.1753 - val_loss: 2.8127 - val_mae: 1.5199\n",
      "Epoch 3211/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0474 - mae: 0.1656 - val_loss: 2.9426 - val_mae: 1.5621\n",
      "Epoch 3212/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0571 - mae: 0.1810 - val_loss: 2.9670 - val_mae: 1.5699\n",
      "Epoch 3213/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0592 - mae: 0.1844 - val_loss: 2.8378 - val_mae: 1.5281\n",
      "Epoch 3214/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0502 - mae: 0.1678 - val_loss: 2.6493 - val_mae: 1.4651\n",
      "Epoch 3215/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1768 - val_loss: 2.5424 - val_mae: 1.4281\n",
      "Epoch 3216/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0534 - mae: 0.1900 - val_loss: 2.5867 - val_mae: 1.4435\n",
      "Epoch 3217/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0511 - mae: 0.1867 - val_loss: 2.6733 - val_mae: 1.4732\n",
      "Epoch 3218/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1875 - val_loss: 2.7083 - val_mae: 1.4851\n",
      "Epoch 3219/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1913 - val_loss: 2.7201 - val_mae: 1.4891\n",
      "Epoch 3220/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1797 - val_loss: 2.6502 - val_mae: 1.4654\n",
      "Epoch 3221/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1767 - val_loss: 2.5858 - val_mae: 1.4432\n",
      "Epoch 3222/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1957 - val_loss: 2.6460 - val_mae: 1.4639\n",
      "Epoch 3223/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0511 - mae: 0.1875 - val_loss: 2.7662 - val_mae: 1.5044\n",
      "Epoch 3224/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1708 - val_loss: 2.8830 - val_mae: 1.5428\n",
      "Epoch 3225/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1701 - val_loss: 2.9196 - val_mae: 1.5546\n",
      "Epoch 3226/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1694 - val_loss: 2.8197 - val_mae: 1.5220\n",
      "Epoch 3227/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1709 - val_loss: 2.7032 - val_mae: 1.4832\n",
      "Epoch 3228/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0495 - mae: 0.1837 - val_loss: 2.6685 - val_mae: 1.4714\n",
      "Epoch 3229/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0510 - mae: 0.1900 - val_loss: 2.7125 - val_mae: 1.4863\n",
      "Epoch 3230/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1837 - val_loss: 2.8229 - val_mae: 1.5230\n",
      "Epoch 3231/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1733 - val_loss: 2.9594 - val_mae: 1.5672\n",
      "Epoch 3232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1719 - val_loss: 3.0366 - val_mae: 1.5916\n",
      "Epoch 3233/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0543 - mae: 0.1762 - val_loss: 3.0100 - val_mae: 1.5832\n",
      "Epoch 3234/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1724 - val_loss: 2.8508 - val_mae: 1.5321\n",
      "Epoch 3235/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1675 - val_loss: 2.6517 - val_mae: 1.4656\n",
      "Epoch 3236/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1868 - val_loss: 2.5905 - val_mae: 1.4446\n",
      "Epoch 3237/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1906 - val_loss: 2.6878 - val_mae: 1.4779\n",
      "Epoch 3238/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0463 - mae: 0.1705 - val_loss: 2.8616 - val_mae: 1.5357\n",
      "Epoch 3239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1747 - val_loss: 2.9611 - val_mae: 1.5678\n",
      "Epoch 3240/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0623 - mae: 0.1910 - val_loss: 2.8280 - val_mae: 1.5247\n",
      "Epoch 3241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0506 - mae: 0.1666 - val_loss: 2.5607 - val_mae: 1.4343\n",
      "Epoch 3242/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0517 - mae: 0.1895 - val_loss: 2.3923 - val_mae: 1.3743\n",
      "Epoch 3243/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0649 - mae: 0.2160 - val_loss: 2.4597 - val_mae: 1.3986\n",
      "Epoch 3244/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0546 - mae: 0.1930 - val_loss: 2.7210 - val_mae: 1.4892\n",
      "Epoch 3245/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1692 - val_loss: 2.9418 - val_mae: 1.5616\n",
      "Epoch 3246/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0594 - mae: 0.1891 - val_loss: 2.9346 - val_mae: 1.5592\n",
      "Epoch 3247/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0546 - mae: 0.1820 - val_loss: 2.7831 - val_mae: 1.5098\n",
      "Epoch 3248/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1714 - val_loss: 2.6393 - val_mae: 1.4614\n",
      "Epoch 3249/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1831 - val_loss: 2.5501 - val_mae: 1.4305\n",
      "Epoch 3250/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1975 - val_loss: 2.5535 - val_mae: 1.4317\n",
      "Epoch 3251/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0497 - mae: 0.1819 - val_loss: 2.6650 - val_mae: 1.4702\n",
      "Epoch 3252/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1646 - val_loss: 2.8747 - val_mae: 1.5400\n",
      "Epoch 3253/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0705 - mae: 0.2093 - val_loss: 3.0082 - val_mae: 1.5828\n",
      "Epoch 3254/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0868 - mae: 0.2348 - val_loss: 2.9073 - val_mae: 1.5505\n",
      "Epoch 3255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.1952 - val_loss: 2.6299 - val_mae: 1.4582\n",
      "Epoch 3256/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1945 - val_loss: 2.4584 - val_mae: 1.3980\n",
      "Epoch 3257/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0941 - mae: 0.2622 - val_loss: 2.6140 - val_mae: 1.4526\n",
      "Epoch 3258/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0887 - mae: 0.2534 - val_loss: 3.0010 - val_mae: 1.5803\n",
      "Epoch 3259/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0547 - mae: 0.1889 - val_loss: 3.4931 - val_mae: 1.7291\n",
      "Epoch 3260/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0819 - mae: 0.2151 - val_loss: 3.7504 - val_mae: 1.8020\n",
      "Epoch 3261/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1102 - mae: 0.2696 - val_loss: 3.5079 - val_mae: 1.7334\n",
      "Epoch 3262/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0707 - mae: 0.1984 - val_loss: 3.0052 - val_mae: 1.5817\n",
      "Epoch 3263/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0654 - mae: 0.2099 - val_loss: 2.6451 - val_mae: 1.4634\n",
      "Epoch 3264/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0982 - mae: 0.2679 - val_loss: 2.6060 - val_mae: 1.4499\n",
      "Epoch 3265/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0820 - mae: 0.2442 - val_loss: 2.7660 - val_mae: 1.5042\n",
      "Epoch 3266/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1780 - val_loss: 2.9409 - val_mae: 1.5613\n",
      "Epoch 3267/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0529 - mae: 0.1720 - val_loss: 2.9916 - val_mae: 1.5776\n",
      "Epoch 3268/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0688 - mae: 0.2080 - val_loss: 2.8319 - val_mae: 1.5261\n",
      "Epoch 3269/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.1934 - val_loss: 2.5709 - val_mae: 1.4380\n",
      "Epoch 3270/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0475 - mae: 0.1666 - val_loss: 2.3186 - val_mae: 1.3474\n",
      "Epoch 3271/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0627 - mae: 0.2059 - val_loss: 2.1864 - val_mae: 1.2974\n",
      "Epoch 3272/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0733 - mae: 0.2214 - val_loss: 2.2881 - val_mae: 1.3360\n",
      "Epoch 3273/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0582 - mae: 0.1845 - val_loss: 2.5007 - val_mae: 1.4135\n",
      "Epoch 3274/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0581 - mae: 0.1926 - val_loss: 2.6945 - val_mae: 1.4805\n",
      "Epoch 3275/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0759 - mae: 0.2234 - val_loss: 2.8113 - val_mae: 1.5195\n",
      "Epoch 3276/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0824 - mae: 0.2375 - val_loss: 2.7473 - val_mae: 1.4981\n",
      "Epoch 3277/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0582 - mae: 0.1904 - val_loss: 2.5555 - val_mae: 1.4326\n",
      "Epoch 3278/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0487 - mae: 0.1761 - val_loss: 2.4701 - val_mae: 1.4023\n",
      "Epoch 3279/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0649 - mae: 0.2197 - val_loss: 2.5506 - val_mae: 1.4307\n",
      "Epoch 3280/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0670 - mae: 0.2251 - val_loss: 2.7502 - val_mae: 1.4989\n",
      "Epoch 3281/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0549 - mae: 0.1969 - val_loss: 3.0374 - val_mae: 1.5919\n",
      "Epoch 3282/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0541 - mae: 0.1762 - val_loss: 3.2785 - val_mae: 1.6659\n",
      "Epoch 3283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0672 - mae: 0.1902 - val_loss: 3.3302 - val_mae: 1.6814\n",
      "Epoch 3284/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0686 - mae: 0.1926 - val_loss: 3.1957 - val_mae: 1.6408\n",
      "Epoch 3285/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0585 - mae: 0.1805 - val_loss: 3.0160 - val_mae: 1.5850\n",
      "Epoch 3286/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0578 - mae: 0.1950 - val_loss: 2.9295 - val_mae: 1.5575\n",
      "Epoch 3287/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.2056 - val_loss: 2.9181 - val_mae: 1.5538\n",
      "Epoch 3288/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0552 - mae: 0.1953 - val_loss: 2.9627 - val_mae: 1.5682\n",
      "Epoch 3289/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1742 - val_loss: 2.9639 - val_mae: 1.5686\n",
      "Epoch 3290/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1653 - val_loss: 2.8634 - val_mae: 1.5363\n",
      "Epoch 3291/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0475 - mae: 0.1664 - val_loss: 2.8260 - val_mae: 1.5241\n",
      "Epoch 3292/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0485 - mae: 0.1675 - val_loss: 2.8673 - val_mae: 1.5376\n",
      "Epoch 3293/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0541 - mae: 0.1770 - val_loss: 2.8287 - val_mae: 1.5250\n",
      "Epoch 3294/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1770 - val_loss: 2.6478 - val_mae: 1.4645\n",
      "Epoch 3295/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0480 - mae: 0.1727 - val_loss: 2.4379 - val_mae: 1.3910\n",
      "Epoch 3296/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0553 - mae: 0.1895 - val_loss: 2.3458 - val_mae: 1.3574\n",
      "Epoch 3297/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0632 - mae: 0.2036 - val_loss: 2.3707 - val_mae: 1.3666\n",
      "Epoch 3298/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0599 - mae: 0.1980 - val_loss: 2.4833 - val_mae: 1.4072\n",
      "Epoch 3299/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1840 - val_loss: 2.6767 - val_mae: 1.4744\n",
      "Epoch 3300/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0496 - mae: 0.1764 - val_loss: 2.8207 - val_mae: 1.5225\n",
      "Epoch 3301/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0511 - mae: 0.1746 - val_loss: 2.8694 - val_mae: 1.5384\n",
      "Epoch 3302/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0488 - mae: 0.1701 - val_loss: 2.8009 - val_mae: 1.5159\n",
      "Epoch 3303/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0455 - mae: 0.1684 - val_loss: 2.6886 - val_mae: 1.4783\n",
      "Epoch 3304/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0516 - mae: 0.1910 - val_loss: 2.6390 - val_mae: 1.4615\n",
      "Epoch 3305/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0596 - mae: 0.2090 - val_loss: 2.6964 - val_mae: 1.4810\n",
      "Epoch 3306/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0528 - mae: 0.1911 - val_loss: 2.8633 - val_mae: 1.5363\n",
      "Epoch 3307/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0453 - mae: 0.1705 - val_loss: 3.0194 - val_mae: 1.5864\n",
      "Epoch 3308/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1739 - val_loss: 3.1464 - val_mae: 1.6260\n",
      "Epoch 3309/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0656 - mae: 0.1980 - val_loss: 3.1219 - val_mae: 1.6184\n",
      "Epoch 3310/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1904 - val_loss: 2.9559 - val_mae: 1.5663\n",
      "Epoch 3311/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1731 - val_loss: 2.8582 - val_mae: 1.5348\n",
      "Epoch 3312/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0464 - mae: 0.1755 - val_loss: 2.8390 - val_mae: 1.5285\n",
      "Epoch 3313/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1803 - val_loss: 2.8576 - val_mae: 1.5347\n",
      "Epoch 3314/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1763 - val_loss: 2.9137 - val_mae: 1.5529\n",
      "Epoch 3315/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0461 - mae: 0.1698 - val_loss: 2.9619 - val_mae: 1.5683\n",
      "Epoch 3316/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0489 - mae: 0.1688 - val_loss: 2.9289 - val_mae: 1.5578\n",
      "Epoch 3317/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0489 - mae: 0.1680 - val_loss: 2.8458 - val_mae: 1.5309\n",
      "Epoch 3318/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1683 - val_loss: 2.8292 - val_mae: 1.5255\n",
      "Epoch 3319/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1695 - val_loss: 2.8855 - val_mae: 1.5439\n",
      "Epoch 3320/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1681 - val_loss: 2.9833 - val_mae: 1.5753\n",
      "Epoch 3321/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1685 - val_loss: 2.9847 - val_mae: 1.5758\n",
      "Epoch 3322/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0458 - mae: 0.1667 - val_loss: 2.8366 - val_mae: 1.5282\n",
      "Epoch 3323/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0519 - mae: 0.1905 - val_loss: 2.7250 - val_mae: 1.4914\n",
      "Epoch 3324/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0688 - mae: 0.2211 - val_loss: 2.7382 - val_mae: 1.4959\n",
      "Epoch 3325/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0685 - mae: 0.2186 - val_loss: 2.8901 - val_mae: 1.5458\n",
      "Epoch 3326/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0550 - mae: 0.1911 - val_loss: 3.0577 - val_mae: 1.5992\n",
      "Epoch 3327/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0485 - mae: 0.1780 - val_loss: 3.1360 - val_mae: 1.6235\n",
      "Epoch 3328/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1778 - val_loss: 3.1691 - val_mae: 1.6337\n",
      "Epoch 3329/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1751 - val_loss: 3.1470 - val_mae: 1.6269\n",
      "Epoch 3330/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1700 - val_loss: 3.1087 - val_mae: 1.6151\n",
      "Epoch 3331/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1694 - val_loss: 3.0560 - val_mae: 1.5988\n",
      "Epoch 3332/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0477 - mae: 0.1724 - val_loss: 2.9904 - val_mae: 1.5781\n",
      "Epoch 3333/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1754 - val_loss: 2.9375 - val_mae: 1.5612\n",
      "Epoch 3334/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1787 - val_loss: 2.9187 - val_mae: 1.5551\n",
      "Epoch 3335/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1771 - val_loss: 2.9249 - val_mae: 1.5571\n",
      "Epoch 3336/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1702 - val_loss: 2.9793 - val_mae: 1.5745\n",
      "Epoch 3337/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1672 - val_loss: 3.0151 - val_mae: 1.5859\n",
      "Epoch 3338/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1665 - val_loss: 2.9439 - val_mae: 1.5632\n",
      "Epoch 3339/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1652 - val_loss: 2.7668 - val_mae: 1.5055\n",
      "Epoch 3340/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1771 - val_loss: 2.6551 - val_mae: 1.4680\n",
      "Epoch 3341/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0611 - mae: 0.2114 - val_loss: 2.7007 - val_mae: 1.4836\n",
      "Epoch 3342/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0611 - mae: 0.2086 - val_loss: 2.8922 - val_mae: 1.5469\n",
      "Epoch 3343/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0448 - mae: 0.1691 - val_loss: 3.1531 - val_mae: 1.6291\n",
      "Epoch 3344/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0672 - mae: 0.1995 - val_loss: 3.2393 - val_mae: 1.6554\n",
      "Epoch 3345/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0868 - mae: 0.2350 - val_loss: 3.0418 - val_mae: 1.5947\n",
      "Epoch 3346/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1716 - val_loss: 2.6992 - val_mae: 1.4835\n",
      "Epoch 3347/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0572 - mae: 0.2067 - val_loss: 2.4889 - val_mae: 1.4110\n",
      "Epoch 3348/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1014 - mae: 0.2719 - val_loss: 2.5680 - val_mae: 1.4388\n",
      "Epoch 3349/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0732 - mae: 0.2333 - val_loss: 2.7909 - val_mae: 1.5144\n",
      "Epoch 3350/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1676 - val_loss: 2.8912 - val_mae: 1.5472\n",
      "Epoch 3351/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.1920 - val_loss: 2.8104 - val_mae: 1.5209\n",
      "Epoch 3352/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1907 - val_loss: 2.6440 - val_mae: 1.4652\n",
      "Epoch 3353/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0520 - mae: 0.1719 - val_loss: 2.5277 - val_mae: 1.4250\n",
      "Epoch 3354/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0499 - mae: 0.1730 - val_loss: 2.5149 - val_mae: 1.4206\n",
      "Epoch 3355/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0505 - mae: 0.1823 - val_loss: 2.6216 - val_mae: 1.4580\n",
      "Epoch 3356/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1813 - val_loss: 2.8400 - val_mae: 1.5314\n",
      "Epoch 3357/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1753 - val_loss: 2.9694 - val_mae: 1.5734\n",
      "Epoch 3358/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0481 - mae: 0.1737 - val_loss: 2.9200 - val_mae: 1.5576\n",
      "Epoch 3359/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0496 - mae: 0.1781 - val_loss: 2.8428 - val_mae: 1.5326\n",
      "Epoch 3360/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1898 - val_loss: 2.8187 - val_mae: 1.5246\n",
      "Epoch 3361/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0556 - mae: 0.1931 - val_loss: 2.8380 - val_mae: 1.5308\n",
      "Epoch 3362/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1856 - val_loss: 2.8450 - val_mae: 1.5329\n",
      "Epoch 3363/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0492 - mae: 0.1812 - val_loss: 2.8273 - val_mae: 1.5270\n",
      "Epoch 3364/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0476 - mae: 0.1783 - val_loss: 2.8050 - val_mae: 1.5195\n",
      "Epoch 3365/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0469 - mae: 0.1763 - val_loss: 2.8032 - val_mae: 1.5187\n",
      "Epoch 3366/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0461 - mae: 0.1723 - val_loss: 2.7361 - val_mae: 1.4962\n",
      "Epoch 3367/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0461 - mae: 0.1717 - val_loss: 2.6443 - val_mae: 1.4649\n",
      "Epoch 3368/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1721 - val_loss: 2.6442 - val_mae: 1.4647\n",
      "Epoch 3369/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1655 - val_loss: 2.6843 - val_mae: 1.4783\n",
      "Epoch 3370/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1647 - val_loss: 2.7781 - val_mae: 1.5096\n",
      "Epoch 3371/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0564 - mae: 0.1782 - val_loss: 2.7818 - val_mae: 1.5108\n",
      "Epoch 3372/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1663 - val_loss: 2.7248 - val_mae: 1.4918\n",
      "Epoch 3373/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1700 - val_loss: 2.7665 - val_mae: 1.5058\n",
      "Epoch 3374/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0515 - mae: 0.1835 - val_loss: 2.8123 - val_mae: 1.5210\n",
      "Epoch 3375/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1885 - val_loss: 2.8265 - val_mae: 1.5256\n",
      "Epoch 3376/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1878 - val_loss: 2.7926 - val_mae: 1.5144\n",
      "Epoch 3377/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1897 - val_loss: 2.8227 - val_mae: 1.5243\n",
      "Epoch 3378/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0523 - mae: 0.1836 - val_loss: 2.9302 - val_mae: 1.5592\n",
      "Epoch 3379/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1754 - val_loss: 2.9865 - val_mae: 1.5772\n",
      "Epoch 3380/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1695 - val_loss: 2.9637 - val_mae: 1.5699\n",
      "Epoch 3381/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1672 - val_loss: 2.9207 - val_mae: 1.5561\n",
      "Epoch 3382/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1640 - val_loss: 2.7869 - val_mae: 1.5125\n",
      "Epoch 3383/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0458 - mae: 0.1626 - val_loss: 2.5938 - val_mae: 1.4472\n",
      "Epoch 3384/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1845 - val_loss: 2.5097 - val_mae: 1.4179\n",
      "Epoch 3385/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.2100 - val_loss: 2.5459 - val_mae: 1.4307\n",
      "Epoch 3386/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.2057 - val_loss: 2.6953 - val_mae: 1.4820\n",
      "Epoch 3387/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1779 - val_loss: 2.9411 - val_mae: 1.5628\n",
      "Epoch 3388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0480 - mae: 0.1727 - val_loss: 3.1395 - val_mae: 1.6250\n",
      "Epoch 3389/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0612 - mae: 0.1912 - val_loss: 3.1526 - val_mae: 1.6290\n",
      "Epoch 3390/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1827 - val_loss: 3.0356 - val_mae: 1.5926\n",
      "Epoch 3391/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0482 - mae: 0.1651 - val_loss: 2.9342 - val_mae: 1.5604\n",
      "Epoch 3392/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0475 - mae: 0.1767 - val_loss: 2.9030 - val_mae: 1.5503\n",
      "Epoch 3393/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0497 - mae: 0.1841 - val_loss: 2.8820 - val_mae: 1.5435\n",
      "Epoch 3394/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1865 - val_loss: 2.8773 - val_mae: 1.5419\n",
      "Epoch 3395/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1824 - val_loss: 2.8884 - val_mae: 1.5454\n",
      "Epoch 3396/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0511 - mae: 0.1743 - val_loss: 2.8996 - val_mae: 1.5490\n",
      "Epoch 3397/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1711 - val_loss: 2.8920 - val_mae: 1.5466\n",
      "Epoch 3398/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1710 - val_loss: 2.8606 - val_mae: 1.5364\n",
      "Epoch 3399/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1695 - val_loss: 2.8933 - val_mae: 1.5470\n",
      "Epoch 3400/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0464 - mae: 0.1630 - val_loss: 2.9243 - val_mae: 1.5570\n",
      "Epoch 3401/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1622 - val_loss: 2.8329 - val_mae: 1.5274\n",
      "Epoch 3402/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0462 - mae: 0.1723 - val_loss: 2.7354 - val_mae: 1.4951\n",
      "Epoch 3403/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1913 - val_loss: 2.7150 - val_mae: 1.4883\n",
      "Epoch 3404/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0630 - mae: 0.2039 - val_loss: 2.7027 - val_mae: 1.4842\n",
      "Epoch 3405/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0612 - mae: 0.2021 - val_loss: 2.7122 - val_mae: 1.4874\n",
      "Epoch 3406/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0519 - mae: 0.1882 - val_loss: 2.6862 - val_mae: 1.4786\n",
      "Epoch 3407/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1771 - val_loss: 2.6643 - val_mae: 1.4712\n",
      "Epoch 3408/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0458 - mae: 0.1708 - val_loss: 2.6490 - val_mae: 1.4660\n",
      "Epoch 3409/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1668 - val_loss: 2.5970 - val_mae: 1.4481\n",
      "Epoch 3410/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1708 - val_loss: 2.5725 - val_mae: 1.4397\n",
      "Epoch 3411/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1717 - val_loss: 2.6427 - val_mae: 1.4639\n",
      "Epoch 3412/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1738 - val_loss: 2.7568 - val_mae: 1.5024\n",
      "Epoch 3413/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0552 - mae: 0.1747 - val_loss: 2.8370 - val_mae: 1.5288\n",
      "Epoch 3414/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0530 - mae: 0.1697 - val_loss: 2.8618 - val_mae: 1.5369\n",
      "Epoch 3415/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1602 - val_loss: 2.7556 - val_mae: 1.5019\n",
      "Epoch 3416/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0485 - mae: 0.1779 - val_loss: 2.6813 - val_mae: 1.4770\n",
      "Epoch 3417/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0516 - mae: 0.1949 - val_loss: 2.7617 - val_mae: 1.5039\n",
      "Epoch 3418/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1815 - val_loss: 2.9323 - val_mae: 1.5597\n",
      "Epoch 3419/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1652 - val_loss: 3.1666 - val_mae: 1.6331\n",
      "Epoch 3420/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0633 - mae: 0.1890 - val_loss: 3.2244 - val_mae: 1.6507\n",
      "Epoch 3421/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0623 - mae: 0.1910 - val_loss: 3.0494 - val_mae: 1.5968\n",
      "Epoch 3422/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0555 - mae: 0.1862 - val_loss: 2.9450 - val_mae: 1.5638\n",
      "Epoch 3423/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0566 - mae: 0.1894 - val_loss: 2.9832 - val_mae: 1.5760\n",
      "Epoch 3424/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1827 - val_loss: 2.9981 - val_mae: 1.5807\n",
      "Epoch 3425/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1753 - val_loss: 2.9194 - val_mae: 1.5556\n",
      "Epoch 3426/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0467 - mae: 0.1713 - val_loss: 2.8391 - val_mae: 1.5296\n",
      "Epoch 3427/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0452 - mae: 0.1692 - val_loss: 2.7260 - val_mae: 1.4921\n",
      "Epoch 3428/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0459 - mae: 0.1753 - val_loss: 2.5679 - val_mae: 1.4381\n",
      "Epoch 3429/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1865 - val_loss: 2.4581 - val_mae: 1.3994\n",
      "Epoch 3430/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0521 - mae: 0.1868 - val_loss: 2.4624 - val_mae: 1.4010\n",
      "Epoch 3431/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1726 - val_loss: 2.5331 - val_mae: 1.4260\n",
      "Epoch 3432/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1697 - val_loss: 2.5409 - val_mae: 1.4287\n",
      "Epoch 3433/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0474 - mae: 0.1672 - val_loss: 2.4912 - val_mae: 1.4111\n",
      "Epoch 3434/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1793 - val_loss: 2.5830 - val_mae: 1.4432\n",
      "Epoch 3435/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1838 - val_loss: 2.9101 - val_mae: 1.5524\n",
      "Epoch 3436/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1846 - val_loss: 3.2465 - val_mae: 1.6573\n",
      "Epoch 3437/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0712 - mae: 0.2097 - val_loss: 3.4355 - val_mae: 1.7134\n",
      "Epoch 3438/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0831 - mae: 0.2258 - val_loss: 3.3871 - val_mae: 1.6992\n",
      "Epoch 3439/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0755 - mae: 0.2065 - val_loss: 3.1638 - val_mae: 1.6321\n",
      "Epoch 3440/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0741 - mae: 0.2037 - val_loss: 3.1062 - val_mae: 1.6145\n",
      "Epoch 3441/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0637 - mae: 0.1941 - val_loss: 3.2293 - val_mae: 1.6523\n",
      "Epoch 3442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0639 - mae: 0.1884 - val_loss: 3.1787 - val_mae: 1.6371\n",
      "Epoch 3443/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0599 - mae: 0.1800 - val_loss: 2.9618 - val_mae: 1.5694\n",
      "Epoch 3444/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1698 - val_loss: 2.7549 - val_mae: 1.5021\n",
      "Epoch 3445/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0486 - mae: 0.1820 - val_loss: 2.5802 - val_mae: 1.4428\n",
      "Epoch 3446/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0544 - mae: 0.1988 - val_loss: 2.4954 - val_mae: 1.4131\n",
      "Epoch 3447/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0573 - mae: 0.2048 - val_loss: 2.5227 - val_mae: 1.4228\n",
      "Epoch 3448/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0524 - mae: 0.1903 - val_loss: 2.6410 - val_mae: 1.4638\n",
      "Epoch 3449/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0462 - mae: 0.1710 - val_loss: 2.8070 - val_mae: 1.5196\n",
      "Epoch 3450/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1780 - val_loss: 2.9074 - val_mae: 1.5523\n",
      "Epoch 3451/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0537 - mae: 0.1866 - val_loss: 2.8390 - val_mae: 1.5301\n",
      "Epoch 3452/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1849 - val_loss: 2.7985 - val_mae: 1.5169\n",
      "Epoch 3453/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1908 - val_loss: 2.8418 - val_mae: 1.5311\n",
      "Epoch 3454/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.1980 - val_loss: 2.8450 - val_mae: 1.5322\n",
      "Epoch 3455/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0610 - mae: 0.2007 - val_loss: 2.8861 - val_mae: 1.5455\n",
      "Epoch 3456/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1909 - val_loss: 2.9322 - val_mae: 1.5604\n",
      "Epoch 3457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0494 - mae: 0.1808 - val_loss: 2.9320 - val_mae: 1.5603\n",
      "Epoch 3458/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1741 - val_loss: 2.8576 - val_mae: 1.5362\n",
      "Epoch 3459/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0456 - mae: 0.1697 - val_loss: 2.6889 - val_mae: 1.4802\n",
      "Epoch 3460/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1727 - val_loss: 2.4982 - val_mae: 1.4143\n",
      "Epoch 3461/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0547 - mae: 0.1942 - val_loss: 2.4195 - val_mae: 1.3861\n",
      "Epoch 3462/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0586 - mae: 0.2003 - val_loss: 2.4690 - val_mae: 1.4039\n",
      "Epoch 3463/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0525 - mae: 0.1850 - val_loss: 2.6184 - val_mae: 1.4561\n",
      "Epoch 3464/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1759 - val_loss: 2.8211 - val_mae: 1.5242\n",
      "Epoch 3465/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1729 - val_loss: 2.9212 - val_mae: 1.5567\n",
      "Epoch 3466/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0484 - mae: 0.1716 - val_loss: 2.9151 - val_mae: 1.5547\n",
      "Epoch 3467/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1687 - val_loss: 2.8588 - val_mae: 1.5365\n",
      "Epoch 3468/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0527 - mae: 0.1858 - val_loss: 2.8431 - val_mae: 1.5314\n",
      "Epoch 3469/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1905 - val_loss: 2.8982 - val_mae: 1.5492\n",
      "Epoch 3470/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0460 - mae: 0.1731 - val_loss: 3.0092 - val_mae: 1.5846\n",
      "Epoch 3471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1694 - val_loss: 3.0320 - val_mae: 1.5917\n",
      "Epoch 3472/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1730 - val_loss: 2.9492 - val_mae: 1.5654\n",
      "Epoch 3473/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0463 - mae: 0.1715 - val_loss: 2.9011 - val_mae: 1.5498\n",
      "Epoch 3474/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0463 - mae: 0.1747 - val_loss: 2.8685 - val_mae: 1.5393\n",
      "Epoch 3475/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1786 - val_loss: 2.8392 - val_mae: 1.5296\n",
      "Epoch 3476/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1809 - val_loss: 2.7817 - val_mae: 1.5107\n",
      "Epoch 3477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1832 - val_loss: 2.7238 - val_mae: 1.4914\n",
      "Epoch 3478/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1783 - val_loss: 2.7342 - val_mae: 1.4949\n",
      "Epoch 3479/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0494 - mae: 0.1758 - val_loss: 2.7154 - val_mae: 1.4887\n",
      "Epoch 3480/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1730 - val_loss: 2.7034 - val_mae: 1.4846\n",
      "Epoch 3481/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1694 - val_loss: 2.7393 - val_mae: 1.4966\n",
      "Epoch 3482/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1669 - val_loss: 2.7346 - val_mae: 1.4950\n",
      "Epoch 3483/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1681 - val_loss: 2.7613 - val_mae: 1.5039\n",
      "Epoch 3484/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1688 - val_loss: 2.8244 - val_mae: 1.5248\n",
      "Epoch 3485/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0445 - mae: 0.1664 - val_loss: 2.8688 - val_mae: 1.5393\n",
      "Epoch 3486/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0447 - mae: 0.1639 - val_loss: 2.8393 - val_mae: 1.5296\n",
      "Epoch 3487/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0441 - mae: 0.1640 - val_loss: 2.7378 - val_mae: 1.4961\n",
      "Epoch 3488/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0450 - mae: 0.1707 - val_loss: 2.6298 - val_mae: 1.4595\n",
      "Epoch 3489/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1815 - val_loss: 2.5682 - val_mae: 1.4382\n",
      "Epoch 3490/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0502 - mae: 0.1845 - val_loss: 2.5915 - val_mae: 1.4463\n",
      "Epoch 3491/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1760 - val_loss: 2.6916 - val_mae: 1.4805\n",
      "Epoch 3492/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0450 - mae: 0.1688 - val_loss: 2.8145 - val_mae: 1.5215\n",
      "Epoch 3493/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0477 - mae: 0.1700 - val_loss: 2.9063 - val_mae: 1.5514\n",
      "Epoch 3494/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1681 - val_loss: 2.8762 - val_mae: 1.5416\n",
      "Epoch 3495/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0463 - mae: 0.1616 - val_loss: 2.8157 - val_mae: 1.5218\n",
      "Epoch 3496/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1667 - val_loss: 2.7785 - val_mae: 1.5095\n",
      "Epoch 3497/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1799 - val_loss: 2.7581 - val_mae: 1.5027\n",
      "Epoch 3498/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0487 - mae: 0.1853 - val_loss: 2.7723 - val_mae: 1.5075\n",
      "Epoch 3499/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0472 - mae: 0.1792 - val_loss: 2.8184 - val_mae: 1.5227\n",
      "Epoch 3500/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0442 - mae: 0.1657 - val_loss: 2.9243 - val_mae: 1.5572\n",
      "Epoch 3501/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0475 - mae: 0.1632 - val_loss: 3.0324 - val_mae: 1.5916\n",
      "Epoch 3502/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0577 - mae: 0.1788 - val_loss: 3.0182 - val_mae: 1.5871\n",
      "Epoch 3503/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0569 - mae: 0.1756 - val_loss: 2.9213 - val_mae: 1.5563\n",
      "Epoch 3504/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0488 - mae: 0.1618 - val_loss: 2.8701 - val_mae: 1.5397\n",
      "Epoch 3505/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0465 - mae: 0.1628 - val_loss: 2.8099 - val_mae: 1.5201\n",
      "Epoch 3506/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0465 - mae: 0.1735 - val_loss: 2.8025 - val_mae: 1.5177\n",
      "Epoch 3507/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0462 - mae: 0.1742 - val_loss: 2.9254 - val_mae: 1.5577\n",
      "Epoch 3508/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0465 - mae: 0.1620 - val_loss: 3.1043 - val_mae: 1.6141\n",
      "Epoch 3509/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0545 - mae: 0.1653 - val_loss: 3.0913 - val_mae: 1.6101\n",
      "Epoch 3510/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0516 - mae: 0.1624 - val_loss: 2.9065 - val_mae: 1.5517\n",
      "Epoch 3511/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0453 - mae: 0.1664 - val_loss: 2.7551 - val_mae: 1.5021\n",
      "Epoch 3512/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0473 - mae: 0.1817 - val_loss: 2.6820 - val_mae: 1.4775\n",
      "Epoch 3513/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0503 - mae: 0.1918 - val_loss: 2.6855 - val_mae: 1.4787\n",
      "Epoch 3514/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0483 - mae: 0.1849 - val_loss: 2.7507 - val_mae: 1.5006\n",
      "Epoch 3515/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0438 - mae: 0.1664 - val_loss: 2.8918 - val_mae: 1.5470\n",
      "Epoch 3516/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0470 - mae: 0.1642 - val_loss: 3.0398 - val_mae: 1.5942\n",
      "Epoch 3517/5000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0587 - mae: 0.1860 - val_loss: 3.0431 - val_mae: 1.5952\n",
      "Epoch 3518/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0527 - mae: 0.1736 - val_loss: 2.9212 - val_mae: 1.5565\n",
      "Epoch 3519/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0482 - mae: 0.1771 - val_loss: 2.8247 - val_mae: 1.5252\n",
      "Epoch 3520/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0525 - mae: 0.1862 - val_loss: 2.7662 - val_mae: 1.5060\n",
      "Epoch 3521/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0522 - mae: 0.1895 - val_loss: 2.7571 - val_mae: 1.5030\n",
      "Epoch 3522/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0471 - mae: 0.1762 - val_loss: 2.7430 - val_mae: 1.4984\n",
      "Epoch 3523/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0444 - mae: 0.1630 - val_loss: 2.6792 - val_mae: 1.4770\n",
      "Epoch 3524/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0467 - mae: 0.1648 - val_loss: 2.6462 - val_mae: 1.4659\n",
      "Epoch 3525/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0496 - mae: 0.1683 - val_loss: 2.5773 - val_mae: 1.4422\n",
      "Epoch 3526/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0453 - mae: 0.1644 - val_loss: 2.4499 - val_mae: 1.3973\n",
      "Epoch 3527/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0557 - mae: 0.1963 - val_loss: 2.3619 - val_mae: 1.3655\n",
      "Epoch 3528/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0797 - mae: 0.2282 - val_loss: 2.4080 - val_mae: 1.3823\n",
      "Epoch 3529/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0804 - mae: 0.2228 - val_loss: 2.5930 - val_mae: 1.4478\n",
      "Epoch 3530/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0622 - mae: 0.2078 - val_loss: 2.8502 - val_mae: 1.5341\n",
      "Epoch 3531/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0582 - mae: 0.2052 - val_loss: 3.0120 - val_mae: 1.5861\n",
      "Epoch 3532/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0606 - mae: 0.2005 - val_loss: 3.0473 - val_mae: 1.5972\n",
      "Epoch 3533/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0557 - mae: 0.1851 - val_loss: 2.9776 - val_mae: 1.5752\n",
      "Epoch 3534/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0489 - mae: 0.1679 - val_loss: 2.8186 - val_mae: 1.5239\n",
      "Epoch 3535/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0472 - mae: 0.1713 - val_loss: 2.7614 - val_mae: 1.5050\n",
      "Epoch 3536/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0480 - mae: 0.1781 - val_loss: 2.8168 - val_mae: 1.5234\n",
      "Epoch 3537/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0487 - mae: 0.1776 - val_loss: 2.8807 - val_mae: 1.5443\n",
      "Epoch 3538/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0493 - mae: 0.1774 - val_loss: 2.9037 - val_mae: 1.5517\n",
      "Epoch 3539/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489 - mae: 0.1763 - val_loss: 2.8632 - val_mae: 1.5386\n",
      "Epoch 3540/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0479 - mae: 0.1774 - val_loss: 2.7447 - val_mae: 1.4995\n",
      "Epoch 3541/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0494 - mae: 0.1848 - val_loss: 2.6364 - val_mae: 1.4629\n",
      "Epoch 3542/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0496 - mae: 0.1854 - val_loss: 2.6240 - val_mae: 1.4586\n",
      "Epoch 3543/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0454 - mae: 0.1723 - val_loss: 2.6655 - val_mae: 1.4727\n",
      "Epoch 3544/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0467 - mae: 0.1709 - val_loss: 2.6818 - val_mae: 1.4782\n",
      "Epoch 3545/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0506 - mae: 0.1775 - val_loss: 2.5602 - val_mae: 1.4364\n",
      "Epoch 3546/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1719 - val_loss: 2.3434 - val_mae: 1.3587\n",
      "Epoch 3547/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0548 - mae: 0.1811 - val_loss: 2.1536 - val_mae: 1.2869\n",
      "Epoch 3548/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0757 - mae: 0.2222 - val_loss: 2.0991 - val_mae: 1.2655\n",
      "Epoch 3549/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0840 - mae: 0.2349 - val_loss: 2.2441 - val_mae: 1.3216\n",
      "Epoch 3550/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0605 - mae: 0.1922 - val_loss: 2.5496 - val_mae: 1.4325\n",
      "Epoch 3551/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1750 - val_loss: 2.8358 - val_mae: 1.5292\n",
      "Epoch 3552/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0658 - mae: 0.2047 - val_loss: 2.9568 - val_mae: 1.5682\n",
      "Epoch 3553/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0721 - mae: 0.2155 - val_loss: 2.8666 - val_mae: 1.5391\n",
      "Epoch 3554/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0529 - mae: 0.1723 - val_loss: 2.6438 - val_mae: 1.4648\n",
      "Epoch 3555/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1749 - val_loss: 2.5215 - val_mae: 1.4224\n",
      "Epoch 3556/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0540 - mae: 0.1986 - val_loss: 2.6075 - val_mae: 1.4523\n",
      "Epoch 3557/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1779 - val_loss: 2.7686 - val_mae: 1.5069\n",
      "Epoch 3558/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1620 - val_loss: 2.8543 - val_mae: 1.5351\n",
      "Epoch 3559/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1746 - val_loss: 2.8458 - val_mae: 1.5324\n",
      "Epoch 3560/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1781 - val_loss: 2.7051 - val_mae: 1.4857\n",
      "Epoch 3561/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0478 - mae: 0.1691 - val_loss: 2.5630 - val_mae: 1.4371\n",
      "Epoch 3562/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1723 - val_loss: 2.5877 - val_mae: 1.4457\n",
      "Epoch 3563/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0449 - mae: 0.1695 - val_loss: 2.7020 - val_mae: 1.4847\n",
      "Epoch 3564/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0453 - mae: 0.1613 - val_loss: 2.8019 - val_mae: 1.5180\n",
      "Epoch 3565/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1612 - val_loss: 2.8225 - val_mae: 1.5247\n",
      "Epoch 3566/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0462 - mae: 0.1589 - val_loss: 2.7655 - val_mae: 1.5059\n",
      "Epoch 3567/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0439 - mae: 0.1622 - val_loss: 2.7094 - val_mae: 1.4871\n",
      "Epoch 3568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1711 - val_loss: 2.6647 - val_mae: 1.4719\n",
      "Epoch 3569/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1851 - val_loss: 2.6657 - val_mae: 1.4723\n",
      "Epoch 3570/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0485 - mae: 0.1842 - val_loss: 2.7585 - val_mae: 1.5035\n",
      "Epoch 3571/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0446 - mae: 0.1680 - val_loss: 2.8557 - val_mae: 1.5355\n",
      "Epoch 3572/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0443 - mae: 0.1617 - val_loss: 2.8862 - val_mae: 1.5455\n",
      "Epoch 3573/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0456 - mae: 0.1608 - val_loss: 2.8360 - val_mae: 1.5291\n",
      "Epoch 3574/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0443 - mae: 0.1598 - val_loss: 2.7100 - val_mae: 1.4873\n",
      "Epoch 3575/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1652 - val_loss: 2.5851 - val_mae: 1.4447\n",
      "Epoch 3576/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0486 - mae: 0.1818 - val_loss: 2.5630 - val_mae: 1.4371\n",
      "Epoch 3577/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1811 - val_loss: 2.6700 - val_mae: 1.4738\n",
      "Epoch 3578/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1662 - val_loss: 2.8018 - val_mae: 1.5179\n",
      "Epoch 3579/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0458 - mae: 0.1621 - val_loss: 2.8940 - val_mae: 1.5480\n",
      "Epoch 3580/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1650 - val_loss: 2.9226 - val_mae: 1.5572\n",
      "Epoch 3581/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0487 - mae: 0.1614 - val_loss: 2.8521 - val_mae: 1.5344\n",
      "Epoch 3582/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0444 - mae: 0.1590 - val_loss: 2.7452 - val_mae: 1.4990\n",
      "Epoch 3583/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0454 - mae: 0.1728 - val_loss: 2.6910 - val_mae: 1.4808\n",
      "Epoch 3584/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0480 - mae: 0.1839 - val_loss: 2.6855 - val_mae: 1.4790\n",
      "Epoch 3585/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0463 - mae: 0.1774 - val_loss: 2.7119 - val_mae: 1.4880\n",
      "Epoch 3586/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0441 - mae: 0.1656 - val_loss: 2.7134 - val_mae: 1.4885\n",
      "Epoch 3587/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1628 - val_loss: 2.7021 - val_mae: 1.4848\n",
      "Epoch 3588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1644 - val_loss: 2.6714 - val_mae: 1.4744\n",
      "Epoch 3589/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1657 - val_loss: 2.6714 - val_mae: 1.4744\n",
      "Epoch 3590/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0471 - mae: 0.1645 - val_loss: 2.6601 - val_mae: 1.4705\n",
      "Epoch 3591/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0444 - mae: 0.1630 - val_loss: 2.6093 - val_mae: 1.4530\n",
      "Epoch 3592/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0510 - mae: 0.1901 - val_loss: 2.6816 - val_mae: 1.4777\n",
      "Epoch 3593/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.1948 - val_loss: 2.8135 - val_mae: 1.5217\n",
      "Epoch 3594/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1821 - val_loss: 2.9619 - val_mae: 1.5697\n",
      "Epoch 3595/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1739 - val_loss: 3.1562 - val_mae: 1.6305\n",
      "Epoch 3596/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0535 - mae: 0.1732 - val_loss: 3.3083 - val_mae: 1.6765\n",
      "Epoch 3597/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0635 - mae: 0.1855 - val_loss: 3.1827 - val_mae: 1.6386\n",
      "Epoch 3598/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1647 - val_loss: 2.8655 - val_mae: 1.5387\n",
      "Epoch 3599/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0471 - mae: 0.1770 - val_loss: 2.6589 - val_mae: 1.4701\n",
      "Epoch 3600/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0503 - mae: 0.1934 - val_loss: 2.6362 - val_mae: 1.4624\n",
      "Epoch 3601/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0470 - mae: 0.1783 - val_loss: 2.6837 - val_mae: 1.4786\n",
      "Epoch 3602/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1640 - val_loss: 2.7180 - val_mae: 1.4901\n",
      "Epoch 3603/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1710 - val_loss: 2.7033 - val_mae: 1.4852\n",
      "Epoch 3604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1735 - val_loss: 2.7074 - val_mae: 1.4866\n",
      "Epoch 3605/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0458 - mae: 0.1727 - val_loss: 2.6837 - val_mae: 1.4786\n",
      "Epoch 3606/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0444 - mae: 0.1702 - val_loss: 2.5850 - val_mae: 1.4448\n",
      "Epoch 3607/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0462 - mae: 0.1744 - val_loss: 2.5476 - val_mae: 1.4318\n",
      "Epoch 3608/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1770 - val_loss: 2.5946 - val_mae: 1.4482\n",
      "Epoch 3609/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0454 - mae: 0.1693 - val_loss: 2.6749 - val_mae: 1.4757\n",
      "Epoch 3610/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1614 - val_loss: 2.8189 - val_mae: 1.5237\n",
      "Epoch 3611/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0452 - mae: 0.1624 - val_loss: 2.9859 - val_mae: 1.5775\n",
      "Epoch 3612/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1633 - val_loss: 2.9886 - val_mae: 1.5783\n",
      "Epoch 3613/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0485 - mae: 0.1649 - val_loss: 2.9422 - val_mae: 1.5635\n",
      "Epoch 3614/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0476 - mae: 0.1664 - val_loss: 2.9170 - val_mae: 1.5554\n",
      "Epoch 3615/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0474 - mae: 0.1671 - val_loss: 2.8151 - val_mae: 1.5223\n",
      "Epoch 3616/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0477 - mae: 0.1747 - val_loss: 2.6839 - val_mae: 1.4786\n",
      "Epoch 3617/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1870 - val_loss: 2.6422 - val_mae: 1.4645\n",
      "Epoch 3618/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0458 - mae: 0.1740 - val_loss: 2.6891 - val_mae: 1.4806\n",
      "Epoch 3619/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1584 - val_loss: 2.7361 - val_mae: 1.4965\n",
      "Epoch 3620/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1702 - val_loss: 2.7020 - val_mae: 1.4851\n",
      "Epoch 3621/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1707 - val_loss: 2.5939 - val_mae: 1.4482\n",
      "Epoch 3622/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0467 - mae: 0.1635 - val_loss: 2.4094 - val_mae: 1.3829\n",
      "Epoch 3623/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1909 - val_loss: 2.2933 - val_mae: 1.3403\n",
      "Epoch 3624/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0755 - mae: 0.2308 - val_loss: 2.3455 - val_mae: 1.3597\n",
      "Epoch 3625/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0710 - mae: 0.2231 - val_loss: 2.5583 - val_mae: 1.4358\n",
      "Epoch 3626/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0481 - mae: 0.1790 - val_loss: 2.8918 - val_mae: 1.5477\n",
      "Epoch 3627/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1659 - val_loss: 3.0972 - val_mae: 1.6127\n",
      "Epoch 3628/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0580 - mae: 0.1814 - val_loss: 3.0378 - val_mae: 1.5941\n",
      "Epoch 3629/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0484 - mae: 0.1644 - val_loss: 2.8361 - val_mae: 1.5295\n",
      "Epoch 3630/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1903 - val_loss: 2.7126 - val_mae: 1.4885\n",
      "Epoch 3631/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0680 - mae: 0.2186 - val_loss: 2.8016 - val_mae: 1.5181\n",
      "Epoch 3632/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0561 - mae: 0.1932 - val_loss: 3.0191 - val_mae: 1.5882\n",
      "Epoch 3633/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0492 - mae: 0.1676 - val_loss: 3.1595 - val_mae: 1.6319\n",
      "Epoch 3634/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0601 - mae: 0.1821 - val_loss: 3.1302 - val_mae: 1.6230\n",
      "Epoch 3635/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1836 - val_loss: 2.8980 - val_mae: 1.5497\n",
      "Epoch 3636/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0471 - mae: 0.1629 - val_loss: 2.6184 - val_mae: 1.4566\n",
      "Epoch 3637/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0529 - mae: 0.1986 - val_loss: 2.4597 - val_mae: 1.4010\n",
      "Epoch 3638/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0704 - mae: 0.2297 - val_loss: 2.4551 - val_mae: 1.3994\n",
      "Epoch 3639/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0607 - mae: 0.2121 - val_loss: 2.6547 - val_mae: 1.4691\n",
      "Epoch 3640/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0429 - mae: 0.1585 - val_loss: 2.9106 - val_mae: 1.5539\n",
      "Epoch 3641/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0717 - mae: 0.2119 - val_loss: 2.9244 - val_mae: 1.5583\n",
      "Epoch 3642/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0669 - mae: 0.2069 - val_loss: 2.7090 - val_mae: 1.4875\n",
      "Epoch 3643/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0449 - mae: 0.1650 - val_loss: 2.5578 - val_mae: 1.4356\n",
      "Epoch 3644/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1882 - val_loss: 2.5998 - val_mae: 1.4502\n",
      "Epoch 3645/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0558 - mae: 0.1915 - val_loss: 2.7949 - val_mae: 1.5160\n",
      "Epoch 3646/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0505 - mae: 0.1776 - val_loss: 2.9327 - val_mae: 1.5608\n",
      "Epoch 3647/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0511 - mae: 0.1739 - val_loss: 2.9661 - val_mae: 1.5715\n",
      "Epoch 3648/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1743 - val_loss: 2.9437 - val_mae: 1.5643\n",
      "Epoch 3649/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1746 - val_loss: 2.9384 - val_mae: 1.5627\n",
      "Epoch 3650/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0511 - mae: 0.1722 - val_loss: 2.8970 - val_mae: 1.5494\n",
      "Epoch 3651/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0473 - mae: 0.1682 - val_loss: 2.7185 - val_mae: 1.4907\n",
      "Epoch 3652/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0484 - mae: 0.1790 - val_loss: 2.6152 - val_mae: 1.4557\n",
      "Epoch 3653/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1815 - val_loss: 2.6581 - val_mae: 1.4704\n",
      "Epoch 3654/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0439 - mae: 0.1608 - val_loss: 2.7779 - val_mae: 1.5107\n",
      "Epoch 3655/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1635 - val_loss: 2.8907 - val_mae: 1.5477\n",
      "Epoch 3656/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0600 - mae: 0.1851 - val_loss: 2.8410 - val_mae: 1.5315\n",
      "Epoch 3657/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1728 - val_loss: 2.6876 - val_mae: 1.4805\n",
      "Epoch 3658/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1607 - val_loss: 2.5641 - val_mae: 1.4382\n",
      "Epoch 3659/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0466 - mae: 0.1760 - val_loss: 2.4739 - val_mae: 1.4064\n",
      "Epoch 3660/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0538 - mae: 0.1973 - val_loss: 2.4293 - val_mae: 1.3904\n",
      "Epoch 3661/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.2018 - val_loss: 2.5102 - val_mae: 1.4192\n",
      "Epoch 3662/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0482 - mae: 0.1798 - val_loss: 2.6806 - val_mae: 1.4781\n",
      "Epoch 3663/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1678 - val_loss: 2.8517 - val_mae: 1.5350\n",
      "Epoch 3664/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1862 - val_loss: 2.9456 - val_mae: 1.5653\n",
      "Epoch 3665/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0641 - mae: 0.2000 - val_loss: 2.8982 - val_mae: 1.5500\n",
      "Epoch 3666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.1743 - val_loss: 2.7701 - val_mae: 1.5081\n",
      "Epoch 3667/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1574 - val_loss: 2.6791 - val_mae: 1.4776\n",
      "Epoch 3668/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1707 - val_loss: 2.7253 - val_mae: 1.4931\n",
      "Epoch 3669/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0444 - mae: 0.1712 - val_loss: 2.9575 - val_mae: 1.5690\n",
      "Epoch 3670/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0509 - mae: 0.1644 - val_loss: 3.1080 - val_mae: 1.6163\n",
      "Epoch 3671/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0525 - mae: 0.1617 - val_loss: 3.0569 - val_mae: 1.6004\n",
      "Epoch 3672/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0482 - mae: 0.1636 - val_loss: 2.9590 - val_mae: 1.5695\n",
      "Epoch 3673/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0506 - mae: 0.1821 - val_loss: 2.8822 - val_mae: 1.5448\n",
      "Epoch 3674/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0535 - mae: 0.1953 - val_loss: 2.8466 - val_mae: 1.5332\n",
      "Epoch 3675/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0496 - mae: 0.1878 - val_loss: 2.7128 - val_mae: 1.4890\n",
      "Epoch 3676/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1873 - val_loss: 2.5349 - val_mae: 1.4281\n",
      "Epoch 3677/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0521 - mae: 0.1950 - val_loss: 2.4889 - val_mae: 1.4119\n",
      "Epoch 3678/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0491 - mae: 0.1782 - val_loss: 2.5571 - val_mae: 1.4360\n",
      "Epoch 3679/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0480 - mae: 0.1681 - val_loss: 2.5914 - val_mae: 1.4479\n",
      "Epoch 3680/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0520 - mae: 0.1770 - val_loss: 2.5395 - val_mae: 1.4300\n",
      "Epoch 3681/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0535 - mae: 0.1778 - val_loss: 2.5200 - val_mae: 1.4231\n",
      "Epoch 3682/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0519 - mae: 0.1712 - val_loss: 2.5680 - val_mae: 1.4399\n",
      "Epoch 3683/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0513 - mae: 0.1689 - val_loss: 2.6750 - val_mae: 1.4766\n",
      "Epoch 3684/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1662 - val_loss: 2.7952 - val_mae: 1.5167\n",
      "Epoch 3685/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0519 - mae: 0.1661 - val_loss: 2.7901 - val_mae: 1.5150\n",
      "Epoch 3686/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0466 - mae: 0.1585 - val_loss: 2.7141 - val_mae: 1.4896\n",
      "Epoch 3687/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0436 - mae: 0.1639 - val_loss: 2.6401 - val_mae: 1.4645\n",
      "Epoch 3688/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1827 - val_loss: 2.6879 - val_mae: 1.4807\n",
      "Epoch 3689/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0456 - mae: 0.1760 - val_loss: 2.8713 - val_mae: 1.5414\n",
      "Epoch 3690/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0439 - mae: 0.1596 - val_loss: 3.0363 - val_mae: 1.5941\n",
      "Epoch 3691/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0503 - mae: 0.1621 - val_loss: 3.1120 - val_mae: 1.6177\n",
      "Epoch 3692/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mae: 0.1700 - val_loss: 3.0996 - val_mae: 1.6139\n",
      "Epoch 3693/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0540 - mae: 0.1654 - val_loss: 3.0559 - val_mae: 1.6003\n",
      "Epoch 3694/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1591 - val_loss: 2.9671 - val_mae: 1.5722\n",
      "Epoch 3695/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1621 - val_loss: 2.7595 - val_mae: 1.5047\n",
      "Epoch 3696/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.2041 - val_loss: 2.6113 - val_mae: 1.4546\n",
      "Epoch 3697/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0625 - mae: 0.2172 - val_loss: 2.6193 - val_mae: 1.4575\n",
      "Epoch 3698/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - mae: 0.1836 - val_loss: 2.6450 - val_mae: 1.4664\n",
      "Epoch 3699/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1627 - val_loss: 2.6914 - val_mae: 1.4823\n",
      "Epoch 3700/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0543 - mae: 0.1785 - val_loss: 2.7398 - val_mae: 1.4987\n",
      "Epoch 3701/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0632 - mae: 0.1935 - val_loss: 2.6981 - val_mae: 1.4847\n",
      "Epoch 3702/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1882 - val_loss: 2.6218 - val_mae: 1.4587\n",
      "Epoch 3703/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0553 - mae: 0.1724 - val_loss: 2.5275 - val_mae: 1.4260\n",
      "Epoch 3704/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1725 - val_loss: 2.4345 - val_mae: 1.3930\n",
      "Epoch 3705/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1857 - val_loss: 2.4262 - val_mae: 1.3900\n",
      "Epoch 3706/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0548 - mae: 0.1882 - val_loss: 2.5407 - val_mae: 1.4306\n",
      "Epoch 3707/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1730 - val_loss: 2.7480 - val_mae: 1.5013\n",
      "Epoch 3708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mae: 0.1605 - val_loss: 2.9816 - val_mae: 1.5773\n",
      "Epoch 3709/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0592 - mae: 0.1796 - val_loss: 3.1419 - val_mae: 1.6273\n",
      "Epoch 3710/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0682 - mae: 0.1980 - val_loss: 3.1134 - val_mae: 1.6185\n",
      "Epoch 3711/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0568 - mae: 0.1766 - val_loss: 2.9135 - val_mae: 1.5554\n",
      "Epoch 3712/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1611 - val_loss: 2.6919 - val_mae: 1.4824\n",
      "Epoch 3713/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0485 - mae: 0.1881 - val_loss: 2.5291 - val_mae: 1.4264\n",
      "Epoch 3714/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0604 - mae: 0.2139 - val_loss: 2.5391 - val_mae: 1.4300\n",
      "Epoch 3715/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0520 - mae: 0.1962 - val_loss: 2.6795 - val_mae: 1.4784\n",
      "Epoch 3716/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0428 - mae: 0.1559 - val_loss: 2.7795 - val_mae: 1.5120\n",
      "Epoch 3717/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0493 - mae: 0.1650 - val_loss: 2.8415 - val_mae: 1.5324\n",
      "Epoch 3718/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0580 - mae: 0.1855 - val_loss: 2.8264 - val_mae: 1.5274\n",
      "Epoch 3719/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0505 - mae: 0.1689 - val_loss: 2.7203 - val_mae: 1.4923\n",
      "Epoch 3720/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0436 - mae: 0.1628 - val_loss: 2.6330 - val_mae: 1.4627\n",
      "Epoch 3721/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0526 - mae: 0.1899 - val_loss: 2.6382 - val_mae: 1.4645\n",
      "Epoch 3722/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1949 - val_loss: 2.6981 - val_mae: 1.4848\n",
      "Epoch 3723/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0482 - mae: 0.1783 - val_loss: 2.8319 - val_mae: 1.5293\n",
      "Epoch 3724/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0458 - mae: 0.1635 - val_loss: 2.9619 - val_mae: 1.5713\n",
      "Epoch 3725/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0510 - mae: 0.1657 - val_loss: 2.9299 - val_mae: 1.5611\n",
      "Epoch 3726/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0490 - mae: 0.1622 - val_loss: 2.7479 - val_mae: 1.5016\n",
      "Epoch 3727/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0422 - mae: 0.1597 - val_loss: 2.4784 - val_mae: 1.4089\n",
      "Epoch 3728/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0569 - mae: 0.2027 - val_loss: 2.3265 - val_mae: 1.3539\n",
      "Epoch 3729/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0641 - mae: 0.2112 - val_loss: 2.4899 - val_mae: 1.4131\n",
      "Epoch 3730/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0444 - mae: 0.1644 - val_loss: 2.8149 - val_mae: 1.5240\n",
      "Epoch 3731/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0610 - mae: 0.1961 - val_loss: 2.9802 - val_mae: 1.5774\n",
      "Epoch 3732/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0778 - mae: 0.2283 - val_loss: 2.9245 - val_mae: 1.5597\n",
      "Epoch 3733/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0606 - mae: 0.1905 - val_loss: 2.7618 - val_mae: 1.5066\n",
      "Epoch 3734/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0452 - mae: 0.1561 - val_loss: 2.6094 - val_mae: 1.4551\n",
      "Epoch 3735/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489 - mae: 0.1874 - val_loss: 2.4995 - val_mae: 1.4168\n",
      "Epoch 3736/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0612 - mae: 0.2166 - val_loss: 2.5380 - val_mae: 1.4304\n",
      "Epoch 3737/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0544 - mae: 0.2042 - val_loss: 2.8296 - val_mae: 1.5291\n",
      "Epoch 3738/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0481 - mae: 0.1683 - val_loss: 3.1304 - val_mae: 1.6247\n",
      "Epoch 3739/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0672 - mae: 0.1918 - val_loss: 3.1435 - val_mae: 1.6288\n",
      "Epoch 3740/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0627 - mae: 0.1840 - val_loss: 2.8756 - val_mae: 1.5442\n",
      "Epoch 3741/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0449 - mae: 0.1634 - val_loss: 2.5824 - val_mae: 1.4461\n",
      "Epoch 3742/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0583 - mae: 0.2116 - val_loss: 2.4811 - val_mae: 1.4106\n",
      "Epoch 3743/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0694 - mae: 0.2267 - val_loss: 2.6055 - val_mae: 1.4541\n",
      "Epoch 3744/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0524 - mae: 0.1957 - val_loss: 2.8323 - val_mae: 1.5302\n",
      "Epoch 3745/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0436 - mae: 0.1630 - val_loss: 2.9960 - val_mae: 1.5828\n",
      "Epoch 3746/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1620 - val_loss: 3.0411 - val_mae: 1.5970\n",
      "Epoch 3747/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1637 - val_loss: 2.9728 - val_mae: 1.5754\n",
      "Epoch 3748/5000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0471 - mae: 0.1558 - val_loss: 2.8131 - val_mae: 1.5238\n",
      "Epoch 3749/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0427 - mae: 0.1618 - val_loss: 2.6000 - val_mae: 1.4520\n",
      "Epoch 3750/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0485 - mae: 0.1890 - val_loss: 2.4475 - val_mae: 1.3984\n",
      "Epoch 3751/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.2080 - val_loss: 2.4277 - val_mae: 1.3912\n",
      "Epoch 3752/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0549 - mae: 0.2024 - val_loss: 2.4647 - val_mae: 1.4045\n",
      "Epoch 3753/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0481 - mae: 0.1823 - val_loss: 2.5198 - val_mae: 1.4241\n",
      "Epoch 3754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0457 - mae: 0.1635 - val_loss: 2.5455 - val_mae: 1.4330\n",
      "Epoch 3755/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1601 - val_loss: 2.5667 - val_mae: 1.4404\n",
      "Epoch 3756/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1604 - val_loss: 2.7034 - val_mae: 1.4871\n",
      "Epoch 3757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1644 - val_loss: 2.8174 - val_mae: 1.5249\n",
      "Epoch 3758/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1709 - val_loss: 2.8103 - val_mae: 1.5226\n",
      "Epoch 3759/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1695 - val_loss: 2.7372 - val_mae: 1.4983\n",
      "Epoch 3760/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1728 - val_loss: 2.6834 - val_mae: 1.4802\n",
      "Epoch 3761/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0452 - mae: 0.1702 - val_loss: 2.7213 - val_mae: 1.4930\n",
      "Epoch 3762/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0437 - mae: 0.1656 - val_loss: 2.7292 - val_mae: 1.4957\n",
      "Epoch 3763/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1616 - val_loss: 2.7019 - val_mae: 1.4865\n",
      "Epoch 3764/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0427 - mae: 0.1588 - val_loss: 2.6664 - val_mae: 1.4746\n",
      "Epoch 3765/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0429 - mae: 0.1571 - val_loss: 2.6257 - val_mae: 1.4607\n",
      "Epoch 3766/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0430 - mae: 0.1579 - val_loss: 2.6196 - val_mae: 1.4587\n",
      "Epoch 3767/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1576 - val_loss: 2.6186 - val_mae: 1.4583\n",
      "Epoch 3768/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - mae: 0.1580 - val_loss: 2.6325 - val_mae: 1.4631\n",
      "Epoch 3769/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1577 - val_loss: 2.6535 - val_mae: 1.4703\n",
      "Epoch 3770/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0432 - mae: 0.1573 - val_loss: 2.7200 - val_mae: 1.4927\n",
      "Epoch 3771/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1562 - val_loss: 2.8295 - val_mae: 1.5290\n",
      "Epoch 3772/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0446 - mae: 0.1530 - val_loss: 2.8802 - val_mae: 1.5455\n",
      "Epoch 3773/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1528 - val_loss: 2.8460 - val_mae: 1.5344\n",
      "Epoch 3774/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0440 - mae: 0.1559 - val_loss: 2.7612 - val_mae: 1.5065\n",
      "Epoch 3775/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0431 - mae: 0.1631 - val_loss: 2.7196 - val_mae: 1.4926\n",
      "Epoch 3776/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1663 - val_loss: 2.7471 - val_mae: 1.5018\n",
      "Epoch 3777/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0426 - mae: 0.1601 - val_loss: 2.7803 - val_mae: 1.5129\n",
      "Epoch 3778/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0435 - mae: 0.1555 - val_loss: 2.8316 - val_mae: 1.5298\n",
      "Epoch 3779/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1587 - val_loss: 2.8768 - val_mae: 1.5445\n",
      "Epoch 3780/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0479 - mae: 0.1571 - val_loss: 2.8281 - val_mae: 1.5287\n",
      "Epoch 3781/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0442 - mae: 0.1515 - val_loss: 2.7434 - val_mae: 1.5006\n",
      "Epoch 3782/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0440 - mae: 0.1667 - val_loss: 2.6461 - val_mae: 1.4678\n",
      "Epoch 3783/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1854 - val_loss: 2.5768 - val_mae: 1.4440\n",
      "Epoch 3784/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0500 - mae: 0.1930 - val_loss: 2.6222 - val_mae: 1.4596\n",
      "Epoch 3785/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1756 - val_loss: 2.7997 - val_mae: 1.5193\n",
      "Epoch 3786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1552 - val_loss: 2.9700 - val_mae: 1.5744\n",
      "Epoch 3787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1650 - val_loss: 3.0160 - val_mae: 1.5890\n",
      "Epoch 3788/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1679 - val_loss: 2.9075 - val_mae: 1.5544\n",
      "Epoch 3789/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1496 - val_loss: 2.7166 - val_mae: 1.4917\n",
      "Epoch 3790/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0437 - mae: 0.1681 - val_loss: 2.5618 - val_mae: 1.4388\n",
      "Epoch 3791/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0560 - mae: 0.2046 - val_loss: 2.5540 - val_mae: 1.4361\n",
      "Epoch 3792/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0525 - mae: 0.1983 - val_loss: 2.6908 - val_mae: 1.4830\n",
      "Epoch 3793/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0420 - mae: 0.1594 - val_loss: 2.8759 - val_mae: 1.5443\n",
      "Epoch 3794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1701 - val_loss: 3.0007 - val_mae: 1.5843\n",
      "Epoch 3795/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0681 - mae: 0.2007 - val_loss: 2.8949 - val_mae: 1.5504\n",
      "Epoch 3796/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0508 - mae: 0.1755 - val_loss: 2.6121 - val_mae: 1.4562\n",
      "Epoch 3797/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0500 - mae: 0.1847 - val_loss: 2.4742 - val_mae: 1.4079\n",
      "Epoch 3798/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0697 - mae: 0.2160 - val_loss: 2.5767 - val_mae: 1.4439\n",
      "Epoch 3799/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.2075 - val_loss: 2.7915 - val_mae: 1.5166\n",
      "Epoch 3800/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0520 - mae: 0.1816 - val_loss: 2.9748 - val_mae: 1.5759\n",
      "Epoch 3801/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1781 - val_loss: 3.0184 - val_mae: 1.5898\n",
      "Epoch 3802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0503 - mae: 0.1746 - val_loss: 2.9497 - val_mae: 1.5680\n",
      "Epoch 3803/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0468 - mae: 0.1678 - val_loss: 2.8569 - val_mae: 1.5381\n",
      "Epoch 3804/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1634 - val_loss: 2.7709 - val_mae: 1.5099\n",
      "Epoch 3805/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0426 - mae: 0.1628 - val_loss: 2.7499 - val_mae: 1.5030\n",
      "Epoch 3806/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1595 - val_loss: 2.8102 - val_mae: 1.5230\n",
      "Epoch 3807/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1532 - val_loss: 2.8709 - val_mae: 1.5428\n",
      "Epoch 3808/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0479 - mae: 0.1580 - val_loss: 2.8657 - val_mae: 1.5412\n",
      "Epoch 3809/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1571 - val_loss: 2.8705 - val_mae: 1.5428\n",
      "Epoch 3810/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1545 - val_loss: 2.8923 - val_mae: 1.5498\n",
      "Epoch 3811/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1539 - val_loss: 2.8733 - val_mae: 1.5437\n",
      "Epoch 3812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - mae: 0.1576 - val_loss: 2.8158 - val_mae: 1.5249\n",
      "Epoch 3813/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - mae: 0.1637 - val_loss: 2.8277 - val_mae: 1.5288\n",
      "Epoch 3814/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0435 - mae: 0.1647 - val_loss: 2.9214 - val_mae: 1.5593\n",
      "Epoch 3815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1674 - val_loss: 2.9560 - val_mae: 1.5704\n",
      "Epoch 3816/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1715 - val_loss: 2.8938 - val_mae: 1.5504\n",
      "Epoch 3817/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0453 - mae: 0.1725 - val_loss: 2.7826 - val_mae: 1.5141\n",
      "Epoch 3818/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1716 - val_loss: 2.6470 - val_mae: 1.4686\n",
      "Epoch 3819/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0463 - mae: 0.1770 - val_loss: 2.4974 - val_mae: 1.4167\n",
      "Epoch 3820/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0531 - mae: 0.1924 - val_loss: 2.4063 - val_mae: 1.3842\n",
      "Epoch 3821/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0572 - mae: 0.1978 - val_loss: 2.4050 - val_mae: 1.3837\n",
      "Epoch 3822/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0530 - mae: 0.1866 - val_loss: 2.4878 - val_mae: 1.4134\n",
      "Epoch 3823/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0468 - mae: 0.1753 - val_loss: 2.5746 - val_mae: 1.4438\n",
      "Epoch 3824/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0469 - mae: 0.1752 - val_loss: 2.5889 - val_mae: 1.4488\n",
      "Epoch 3825/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0473 - mae: 0.1736 - val_loss: 2.5633 - val_mae: 1.4400\n",
      "Epoch 3826/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1675 - val_loss: 2.5577 - val_mae: 1.4380\n",
      "Epoch 3827/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0439 - mae: 0.1609 - val_loss: 2.5962 - val_mae: 1.4514\n",
      "Epoch 3828/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0428 - mae: 0.1574 - val_loss: 2.6734 - val_mae: 1.4778\n",
      "Epoch 3829/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0428 - mae: 0.1541 - val_loss: 2.7611 - val_mae: 1.5072\n",
      "Epoch 3830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0437 - mae: 0.1525 - val_loss: 2.8927 - val_mae: 1.5503\n",
      "Epoch 3831/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1567 - val_loss: 2.9631 - val_mae: 1.5728\n",
      "Epoch 3832/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0486 - mae: 0.1556 - val_loss: 2.8496 - val_mae: 1.5363\n",
      "Epoch 3833/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0442 - mae: 0.1630 - val_loss: 2.7386 - val_mae: 1.4997\n",
      "Epoch 3834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1802 - val_loss: 2.6892 - val_mae: 1.4831\n",
      "Epoch 3835/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0528 - mae: 0.1966 - val_loss: 2.7570 - val_mae: 1.5058\n",
      "Epoch 3836/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1706 - val_loss: 2.9300 - val_mae: 1.5623\n",
      "Epoch 3837/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0525 - mae: 0.1667 - val_loss: 2.9378 - val_mae: 1.5649\n",
      "Epoch 3838/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1873 - val_loss: 2.6820 - val_mae: 1.4809\n",
      "Epoch 3839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0511 - mae: 0.1655 - val_loss: 2.3641 - val_mae: 1.3692\n",
      "Epoch 3840/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0532 - mae: 0.1772 - val_loss: 2.1655 - val_mae: 1.2946\n",
      "Epoch 3841/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0683 - mae: 0.2081 - val_loss: 2.1765 - val_mae: 1.2988\n",
      "Epoch 3842/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0636 - mae: 0.1980 - val_loss: 2.4072 - val_mae: 1.3849\n",
      "Epoch 3843/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1699 - val_loss: 2.7102 - val_mae: 1.4903\n",
      "Epoch 3844/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0620 - mae: 0.1910 - val_loss: 2.8486 - val_mae: 1.5360\n",
      "Epoch 3845/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0632 - mae: 0.1928 - val_loss: 2.7243 - val_mae: 1.4949\n",
      "Epoch 3846/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0490 - mae: 0.1676 - val_loss: 2.6107 - val_mae: 1.4563\n",
      "Epoch 3847/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0454 - mae: 0.1738 - val_loss: 2.6542 - val_mae: 1.4711\n",
      "Epoch 3848/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0480 - mae: 0.1847 - val_loss: 2.6944 - val_mae: 1.4847\n",
      "Epoch 3849/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1884 - val_loss: 2.7642 - val_mae: 1.5080\n",
      "Epoch 3850/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1769 - val_loss: 2.9712 - val_mae: 1.5752\n",
      "Epoch 3851/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1644 - val_loss: 3.1555 - val_mae: 1.6327\n",
      "Epoch 3852/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0519 - mae: 0.1628 - val_loss: 3.1722 - val_mae: 1.6378\n",
      "Epoch 3853/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0517 - mae: 0.1616 - val_loss: 3.1236 - val_mae: 1.6229\n",
      "Epoch 3854/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0486 - mae: 0.1589 - val_loss: 3.0787 - val_mae: 1.6090\n",
      "Epoch 3855/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0468 - mae: 0.1583 - val_loss: 2.9838 - val_mae: 1.5793\n",
      "Epoch 3856/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0449 - mae: 0.1630 - val_loss: 2.8222 - val_mae: 1.5272\n",
      "Epoch 3857/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1847 - val_loss: 2.7338 - val_mae: 1.4980\n",
      "Epoch 3858/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1901 - val_loss: 2.8342 - val_mae: 1.5312\n",
      "Epoch 3859/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0442 - mae: 0.1702 - val_loss: 3.0032 - val_mae: 1.5855\n",
      "Epoch 3860/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0473 - mae: 0.1547 - val_loss: 3.0313 - val_mae: 1.5943\n",
      "Epoch 3861/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1541 - val_loss: 2.9549 - val_mae: 1.5702\n",
      "Epoch 3862/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1543 - val_loss: 2.8709 - val_mae: 1.5432\n",
      "Epoch 3863/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0428 - mae: 0.1608 - val_loss: 2.7865 - val_mae: 1.5156\n",
      "Epoch 3864/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1691 - val_loss: 2.6698 - val_mae: 1.4765\n",
      "Epoch 3865/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0473 - mae: 0.1822 - val_loss: 2.6121 - val_mae: 1.4569\n",
      "Epoch 3866/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0475 - mae: 0.1812 - val_loss: 2.6576 - val_mae: 1.4724\n",
      "Epoch 3867/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1704 - val_loss: 2.6313 - val_mae: 1.4635\n",
      "Epoch 3868/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0436 - mae: 0.1712 - val_loss: 2.5178 - val_mae: 1.4242\n",
      "Epoch 3869/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0461 - mae: 0.1758 - val_loss: 2.4525 - val_mae: 1.4012\n",
      "Epoch 3870/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1752 - val_loss: 2.4699 - val_mae: 1.4074\n",
      "Epoch 3871/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0459 - mae: 0.1693 - val_loss: 2.5673 - val_mae: 1.4417\n",
      "Epoch 3872/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0461 - mae: 0.1658 - val_loss: 2.6926 - val_mae: 1.4846\n",
      "Epoch 3873/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1686 - val_loss: 2.7366 - val_mae: 1.4994\n",
      "Epoch 3874/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1640 - val_loss: 2.7274 - val_mae: 1.4963\n",
      "Epoch 3875/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1567 - val_loss: 2.7402 - val_mae: 1.5005\n",
      "Epoch 3876/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0433 - mae: 0.1541 - val_loss: 2.7669 - val_mae: 1.5094\n",
      "Epoch 3877/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0427 - mae: 0.1558 - val_loss: 2.8453 - val_mae: 1.5352\n",
      "Epoch 3878/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0433 - mae: 0.1555 - val_loss: 2.9608 - val_mae: 1.5723\n",
      "Epoch 3879/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0467 - mae: 0.1550 - val_loss: 2.9256 - val_mae: 1.5611\n",
      "Epoch 3880/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0461 - mae: 0.1618 - val_loss: 2.8574 - val_mae: 1.5391\n",
      "Epoch 3881/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0436 - mae: 0.1615 - val_loss: 2.7983 - val_mae: 1.5198\n",
      "Epoch 3882/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0427 - mae: 0.1614 - val_loss: 2.6910 - val_mae: 1.4841\n",
      "Epoch 3883/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1619 - val_loss: 2.6445 - val_mae: 1.4684\n",
      "Epoch 3884/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1613 - val_loss: 2.6264 - val_mae: 1.4622\n",
      "Epoch 3885/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1625 - val_loss: 2.5817 - val_mae: 1.4468\n",
      "Epoch 3886/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1647 - val_loss: 2.5377 - val_mae: 1.4316\n",
      "Epoch 3887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1624 - val_loss: 2.5706 - val_mae: 1.4431\n",
      "Epoch 3888/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0438 - mae: 0.1607 - val_loss: 2.5828 - val_mae: 1.4473\n",
      "Epoch 3889/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0446 - mae: 0.1590 - val_loss: 2.5739 - val_mae: 1.4443\n",
      "Epoch 3890/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0444 - mae: 0.1572 - val_loss: 2.6258 - val_mae: 1.4622\n",
      "Epoch 3891/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1557 - val_loss: 2.6803 - val_mae: 1.4807\n",
      "Epoch 3892/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0443 - mae: 0.1537 - val_loss: 2.7218 - val_mae: 1.4947\n",
      "Epoch 3893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1511 - val_loss: 2.7014 - val_mae: 1.4877\n",
      "Epoch 3894/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0425 - mae: 0.1665 - val_loss: 2.6372 - val_mae: 1.4659\n",
      "Epoch 3895/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0514 - mae: 0.1927 - val_loss: 2.6794 - val_mae: 1.4802\n",
      "Epoch 3896/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0570 - mae: 0.1990 - val_loss: 2.7240 - val_mae: 1.4952\n",
      "Epoch 3897/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0550 - mae: 0.1900 - val_loss: 2.7453 - val_mae: 1.5023\n",
      "Epoch 3898/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0496 - mae: 0.1783 - val_loss: 2.8336 - val_mae: 1.5315\n",
      "Epoch 3899/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0458 - mae: 0.1648 - val_loss: 2.8472 - val_mae: 1.5361\n",
      "Epoch 3900/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0442 - mae: 0.1587 - val_loss: 2.7332 - val_mae: 1.4985\n",
      "Epoch 3901/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1558 - val_loss: 2.6209 - val_mae: 1.4606\n",
      "Epoch 3902/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0415 - mae: 0.1595 - val_loss: 2.5652 - val_mae: 1.4414\n",
      "Epoch 3903/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0417 - mae: 0.1600 - val_loss: 2.5635 - val_mae: 1.4409\n",
      "Epoch 3904/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0418 - mae: 0.1567 - val_loss: 2.5615 - val_mae: 1.4402\n",
      "Epoch 3905/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0423 - mae: 0.1555 - val_loss: 2.5381 - val_mae: 1.4320\n",
      "Epoch 3906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0414 - mae: 0.1594 - val_loss: 2.5107 - val_mae: 1.4223\n",
      "Epoch 3907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0450 - mae: 0.1730 - val_loss: 2.5703 - val_mae: 1.4432\n",
      "Epoch 3908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1647 - val_loss: 2.7539 - val_mae: 1.5055\n",
      "Epoch 3909/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0449 - mae: 0.1638 - val_loss: 2.8997 - val_mae: 1.5533\n",
      "Epoch 3910/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1751 - val_loss: 2.8587 - val_mae: 1.5400\n",
      "Epoch 3911/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1602 - val_loss: 2.7088 - val_mae: 1.4905\n",
      "Epoch 3912/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1581 - val_loss: 2.6096 - val_mae: 1.4569\n",
      "Epoch 3913/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0432 - mae: 0.1676 - val_loss: 2.6071 - val_mae: 1.4561\n",
      "Epoch 3914/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1641 - val_loss: 2.7072 - val_mae: 1.4902\n",
      "Epoch 3915/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0489 - mae: 0.1630 - val_loss: 2.8519 - val_mae: 1.5381\n",
      "Epoch 3916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1814 - val_loss: 2.9446 - val_mae: 1.5680\n",
      "Epoch 3917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0678 - mae: 0.1951 - val_loss: 2.9616 - val_mae: 1.5733\n",
      "Epoch 3918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0628 - mae: 0.1850 - val_loss: 2.8671 - val_mae: 1.5428\n",
      "Epoch 3919/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0481 - mae: 0.1551 - val_loss: 2.6730 - val_mae: 1.4784\n",
      "Epoch 3920/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1677 - val_loss: 2.5265 - val_mae: 1.4279\n",
      "Epoch 3921/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1945 - val_loss: 2.5160 - val_mae: 1.4242\n",
      "Epoch 3922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0536 - mae: 0.1958 - val_loss: 2.5533 - val_mae: 1.4373\n",
      "Epoch 3923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0495 - mae: 0.1846 - val_loss: 2.5533 - val_mae: 1.4373\n",
      "Epoch 3924/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0472 - mae: 0.1780 - val_loss: 2.5438 - val_mae: 1.4340\n",
      "Epoch 3925/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1771 - val_loss: 2.5730 - val_mae: 1.4442\n",
      "Epoch 3926/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0441 - mae: 0.1731 - val_loss: 2.6263 - val_mae: 1.4626\n",
      "Epoch 3927/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0425 - mae: 0.1673 - val_loss: 2.7277 - val_mae: 1.4969\n",
      "Epoch 3928/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1655 - val_loss: 2.8890 - val_mae: 1.5499\n",
      "Epoch 3929/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1631 - val_loss: 3.0354 - val_mae: 1.5965\n",
      "Epoch 3930/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0493 - mae: 0.1618 - val_loss: 3.0370 - val_mae: 1.5970\n",
      "Epoch 3931/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0473 - mae: 0.1588 - val_loss: 2.9322 - val_mae: 1.5638\n",
      "Epoch 3932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1702 - val_loss: 2.7513 - val_mae: 1.5048\n",
      "Epoch 3933/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0574 - mae: 0.2071 - val_loss: 2.6434 - val_mae: 1.4684\n",
      "Epoch 3934/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2208 - val_loss: 2.7514 - val_mae: 1.5048\n",
      "Epoch 3935/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0504 - mae: 0.1939 - val_loss: 2.9059 - val_mae: 1.5555\n",
      "Epoch 3936/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0445 - mae: 0.1609 - val_loss: 2.9590 - val_mae: 1.5725\n",
      "Epoch 3937/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0468 - mae: 0.1526 - val_loss: 2.9189 - val_mae: 1.5597\n",
      "Epoch 3938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1565 - val_loss: 2.8246 - val_mae: 1.5291\n",
      "Epoch 3939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1589 - val_loss: 2.7024 - val_mae: 1.4885\n",
      "Epoch 3940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1620 - val_loss: 2.6351 - val_mae: 1.4657\n",
      "Epoch 3941/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1651 - val_loss: 2.6419 - val_mae: 1.4680\n",
      "Epoch 3942/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0422 - mae: 0.1638 - val_loss: 2.6739 - val_mae: 1.4790\n",
      "Epoch 3943/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0424 - mae: 0.1609 - val_loss: 2.6729 - val_mae: 1.4786\n",
      "Epoch 3944/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0420 - mae: 0.1626 - val_loss: 2.6383 - val_mae: 1.4668\n",
      "Epoch 3945/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1728 - val_loss: 2.7043 - val_mae: 1.4892\n",
      "Epoch 3946/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1685 - val_loss: 2.7952 - val_mae: 1.5194\n",
      "Epoch 3947/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0418 - mae: 0.1592 - val_loss: 2.7911 - val_mae: 1.5181\n",
      "Epoch 3948/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1562 - val_loss: 2.7909 - val_mae: 1.5181\n",
      "Epoch 3949/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0426 - mae: 0.1541 - val_loss: 2.8053 - val_mae: 1.5229\n",
      "Epoch 3950/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0444 - mae: 0.1535 - val_loss: 2.8062 - val_mae: 1.5233\n",
      "Epoch 3951/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1543 - val_loss: 2.8068 - val_mae: 1.5235\n",
      "Epoch 3952/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0449 - mae: 0.1550 - val_loss: 2.7881 - val_mae: 1.5173\n",
      "Epoch 3953/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0441 - mae: 0.1568 - val_loss: 2.7517 - val_mae: 1.5052\n",
      "Epoch 3954/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0432 - mae: 0.1600 - val_loss: 2.7699 - val_mae: 1.5113\n",
      "Epoch 3955/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0428 - mae: 0.1585 - val_loss: 2.8487 - val_mae: 1.5372\n",
      "Epoch 3956/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0447 - mae: 0.1515 - val_loss: 2.8684 - val_mae: 1.5436\n",
      "Epoch 3957/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1498 - val_loss: 2.7873 - val_mae: 1.5171\n",
      "Epoch 3958/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0423 - mae: 0.1530 - val_loss: 2.6862 - val_mae: 1.4833\n",
      "Epoch 3959/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0413 - mae: 0.1613 - val_loss: 2.6187 - val_mae: 1.4604\n",
      "Epoch 3960/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0430 - mae: 0.1683 - val_loss: 2.6909 - val_mae: 1.4849\n",
      "Epoch 3961/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1641 - val_loss: 2.7784 - val_mae: 1.5141\n",
      "Epoch 3962/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0424 - mae: 0.1591 - val_loss: 2.7706 - val_mae: 1.5116\n",
      "Epoch 3963/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1589 - val_loss: 2.7789 - val_mae: 1.5144\n",
      "Epoch 3964/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0423 - mae: 0.1575 - val_loss: 2.7665 - val_mae: 1.5103\n",
      "Epoch 3965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1554 - val_loss: 2.7066 - val_mae: 1.4903\n",
      "Epoch 3966/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0411 - mae: 0.1554 - val_loss: 2.6109 - val_mae: 1.4579\n",
      "Epoch 3967/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0409 - mae: 0.1576 - val_loss: 2.5334 - val_mae: 1.4311\n",
      "Epoch 3968/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0417 - mae: 0.1619 - val_loss: 2.4583 - val_mae: 1.4046\n",
      "Epoch 3969/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1699 - val_loss: 2.3917 - val_mae: 1.3807\n",
      "Epoch 3970/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1769 - val_loss: 2.4079 - val_mae: 1.3866\n",
      "Epoch 3971/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1682 - val_loss: 2.4762 - val_mae: 1.4111\n",
      "Epoch 3972/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0410 - mae: 0.1548 - val_loss: 2.5790 - val_mae: 1.4472\n",
      "Epoch 3973/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1499 - val_loss: 2.6959 - val_mae: 1.4871\n",
      "Epoch 3974/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0471 - mae: 0.1596 - val_loss: 2.7210 - val_mae: 1.4955\n",
      "Epoch 3975/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1556 - val_loss: 2.6828 - val_mae: 1.4827\n",
      "Epoch 3976/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0426 - mae: 0.1486 - val_loss: 2.6218 - val_mae: 1.4619\n",
      "Epoch 3977/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1576 - val_loss: 2.5579 - val_mae: 1.4399\n",
      "Epoch 3978/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0427 - mae: 0.1672 - val_loss: 2.5449 - val_mae: 1.4354\n",
      "Epoch 3979/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0422 - mae: 0.1642 - val_loss: 2.5345 - val_mae: 1.4318\n",
      "Epoch 3980/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0417 - mae: 0.1605 - val_loss: 2.4765 - val_mae: 1.4113\n",
      "Epoch 3981/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1682 - val_loss: 2.4308 - val_mae: 1.3950\n",
      "Epoch 3982/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0437 - mae: 0.1709 - val_loss: 2.5089 - val_mae: 1.4228\n",
      "Epoch 3983/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0406 - mae: 0.1549 - val_loss: 2.6643 - val_mae: 1.4764\n",
      "Epoch 3984/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1520 - val_loss: 2.6809 - val_mae: 1.4821\n",
      "Epoch 3985/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0432 - mae: 0.1532 - val_loss: 2.5743 - val_mae: 1.4456\n",
      "Epoch 3986/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0402 - mae: 0.1517 - val_loss: 2.4652 - val_mae: 1.4072\n",
      "Epoch 3987/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1652 - val_loss: 2.4100 - val_mae: 1.3875\n",
      "Epoch 3988/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1748 - val_loss: 2.4077 - val_mae: 1.3867\n",
      "Epoch 3989/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0443 - mae: 0.1716 - val_loss: 2.4729 - val_mae: 1.4100\n",
      "Epoch 3990/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0427 - mae: 0.1594 - val_loss: 2.5386 - val_mae: 1.4332\n",
      "Epoch 3991/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0418 - mae: 0.1539 - val_loss: 2.5019 - val_mae: 1.4203\n",
      "Epoch 3992/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0416 - mae: 0.1550 - val_loss: 2.4109 - val_mae: 1.3878\n",
      "Epoch 3993/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0430 - mae: 0.1601 - val_loss: 2.3296 - val_mae: 1.3581\n",
      "Epoch 3994/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0465 - mae: 0.1709 - val_loss: 2.3661 - val_mae: 1.3715\n",
      "Epoch 3995/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1647 - val_loss: 2.4695 - val_mae: 1.4087\n",
      "Epoch 3996/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0416 - mae: 0.1611 - val_loss: 2.5148 - val_mae: 1.4247\n",
      "Epoch 3997/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0419 - mae: 0.1643 - val_loss: 2.4686 - val_mae: 1.4083\n",
      "Epoch 3998/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1837 - val_loss: 2.4255 - val_mae: 1.3928\n",
      "Epoch 3999/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0650 - mae: 0.2033 - val_loss: 2.4951 - val_mae: 1.4176\n",
      "Epoch 4000/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0590 - mae: 0.1923 - val_loss: 2.7128 - val_mae: 1.4926\n",
      "Epoch 4001/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0424 - mae: 0.1655 - val_loss: 3.0639 - val_mae: 1.6062\n",
      "Epoch 4002/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0779 - mae: 0.2310 - val_loss: 3.2167 - val_mae: 1.6532\n",
      "Epoch 4003/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1029 - mae: 0.2750 - val_loss: 2.9332 - val_mae: 1.5650\n",
      "Epoch 4004/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0597 - mae: 0.1859 - val_loss: 2.4997 - val_mae: 1.4195\n",
      "Epoch 4005/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1764 - val_loss: 2.2304 - val_mae: 1.3211\n",
      "Epoch 4006/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0720 - mae: 0.2297 - val_loss: 2.2266 - val_mae: 1.3196\n",
      "Epoch 4007/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0691 - mae: 0.2240 - val_loss: 2.4097 - val_mae: 1.3874\n",
      "Epoch 4008/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0481 - mae: 0.1792 - val_loss: 2.6145 - val_mae: 1.4595\n",
      "Epoch 4009/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1627 - val_loss: 2.6361 - val_mae: 1.4668\n",
      "Epoch 4010/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0431 - mae: 0.1584 - val_loss: 2.5493 - val_mae: 1.4368\n",
      "Epoch 4011/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0430 - mae: 0.1673 - val_loss: 2.5196 - val_mae: 1.4263\n",
      "Epoch 4012/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0515 - mae: 0.1822 - val_loss: 2.5465 - val_mae: 1.4358\n",
      "Epoch 4013/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0503 - mae: 0.1777 - val_loss: 2.6550 - val_mae: 1.4732\n",
      "Epoch 4014/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0458 - mae: 0.1747 - val_loss: 2.6953 - val_mae: 1.4870\n",
      "Epoch 4015/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0442 - mae: 0.1664 - val_loss: 2.6269 - val_mae: 1.4639\n",
      "Epoch 4016/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0414 - mae: 0.1574 - val_loss: 2.4738 - val_mae: 1.4106\n",
      "Epoch 4017/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0416 - mae: 0.1608 - val_loss: 2.3316 - val_mae: 1.3593\n",
      "Epoch 4018/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0452 - mae: 0.1743 - val_loss: 2.2776 - val_mae: 1.3393\n",
      "Epoch 4019/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0468 - mae: 0.1768 - val_loss: 2.2779 - val_mae: 1.3395\n",
      "Epoch 4020/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0443 - mae: 0.1660 - val_loss: 2.3597 - val_mae: 1.3699\n",
      "Epoch 4021/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0441 - mae: 0.1529 - val_loss: 2.4040 - val_mae: 1.3860\n",
      "Epoch 4022/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0430 - mae: 0.1522 - val_loss: 2.3882 - val_mae: 1.3802\n",
      "Epoch 4023/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0418 - mae: 0.1585 - val_loss: 2.4189 - val_mae: 1.3913\n",
      "Epoch 4024/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0428 - mae: 0.1636 - val_loss: 2.4740 - val_mae: 1.4110\n",
      "Epoch 4025/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0438 - mae: 0.1656 - val_loss: 2.5599 - val_mae: 1.4413\n",
      "Epoch 4026/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0451 - mae: 0.1662 - val_loss: 2.7018 - val_mae: 1.4898\n",
      "Epoch 4027/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0505 - mae: 0.1730 - val_loss: 2.7723 - val_mae: 1.5134\n",
      "Epoch 4028/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0510 - mae: 0.1689 - val_loss: 2.6437 - val_mae: 1.4701\n",
      "Epoch 4029/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0452 - mae: 0.1587 - val_loss: 2.4316 - val_mae: 1.3959\n",
      "Epoch 4030/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0534 - mae: 0.1921 - val_loss: 2.3143 - val_mae: 1.3532\n",
      "Epoch 4031/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0631 - mae: 0.2123 - val_loss: 2.3491 - val_mae: 1.3661\n",
      "Epoch 4032/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0527 - mae: 0.1951 - val_loss: 2.4988 - val_mae: 1.4200\n",
      "Epoch 4033/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0414 - mae: 0.1599 - val_loss: 2.6225 - val_mae: 1.4630\n",
      "Epoch 4034/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0446 - mae: 0.1514 - val_loss: 2.6235 - val_mae: 1.4635\n",
      "Epoch 4035/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0471 - mae: 0.1569 - val_loss: 2.4903 - val_mae: 1.4171\n",
      "Epoch 4036/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0409 - mae: 0.1516 - val_loss: 2.3329 - val_mae: 1.3602\n",
      "Epoch 4037/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0456 - mae: 0.1758 - val_loss: 2.2754 - val_mae: 1.3388\n",
      "Epoch 4038/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0527 - mae: 0.1887 - val_loss: 2.3375 - val_mae: 1.3618\n",
      "Epoch 4039/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0467 - mae: 0.1744 - val_loss: 2.5102 - val_mae: 1.4240\n",
      "Epoch 4040/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0430 - mae: 0.1657 - val_loss: 2.6130 - val_mae: 1.4598\n",
      "Epoch 4041/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0485 - mae: 0.1683 - val_loss: 2.5466 - val_mae: 1.4369\n",
      "Epoch 4042/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0459 - mae: 0.1571 - val_loss: 2.3936 - val_mae: 1.3826\n",
      "Epoch 4043/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0427 - mae: 0.1530 - val_loss: 2.2529 - val_mae: 1.3307\n",
      "Epoch 4044/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0464 - mae: 0.1712 - val_loss: 2.2140 - val_mae: 1.3160\n",
      "Epoch 4045/5000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0486 - mae: 0.1774 - val_loss: 2.2662 - val_mae: 1.3358\n",
      "Epoch 4046/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0460 - mae: 0.1682 - val_loss: 2.3332 - val_mae: 1.3608\n",
      "Epoch 4047/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0439 - mae: 0.1584 - val_loss: 2.3470 - val_mae: 1.3659\n",
      "Epoch 4048/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0430 - mae: 0.1525 - val_loss: 2.2865 - val_mae: 1.3434\n",
      "Epoch 4049/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0425 - mae: 0.1546 - val_loss: 2.1980 - val_mae: 1.3100\n",
      "Epoch 4050/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0453 - mae: 0.1621 - val_loss: 2.2256 - val_mae: 1.3205\n",
      "Epoch 4051/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0435 - mae: 0.1568 - val_loss: 2.3406 - val_mae: 1.3634\n",
      "Epoch 4052/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0414 - mae: 0.1505 - val_loss: 2.4222 - val_mae: 1.3931\n",
      "Epoch 4053/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0422 - mae: 0.1508 - val_loss: 2.4846 - val_mae: 1.4154\n",
      "Epoch 4054/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0428 - mae: 0.1509 - val_loss: 2.4745 - val_mae: 1.4117\n",
      "Epoch 4055/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0410 - mae: 0.1495 - val_loss: 2.4718 - val_mae: 1.4108\n",
      "Epoch 4056/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0399 - mae: 0.1536 - val_loss: 2.5689 - val_mae: 1.4448\n",
      "Epoch 4057/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0398 - mae: 0.1493 - val_loss: 2.7133 - val_mae: 1.4941\n",
      "Epoch 4058/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1498 - val_loss: 2.7984 - val_mae: 1.5224\n",
      "Epoch 4059/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0501 - mae: 0.1596 - val_loss: 2.7418 - val_mae: 1.5036\n",
      "Epoch 4060/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1510 - val_loss: 2.7018 - val_mae: 1.4902\n",
      "Epoch 4061/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1512 - val_loss: 2.6736 - val_mae: 1.4807\n",
      "Epoch 4062/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0409 - mae: 0.1571 - val_loss: 2.5170 - val_mae: 1.4267\n",
      "Epoch 4063/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1749 - val_loss: 2.4323 - val_mae: 1.3965\n",
      "Epoch 4064/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0474 - mae: 0.1863 - val_loss: 2.5024 - val_mae: 1.4215\n",
      "Epoch 4065/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0420 - mae: 0.1695 - val_loss: 2.6283 - val_mae: 1.4652\n",
      "Epoch 4066/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0397 - mae: 0.1528 - val_loss: 2.7537 - val_mae: 1.5075\n",
      "Epoch 4067/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1552 - val_loss: 2.8030 - val_mae: 1.5237\n",
      "Epoch 4068/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0460 - mae: 0.1618 - val_loss: 2.8023 - val_mae: 1.5235\n",
      "Epoch 4069/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0449 - mae: 0.1613 - val_loss: 2.7395 - val_mae: 1.5026\n",
      "Epoch 4070/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0396 - mae: 0.1567 - val_loss: 2.5817 - val_mae: 1.4490\n",
      "Epoch 4071/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0478 - mae: 0.1781 - val_loss: 2.4081 - val_mae: 1.3877\n",
      "Epoch 4072/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0728 - mae: 0.2214 - val_loss: 2.4053 - val_mae: 1.3867\n",
      "Epoch 4073/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0695 - mae: 0.2110 - val_loss: 2.5798 - val_mae: 1.4485\n",
      "Epoch 4074/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - mae: 0.1778 - val_loss: 2.8015 - val_mae: 1.5233\n",
      "Epoch 4075/5000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0470 - mae: 0.1723 - val_loss: 2.9601 - val_mae: 1.5747\n",
      "Epoch 4076/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0609 - mae: 0.1902 - val_loss: 2.9165 - val_mae: 1.5608\n",
      "Epoch 4077/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0537 - mae: 0.1714 - val_loss: 2.6902 - val_mae: 1.4864\n",
      "Epoch 4078/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0404 - mae: 0.1544 - val_loss: 2.4577 - val_mae: 1.4059\n",
      "Epoch 4079/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0440 - mae: 0.1768 - val_loss: 2.3262 - val_mae: 1.3583\n",
      "Epoch 4080/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0494 - mae: 0.1883 - val_loss: 2.3491 - val_mae: 1.3667\n",
      "Epoch 4081/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0462 - mae: 0.1751 - val_loss: 2.4596 - val_mae: 1.4067\n",
      "Epoch 4082/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0450 - mae: 0.1624 - val_loss: 2.5593 - val_mae: 1.4418\n",
      "Epoch 4083/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0494 - mae: 0.1645 - val_loss: 2.6162 - val_mae: 1.4615\n",
      "Epoch 4084/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0518 - mae: 0.1690 - val_loss: 2.6133 - val_mae: 1.4604\n",
      "Epoch 4085/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0487 - mae: 0.1665 - val_loss: 2.5640 - val_mae: 1.4434\n",
      "Epoch 4086/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1583 - val_loss: 2.4709 - val_mae: 1.4107\n",
      "Epoch 4087/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0411 - mae: 0.1536 - val_loss: 2.4527 - val_mae: 1.4042\n",
      "Epoch 4088/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0400 - mae: 0.1556 - val_loss: 2.4936 - val_mae: 1.4187\n",
      "Epoch 4089/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0402 - mae: 0.1589 - val_loss: 2.5159 - val_mae: 1.4266\n",
      "Epoch 4090/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0418 - mae: 0.1632 - val_loss: 2.6004 - val_mae: 1.4560\n",
      "Epoch 4091/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0404 - mae: 0.1566 - val_loss: 2.6763 - val_mae: 1.4820\n",
      "Epoch 4092/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0425 - mae: 0.1518 - val_loss: 2.6559 - val_mae: 1.4751\n",
      "Epoch 4093/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1520 - val_loss: 2.5947 - val_mae: 1.4542\n",
      "Epoch 4094/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0416 - mae: 0.1486 - val_loss: 2.4938 - val_mae: 1.4191\n",
      "Epoch 4095/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0394 - mae: 0.1479 - val_loss: 2.3026 - val_mae: 1.3499\n",
      "Epoch 4096/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1659 - val_loss: 2.1566 - val_mae: 1.2946\n",
      "Epoch 4097/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1832 - val_loss: 2.1834 - val_mae: 1.3050\n",
      "Epoch 4098/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0455 - mae: 0.1650 - val_loss: 2.3767 - val_mae: 1.3774\n",
      "Epoch 4099/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0457 - mae: 0.1552 - val_loss: 2.5783 - val_mae: 1.4489\n",
      "Epoch 4100/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0613 - mae: 0.1949 - val_loss: 2.6268 - val_mae: 1.4657\n",
      "Epoch 4101/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0606 - mae: 0.1934 - val_loss: 2.4650 - val_mae: 1.4092\n",
      "Epoch 4102/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0434 - mae: 0.1490 - val_loss: 2.3100 - val_mae: 1.3529\n",
      "Epoch 4103/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0506 - mae: 0.1885 - val_loss: 2.3458 - val_mae: 1.3661\n",
      "Epoch 4104/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0576 - mae: 0.1989 - val_loss: 2.5393 - val_mae: 1.4353\n",
      "Epoch 4105/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0522 - mae: 0.1768 - val_loss: 2.7856 - val_mae: 1.5189\n",
      "Epoch 4106/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0541 - mae: 0.1735 - val_loss: 2.8990 - val_mae: 1.5559\n",
      "Epoch 4107/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0598 - mae: 0.1882 - val_loss: 2.8313 - val_mae: 1.5339\n",
      "Epoch 4108/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0562 - mae: 0.1791 - val_loss: 2.6484 - val_mae: 1.4728\n",
      "Epoch 4109/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0549 - mae: 0.1816 - val_loss: 2.4646 - val_mae: 1.4089\n",
      "Epoch 4110/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0616 - mae: 0.1922 - val_loss: 2.3515 - val_mae: 1.3680\n",
      "Epoch 4111/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0627 - mae: 0.1967 - val_loss: 2.3487 - val_mae: 1.3670\n",
      "Epoch 4112/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1816 - val_loss: 2.4271 - val_mae: 1.3955\n",
      "Epoch 4113/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0415 - mae: 0.1635 - val_loss: 2.4972 - val_mae: 1.4206\n",
      "Epoch 4114/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0436 - mae: 0.1590 - val_loss: 2.5104 - val_mae: 1.4254\n",
      "Epoch 4115/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0483 - mae: 0.1682 - val_loss: 2.4535 - val_mae: 1.4054\n",
      "Epoch 4116/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0492 - mae: 0.1667 - val_loss: 2.4117 - val_mae: 1.3905\n",
      "Epoch 4117/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0475 - mae: 0.1632 - val_loss: 2.3994 - val_mae: 1.3861\n",
      "Epoch 4118/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0457 - mae: 0.1627 - val_loss: 2.3675 - val_mae: 1.3746\n",
      "Epoch 4119/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0450 - mae: 0.1686 - val_loss: 2.4129 - val_mae: 1.3911\n",
      "Epoch 4120/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0446 - mae: 0.1709 - val_loss: 2.5022 - val_mae: 1.4229\n",
      "Epoch 4121/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0429 - mae: 0.1648 - val_loss: 2.5474 - val_mae: 1.4387\n",
      "Epoch 4122/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0415 - mae: 0.1587 - val_loss: 2.5212 - val_mae: 1.4295\n",
      "Epoch 4123/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0401 - mae: 0.1563 - val_loss: 2.4664 - val_mae: 1.4101\n",
      "Epoch 4124/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0408 - mae: 0.1604 - val_loss: 2.4696 - val_mae: 1.4111\n",
      "Epoch 4125/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0417 - mae: 0.1632 - val_loss: 2.5716 - val_mae: 1.4468\n",
      "Epoch 4126/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0417 - mae: 0.1624 - val_loss: 2.7207 - val_mae: 1.4976\n",
      "Epoch 4127/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0444 - mae: 0.1605 - val_loss: 2.7837 - val_mae: 1.5185\n",
      "Epoch 4128/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0481 - mae: 0.1620 - val_loss: 2.8066 - val_mae: 1.5261\n",
      "Epoch 4129/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1609 - val_loss: 2.8197 - val_mae: 1.5305\n",
      "Epoch 4130/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1549 - val_loss: 2.7220 - val_mae: 1.4981\n",
      "Epoch 4131/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0412 - mae: 0.1503 - val_loss: 2.6066 - val_mae: 1.4590\n",
      "Epoch 4132/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1612 - val_loss: 2.5792 - val_mae: 1.4496\n",
      "Epoch 4133/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0420 - mae: 0.1716 - val_loss: 2.5925 - val_mae: 1.4542\n",
      "Epoch 4134/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1716 - val_loss: 2.6685 - val_mae: 1.4801\n",
      "Epoch 4135/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1594 - val_loss: 2.8198 - val_mae: 1.5304\n",
      "Epoch 4136/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1479 - val_loss: 2.9564 - val_mae: 1.5744\n",
      "Epoch 4137/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0456 - mae: 0.1515 - val_loss: 3.0896 - val_mae: 1.6161\n",
      "Epoch 4138/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0498 - mae: 0.1622 - val_loss: 3.0235 - val_mae: 1.5955\n",
      "Epoch 4139/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0510 - mae: 0.1681 - val_loss: 2.9203 - val_mae: 1.5629\n",
      "Epoch 4140/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0456 - mae: 0.1632 - val_loss: 2.9637 - val_mae: 1.5769\n",
      "Epoch 4141/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1534 - val_loss: 2.7817 - val_mae: 1.5181\n",
      "Epoch 4142/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1518 - val_loss: 2.4516 - val_mae: 1.4050\n",
      "Epoch 4143/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0428 - mae: 0.1694 - val_loss: 2.2187 - val_mae: 1.3193\n",
      "Epoch 4144/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0563 - mae: 0.1968 - val_loss: 2.1887 - val_mae: 1.3079\n",
      "Epoch 4145/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1910 - val_loss: 2.3610 - val_mae: 1.3724\n",
      "Epoch 4146/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0416 - mae: 0.1579 - val_loss: 2.5583 - val_mae: 1.4428\n",
      "Epoch 4147/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0445 - mae: 0.1606 - val_loss: 2.6826 - val_mae: 1.4854\n",
      "Epoch 4148/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0523 - mae: 0.1762 - val_loss: 2.7081 - val_mae: 1.4941\n",
      "Epoch 4149/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0517 - mae: 0.1746 - val_loss: 2.6736 - val_mae: 1.4825\n",
      "Epoch 4150/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0448 - mae: 0.1578 - val_loss: 2.6478 - val_mae: 1.4738\n",
      "Epoch 4151/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0404 - mae: 0.1500 - val_loss: 2.5956 - val_mae: 1.4560\n",
      "Epoch 4152/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0421 - mae: 0.1620 - val_loss: 2.4798 - val_mae: 1.4155\n",
      "Epoch 4153/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0527 - mae: 0.1896 - val_loss: 2.3571 - val_mae: 1.3713\n",
      "Epoch 4154/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0679 - mae: 0.2184 - val_loss: 2.3584 - val_mae: 1.3718\n",
      "Epoch 4155/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0600 - mae: 0.2067 - val_loss: 2.5563 - val_mae: 1.4423\n",
      "Epoch 4156/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0404 - mae: 0.1543 - val_loss: 2.7678 - val_mae: 1.5141\n",
      "Epoch 4157/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0547 - mae: 0.1755 - val_loss: 2.8221 - val_mae: 1.5320\n",
      "Epoch 4158/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0742 - mae: 0.2162 - val_loss: 2.7074 - val_mae: 1.4941\n",
      "Epoch 4159/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1912 - val_loss: 2.5204 - val_mae: 1.4299\n",
      "Epoch 4160/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0472 - mae: 0.1579 - val_loss: 2.3926 - val_mae: 1.3844\n",
      "Epoch 4161/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0416 - mae: 0.1620 - val_loss: 2.3320 - val_mae: 1.3622\n",
      "Epoch 4162/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1861 - val_loss: 2.2683 - val_mae: 1.3385\n",
      "Epoch 4163/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0611 - mae: 0.2141 - val_loss: 2.3307 - val_mae: 1.3615\n",
      "Epoch 4164/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0530 - mae: 0.1973 - val_loss: 2.5296 - val_mae: 1.4329\n",
      "Epoch 4165/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0385 - mae: 0.1563 - val_loss: 2.6995 - val_mae: 1.4912\n",
      "Epoch 4166/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0455 - mae: 0.1520 - val_loss: 2.7571 - val_mae: 1.5105\n",
      "Epoch 4167/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0502 - mae: 0.1622 - val_loss: 2.6636 - val_mae: 1.4791\n",
      "Epoch 4168/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0429 - mae: 0.1465 - val_loss: 2.5255 - val_mae: 1.4315\n",
      "Epoch 4169/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0383 - mae: 0.1512 - val_loss: 2.4052 - val_mae: 1.3888\n",
      "Epoch 4170/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0428 - mae: 0.1732 - val_loss: 2.3727 - val_mae: 1.3770\n",
      "Epoch 4171/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0474 - mae: 0.1848 - val_loss: 2.4360 - val_mae: 1.3998\n",
      "Epoch 4172/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0444 - mae: 0.1740 - val_loss: 2.5501 - val_mae: 1.4401\n",
      "Epoch 4173/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0407 - mae: 0.1611 - val_loss: 2.6420 - val_mae: 1.4718\n",
      "Epoch 4174/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0407 - mae: 0.1582 - val_loss: 2.6252 - val_mae: 1.4661\n",
      "Epoch 4175/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0403 - mae: 0.1561 - val_loss: 2.5712 - val_mae: 1.4475\n",
      "Epoch 4176/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0391 - mae: 0.1550 - val_loss: 2.5204 - val_mae: 1.4298\n",
      "Epoch 4177/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0391 - mae: 0.1581 - val_loss: 2.4683 - val_mae: 1.4114\n",
      "Epoch 4178/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1617 - val_loss: 2.3807 - val_mae: 1.3800\n",
      "Epoch 4179/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438 - mae: 0.1731 - val_loss: 2.3096 - val_mae: 1.3539\n",
      "Epoch 4180/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1772 - val_loss: 2.4012 - val_mae: 1.3874\n",
      "Epoch 4181/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0382 - mae: 0.1584 - val_loss: 2.6449 - val_mae: 1.4729\n",
      "Epoch 4182/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0420 - mae: 0.1526 - val_loss: 2.8801 - val_mae: 1.5510\n",
      "Epoch 4183/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0597 - mae: 0.1861 - val_loss: 2.8974 - val_mae: 1.5566\n",
      "Epoch 4184/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0563 - mae: 0.1770 - val_loss: 2.6977 - val_mae: 1.4909\n",
      "Epoch 4185/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0410 - mae: 0.1472 - val_loss: 2.4798 - val_mae: 1.4158\n",
      "Epoch 4186/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0421 - mae: 0.1746 - val_loss: 2.3526 - val_mae: 1.3699\n",
      "Epoch 4187/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0514 - mae: 0.1976 - val_loss: 2.2758 - val_mae: 1.3415\n",
      "Epoch 4188/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0577 - mae: 0.2085 - val_loss: 2.2828 - val_mae: 1.3441\n",
      "Epoch 4189/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0532 - mae: 0.1995 - val_loss: 2.3507 - val_mae: 1.3692\n",
      "Epoch 4190/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0431 - mae: 0.1746 - val_loss: 2.4052 - val_mae: 1.3891\n",
      "Epoch 4191/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0394 - mae: 0.1579 - val_loss: 2.4456 - val_mae: 1.4036\n",
      "Epoch 4192/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0387 - mae: 0.1471 - val_loss: 2.4093 - val_mae: 1.3905\n",
      "Epoch 4193/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0397 - mae: 0.1485 - val_loss: 2.3755 - val_mae: 1.3783\n",
      "Epoch 4194/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0398 - mae: 0.1504 - val_loss: 2.4243 - val_mae: 1.3959\n",
      "Epoch 4195/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0413 - mae: 0.1522 - val_loss: 2.4497 - val_mae: 1.4051\n",
      "Epoch 4196/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0408 - mae: 0.1498 - val_loss: 2.4232 - val_mae: 1.3957\n",
      "Epoch 4197/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0384 - mae: 0.1472 - val_loss: 2.3876 - val_mae: 1.3829\n",
      "Epoch 4198/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0385 - mae: 0.1529 - val_loss: 2.3999 - val_mae: 1.3874\n",
      "Epoch 4199/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0395 - mae: 0.1580 - val_loss: 2.4874 - val_mae: 1.4188\n",
      "Epoch 4200/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1509 - val_loss: 2.5225 - val_mae: 1.4312\n",
      "Epoch 4201/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1450 - val_loss: 2.5140 - val_mae: 1.4282\n",
      "Epoch 4202/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0402 - mae: 0.1435 - val_loss: 2.4398 - val_mae: 1.4019\n",
      "Epoch 4203/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0377 - mae: 0.1474 - val_loss: 2.2781 - val_mae: 1.3428\n",
      "Epoch 4204/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0440 - mae: 0.1762 - val_loss: 2.2031 - val_mae: 1.3144\n",
      "Epoch 4205/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0477 - mae: 0.1827 - val_loss: 2.3154 - val_mae: 1.3566\n",
      "Epoch 4206/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0392 - mae: 0.1561 - val_loss: 2.4947 - val_mae: 1.4213\n",
      "Epoch 4207/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0417 - mae: 0.1535 - val_loss: 2.5642 - val_mae: 1.4456\n",
      "Epoch 4208/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0490 - mae: 0.1667 - val_loss: 2.5172 - val_mae: 1.4293\n",
      "Epoch 4209/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0440 - mae: 0.1555 - val_loss: 2.3746 - val_mae: 1.3784\n",
      "Epoch 4210/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0363 - mae: 0.1430 - val_loss: 2.1566 - val_mae: 1.2966\n",
      "Epoch 4211/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1794 - val_loss: 2.0144 - val_mae: 1.2403\n",
      "Epoch 4212/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0610 - mae: 0.2079 - val_loss: 2.0700 - val_mae: 1.2626\n",
      "Epoch 4213/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1811 - val_loss: 2.2603 - val_mae: 1.3361\n",
      "Epoch 4214/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0394 - mae: 0.1475 - val_loss: 2.4900 - val_mae: 1.4197\n",
      "Epoch 4215/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0518 - mae: 0.1712 - val_loss: 2.6241 - val_mae: 1.4664\n",
      "Epoch 4216/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0624 - mae: 0.1965 - val_loss: 2.5410 - val_mae: 1.4377\n",
      "Epoch 4217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0471 - mae: 0.1600 - val_loss: 2.3552 - val_mae: 1.3715\n",
      "Epoch 4218/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0369 - mae: 0.1509 - val_loss: 2.1721 - val_mae: 1.3028\n",
      "Epoch 4219/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0532 - mae: 0.1929 - val_loss: 2.1171 - val_mae: 1.2815\n",
      "Epoch 4220/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0643 - mae: 0.2145 - val_loss: 2.2463 - val_mae: 1.3311\n",
      "Epoch 4221/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0497 - mae: 0.1891 - val_loss: 2.4786 - val_mae: 1.4160\n",
      "Epoch 4222/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0370 - mae: 0.1474 - val_loss: 2.7305 - val_mae: 1.5026\n",
      "Epoch 4223/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0537 - mae: 0.1727 - val_loss: 2.7684 - val_mae: 1.5152\n",
      "Epoch 4224/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0584 - mae: 0.1875 - val_loss: 2.5859 - val_mae: 1.4534\n",
      "Epoch 4225/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0422 - mae: 0.1555 - val_loss: 2.3776 - val_mae: 1.3796\n",
      "Epoch 4226/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0374 - mae: 0.1551 - val_loss: 2.1935 - val_mae: 1.3109\n",
      "Epoch 4227/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0467 - mae: 0.1740 - val_loss: 2.0656 - val_mae: 1.2610\n",
      "Epoch 4228/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0570 - mae: 0.1922 - val_loss: 2.0688 - val_mae: 1.2623\n",
      "Epoch 4229/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0531 - mae: 0.1804 - val_loss: 2.1545 - val_mae: 1.2960\n",
      "Epoch 4230/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1633 - val_loss: 2.2936 - val_mae: 1.3488\n",
      "Epoch 4231/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0394 - mae: 0.1583 - val_loss: 2.4869 - val_mae: 1.4190\n",
      "Epoch 4232/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0410 - mae: 0.1610 - val_loss: 2.6147 - val_mae: 1.4636\n",
      "Epoch 4233/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0442 - mae: 0.1632 - val_loss: 2.6335 - val_mae: 1.4701\n",
      "Epoch 4234/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1605 - val_loss: 2.5518 - val_mae: 1.4421\n",
      "Epoch 4235/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0455 - mae: 0.1677 - val_loss: 2.4756 - val_mae: 1.4154\n",
      "Epoch 4236/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0516 - mae: 0.1821 - val_loss: 2.5032 - val_mae: 1.4252\n",
      "Epoch 4237/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0493 - mae: 0.1787 - val_loss: 2.6277 - val_mae: 1.4684\n",
      "Epoch 4238/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0429 - mae: 0.1578 - val_loss: 2.8023 - val_mae: 1.5269\n",
      "Epoch 4239/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0469 - mae: 0.1552 - val_loss: 2.9221 - val_mae: 1.5658\n",
      "Epoch 4240/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0573 - mae: 0.1758 - val_loss: 2.8289 - val_mae: 1.5357\n",
      "Epoch 4241/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0491 - mae: 0.1579 - val_loss: 2.6027 - val_mae: 1.4600\n",
      "Epoch 4242/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0410 - mae: 0.1572 - val_loss: 2.4606 - val_mae: 1.4103\n",
      "Epoch 4243/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0440 - mae: 0.1744 - val_loss: 2.4881 - val_mae: 1.4200\n",
      "Epoch 4244/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0414 - mae: 0.1662 - val_loss: 2.6213 - val_mae: 1.4664\n",
      "Epoch 4245/5000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0399 - mae: 0.1484 - val_loss: 2.7011 - val_mae: 1.4934\n",
      "Epoch 4246/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1443 - val_loss: 2.6869 - val_mae: 1.4886\n",
      "Epoch 4247/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0409 - mae: 0.1449 - val_loss: 2.5540 - val_mae: 1.4430\n",
      "Epoch 4248/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0402 - mae: 0.1586 - val_loss: 2.4383 - val_mae: 1.4022\n",
      "Epoch 4249/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0429 - mae: 0.1686 - val_loss: 2.3328 - val_mae: 1.3638\n",
      "Epoch 4250/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0478 - mae: 0.1807 - val_loss: 2.2424 - val_mae: 1.3300\n",
      "Epoch 4251/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487 - mae: 0.1799 - val_loss: 2.3274 - val_mae: 1.3616\n",
      "Epoch 4252/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0415 - mae: 0.1663 - val_loss: 2.4213 - val_mae: 1.3957\n",
      "Epoch 4253/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0401 - mae: 0.1596 - val_loss: 2.4262 - val_mae: 1.3975\n",
      "Epoch 4254/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0396 - mae: 0.1569 - val_loss: 2.4007 - val_mae: 1.3884\n",
      "Epoch 4255/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0374 - mae: 0.1504 - val_loss: 2.3662 - val_mae: 1.3760\n",
      "Epoch 4256/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0370 - mae: 0.1505 - val_loss: 2.3781 - val_mae: 1.3805\n",
      "Epoch 4257/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0372 - mae: 0.1501 - val_loss: 2.3932 - val_mae: 1.3861\n",
      "Epoch 4258/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0374 - mae: 0.1516 - val_loss: 2.4124 - val_mae: 1.3931\n",
      "Epoch 4259/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0377 - mae: 0.1503 - val_loss: 2.4471 - val_mae: 1.4056\n",
      "Epoch 4260/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0382 - mae: 0.1472 - val_loss: 2.4240 - val_mae: 1.3974\n",
      "Epoch 4261/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0382 - mae: 0.1502 - val_loss: 2.3899 - val_mae: 1.3851\n",
      "Epoch 4262/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0376 - mae: 0.1503 - val_loss: 2.3999 - val_mae: 1.3888\n",
      "Epoch 4263/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0375 - mae: 0.1426 - val_loss: 2.4287 - val_mae: 1.3991\n",
      "Epoch 4264/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0387 - mae: 0.1423 - val_loss: 2.4300 - val_mae: 1.3996\n",
      "Epoch 4265/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0391 - mae: 0.1433 - val_loss: 2.3058 - val_mae: 1.3542\n",
      "Epoch 4266/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0365 - mae: 0.1452 - val_loss: 2.1101 - val_mae: 1.2795\n",
      "Epoch 4267/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0449 - mae: 0.1694 - val_loss: 2.0047 - val_mae: 1.2374\n",
      "Epoch 4268/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1919 - val_loss: 2.0172 - val_mae: 1.2425\n",
      "Epoch 4269/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0556 - mae: 0.1877 - val_loss: 2.0902 - val_mae: 1.2717\n",
      "Epoch 4270/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0450 - mae: 0.1672 - val_loss: 2.1901 - val_mae: 1.3106\n",
      "Epoch 4271/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0399 - mae: 0.1586 - val_loss: 2.3130 - val_mae: 1.3570\n",
      "Epoch 4272/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0429 - mae: 0.1604 - val_loss: 2.3342 - val_mae: 1.3649\n",
      "Epoch 4273/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0420 - mae: 0.1560 - val_loss: 2.2763 - val_mae: 1.3437\n",
      "Epoch 4274/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0383 - mae: 0.1455 - val_loss: 2.2852 - val_mae: 1.3472\n",
      "Epoch 4275/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0373 - mae: 0.1420 - val_loss: 2.3258 - val_mae: 1.3624\n",
      "Epoch 4276/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0372 - mae: 0.1405 - val_loss: 2.3034 - val_mae: 1.3542\n",
      "Epoch 4277/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0369 - mae: 0.1455 - val_loss: 2.2143 - val_mae: 1.3208\n",
      "Epoch 4278/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0387 - mae: 0.1580 - val_loss: 2.1429 - val_mae: 1.2934\n",
      "Epoch 4279/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0407 - mae: 0.1635 - val_loss: 2.1177 - val_mae: 1.2835\n",
      "Epoch 4280/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0405 - mae: 0.1602 - val_loss: 2.0881 - val_mae: 1.2718\n",
      "Epoch 4281/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0409 - mae: 0.1574 - val_loss: 2.0353 - val_mae: 1.2506\n",
      "Epoch 4282/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0427 - mae: 0.1613 - val_loss: 2.0110 - val_mae: 1.2407\n",
      "Epoch 4283/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1672 - val_loss: 2.0878 - val_mae: 1.2712\n",
      "Epoch 4284/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0418 - mae: 0.1652 - val_loss: 2.2522 - val_mae: 1.3346\n",
      "Epoch 4285/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0416 - mae: 0.1644 - val_loss: 2.3515 - val_mae: 1.3714\n",
      "Epoch 4286/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0412 - mae: 0.1617 - val_loss: 2.3493 - val_mae: 1.3707\n",
      "Epoch 4287/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0383 - mae: 0.1534 - val_loss: 2.3088 - val_mae: 1.3559\n",
      "Epoch 4288/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0369 - mae: 0.1491 - val_loss: 2.2320 - val_mae: 1.3272\n",
      "Epoch 4289/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0401 - mae: 0.1634 - val_loss: 2.2122 - val_mae: 1.3198\n",
      "Epoch 4290/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0397 - mae: 0.1653 - val_loss: 2.3169 - val_mae: 1.3590\n",
      "Epoch 4291/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0367 - mae: 0.1457 - val_loss: 2.4704 - val_mae: 1.4147\n",
      "Epoch 4292/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1492 - val_loss: 2.5752 - val_mae: 1.4515\n",
      "Epoch 4293/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0510 - mae: 0.1654 - val_loss: 2.6415 - val_mae: 1.4743\n",
      "Epoch 4294/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0534 - mae: 0.1708 - val_loss: 2.5946 - val_mae: 1.4583\n",
      "Epoch 4295/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1468 - val_loss: 2.4225 - val_mae: 1.3978\n",
      "Epoch 4296/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0396 - mae: 0.1602 - val_loss: 2.3799 - val_mae: 1.3824\n",
      "Epoch 4297/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0419 - mae: 0.1727 - val_loss: 2.4528 - val_mae: 1.4087\n",
      "Epoch 4298/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1696 - val_loss: 2.5276 - val_mae: 1.4351\n",
      "Epoch 4299/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0403 - mae: 0.1599 - val_loss: 2.6137 - val_mae: 1.4650\n",
      "Epoch 4300/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0392 - mae: 0.1498 - val_loss: 2.5976 - val_mae: 1.4594\n",
      "Epoch 4301/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0379 - mae: 0.1472 - val_loss: 2.5008 - val_mae: 1.4257\n",
      "Epoch 4302/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0369 - mae: 0.1520 - val_loss: 2.4482 - val_mae: 1.4070\n",
      "Epoch 4303/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0359 - mae: 0.1485 - val_loss: 2.4862 - val_mae: 1.4205\n",
      "Epoch 4304/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0384 - mae: 0.1452 - val_loss: 2.4758 - val_mae: 1.4169\n",
      "Epoch 4305/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0413 - mae: 0.1488 - val_loss: 2.4056 - val_mae: 1.3918\n",
      "Epoch 4306/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0410 - mae: 0.1505 - val_loss: 2.3347 - val_mae: 1.3659\n",
      "Epoch 4307/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0403 - mae: 0.1532 - val_loss: 2.2306 - val_mae: 1.3271\n",
      "Epoch 4308/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1611 - val_loss: 2.1972 - val_mae: 1.3143\n",
      "Epoch 4309/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0413 - mae: 0.1580 - val_loss: 2.2095 - val_mae: 1.3188\n",
      "Epoch 4310/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1512 - val_loss: 2.1805 - val_mae: 1.3076\n",
      "Epoch 4311/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0393 - mae: 0.1548 - val_loss: 2.2142 - val_mae: 1.3204\n",
      "Epoch 4312/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0401 - mae: 0.1636 - val_loss: 2.3987 - val_mae: 1.3889\n",
      "Epoch 4313/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0417 - mae: 0.1666 - val_loss: 2.5078 - val_mae: 1.4278\n",
      "Epoch 4314/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1625 - val_loss: 2.3957 - val_mae: 1.3878\n",
      "Epoch 4315/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0384 - mae: 0.1583 - val_loss: 2.2616 - val_mae: 1.3384\n",
      "Epoch 4316/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0366 - mae: 0.1511 - val_loss: 2.1652 - val_mae: 1.3017\n",
      "Epoch 4317/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0392 - mae: 0.1512 - val_loss: 2.1735 - val_mae: 1.3049\n",
      "Epoch 4318/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0402 - mae: 0.1518 - val_loss: 2.2379 - val_mae: 1.3296\n",
      "Epoch 4319/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0406 - mae: 0.1495 - val_loss: 2.2684 - val_mae: 1.3411\n",
      "Epoch 4320/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0405 - mae: 0.1487 - val_loss: 2.3295 - val_mae: 1.3639\n",
      "Epoch 4321/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0400 - mae: 0.1465 - val_loss: 2.3775 - val_mae: 1.3816\n",
      "Epoch 4322/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0385 - mae: 0.1439 - val_loss: 2.3800 - val_mae: 1.3825\n",
      "Epoch 4323/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0367 - mae: 0.1436 - val_loss: 2.3691 - val_mae: 1.3786\n",
      "Epoch 4324/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0358 - mae: 0.1478 - val_loss: 2.3700 - val_mae: 1.3789\n",
      "Epoch 4325/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0357 - mae: 0.1503 - val_loss: 2.3689 - val_mae: 1.3785\n",
      "Epoch 4326/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0359 - mae: 0.1513 - val_loss: 2.3581 - val_mae: 1.3745\n",
      "Epoch 4327/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0364 - mae: 0.1530 - val_loss: 2.2814 - val_mae: 1.3460\n",
      "Epoch 4328/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0379 - mae: 0.1588 - val_loss: 2.1441 - val_mae: 1.2936\n",
      "Epoch 4329/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0453 - mae: 0.1714 - val_loss: 2.1465 - val_mae: 1.2944\n",
      "Epoch 4330/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0397 - mae: 0.1575 - val_loss: 2.3386 - val_mae: 1.3671\n",
      "Epoch 4331/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1534 - val_loss: 2.5018 - val_mae: 1.4260\n",
      "Epoch 4332/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0512 - mae: 0.1779 - val_loss: 2.4962 - val_mae: 1.4242\n",
      "Epoch 4333/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0500 - mae: 0.1749 - val_loss: 2.3435 - val_mae: 1.3694\n",
      "Epoch 4334/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0379 - mae: 0.1454 - val_loss: 2.2162 - val_mae: 1.3220\n",
      "Epoch 4335/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0408 - mae: 0.1657 - val_loss: 2.2582 - val_mae: 1.3381\n",
      "Epoch 4336/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0417 - mae: 0.1659 - val_loss: 2.3876 - val_mae: 1.3859\n",
      "Epoch 4337/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0391 - mae: 0.1547 - val_loss: 2.4494 - val_mae: 1.4082\n",
      "Epoch 4338/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0384 - mae: 0.1474 - val_loss: 2.4154 - val_mae: 1.3961\n",
      "Epoch 4339/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0389 - mae: 0.1508 - val_loss: 2.3577 - val_mae: 1.3751\n",
      "Epoch 4340/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0373 - mae: 0.1490 - val_loss: 2.2712 - val_mae: 1.3430\n",
      "Epoch 4341/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0351 - mae: 0.1448 - val_loss: 2.1850 - val_mae: 1.3103\n",
      "Epoch 4342/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0362 - mae: 0.1459 - val_loss: 2.1747 - val_mae: 1.3064\n",
      "Epoch 4343/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0368 - mae: 0.1427 - val_loss: 2.1857 - val_mae: 1.3106\n",
      "Epoch 4344/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0375 - mae: 0.1425 - val_loss: 2.0943 - val_mae: 1.2751\n",
      "Epoch 4345/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1545 - val_loss: 2.0778 - val_mae: 1.2685\n",
      "Epoch 4346/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0402 - mae: 0.1620 - val_loss: 2.2236 - val_mae: 1.3252\n",
      "Epoch 4347/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0363 - mae: 0.1480 - val_loss: 2.3545 - val_mae: 1.3741\n",
      "Epoch 4348/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0362 - mae: 0.1447 - val_loss: 2.4244 - val_mae: 1.3996\n",
      "Epoch 4349/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0382 - mae: 0.1445 - val_loss: 2.4248 - val_mae: 1.3998\n",
      "Epoch 4350/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0376 - mae: 0.1426 - val_loss: 2.3137 - val_mae: 1.3593\n",
      "Epoch 4351/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0377 - mae: 0.1494 - val_loss: 2.2267 - val_mae: 1.3268\n",
      "Epoch 4352/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0384 - mae: 0.1573 - val_loss: 2.2372 - val_mae: 1.3308\n",
      "Epoch 4353/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0350 - mae: 0.1457 - val_loss: 2.2788 - val_mae: 1.3464\n",
      "Epoch 4354/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0366 - mae: 0.1363 - val_loss: 2.3269 - val_mae: 1.3642\n",
      "Epoch 4355/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0428 - mae: 0.1506 - val_loss: 2.3341 - val_mae: 1.3667\n",
      "Epoch 4356/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1551 - val_loss: 2.2957 - val_mae: 1.3525\n",
      "Epoch 4357/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0412 - mae: 0.1455 - val_loss: 2.2246 - val_mae: 1.3258\n",
      "Epoch 4358/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0368 - mae: 0.1434 - val_loss: 2.1589 - val_mae: 1.3007\n",
      "Epoch 4359/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0381 - mae: 0.1556 - val_loss: 2.1998 - val_mae: 1.3165\n",
      "Epoch 4360/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0366 - mae: 0.1548 - val_loss: 2.3738 - val_mae: 1.3815\n",
      "Epoch 4361/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0343 - mae: 0.1418 - val_loss: 2.5449 - val_mae: 1.4426\n",
      "Epoch 4362/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0389 - mae: 0.1400 - val_loss: 2.5582 - val_mae: 1.4473\n",
      "Epoch 4363/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0382 - mae: 0.1375 - val_loss: 2.4444 - val_mae: 1.4073\n",
      "Epoch 4364/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0357 - mae: 0.1449 - val_loss: 2.3752 - val_mae: 1.3824\n",
      "Epoch 4365/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0365 - mae: 0.1559 - val_loss: 2.3753 - val_mae: 1.3825\n",
      "Epoch 4366/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0362 - mae: 0.1546 - val_loss: 2.4180 - val_mae: 1.3979\n",
      "Epoch 4367/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0349 - mae: 0.1435 - val_loss: 2.5075 - val_mae: 1.4297\n",
      "Epoch 4368/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0376 - mae: 0.1367 - val_loss: 2.5476 - val_mae: 1.4437\n",
      "Epoch 4369/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0391 - mae: 0.1399 - val_loss: 2.4404 - val_mae: 1.4057\n",
      "Epoch 4370/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0358 - mae: 0.1440 - val_loss: 2.3200 - val_mae: 1.3619\n",
      "Epoch 4371/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0347 - mae: 0.1481 - val_loss: 2.2990 - val_mae: 1.3540\n",
      "Epoch 4372/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0342 - mae: 0.1448 - val_loss: 2.3225 - val_mae: 1.3627\n",
      "Epoch 4373/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0356 - mae: 0.1397 - val_loss: 2.2158 - val_mae: 1.3228\n",
      "Epoch 4374/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0370 - mae: 0.1524 - val_loss: 2.1131 - val_mae: 1.2831\n",
      "Epoch 4375/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0412 - mae: 0.1678 - val_loss: 2.1613 - val_mae: 1.3018\n",
      "Epoch 4376/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0378 - mae: 0.1592 - val_loss: 2.2675 - val_mae: 1.3422\n",
      "Epoch 4377/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0344 - mae: 0.1411 - val_loss: 2.3780 - val_mae: 1.3830\n",
      "Epoch 4378/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0385 - mae: 0.1420 - val_loss: 2.3577 - val_mae: 1.3755\n",
      "Epoch 4379/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0373 - mae: 0.1414 - val_loss: 2.1837 - val_mae: 1.3102\n",
      "Epoch 4380/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0355 - mae: 0.1443 - val_loss: 1.9981 - val_mae: 1.2367\n",
      "Epoch 4381/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0446 - mae: 0.1699 - val_loss: 1.9121 - val_mae: 1.2010\n",
      "Epoch 4382/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0545 - mae: 0.1862 - val_loss: 1.9031 - val_mae: 1.1970\n",
      "Epoch 4383/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0558 - mae: 0.1849 - val_loss: 1.9980 - val_mae: 1.2362\n",
      "Epoch 4384/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0456 - mae: 0.1663 - val_loss: 2.1284 - val_mae: 1.2882\n",
      "Epoch 4385/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0380 - mae: 0.1547 - val_loss: 2.2410 - val_mae: 1.3316\n",
      "Epoch 4386/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0376 - mae: 0.1531 - val_loss: 2.2787 - val_mae: 1.3461\n",
      "Epoch 4387/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0349 - mae: 0.1428 - val_loss: 2.2037 - val_mae: 1.3179\n",
      "Epoch 4388/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0354 - mae: 0.1472 - val_loss: 2.1737 - val_mae: 1.3066\n",
      "Epoch 4389/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0355 - mae: 0.1493 - val_loss: 2.1915 - val_mae: 1.3136\n",
      "Epoch 4390/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0352 - mae: 0.1436 - val_loss: 2.2384 - val_mae: 1.3316\n",
      "Epoch 4391/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0363 - mae: 0.1386 - val_loss: 2.3700 - val_mae: 1.3805\n",
      "Epoch 4392/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0427 - mae: 0.1498 - val_loss: 2.4547 - val_mae: 1.4112\n",
      "Epoch 4393/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0451 - mae: 0.1542 - val_loss: 2.3752 - val_mae: 1.3827\n",
      "Epoch 4394/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0371 - mae: 0.1345 - val_loss: 2.2032 - val_mae: 1.3187\n",
      "Epoch 4395/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0367 - mae: 0.1563 - val_loss: 2.0958 - val_mae: 1.2771\n",
      "Epoch 4396/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0407 - mae: 0.1698 - val_loss: 2.1250 - val_mae: 1.2886\n",
      "Epoch 4397/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0376 - mae: 0.1581 - val_loss: 2.1646 - val_mae: 1.3039\n",
      "Epoch 4398/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0342 - mae: 0.1435 - val_loss: 2.1560 - val_mae: 1.3004\n",
      "Epoch 4399/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0340 - mae: 0.1396 - val_loss: 2.0903 - val_mae: 1.2745\n",
      "Epoch 4400/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0348 - mae: 0.1416 - val_loss: 2.0088 - val_mae: 1.2418\n",
      "Epoch 4401/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0369 - mae: 0.1455 - val_loss: 1.9509 - val_mae: 1.2182\n",
      "Epoch 4402/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1530 - val_loss: 1.9589 - val_mae: 1.2216\n",
      "Epoch 4403/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0387 - mae: 0.1533 - val_loss: 2.0633 - val_mae: 1.2641\n",
      "Epoch 4404/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0349 - mae: 0.1415 - val_loss: 2.1858 - val_mae: 1.3122\n",
      "Epoch 4405/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0345 - mae: 0.1372 - val_loss: 2.3064 - val_mae: 1.3579\n",
      "Epoch 4406/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0386 - mae: 0.1420 - val_loss: 2.3645 - val_mae: 1.3795\n",
      "Epoch 4407/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0389 - mae: 0.1415 - val_loss: 2.2820 - val_mae: 1.3493\n",
      "Epoch 4408/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0362 - mae: 0.1432 - val_loss: 2.1856 - val_mae: 1.3131\n",
      "Epoch 4409/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0411 - mae: 0.1633 - val_loss: 2.1939 - val_mae: 1.3165\n",
      "Epoch 4410/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0417 - mae: 0.1637 - val_loss: 2.3139 - val_mae: 1.3616\n",
      "Epoch 4411/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0385 - mae: 0.1448 - val_loss: 2.4329 - val_mae: 1.4050\n",
      "Epoch 4412/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0404 - mae: 0.1436 - val_loss: 2.4416 - val_mae: 1.4080\n",
      "Epoch 4413/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0409 - mae: 0.1439 - val_loss: 2.3283 - val_mae: 1.3669\n",
      "Epoch 4414/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0353 - mae: 0.1343 - val_loss: 2.1277 - val_mae: 1.2907\n",
      "Epoch 4415/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0331 - mae: 0.1406 - val_loss: 1.9404 - val_mae: 1.2151\n",
      "Epoch 4416/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0406 - mae: 0.1645 - val_loss: 1.8437 - val_mae: 1.1739\n",
      "Epoch 4417/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0465 - mae: 0.1708 - val_loss: 1.8699 - val_mae: 1.1848\n",
      "Epoch 4418/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0431 - mae: 0.1564 - val_loss: 1.9767 - val_mae: 1.2292\n",
      "Epoch 4419/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0400 - mae: 0.1466 - val_loss: 2.0746 - val_mae: 1.2686\n",
      "Epoch 4420/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0413 - mae: 0.1509 - val_loss: 2.0934 - val_mae: 1.2761\n",
      "Epoch 4421/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0398 - mae: 0.1480 - val_loss: 2.1150 - val_mae: 1.2848\n",
      "Epoch 4422/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0363 - mae: 0.1376 - val_loss: 2.1563 - val_mae: 1.3012\n",
      "Epoch 4423/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0338 - mae: 0.1309 - val_loss: 2.1349 - val_mae: 1.2931\n",
      "Epoch 4424/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0330 - mae: 0.1399 - val_loss: 2.0895 - val_mae: 1.2755\n",
      "Epoch 4425/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0365 - mae: 0.1571 - val_loss: 2.1053 - val_mae: 1.2817\n",
      "Epoch 4426/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0352 - mae: 0.1519 - val_loss: 2.1658 - val_mae: 1.3052\n",
      "Epoch 4427/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0325 - mae: 0.1360 - val_loss: 2.2398 - val_mae: 1.3334\n",
      "Epoch 4428/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0353 - mae: 0.1314 - val_loss: 2.2900 - val_mae: 1.3522\n",
      "Epoch 4429/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0390 - mae: 0.1390 - val_loss: 2.1949 - val_mae: 1.3162\n",
      "Epoch 4430/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0342 - mae: 0.1325 - val_loss: 2.0242 - val_mae: 1.2491\n",
      "Epoch 4431/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0358 - mae: 0.1495 - val_loss: 1.9250 - val_mae: 1.2082\n",
      "Epoch 4432/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0433 - mae: 0.1699 - val_loss: 1.9677 - val_mae: 1.2257\n",
      "Epoch 4433/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0382 - mae: 0.1529 - val_loss: 2.0876 - val_mae: 1.2739\n",
      "Epoch 4434/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0370 - mae: 0.1402 - val_loss: 2.2075 - val_mae: 1.3203\n",
      "Epoch 4435/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0459 - mae: 0.1556 - val_loss: 2.2962 - val_mae: 1.3538\n",
      "Epoch 4436/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0525 - mae: 0.1702 - val_loss: 2.2426 - val_mae: 1.3336\n",
      "Epoch 4437/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0430 - mae: 0.1500 - val_loss: 2.0673 - val_mae: 1.2657\n",
      "Epoch 4438/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0363 - mae: 0.1450 - val_loss: 1.9402 - val_mae: 1.2140\n",
      "Epoch 4439/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0426 - mae: 0.1667 - val_loss: 1.9570 - val_mae: 1.2211\n",
      "Epoch 4440/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0402 - mae: 0.1644 - val_loss: 2.1337 - val_mae: 1.2923\n",
      "Epoch 4441/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0322 - mae: 0.1324 - val_loss: 2.3900 - val_mae: 1.3889\n",
      "Epoch 4442/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0420 - mae: 0.1494 - val_loss: 2.5243 - val_mae: 1.4371\n",
      "Epoch 4443/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0503 - mae: 0.1710 - val_loss: 2.4420 - val_mae: 1.4082\n",
      "Epoch 4444/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0383 - mae: 0.1355 - val_loss: 2.2427 - val_mae: 1.3352\n",
      "Epoch 4445/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0352 - mae: 0.1524 - val_loss: 2.1073 - val_mae: 1.2833\n",
      "Epoch 4446/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0451 - mae: 0.1806 - val_loss: 2.0736 - val_mae: 1.2700\n",
      "Epoch 4447/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0470 - mae: 0.1842 - val_loss: 2.1061 - val_mae: 1.2826\n",
      "Epoch 4448/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0386 - mae: 0.1620 - val_loss: 2.2079 - val_mae: 1.3216\n",
      "Epoch 4449/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0342 - mae: 0.1415 - val_loss: 2.2104 - val_mae: 1.3222\n",
      "Epoch 4450/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0322 - mae: 0.1398 - val_loss: 2.0244 - val_mae: 1.2489\n",
      "Epoch 4451/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0410 - mae: 0.1632 - val_loss: 1.9542 - val_mae: 1.2200\n",
      "Epoch 4452/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - mae: 0.1695 - val_loss: 2.1048 - val_mae: 1.2808\n",
      "Epoch 4453/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0363 - mae: 0.1560 - val_loss: 2.2573 - val_mae: 1.3398\n",
      "Epoch 4454/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0364 - mae: 0.1460 - val_loss: 2.2987 - val_mae: 1.3556\n",
      "Epoch 4455/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0366 - mae: 0.1385 - val_loss: 2.2707 - val_mae: 1.3454\n",
      "Epoch 4456/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0346 - mae: 0.1294 - val_loss: 2.2022 - val_mae: 1.3198\n",
      "Epoch 4457/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0326 - mae: 0.1323 - val_loss: 2.0784 - val_mae: 1.2717\n",
      "Epoch 4458/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0346 - mae: 0.1504 - val_loss: 1.9841 - val_mae: 1.2336\n",
      "Epoch 4459/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0391 - mae: 0.1644 - val_loss: 1.9963 - val_mae: 1.2384\n",
      "Epoch 4460/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0362 - mae: 0.1551 - val_loss: 2.1030 - val_mae: 1.2810\n",
      "Epoch 4461/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0319 - mae: 0.1328 - val_loss: 2.2400 - val_mae: 1.3337\n",
      "Epoch 4462/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0364 - mae: 0.1364 - val_loss: 2.3173 - val_mae: 1.3627\n",
      "Epoch 4463/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0408 - mae: 0.1489 - val_loss: 2.2710 - val_mae: 1.3455\n",
      "Epoch 4464/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0358 - mae: 0.1355 - val_loss: 2.1630 - val_mae: 1.3044\n",
      "Epoch 4465/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0319 - mae: 0.1342 - val_loss: 2.0965 - val_mae: 1.2784\n",
      "Epoch 4466/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0326 - mae: 0.1414 - val_loss: 2.1221 - val_mae: 1.2886\n",
      "Epoch 4467/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1399 - val_loss: 2.1975 - val_mae: 1.3180\n",
      "Epoch 4468/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0318 - mae: 0.1360 - val_loss: 2.2830 - val_mae: 1.3504\n",
      "Epoch 4469/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0333 - mae: 0.1317 - val_loss: 2.3316 - val_mae: 1.3686\n",
      "Epoch 4470/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0358 - mae: 0.1323 - val_loss: 2.2877 - val_mae: 1.3523\n",
      "Epoch 4471/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0348 - mae: 0.1301 - val_loss: 2.2585 - val_mae: 1.3413\n",
      "Epoch 4472/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0331 - mae: 0.1296 - val_loss: 2.2161 - val_mae: 1.3252\n",
      "Epoch 4473/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1363 - val_loss: 2.1485 - val_mae: 1.2991\n",
      "Epoch 4474/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0320 - mae: 0.1395 - val_loss: 2.1393 - val_mae: 1.2953\n",
      "Epoch 4475/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0325 - mae: 0.1379 - val_loss: 2.1084 - val_mae: 1.2831\n",
      "Epoch 4476/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0336 - mae: 0.1444 - val_loss: 2.1039 - val_mae: 1.2813\n",
      "Epoch 4477/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0354 - mae: 0.1507 - val_loss: 2.2037 - val_mae: 1.3202\n",
      "Epoch 4478/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0345 - mae: 0.1493 - val_loss: 2.3108 - val_mae: 1.3606\n",
      "Epoch 4479/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0349 - mae: 0.1481 - val_loss: 2.3117 - val_mae: 1.3611\n",
      "Epoch 4480/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0339 - mae: 0.1431 - val_loss: 2.2318 - val_mae: 1.3312\n",
      "Epoch 4481/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1384 - val_loss: 2.2049 - val_mae: 1.3211\n",
      "Epoch 4482/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0312 - mae: 0.1299 - val_loss: 2.2308 - val_mae: 1.3311\n",
      "Epoch 4483/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0333 - mae: 0.1292 - val_loss: 2.2156 - val_mae: 1.3255\n",
      "Epoch 4484/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0334 - mae: 0.1289 - val_loss: 2.0976 - val_mae: 1.2800\n",
      "Epoch 4485/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0315 - mae: 0.1367 - val_loss: 1.9227 - val_mae: 1.2089\n",
      "Epoch 4486/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0406 - mae: 0.1681 - val_loss: 1.8799 - val_mae: 1.1909\n",
      "Epoch 4487/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0409 - mae: 0.1669 - val_loss: 1.9827 - val_mae: 1.2338\n",
      "Epoch 4488/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1376 - val_loss: 2.1143 - val_mae: 1.2865\n",
      "Epoch 4489/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0331 - mae: 0.1263 - val_loss: 2.2593 - val_mae: 1.3423\n",
      "Epoch 4490/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0443 - mae: 0.1588 - val_loss: 2.2947 - val_mae: 1.3557\n",
      "Epoch 4491/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1600 - val_loss: 2.1712 - val_mae: 1.3090\n",
      "Epoch 4492/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0330 - mae: 0.1271 - val_loss: 2.0066 - val_mae: 1.2441\n",
      "Epoch 4493/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0344 - mae: 0.1474 - val_loss: 1.9243 - val_mae: 1.2105\n",
      "Epoch 4494/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0437 - mae: 0.1687 - val_loss: 1.9751 - val_mae: 1.2318\n",
      "Epoch 4495/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0387 - mae: 0.1562 - val_loss: 2.1475 - val_mae: 1.3005\n",
      "Epoch 4496/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0340 - mae: 0.1336 - val_loss: 2.3159 - val_mae: 1.3642\n",
      "Epoch 4497/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0645 - mae: 0.2013 - val_loss: 2.2732 - val_mae: 1.3481\n",
      "Epoch 4498/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0728 - mae: 0.2062 - val_loss: 2.0687 - val_mae: 1.2692\n",
      "Epoch 4499/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0533 - mae: 0.1563 - val_loss: 1.8131 - val_mae: 1.1631\n",
      "Epoch 4500/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0468 - mae: 0.1635 - val_loss: 1.5703 - val_mae: 1.0524\n",
      "Epoch 4501/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0775 - mae: 0.2327 - val_loss: 1.5009 - val_mae: 1.0188\n",
      "Epoch 4502/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1097 - mae: 0.2940 - val_loss: 1.7914 - val_mae: 1.1543\n",
      "Epoch 4503/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0622 - mae: 0.2124 - val_loss: 2.3603 - val_mae: 1.3810\n",
      "Epoch 4504/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0429 - mae: 0.1529 - val_loss: 2.8217 - val_mae: 1.5403\n",
      "Epoch 4505/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0849 - mae: 0.2415 - val_loss: 2.9145 - val_mae: 1.5706\n",
      "Epoch 4506/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0893 - mae: 0.2416 - val_loss: 2.6611 - val_mae: 1.4875\n",
      "Epoch 4507/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0607 - mae: 0.1885 - val_loss: 2.2847 - val_mae: 1.3542\n",
      "Epoch 4508/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2033 - val_loss: 2.0177 - val_mae: 1.2505\n",
      "Epoch 4509/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0718 - mae: 0.2291 - val_loss: 2.0177 - val_mae: 1.2496\n",
      "Epoch 4510/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0401 - mae: 0.1655 - val_loss: 2.2109 - val_mae: 1.3242\n",
      "Epoch 4511/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0648 - mae: 0.1821 - val_loss: 2.3154 - val_mae: 1.3625\n",
      "Epoch 4512/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1182 - mae: 0.2630 - val_loss: 2.1832 - val_mae: 1.3120\n",
      "Epoch 4513/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1208 - mae: 0.2572 - val_loss: 1.9178 - val_mae: 1.2051\n",
      "Epoch 4514/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0931 - mae: 0.2147 - val_loss: 1.6687 - val_mae: 1.0954\n",
      "Epoch 4515/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0830 - mae: 0.2135 - val_loss: 1.4950 - val_mae: 1.0169\n",
      "Epoch 4516/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0962 - mae: 0.2372 - val_loss: 1.4648 - val_mae: 1.0081\n",
      "Epoch 4517/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0984 - mae: 0.2434 - val_loss: 1.5687 - val_mae: 1.0483\n",
      "Epoch 4518/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0811 - mae: 0.2131 - val_loss: 1.7555 - val_mae: 1.1353\n",
      "Epoch 4519/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0651 - mae: 0.1842 - val_loss: 1.9983 - val_mae: 1.2390\n",
      "Epoch 4520/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0655 - mae: 0.1862 - val_loss: 2.1931 - val_mae: 1.3163\n",
      "Epoch 4521/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0705 - mae: 0.1964 - val_loss: 2.2027 - val_mae: 1.3202\n",
      "Epoch 4522/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0604 - mae: 0.1829 - val_loss: 2.1615 - val_mae: 1.3046\n",
      "Epoch 4523/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0471 - mae: 0.1605 - val_loss: 2.1909 - val_mae: 1.3162\n",
      "Epoch 4524/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0441 - mae: 0.1563 - val_loss: 2.1875 - val_mae: 1.3152\n",
      "Epoch 4525/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0440 - mae: 0.1582 - val_loss: 2.2008 - val_mae: 1.3205\n",
      "Epoch 4526/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0430 - mae: 0.1631 - val_loss: 2.2897 - val_mae: 1.3541\n",
      "Epoch 4527/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0405 - mae: 0.1550 - val_loss: 2.4003 - val_mae: 1.3946\n",
      "Epoch 4528/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0410 - mae: 0.1563 - val_loss: 2.4630 - val_mae: 1.4170\n",
      "Epoch 4529/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0421 - mae: 0.1567 - val_loss: 2.4685 - val_mae: 1.4189\n",
      "Epoch 4530/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0407 - mae: 0.1525 - val_loss: 2.4110 - val_mae: 1.3982\n",
      "Epoch 4531/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0374 - mae: 0.1468 - val_loss: 2.3260 - val_mae: 1.3670\n",
      "Epoch 4532/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0353 - mae: 0.1468 - val_loss: 2.2978 - val_mae: 1.3565\n",
      "Epoch 4533/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0342 - mae: 0.1458 - val_loss: 2.3337 - val_mae: 1.3696\n",
      "Epoch 4534/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0339 - mae: 0.1417 - val_loss: 2.3713 - val_mae: 1.3833\n",
      "Epoch 4535/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0347 - mae: 0.1393 - val_loss: 2.3449 - val_mae: 1.3737\n",
      "Epoch 4536/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0337 - mae: 0.1391 - val_loss: 2.2522 - val_mae: 1.3393\n",
      "Epoch 4537/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0328 - mae: 0.1433 - val_loss: 2.1843 - val_mae: 1.3135\n",
      "Epoch 4538/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0333 - mae: 0.1468 - val_loss: 2.1715 - val_mae: 1.3086\n",
      "Epoch 4539/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0330 - mae: 0.1446 - val_loss: 2.1650 - val_mae: 1.3061\n",
      "Epoch 4540/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0327 - mae: 0.1413 - val_loss: 2.2144 - val_mae: 1.3251\n",
      "Epoch 4541/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0339 - mae: 0.1361 - val_loss: 2.2280 - val_mae: 1.3305\n",
      "Epoch 4542/5000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0322 - mae: 0.1361 - val_loss: 2.1448 - val_mae: 1.2986\n",
      "Epoch 4543/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0340 - mae: 0.1508 - val_loss: 2.1133 - val_mae: 1.2863\n",
      "Epoch 4544/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0360 - mae: 0.1557 - val_loss: 2.1584 - val_mae: 1.3038\n",
      "Epoch 4545/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0343 - mae: 0.1485 - val_loss: 2.2479 - val_mae: 1.3380\n",
      "Epoch 4546/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0332 - mae: 0.1408 - val_loss: 2.2971 - val_mae: 1.3563\n",
      "Epoch 4547/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0340 - mae: 0.1414 - val_loss: 2.2758 - val_mae: 1.3482\n",
      "Epoch 4548/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0336 - mae: 0.1398 - val_loss: 2.2167 - val_mae: 1.3259\n",
      "Epoch 4549/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0329 - mae: 0.1384 - val_loss: 2.2219 - val_mae: 1.3280\n",
      "Epoch 4550/5000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0322 - mae: 0.1359 - val_loss: 2.2612 - val_mae: 1.3430\n",
      "Epoch 4551/5000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0327 - mae: 0.1328 - val_loss: 2.2457 - val_mae: 1.3373\n",
      "Epoch 4552/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0328 - mae: 0.1308 - val_loss: 2.1619 - val_mae: 1.3053\n",
      "Epoch 4553/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0316 - mae: 0.1328 - val_loss: 2.0640 - val_mae: 1.2669\n",
      "Epoch 4554/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0329 - mae: 0.1476 - val_loss: 1.9882 - val_mae: 1.2362\n",
      "Epoch 4555/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0372 - mae: 0.1608 - val_loss: 1.9495 - val_mae: 1.2200\n",
      "Epoch 4556/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0389 - mae: 0.1637 - val_loss: 2.0003 - val_mae: 1.2406\n",
      "Epoch 4557/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0343 - mae: 0.1491 - val_loss: 2.1128 - val_mae: 1.2854\n",
      "Epoch 4558/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0317 - mae: 0.1366 - val_loss: 2.2200 - val_mae: 1.3269\n",
      "Epoch 4559/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0326 - mae: 0.1338 - val_loss: 2.2317 - val_mae: 1.3314\n",
      "Epoch 4560/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0323 - mae: 0.1335 - val_loss: 2.1857 - val_mae: 1.3139\n",
      "Epoch 4561/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0310 - mae: 0.1324 - val_loss: 2.1333 - val_mae: 1.2937\n",
      "Epoch 4562/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0308 - mae: 0.1360 - val_loss: 2.1201 - val_mae: 1.2887\n",
      "Epoch 4563/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0312 - mae: 0.1395 - val_loss: 2.1651 - val_mae: 1.3063\n",
      "Epoch 4564/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0309 - mae: 0.1347 - val_loss: 2.2327 - val_mae: 1.3322\n",
      "Epoch 4565/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0322 - mae: 0.1306 - val_loss: 2.2139 - val_mae: 1.3249\n",
      "Epoch 4566/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0312 - mae: 0.1301 - val_loss: 2.0925 - val_mae: 1.2777\n",
      "Epoch 4567/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0318 - mae: 0.1423 - val_loss: 1.9934 - val_mae: 1.2377\n",
      "Epoch 4568/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0354 - mae: 0.1534 - val_loss: 2.0395 - val_mae: 1.2564\n",
      "Epoch 4569/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0346 - mae: 0.1440 - val_loss: 2.1127 - val_mae: 1.2856\n",
      "Epoch 4570/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0309 - mae: 0.1306 - val_loss: 2.0800 - val_mae: 1.2728\n",
      "Epoch 4571/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0315 - mae: 0.1407 - val_loss: 2.0731 - val_mae: 1.2703\n",
      "Epoch 4572/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0326 - mae: 0.1452 - val_loss: 2.1038 - val_mae: 1.2825\n",
      "Epoch 4573/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0319 - mae: 0.1417 - val_loss: 2.1226 - val_mae: 1.2899\n",
      "Epoch 4574/5000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0313 - mae: 0.1392 - val_loss: 2.1308 - val_mae: 1.2932\n",
      "Epoch 4575/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0306 - mae: 0.1350 - val_loss: 2.1825 - val_mae: 1.3134\n",
      "Epoch 4576/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0326 - mae: 0.1332 - val_loss: 2.1615 - val_mae: 1.3054\n",
      "Epoch 4577/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0318 - mae: 0.1258 - val_loss: 1.9912 - val_mae: 1.2377\n",
      "Epoch 4578/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0309 - mae: 0.1291 - val_loss: 1.8490 - val_mae: 1.1781\n",
      "Epoch 4579/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0350 - mae: 0.1443 - val_loss: 1.8335 - val_mae: 1.1715\n",
      "Epoch 4580/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0346 - mae: 0.1401 - val_loss: 1.9184 - val_mae: 1.2078\n",
      "Epoch 4581/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0330 - mae: 0.1305 - val_loss: 1.9932 - val_mae: 1.2390\n",
      "Epoch 4582/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0346 - mae: 0.1297 - val_loss: 2.0158 - val_mae: 1.2485\n",
      "Epoch 4583/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0350 - mae: 0.1308 - val_loss: 2.0001 - val_mae: 1.2425\n",
      "Epoch 4584/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0331 - mae: 0.1261 - val_loss: 1.9610 - val_mae: 1.2268\n",
      "Epoch 4585/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0308 - mae: 0.1227 - val_loss: 1.8855 - val_mae: 1.1955\n",
      "Epoch 4586/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0316 - mae: 0.1389 - val_loss: 1.8087 - val_mae: 1.1624\n",
      "Epoch 4587/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0371 - mae: 0.1595 - val_loss: 1.8521 - val_mae: 1.1809\n",
      "Epoch 4588/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0339 - mae: 0.1499 - val_loss: 2.0000 - val_mae: 1.2426\n",
      "Epoch 4589/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0299 - mae: 0.1279 - val_loss: 2.1279 - val_mae: 1.2937\n",
      "Epoch 4590/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0319 - mae: 0.1296 - val_loss: 2.1856 - val_mae: 1.3160\n",
      "Epoch 4591/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0338 - mae: 0.1339 - val_loss: 2.1512 - val_mae: 1.3027\n",
      "Epoch 4592/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0316 - mae: 0.1317 - val_loss: 2.0446 - val_mae: 1.2605\n",
      "Epoch 4593/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0298 - mae: 0.1317 - val_loss: 1.9329 - val_mae: 1.2146\n",
      "Epoch 4594/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0324 - mae: 0.1434 - val_loss: 1.8827 - val_mae: 1.1932\n",
      "Epoch 4595/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0333 - mae: 0.1464 - val_loss: 1.9199 - val_mae: 1.2088\n",
      "Epoch 4596/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0306 - mae: 0.1338 - val_loss: 1.9678 - val_mae: 1.2286\n",
      "Epoch 4597/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0300 - mae: 0.1233 - val_loss: 1.9576 - val_mae: 1.2243\n",
      "Epoch 4598/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0313 - mae: 0.1255 - val_loss: 1.9245 - val_mae: 1.2105\n",
      "Epoch 4599/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0320 - mae: 0.1271 - val_loss: 1.9080 - val_mae: 1.2037\n",
      "Epoch 4600/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0319 - mae: 0.1267 - val_loss: 1.9290 - val_mae: 1.2128\n",
      "Epoch 4601/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0308 - mae: 0.1237 - val_loss: 2.0427 - val_mae: 1.2598\n",
      "Epoch 4602/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0324 - mae: 0.1266 - val_loss: 2.1915 - val_mae: 1.3187\n",
      "Epoch 4603/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0391 - mae: 0.1425 - val_loss: 2.2737 - val_mae: 1.3503\n",
      "Epoch 4604/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1470 - val_loss: 2.2761 - val_mae: 1.3517\n",
      "Epoch 4605/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0407 - mae: 0.1478 - val_loss: 2.2423 - val_mae: 1.3393\n",
      "Epoch 4606/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0390 - mae: 0.1528 - val_loss: 2.2489 - val_mae: 1.3418\n",
      "Epoch 4607/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0383 - mae: 0.1524 - val_loss: 2.1867 - val_mae: 1.3178\n",
      "Epoch 4608/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0341 - mae: 0.1470 - val_loss: 2.0607 - val_mae: 1.2678\n",
      "Epoch 4609/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0305 - mae: 0.1397 - val_loss: 1.9614 - val_mae: 1.2265\n",
      "Epoch 4610/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0312 - mae: 0.1390 - val_loss: 1.9111 - val_mae: 1.2046\n",
      "Epoch 4611/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0323 - mae: 0.1356 - val_loss: 1.9231 - val_mae: 1.2089\n",
      "Epoch 4612/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0336 - mae: 0.1369 - val_loss: 1.9971 - val_mae: 1.2391\n",
      "Epoch 4613/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0366 - mae: 0.1456 - val_loss: 2.0473 - val_mae: 1.2595\n",
      "Epoch 4614/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0364 - mae: 0.1419 - val_loss: 2.0459 - val_mae: 1.2596\n",
      "Epoch 4615/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0329 - mae: 0.1306 - val_loss: 2.0937 - val_mae: 1.2794\n",
      "Epoch 4616/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0312 - mae: 0.1289 - val_loss: 2.1290 - val_mae: 1.2941\n",
      "Epoch 4617/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0308 - mae: 0.1311 - val_loss: 2.1993 - val_mae: 1.3219\n",
      "Epoch 4618/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0318 - mae: 0.1358 - val_loss: 2.3323 - val_mae: 1.3723\n",
      "Epoch 4619/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0366 - mae: 0.1428 - val_loss: 2.3850 - val_mae: 1.3916\n",
      "Epoch 4620/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0383 - mae: 0.1434 - val_loss: 2.2964 - val_mae: 1.3589\n",
      "Epoch 4621/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0351 - mae: 0.1433 - val_loss: 2.1816 - val_mae: 1.3152\n",
      "Epoch 4622/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0315 - mae: 0.1397 - val_loss: 2.1210 - val_mae: 1.2912\n",
      "Epoch 4623/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0293 - mae: 0.1302 - val_loss: 2.0672 - val_mae: 1.2695\n",
      "Epoch 4624/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0303 - mae: 0.1263 - val_loss: 1.9963 - val_mae: 1.2405\n",
      "Epoch 4625/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0330 - mae: 0.1304 - val_loss: 1.9510 - val_mae: 1.2217\n",
      "Epoch 4626/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0347 - mae: 0.1320 - val_loss: 1.9049 - val_mae: 1.2024\n",
      "Epoch 4627/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0351 - mae: 0.1347 - val_loss: 1.8857 - val_mae: 1.1944\n",
      "Epoch 4628/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0334 - mae: 0.1344 - val_loss: 1.9261 - val_mae: 1.2119\n",
      "Epoch 4629/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0301 - mae: 0.1304 - val_loss: 1.9933 - val_mae: 1.2401\n",
      "Epoch 4630/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0316 - mae: 0.1414 - val_loss: 2.0698 - val_mae: 1.2710\n",
      "Epoch 4631/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0369 - mae: 0.1492 - val_loss: 2.1449 - val_mae: 1.3005\n",
      "Epoch 4632/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0405 - mae: 0.1549 - val_loss: 2.2399 - val_mae: 1.3367\n",
      "Epoch 4633/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0411 - mae: 0.1589 - val_loss: 2.2876 - val_mae: 1.3544\n",
      "Epoch 4634/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0403 - mae: 0.1563 - val_loss: 2.2278 - val_mae: 1.3317\n",
      "Epoch 4635/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0361 - mae: 0.1471 - val_loss: 2.1237 - val_mae: 1.2911\n",
      "Epoch 4636/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0315 - mae: 0.1363 - val_loss: 2.0579 - val_mae: 1.2647\n",
      "Epoch 4637/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0287 - mae: 0.1270 - val_loss: 2.0629 - val_mae: 1.2664\n",
      "Epoch 4638/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0296 - mae: 0.1227 - val_loss: 2.1250 - val_mae: 1.2910\n",
      "Epoch 4639/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0362 - mae: 0.1384 - val_loss: 2.1290 - val_mae: 1.2925\n",
      "Epoch 4640/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0366 - mae: 0.1389 - val_loss: 1.9987 - val_mae: 1.2400\n",
      "Epoch 4641/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0296 - mae: 0.1280 - val_loss: 1.8568 - val_mae: 1.1804\n",
      "Epoch 4642/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0356 - mae: 0.1538 - val_loss: 1.7968 - val_mae: 1.1543\n",
      "Epoch 4643/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0490 - mae: 0.1819 - val_loss: 1.8784 - val_mae: 1.1891\n",
      "Epoch 4644/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0391 - mae: 0.1605 - val_loss: 2.0621 - val_mae: 1.2645\n",
      "Epoch 4645/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0289 - mae: 0.1323 - val_loss: 2.2075 - val_mae: 1.3212\n",
      "Epoch 4646/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0375 - mae: 0.1486 - val_loss: 2.2229 - val_mae: 1.3272\n",
      "Epoch 4647/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0400 - mae: 0.1559 - val_loss: 2.0679 - val_mae: 1.2669\n",
      "Epoch 4648/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0320 - mae: 0.1293 - val_loss: 1.9334 - val_mae: 1.2121\n",
      "Epoch 4649/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0294 - mae: 0.1289 - val_loss: 1.9075 - val_mae: 1.2016\n",
      "Epoch 4650/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0305 - mae: 0.1353 - val_loss: 1.9078 - val_mae: 1.2021\n",
      "Epoch 4651/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0307 - mae: 0.1379 - val_loss: 1.9529 - val_mae: 1.2213\n",
      "Epoch 4652/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0289 - mae: 0.1293 - val_loss: 2.0338 - val_mae: 1.2546\n",
      "Epoch 4653/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0286 - mae: 0.1221 - val_loss: 2.0892 - val_mae: 1.2769\n",
      "Epoch 4654/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0305 - mae: 0.1227 - val_loss: 2.0681 - val_mae: 1.2685\n",
      "Epoch 4655/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0300 - mae: 0.1224 - val_loss: 2.0075 - val_mae: 1.2441\n",
      "Epoch 4656/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0282 - mae: 0.1200 - val_loss: 1.9238 - val_mae: 1.2097\n",
      "Epoch 4657/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0286 - mae: 0.1266 - val_loss: 1.8526 - val_mae: 1.1796\n",
      "Epoch 4658/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0299 - mae: 0.1327 - val_loss: 1.8254 - val_mae: 1.1678\n",
      "Epoch 4659/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0302 - mae: 0.1323 - val_loss: 1.8407 - val_mae: 1.1747\n",
      "Epoch 4660/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0286 - mae: 0.1267 - val_loss: 1.9449 - val_mae: 1.2193\n",
      "Epoch 4661/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0284 - mae: 0.1177 - val_loss: 2.0675 - val_mae: 1.2700\n",
      "Epoch 4662/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0332 - mae: 0.1314 - val_loss: 2.1195 - val_mae: 1.2912\n",
      "Epoch 4663/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0354 - mae: 0.1357 - val_loss: 2.0935 - val_mae: 1.2814\n",
      "Epoch 4664/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0324 - mae: 0.1296 - val_loss: 2.0681 - val_mae: 1.2717\n",
      "Epoch 4665/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0296 - mae: 0.1263 - val_loss: 2.0257 - val_mae: 1.2552\n",
      "Epoch 4666/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0289 - mae: 0.1339 - val_loss: 1.9473 - val_mae: 1.2234\n",
      "Epoch 4667/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0348 - mae: 0.1504 - val_loss: 1.9757 - val_mae: 1.2354\n",
      "Epoch 4668/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0377 - mae: 0.1533 - val_loss: 2.1399 - val_mae: 1.3010\n",
      "Epoch 4669/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0365 - mae: 0.1487 - val_loss: 2.2704 - val_mae: 1.3506\n",
      "Epoch 4670/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0384 - mae: 0.1504 - val_loss: 2.0942 - val_mae: 1.2824\n",
      "Epoch 4671/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1404 - val_loss: 1.8293 - val_mae: 1.1723\n",
      "Epoch 4672/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0343 - mae: 0.1444 - val_loss: 1.7634 - val_mae: 1.1429\n",
      "Epoch 4673/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0318 - mae: 0.1413 - val_loss: 1.7897 - val_mae: 1.1543\n",
      "Epoch 4674/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0288 - mae: 0.1240 - val_loss: 1.7545 - val_mae: 1.1385\n",
      "Epoch 4675/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0306 - mae: 0.1243 - val_loss: 1.6512 - val_mae: 1.0914\n",
      "Epoch 4676/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0344 - mae: 0.1400 - val_loss: 1.6073 - val_mae: 1.0711\n",
      "Epoch 4677/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0376 - mae: 0.1510 - val_loss: 1.6964 - val_mae: 1.1130\n",
      "Epoch 4678/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0303 - mae: 0.1317 - val_loss: 1.8469 - val_mae: 1.1801\n",
      "Epoch 4679/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0299 - mae: 0.1296 - val_loss: 1.9332 - val_mae: 1.2168\n",
      "Epoch 4680/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0336 - mae: 0.1425 - val_loss: 1.8916 - val_mae: 1.1994\n",
      "Epoch 4681/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0311 - mae: 0.1356 - val_loss: 1.8407 - val_mae: 1.1781\n",
      "Epoch 4682/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0288 - mae: 0.1249 - val_loss: 1.8240 - val_mae: 1.1715\n",
      "Epoch 4683/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0291 - mae: 0.1263 - val_loss: 1.7891 - val_mae: 1.1570\n",
      "Epoch 4684/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0320 - mae: 0.1367 - val_loss: 1.8472 - val_mae: 1.1827\n",
      "Epoch 4685/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0313 - mae: 0.1379 - val_loss: 1.9920 - val_mae: 1.2436\n",
      "Epoch 4686/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0330 - mae: 0.1351 - val_loss: 2.1214 - val_mae: 1.2954\n",
      "Epoch 4687/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0418 - mae: 0.1504 - val_loss: 2.1806 - val_mae: 1.3184\n",
      "Epoch 4688/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0455 - mae: 0.1571 - val_loss: 2.1141 - val_mae: 1.2925\n",
      "Epoch 4689/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0372 - mae: 0.1434 - val_loss: 1.9573 - val_mae: 1.2288\n",
      "Epoch 4690/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0304 - mae: 0.1405 - val_loss: 1.7738 - val_mae: 1.1494\n",
      "Epoch 4691/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0359 - mae: 0.1542 - val_loss: 1.7091 - val_mae: 1.1194\n",
      "Epoch 4692/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0393 - mae: 0.1639 - val_loss: 1.7652 - val_mae: 1.1437\n",
      "Epoch 4693/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0319 - mae: 0.1442 - val_loss: 1.8577 - val_mae: 1.1831\n",
      "Epoch 4694/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0268 - mae: 0.1207 - val_loss: 1.9628 - val_mae: 1.2270\n",
      "Epoch 4695/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0299 - mae: 0.1275 - val_loss: 2.0426 - val_mae: 1.2596\n",
      "Epoch 4696/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0343 - mae: 0.1390 - val_loss: 2.0642 - val_mae: 1.2688\n",
      "Epoch 4697/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0315 - mae: 0.1324 - val_loss: 2.0589 - val_mae: 1.2674\n",
      "Epoch 4698/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0287 - mae: 0.1310 - val_loss: 2.0132 - val_mae: 1.2496\n",
      "Epoch 4699/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0335 - mae: 0.1415 - val_loss: 1.9489 - val_mae: 1.2236\n",
      "Epoch 4700/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0433 - mae: 0.1599 - val_loss: 1.9177 - val_mae: 1.2107\n",
      "Epoch 4701/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0476 - mae: 0.1673 - val_loss: 1.9541 - val_mae: 1.2256\n",
      "Epoch 4702/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0407 - mae: 0.1561 - val_loss: 2.0328 - val_mae: 1.2574\n",
      "Epoch 4703/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0328 - mae: 0.1413 - val_loss: 2.0988 - val_mae: 1.2832\n",
      "Epoch 4704/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0305 - mae: 0.1342 - val_loss: 2.1183 - val_mae: 1.2904\n",
      "Epoch 4705/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0325 - mae: 0.1335 - val_loss: 2.0273 - val_mae: 1.2535\n",
      "Epoch 4706/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0302 - mae: 0.1246 - val_loss: 1.8653 - val_mae: 1.1852\n",
      "Epoch 4707/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0283 - mae: 0.1202 - val_loss: 1.7487 - val_mae: 1.1334\n",
      "Epoch 4708/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0326 - mae: 0.1342 - val_loss: 1.6865 - val_mae: 1.1048\n",
      "Epoch 4709/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0370 - mae: 0.1460 - val_loss: 1.7103 - val_mae: 1.1156\n",
      "Epoch 4710/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0355 - mae: 0.1415 - val_loss: 1.7842 - val_mae: 1.1491\n",
      "Epoch 4711/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0311 - mae: 0.1296 - val_loss: 1.8699 - val_mae: 1.1868\n",
      "Epoch 4712/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0294 - mae: 0.1222 - val_loss: 1.9264 - val_mae: 1.2111\n",
      "Epoch 4713/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0280 - mae: 0.1180 - val_loss: 1.9123 - val_mae: 1.2056\n",
      "Epoch 4714/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0264 - mae: 0.1174 - val_loss: 1.8810 - val_mae: 1.1926\n",
      "Epoch 4715/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0264 - mae: 0.1225 - val_loss: 1.8855 - val_mae: 1.1947\n",
      "Epoch 4716/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0264 - mae: 0.1246 - val_loss: 1.9253 - val_mae: 1.2118\n",
      "Epoch 4717/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0263 - mae: 0.1247 - val_loss: 1.9444 - val_mae: 1.2200\n",
      "Epoch 4718/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0268 - mae: 0.1263 - val_loss: 1.9485 - val_mae: 1.2219\n",
      "Epoch 4719/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0266 - mae: 0.1250 - val_loss: 1.9502 - val_mae: 1.2224\n",
      "Epoch 4720/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0269 - mae: 0.1219 - val_loss: 1.9559 - val_mae: 1.2244\n",
      "Epoch 4721/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0284 - mae: 0.1216 - val_loss: 1.9451 - val_mae: 1.2195\n",
      "Epoch 4722/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0295 - mae: 0.1241 - val_loss: 1.9085 - val_mae: 1.2039\n",
      "Epoch 4723/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0284 - mae: 0.1213 - val_loss: 1.8194 - val_mae: 1.1655\n",
      "Epoch 4724/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0256 - mae: 0.1123 - val_loss: 1.6730 - val_mae: 1.0996\n",
      "Epoch 4725/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0319 - mae: 0.1389 - val_loss: 1.6001 - val_mae: 1.0654\n",
      "Epoch 4726/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0385 - mae: 0.1551 - val_loss: 1.6587 - val_mae: 1.0933\n",
      "Epoch 4727/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0314 - mae: 0.1387 - val_loss: 1.7585 - val_mae: 1.1391\n",
      "Epoch 4728/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0266 - mae: 0.1151 - val_loss: 1.7912 - val_mae: 1.1538\n",
      "Epoch 4729/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0257 - mae: 0.1141 - val_loss: 1.7351 - val_mae: 1.1287\n",
      "Epoch 4730/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0262 - mae: 0.1187 - val_loss: 1.6957 - val_mae: 1.1105\n",
      "Epoch 4731/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0274 - mae: 0.1234 - val_loss: 1.7307 - val_mae: 1.1267\n",
      "Epoch 4732/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0266 - mae: 0.1196 - val_loss: 1.7724 - val_mae: 1.1460\n",
      "Epoch 4733/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0270 - mae: 0.1199 - val_loss: 1.7259 - val_mae: 1.1256\n",
      "Epoch 4734/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0272 - mae: 0.1247 - val_loss: 1.6441 - val_mae: 1.0881\n",
      "Epoch 4735/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0306 - mae: 0.1361 - val_loss: 1.6089 - val_mae: 1.0710\n",
      "Epoch 4736/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0319 - mae: 0.1401 - val_loss: 1.6295 - val_mae: 1.0797\n",
      "Epoch 4737/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0283 - mae: 0.1274 - val_loss: 1.7445 - val_mae: 1.1322\n",
      "Epoch 4738/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0277 - mae: 0.1187 - val_loss: 1.8492 - val_mae: 1.1784\n",
      "Epoch 4739/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0333 - mae: 0.1342 - val_loss: 1.8311 - val_mae: 1.1705\n",
      "Epoch 4740/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0307 - mae: 0.1246 - val_loss: 1.7468 - val_mae: 1.1330\n",
      "Epoch 4741/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0270 - mae: 0.1137 - val_loss: 1.7001 - val_mae: 1.1117\n",
      "Epoch 4742/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0265 - mae: 0.1157 - val_loss: 1.7032 - val_mae: 1.1132\n",
      "Epoch 4743/5000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0265 - mae: 0.1166 - val_loss: 1.7106 - val_mae: 1.1167\n",
      "Epoch 4744/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0263 - mae: 0.1175 - val_loss: 1.7760 - val_mae: 1.1467\n",
      "Epoch 4745/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0258 - mae: 0.1150 - val_loss: 1.8883 - val_mae: 1.1961\n",
      "Epoch 4746/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0304 - mae: 0.1262 - val_loss: 1.9147 - val_mae: 1.2072\n",
      "Epoch 4747/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0319 - mae: 0.1285 - val_loss: 1.8535 - val_mae: 1.1807\n",
      "Epoch 4748/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0274 - mae: 0.1190 - val_loss: 1.7764 - val_mae: 1.1464\n",
      "Epoch 4749/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0248 - mae: 0.1149 - val_loss: 1.6737 - val_mae: 1.0990\n",
      "Epoch 4750/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0299 - mae: 0.1341 - val_loss: 1.6615 - val_mae: 1.0928\n",
      "Epoch 4751/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0296 - mae: 0.1346 - val_loss: 1.7890 - val_mae: 1.1508\n",
      "Epoch 4752/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0245 - mae: 0.1126 - val_loss: 1.9369 - val_mae: 1.2150\n",
      "Epoch 4753/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0313 - mae: 0.1294 - val_loss: 1.9681 - val_mae: 1.2288\n",
      "Epoch 4754/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0312 - mae: 0.1328 - val_loss: 1.8923 - val_mae: 1.1977\n",
      "Epoch 4755/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0267 - mae: 0.1247 - val_loss: 1.7930 - val_mae: 1.1548\n",
      "Epoch 4756/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0313 - mae: 0.1364 - val_loss: 1.7113 - val_mae: 1.1176\n",
      "Epoch 4757/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1511 - val_loss: 1.7595 - val_mae: 1.1388\n",
      "Epoch 4758/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0338 - mae: 0.1382 - val_loss: 1.8367 - val_mae: 1.1722\n",
      "Epoch 4759/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0270 - mae: 0.1269 - val_loss: 1.8331 - val_mae: 1.1698\n",
      "Epoch 4760/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0262 - mae: 0.1220 - val_loss: 1.7766 - val_mae: 1.1445\n",
      "Epoch 4761/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0255 - mae: 0.1164 - val_loss: 1.7273 - val_mae: 1.1226\n",
      "Epoch 4762/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0261 - mae: 0.1204 - val_loss: 1.7436 - val_mae: 1.1303\n",
      "Epoch 4763/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0249 - mae: 0.1152 - val_loss: 1.7973 - val_mae: 1.1548\n",
      "Epoch 4764/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0262 - mae: 0.1126 - val_loss: 1.8247 - val_mae: 1.1671\n",
      "Epoch 4765/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0279 - mae: 0.1169 - val_loss: 1.8032 - val_mae: 1.1576\n",
      "Epoch 4766/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0271 - mae: 0.1163 - val_loss: 1.7925 - val_mae: 1.1527\n",
      "Epoch 4767/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0257 - mae: 0.1139 - val_loss: 1.8224 - val_mae: 1.1660\n",
      "Epoch 4768/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0252 - mae: 0.1121 - val_loss: 1.8455 - val_mae: 1.1761\n",
      "Epoch 4769/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0247 - mae: 0.1125 - val_loss: 1.8151 - val_mae: 1.1630\n",
      "Epoch 4770/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0242 - mae: 0.1164 - val_loss: 1.7851 - val_mae: 1.1498\n",
      "Epoch 4771/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0254 - mae: 0.1231 - val_loss: 1.8298 - val_mae: 1.1697\n",
      "Epoch 4772/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0249 - mae: 0.1221 - val_loss: 1.9255 - val_mae: 1.2113\n",
      "Epoch 4773/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0254 - mae: 0.1223 - val_loss: 1.9859 - val_mae: 1.2372\n",
      "Epoch 4774/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0271 - mae: 0.1260 - val_loss: 1.9867 - val_mae: 1.2378\n",
      "Epoch 4775/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0273 - mae: 0.1295 - val_loss: 1.9622 - val_mae: 1.2276\n",
      "Epoch 4776/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0268 - mae: 0.1316 - val_loss: 1.8992 - val_mae: 1.2004\n",
      "Epoch 4777/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0266 - mae: 0.1320 - val_loss: 1.8399 - val_mae: 1.1736\n",
      "Epoch 4778/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0265 - mae: 0.1281 - val_loss: 1.7990 - val_mae: 1.1541\n",
      "Epoch 4779/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0277 - mae: 0.1304 - val_loss: 1.8106 - val_mae: 1.1577\n",
      "Epoch 4780/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0256 - mae: 0.1234 - val_loss: 1.8959 - val_mae: 1.1935\n",
      "Epoch 4781/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0294 - mae: 0.1296 - val_loss: 1.9255 - val_mae: 1.2057\n",
      "Epoch 4782/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0331 - mae: 0.1370 - val_loss: 1.8935 - val_mae: 1.1924\n",
      "Epoch 4783/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0302 - mae: 0.1243 - val_loss: 1.8384 - val_mae: 1.1692\n",
      "Epoch 4784/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0262 - mae: 0.1139 - val_loss: 1.7874 - val_mae: 1.1476\n",
      "Epoch 4785/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0253 - mae: 0.1191 - val_loss: 1.8102 - val_mae: 1.1585\n",
      "Epoch 4786/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0253 - mae: 0.1262 - val_loss: 1.9208 - val_mae: 1.2071\n",
      "Epoch 4787/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0262 - mae: 0.1283 - val_loss: 2.0144 - val_mae: 1.2469\n",
      "Epoch 4788/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0296 - mae: 0.1346 - val_loss: 1.9983 - val_mae: 1.2408\n",
      "Epoch 4789/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0306 - mae: 0.1416 - val_loss: 1.9025 - val_mae: 1.2005\n",
      "Epoch 4790/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0320 - mae: 0.1464 - val_loss: 1.8092 - val_mae: 1.1591\n",
      "Epoch 4791/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0340 - mae: 0.1484 - val_loss: 1.7711 - val_mae: 1.1409\n",
      "Epoch 4792/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0314 - mae: 0.1408 - val_loss: 1.8101 - val_mae: 1.1568\n",
      "Epoch 4793/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0256 - mae: 0.1240 - val_loss: 1.9357 - val_mae: 1.2101\n",
      "Epoch 4794/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0275 - mae: 0.1203 - val_loss: 1.9649 - val_mae: 1.2214\n",
      "Epoch 4795/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0258 - mae: 0.1204 - val_loss: 1.7814 - val_mae: 1.1409\n",
      "Epoch 4796/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0246 - mae: 0.1209 - val_loss: 1.5768 - val_mae: 1.0474\n",
      "Epoch 4797/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0468 - mae: 0.1687 - val_loss: 1.5475 - val_mae: 1.0385\n",
      "Epoch 4798/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1748 - val_loss: 1.6973 - val_mae: 1.0997\n",
      "Epoch 4799/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0326 - mae: 0.1346 - val_loss: 1.8631 - val_mae: 1.1729\n",
      "Epoch 4800/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0314 - mae: 0.1305 - val_loss: 1.8883 - val_mae: 1.1838\n",
      "Epoch 4801/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0300 - mae: 0.1232 - val_loss: 1.7861 - val_mae: 1.1402\n",
      "Epoch 4802/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0277 - mae: 0.1167 - val_loss: 1.7420 - val_mae: 1.1213\n",
      "Epoch 4803/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0282 - mae: 0.1229 - val_loss: 1.7610 - val_mae: 1.1308\n",
      "Epoch 4804/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0277 - mae: 0.1238 - val_loss: 1.8132 - val_mae: 1.1542\n",
      "Epoch 4805/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0256 - mae: 0.1177 - val_loss: 1.9089 - val_mae: 1.1949\n",
      "Epoch 4806/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0252 - mae: 0.1122 - val_loss: 1.9885 - val_mae: 1.2276\n",
      "Epoch 4807/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0281 - mae: 0.1216 - val_loss: 1.9528 - val_mae: 1.2119\n",
      "Epoch 4808/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0243 - mae: 0.1133 - val_loss: 1.7979 - val_mae: 1.1442\n",
      "Epoch 4809/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0287 - mae: 0.1307 - val_loss: 1.7124 - val_mae: 1.1050\n",
      "Epoch 4810/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0399 - mae: 0.1552 - val_loss: 1.8038 - val_mae: 1.1453\n",
      "Epoch 4811/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0250 - mae: 0.1163 - val_loss: 1.9637 - val_mae: 1.2130\n",
      "Epoch 4812/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0419 - mae: 0.1440 - val_loss: 1.9347 - val_mae: 1.2004\n",
      "Epoch 4813/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0312 - mae: 0.1218 - val_loss: 1.7599 - val_mae: 1.1242\n",
      "Epoch 4814/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0310 - mae: 0.1341 - val_loss: 1.6973 - val_mae: 1.0955\n",
      "Epoch 4815/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1737 - val_loss: 1.8434 - val_mae: 1.1604\n",
      "Epoch 4816/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0389 - mae: 0.1461 - val_loss: 2.1283 - val_mae: 1.2779\n",
      "Epoch 4817/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0314 - mae: 0.1324 - val_loss: 2.3580 - val_mae: 1.3657\n",
      "Epoch 4818/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1615 - val_loss: 2.4562 - val_mae: 1.4022\n",
      "Epoch 4819/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0522 - mae: 0.1813 - val_loss: 2.3764 - val_mae: 1.3738\n",
      "Epoch 4820/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0425 - mae: 0.1559 - val_loss: 2.1452 - val_mae: 1.2863\n",
      "Epoch 4821/5000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0314 - mae: 0.1399 - val_loss: 1.9388 - val_mae: 1.2027\n",
      "Epoch 4822/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0372 - mae: 0.1542 - val_loss: 1.9247 - val_mae: 1.1967\n",
      "Epoch 4823/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0282 - mae: 0.1342 - val_loss: 2.0523 - val_mae: 1.2492\n",
      "Epoch 4824/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0316 - mae: 0.1219 - val_loss: 2.0757 - val_mae: 1.2580\n",
      "Epoch 4825/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0318 - mae: 0.1270 - val_loss: 2.0027 - val_mae: 1.2281\n",
      "Epoch 4826/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0243 - mae: 0.1100 - val_loss: 1.9244 - val_mae: 1.1953\n",
      "Epoch 4827/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0253 - mae: 0.1213 - val_loss: 1.8850 - val_mae: 1.1781\n",
      "Epoch 4828/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0302 - mae: 0.1347 - val_loss: 1.9851 - val_mae: 1.2192\n",
      "Epoch 4829/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0262 - mae: 0.1266 - val_loss: 2.1496 - val_mae: 1.2847\n",
      "Epoch 4830/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0286 - mae: 0.1294 - val_loss: 2.1369 - val_mae: 1.2795\n",
      "Epoch 4831/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0283 - mae: 0.1277 - val_loss: 2.0136 - val_mae: 1.2302\n",
      "Epoch 4832/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0249 - mae: 0.1160 - val_loss: 1.9525 - val_mae: 1.2056\n",
      "Epoch 4833/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0242 - mae: 0.1134 - val_loss: 1.9463 - val_mae: 1.2042\n",
      "Epoch 4834/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0237 - mae: 0.1117 - val_loss: 1.9662 - val_mae: 1.2139\n",
      "Epoch 4835/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0237 - mae: 0.1106 - val_loss: 1.9448 - val_mae: 1.2059\n",
      "Epoch 4836/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0235 - mae: 0.1139 - val_loss: 1.9204 - val_mae: 1.1962\n",
      "Epoch 4837/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0252 - mae: 0.1233 - val_loss: 1.9494 - val_mae: 1.2084\n",
      "Epoch 4838/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0257 - mae: 0.1241 - val_loss: 1.9779 - val_mae: 1.2197\n",
      "Epoch 4839/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0270 - mae: 0.1269 - val_loss: 2.0095 - val_mae: 1.2319\n",
      "Epoch 4840/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0275 - mae: 0.1272 - val_loss: 2.0754 - val_mae: 1.2580\n",
      "Epoch 4841/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0272 - mae: 0.1267 - val_loss: 2.0870 - val_mae: 1.2616\n",
      "Epoch 4842/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0251 - mae: 0.1221 - val_loss: 2.0038 - val_mae: 1.2268\n",
      "Epoch 4843/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0245 - mae: 0.1173 - val_loss: 2.0186 - val_mae: 1.2329\n",
      "Epoch 4844/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0233 - mae: 0.1132 - val_loss: 2.0651 - val_mae: 1.2524\n",
      "Epoch 4845/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0234 - mae: 0.1097 - val_loss: 2.0293 - val_mae: 1.2386\n",
      "Epoch 4846/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0234 - mae: 0.1089 - val_loss: 2.0140 - val_mae: 1.2335\n",
      "Epoch 4847/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0236 - mae: 0.1117 - val_loss: 2.0203 - val_mae: 1.2375\n",
      "Epoch 4848/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0244 - mae: 0.1172 - val_loss: 2.0227 - val_mae: 1.2393\n",
      "Epoch 4849/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0250 - mae: 0.1215 - val_loss: 2.0348 - val_mae: 1.2439\n",
      "Epoch 4850/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0247 - mae: 0.1209 - val_loss: 2.0692 - val_mae: 1.2563\n",
      "Epoch 4851/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0241 - mae: 0.1148 - val_loss: 2.0993 - val_mae: 1.2669\n",
      "Epoch 4852/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0241 - mae: 0.1132 - val_loss: 2.0648 - val_mae: 1.2519\n",
      "Epoch 4853/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0233 - mae: 0.1107 - val_loss: 2.0447 - val_mae: 1.2428\n",
      "Epoch 4854/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0228 - mae: 0.1106 - val_loss: 2.0765 - val_mae: 1.2548\n",
      "Epoch 4855/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0233 - mae: 0.1133 - val_loss: 2.0964 - val_mae: 1.2626\n",
      "Epoch 4856/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0230 - mae: 0.1132 - val_loss: 2.0389 - val_mae: 1.2398\n",
      "Epoch 4857/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0226 - mae: 0.1140 - val_loss: 1.9783 - val_mae: 1.2152\n",
      "Epoch 4858/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0258 - mae: 0.1273 - val_loss: 2.0122 - val_mae: 1.2283\n",
      "Epoch 4859/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0249 - mae: 0.1245 - val_loss: 2.1027 - val_mae: 1.2634\n",
      "Epoch 4860/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0259 - mae: 0.1212 - val_loss: 2.2064 - val_mae: 1.3019\n",
      "Epoch 4861/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0306 - mae: 0.1274 - val_loss: 2.2512 - val_mae: 1.3169\n",
      "Epoch 4862/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0300 - mae: 0.1263 - val_loss: 2.1618 - val_mae: 1.2806\n",
      "Epoch 4863/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0240 - mae: 0.1149 - val_loss: 2.1031 - val_mae: 1.2560\n",
      "Epoch 4864/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0345 - mae: 0.1413 - val_loss: 2.2690 - val_mae: 1.3197\n",
      "Epoch 4865/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0250 - mae: 0.1244 - val_loss: 2.4603 - val_mae: 1.3903\n",
      "Epoch 4866/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0388 - mae: 0.1559 - val_loss: 2.3387 - val_mae: 1.3464\n",
      "Epoch 4867/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0392 - mae: 0.1529 - val_loss: 1.9991 - val_mae: 1.2151\n",
      "Epoch 4868/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0279 - mae: 0.1133 - val_loss: 1.6673 - val_mae: 1.0895\n",
      "Epoch 4869/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0517 - mae: 0.1874 - val_loss: 1.5475 - val_mae: 1.0546\n",
      "Epoch 4870/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0753 - mae: 0.2440 - val_loss: 1.7637 - val_mae: 1.1184\n",
      "Epoch 4871/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0370 - mae: 0.1578 - val_loss: 2.1761 - val_mae: 1.2907\n",
      "Epoch 4872/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0287 - mae: 0.1268 - val_loss: 2.4759 - val_mae: 1.4030\n",
      "Epoch 4873/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0560 - mae: 0.1958 - val_loss: 2.4572 - val_mae: 1.3976\n",
      "Epoch 4874/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0517 - mae: 0.1778 - val_loss: 2.2174 - val_mae: 1.3095\n",
      "Epoch 4875/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0349 - mae: 0.1449 - val_loss: 1.9674 - val_mae: 1.2099\n",
      "Epoch 4876/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0425 - mae: 0.1638 - val_loss: 1.8506 - val_mae: 1.1596\n",
      "Epoch 4877/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0530 - mae: 0.1832 - val_loss: 1.9206 - val_mae: 1.1878\n",
      "Epoch 4878/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0388 - mae: 0.1546 - val_loss: 2.1255 - val_mae: 1.2692\n",
      "Epoch 4879/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0268 - mae: 0.1261 - val_loss: 2.2984 - val_mae: 1.3338\n",
      "Epoch 4880/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0354 - mae: 0.1436 - val_loss: 2.2391 - val_mae: 1.3101\n",
      "Epoch 4881/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0318 - mae: 0.1349 - val_loss: 1.9917 - val_mae: 1.2112\n",
      "Epoch 4882/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0230 - mae: 0.1056 - val_loss: 1.7675 - val_mae: 1.1178\n",
      "Epoch 4883/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0432 - mae: 0.1643 - val_loss: 1.7202 - val_mae: 1.1049\n",
      "Epoch 4884/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0482 - mae: 0.1766 - val_loss: 1.8843 - val_mae: 1.1649\n",
      "Epoch 4885/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0286 - mae: 0.1235 - val_loss: 2.1489 - val_mae: 1.2729\n",
      "Epoch 4886/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0272 - mae: 0.1189 - val_loss: 2.3201 - val_mae: 1.3385\n",
      "Epoch 4887/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0357 - mae: 0.1514 - val_loss: 2.3023 - val_mae: 1.3323\n",
      "Epoch 4888/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0291 - mae: 0.1278 - val_loss: 2.1785 - val_mae: 1.2856\n",
      "Epoch 4889/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0236 - mae: 0.1153 - val_loss: 2.1055 - val_mae: 1.2570\n",
      "Epoch 4890/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0267 - mae: 0.1314 - val_loss: 2.1196 - val_mae: 1.2625\n",
      "Epoch 4891/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0305 - mae: 0.1404 - val_loss: 2.2230 - val_mae: 1.3025\n",
      "Epoch 4892/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0251 - mae: 0.1257 - val_loss: 2.4003 - val_mae: 1.3687\n",
      "Epoch 4893/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0281 - mae: 0.1232 - val_loss: 2.4721 - val_mae: 1.3940\n",
      "Epoch 4894/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0352 - mae: 0.1422 - val_loss: 2.3365 - val_mae: 1.3434\n",
      "Epoch 4895/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0269 - mae: 0.1152 - val_loss: 2.1799 - val_mae: 1.2836\n",
      "Epoch 4896/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0229 - mae: 0.1127 - val_loss: 2.1505 - val_mae: 1.2726\n",
      "Epoch 4897/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0245 - mae: 0.1175 - val_loss: 2.1873 - val_mae: 1.2877\n",
      "Epoch 4898/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0236 - mae: 0.1142 - val_loss: 2.2921 - val_mae: 1.3291\n",
      "Epoch 4899/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0261 - mae: 0.1264 - val_loss: 2.3297 - val_mae: 1.3445\n",
      "Epoch 4900/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0274 - mae: 0.1296 - val_loss: 2.1900 - val_mae: 1.2928\n",
      "Epoch 4901/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0229 - mae: 0.1132 - val_loss: 2.0163 - val_mae: 1.2248\n",
      "Epoch 4902/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0244 - mae: 0.1205 - val_loss: 1.9013 - val_mae: 1.1766\n",
      "Epoch 4903/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0307 - mae: 0.1416 - val_loss: 1.8710 - val_mae: 1.1628\n",
      "Epoch 4904/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0322 - mae: 0.1446 - val_loss: 1.9610 - val_mae: 1.2001\n",
      "Epoch 4905/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0242 - mae: 0.1179 - val_loss: 2.1609 - val_mae: 1.2794\n",
      "Epoch 4906/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0273 - mae: 0.1153 - val_loss: 2.3530 - val_mae: 1.3507\n",
      "Epoch 4907/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0431 - mae: 0.1640 - val_loss: 2.3862 - val_mae: 1.3614\n",
      "Epoch 4908/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1625 - val_loss: 2.2631 - val_mae: 1.3143\n",
      "Epoch 4909/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0298 - mae: 0.1195 - val_loss: 2.1002 - val_mae: 1.2500\n",
      "Epoch 4910/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0260 - mae: 0.1150 - val_loss: 2.0377 - val_mae: 1.2248\n",
      "Epoch 4911/5000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0270 - mae: 0.1272 - val_loss: 2.1355 - val_mae: 1.2644\n",
      "Epoch 4912/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0237 - mae: 0.1184 - val_loss: 2.3021 - val_mae: 1.3283\n",
      "Epoch 4913/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0219 - mae: 0.1064 - val_loss: 2.4361 - val_mae: 1.3772\n",
      "Epoch 4914/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0246 - mae: 0.1145 - val_loss: 2.4106 - val_mae: 1.3675\n",
      "Epoch 4915/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0240 - mae: 0.1161 - val_loss: 2.3270 - val_mae: 1.3366\n",
      "Epoch 4916/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0225 - mae: 0.1130 - val_loss: 2.2772 - val_mae: 1.3182\n",
      "Epoch 4917/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0255 - mae: 0.1219 - val_loss: 2.2050 - val_mae: 1.2912\n",
      "Epoch 4918/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0307 - mae: 0.1306 - val_loss: 2.1879 - val_mae: 1.2857\n",
      "Epoch 4919/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0292 - mae: 0.1286 - val_loss: 2.1866 - val_mae: 1.2870\n",
      "Epoch 4920/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0243 - mae: 0.1181 - val_loss: 2.1107 - val_mae: 1.2588\n",
      "Epoch 4921/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0213 - mae: 0.1050 - val_loss: 1.9859 - val_mae: 1.2093\n",
      "Epoch 4922/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0233 - mae: 0.1096 - val_loss: 1.9463 - val_mae: 1.1931\n",
      "Epoch 4923/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0247 - mae: 0.1148 - val_loss: 2.0145 - val_mae: 1.2205\n",
      "Epoch 4924/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0239 - mae: 0.1120 - val_loss: 2.1320 - val_mae: 1.2678\n",
      "Epoch 4925/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0245 - mae: 0.1115 - val_loss: 2.2667 - val_mae: 1.3214\n",
      "Epoch 4926/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0305 - mae: 0.1292 - val_loss: 2.3181 - val_mae: 1.3423\n",
      "Epoch 4927/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0315 - mae: 0.1324 - val_loss: 2.2147 - val_mae: 1.3044\n",
      "Epoch 4928/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0234 - mae: 0.1167 - val_loss: 2.0211 - val_mae: 1.2288\n",
      "Epoch 4929/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0263 - mae: 0.1301 - val_loss: 1.9310 - val_mae: 1.1930\n",
      "Epoch 4930/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0308 - mae: 0.1419 - val_loss: 2.0099 - val_mae: 1.2276\n",
      "Epoch 4931/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0266 - mae: 0.1281 - val_loss: 2.0599 - val_mae: 1.2476\n",
      "Epoch 4932/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0225 - mae: 0.1158 - val_loss: 2.0125 - val_mae: 1.2264\n",
      "Epoch 4933/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0222 - mae: 0.1143 - val_loss: 1.9747 - val_mae: 1.2095\n",
      "Epoch 4934/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0227 - mae: 0.1165 - val_loss: 1.9255 - val_mae: 1.1880\n",
      "Epoch 4935/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0245 - mae: 0.1195 - val_loss: 1.8722 - val_mae: 1.1648\n",
      "Epoch 4936/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0263 - mae: 0.1200 - val_loss: 1.8968 - val_mae: 1.1753\n",
      "Epoch 4937/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0254 - mae: 0.1159 - val_loss: 1.9508 - val_mae: 1.1982\n",
      "Epoch 4938/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0234 - mae: 0.1077 - val_loss: 1.9736 - val_mae: 1.2078\n",
      "Epoch 4939/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0222 - mae: 0.1050 - val_loss: 1.9575 - val_mae: 1.2009\n",
      "Epoch 4940/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0230 - mae: 0.1140 - val_loss: 1.9918 - val_mae: 1.2153\n",
      "Epoch 4941/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0223 - mae: 0.1143 - val_loss: 2.1436 - val_mae: 1.2774\n",
      "Epoch 4942/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0223 - mae: 0.1097 - val_loss: 2.3101 - val_mae: 1.3410\n",
      "Epoch 4943/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0303 - mae: 0.1304 - val_loss: 2.4025 - val_mae: 1.3743\n",
      "Epoch 4944/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0360 - mae: 0.1443 - val_loss: 2.3119 - val_mae: 1.3398\n",
      "Epoch 4945/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0277 - mae: 0.1249 - val_loss: 2.1546 - val_mae: 1.2769\n",
      "Epoch 4946/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0223 - mae: 0.1148 - val_loss: 2.1286 - val_mae: 1.2626\n",
      "Epoch 4947/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0246 - mae: 0.1251 - val_loss: 2.2153 - val_mae: 1.2924\n",
      "Epoch 4948/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0229 - mae: 0.1173 - val_loss: 2.3106 - val_mae: 1.3261\n",
      "Epoch 4949/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0208 - mae: 0.1035 - val_loss: 2.3529 - val_mae: 1.3405\n",
      "Epoch 4950/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0236 - mae: 0.1084 - val_loss: 2.3635 - val_mae: 1.3438\n",
      "Epoch 4951/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0227 - mae: 0.1093 - val_loss: 2.3294 - val_mae: 1.3307\n",
      "Epoch 4952/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0229 - mae: 0.1163 - val_loss: 2.2840 - val_mae: 1.3132\n",
      "Epoch 4953/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0261 - mae: 0.1218 - val_loss: 2.2614 - val_mae: 1.3042\n",
      "Epoch 4954/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0286 - mae: 0.1264 - val_loss: 2.3485 - val_mae: 1.3372\n",
      "Epoch 4955/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0256 - mae: 0.1198 - val_loss: 2.4541 - val_mae: 1.3764\n",
      "Epoch 4956/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0224 - mae: 0.1143 - val_loss: 2.4399 - val_mae: 1.3721\n",
      "Epoch 4957/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0224 - mae: 0.1107 - val_loss: 2.3740 - val_mae: 1.3492\n",
      "Epoch 4958/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0218 - mae: 0.1070 - val_loss: 2.2412 - val_mae: 1.3012\n",
      "Epoch 4959/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0210 - mae: 0.1046 - val_loss: 2.1115 - val_mae: 1.2531\n",
      "Epoch 4960/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0213 - mae: 0.1076 - val_loss: 2.0724 - val_mae: 1.2388\n",
      "Epoch 4961/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0213 - mae: 0.1065 - val_loss: 2.1603 - val_mae: 1.2732\n",
      "Epoch 4962/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0208 - mae: 0.0990 - val_loss: 2.3509 - val_mae: 1.3439\n",
      "Epoch 4963/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0265 - mae: 0.1197 - val_loss: 2.4714 - val_mae: 1.3855\n",
      "Epoch 4964/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0294 - mae: 0.1312 - val_loss: 2.3823 - val_mae: 1.3513\n",
      "Epoch 4965/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0220 - mae: 0.1049 - val_loss: 2.1822 - val_mae: 1.2741\n",
      "Epoch 4966/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0219 - mae: 0.1111 - val_loss: 2.0245 - val_mae: 1.2102\n",
      "Epoch 4967/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0322 - mae: 0.1429 - val_loss: 2.0142 - val_mae: 1.2054\n",
      "Epoch 4968/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0316 - mae: 0.1392 - val_loss: 2.1959 - val_mae: 1.2778\n",
      "Epoch 4969/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0227 - mae: 0.1027 - val_loss: 2.4153 - val_mae: 1.3606\n",
      "Epoch 4970/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0326 - mae: 0.1376 - val_loss: 2.5021 - val_mae: 1.3920\n",
      "Epoch 4971/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0426 - mae: 0.1657 - val_loss: 2.3607 - val_mae: 1.3402\n",
      "Epoch 4972/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0219 - mae: 0.1017 - val_loss: 2.1141 - val_mae: 1.2449\n",
      "Epoch 4973/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0425 - mae: 0.1588 - val_loss: 2.0502 - val_mae: 1.2191\n",
      "Epoch 4974/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0711 - mae: 0.2084 - val_loss: 2.2413 - val_mae: 1.2953\n",
      "Epoch 4975/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0521 - mae: 0.1580 - val_loss: 2.5647 - val_mae: 1.4151\n",
      "Epoch 4976/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0363 - mae: 0.1420 - val_loss: 2.8418 - val_mae: 1.5104\n",
      "Epoch 4977/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0480 - mae: 0.1812 - val_loss: 2.8395 - val_mae: 1.5104\n",
      "Epoch 4978/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.2047 - val_loss: 2.4274 - val_mae: 1.3711\n",
      "Epoch 4979/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0296 - mae: 0.1375 - val_loss: 1.8708 - val_mae: 1.1585\n",
      "Epoch 4980/5000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0290 - mae: 0.1296 - val_loss: 1.5621 - val_mae: 1.0623\n",
      "Epoch 4981/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0464 - mae: 0.1797 - val_loss: 1.5345 - val_mae: 1.0488\n",
      "Epoch 4982/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0400 - mae: 0.1561 - val_loss: 1.6064 - val_mae: 1.0667\n",
      "Epoch 4983/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0314 - mae: 0.1340 - val_loss: 1.7228 - val_mae: 1.1138\n",
      "Epoch 4984/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0314 - mae: 0.1319 - val_loss: 1.8515 - val_mae: 1.1694\n",
      "Epoch 4985/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0355 - mae: 0.1387 - val_loss: 1.9028 - val_mae: 1.1885\n",
      "Epoch 4986/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0313 - mae: 0.1310 - val_loss: 1.8791 - val_mae: 1.1749\n",
      "Epoch 4987/5000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0225 - mae: 0.1041 - val_loss: 1.8276 - val_mae: 1.1490\n",
      "Epoch 4988/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0240 - mae: 0.1150 - val_loss: 1.8481 - val_mae: 1.1524\n",
      "Epoch 4989/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0298 - mae: 0.1312 - val_loss: 1.9940 - val_mae: 1.2071\n",
      "Epoch 4990/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0274 - mae: 0.1245 - val_loss: 2.2623 - val_mae: 1.3095\n",
      "Epoch 4991/5000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0231 - mae: 0.1182 - val_loss: 2.5093 - val_mae: 1.4002\n",
      "Epoch 4992/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0316 - mae: 0.1464 - val_loss: 2.5819 - val_mae: 1.4271\n",
      "Epoch 4993/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0370 - mae: 0.1602 - val_loss: 2.5284 - val_mae: 1.4092\n",
      "Epoch 4994/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0320 - mae: 0.1455 - val_loss: 2.3955 - val_mae: 1.3620\n",
      "Epoch 4995/5000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0242 - mae: 0.1188 - val_loss: 2.2245 - val_mae: 1.2983\n",
      "Epoch 4996/5000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0212 - mae: 0.1121 - val_loss: 2.0547 - val_mae: 1.2303\n",
      "Epoch 4997/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0274 - mae: 0.1314 - val_loss: 1.9780 - val_mae: 1.1964\n",
      "Epoch 4998/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0331 - mae: 0.1444 - val_loss: 2.0610 - val_mae: 1.2289\n",
      "Epoch 4999/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0258 - mae: 0.1224 - val_loss: 2.2270 - val_mae: 1.2946\n",
      "Epoch 5000/5000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0206 - mae: 0.1057 - val_loss: 2.3729 - val_mae: 1.3500\n",
      "CPU times: user 3min 23s, sys: 11.5 s, total: 3min 34s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f008e6628b0>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=5000,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07-A1jQBFGJd",
    "outputId": "1ac34d37-87bf-47cc-ada5-4abb19d93073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3729 - mae: 1.3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.372873306274414, 1.349958062171936]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.550222],\n",
       "       [19.501951],\n",
       "       [19.52603 ],\n",
       "       [19.417261],\n",
       "       [19.324743]], dtype=float32)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train_pred, '.r', label='predicted')\n",
    "plt.plot(np.array(y_train), 'g', label='true')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "40tECAywEJOC",
    "outputId": "85cff644-4a48-443a-cff5-bbe267cd5cb0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test_pred, '.r', label='predicted')\n",
    "plt.plot(y_test, 'g', label='true')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 - 0s - loss: 2.3729 - mae: 1.3500 - 14ms/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_mse: 2.37, test_mae: 1.35'"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "test_mse, test_mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "\n",
    "print \n",
    "(f'test_mse: {round(test_mse, 2)}, test_mae: {round(test_mae,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате применения 4-х разных моделей к прогнозированию медианной заработной платы женщин в условиях ограниченного набора данных (всего 50 экземпляров) мы получили следующие результаты работы моделей:\n",
    "XGboost mse_test 2.754596856556042, mae_test 1.4506931915283203,\n",
    "полносвязная нейронная сеть test_mse 1.63, test_mae: 1.12,\n",
    "lstm test_mse: 2.85, test_mae: 1.53,\n",
    "gru test_mse: 2.37, test_mae: 1.35.\n",
    "Вывод: нейронные сети справляются с анализом и предсказаниями временных рядов не хуже, чем бустинги (даже после применения gridsearch для подбора гиперпараметров). Но у них есть существенный недостаток - они долго обучаются и требуют больших вычислительных ресурсов. Можно рассмотреть для оптимизации решения данной задачи другие типы бустингов или использовать полносвязную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
