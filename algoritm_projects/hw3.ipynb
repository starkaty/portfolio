{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVKnqZEmWjr0"
   },
   "source": [
    "# Домашняя работа. Урок 3. Классификация. Логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sg7z9JsRWjr7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8EL0iGJOVpe"
   },
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "gviMxz7EOuI3",
    "outputId": "af9a2576-f4d7-41d7-e216-46e0a068cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.97958969,  1.        ],\n",
       "       [ 1.        ,  1.        , -0.56713087,  1.        ],\n",
       "       [ 1.        ,  2.        , -0.46401617,  2.        ],\n",
       "       [ 1.        ,  5.        , -0.77336028,  1.        ],\n",
       "       [ 1.        ,  3.        ,  0.97958969,  2.        ],\n",
       "       [ 1.        ,  0.        , -0.36090146,  1.        ],\n",
       "       [ 1.        ,  5.        ,  1.08270439,  3.        ],\n",
       "       [ 1.        , 10.        ,  2.11385144,  3.        ],\n",
       "       [ 1.        ,  1.        , -1.08270439,  1.        ],\n",
       "       [ 1.        ,  2.        ,  0.05155735,  2.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    y_pred = y_pred.astype(np.float64) #преобразуем y_pred к типу float\n",
    "    y_pred[y_pred==0] = 0.0001 #всем значениям 0 присваиваем значение 0,0001, чтобы функция была рабочей и в ln не попадал 0\n",
    "    y_pred[y_pred==1] = 0.9999 #всем значениям 1 присваиваем значение 0,9999, чтобы функция была рабочей и в ln не попадал 0\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R6zfOHMrBvnX",
    "outputId": "46df0625-963f-4401-da30-b5b42bcf1be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16425203348601797"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([0.8, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.716741961645196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Плохой пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([0, 0.2])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9tN8lBEEeXU"
   },
   "outputs": [],
   "source": [
    "z = np.linspace(-10, 10, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvIe3RpbEp4l"
   },
   "outputs": [],
   "source": [
    "probabilities = sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W1 = W\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        #if i % (iterations / 10) == 0:\n",
    "            #print(i, W1, err)\n",
    "    print(f'Final eta {eta}, iterations {i}, W {W1}, err {err}')\n",
    "    return err, W1, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eta 0.001, iterations 99, W [ 0.46072513 -0.27653801  0.64396485  1.46889442], err 0.9469969250572376\n",
      "Final eta 0.001, iterations 99, W [ 0.46072513 -0.27653801  0.64396485  1.46889442], err 0.9469969250572376\n",
      "Final eta 0.001, iterations 99, W [ 0.46072513 -0.27653801  0.64396485  1.46889442], err 0.9469969250572376\n",
      "Final eta 0.001, iterations 99, W [ 0.46072513 -0.27653801  0.64396485  1.46889442], err 0.9469969250572376\n",
      "Final eta 0.01, iterations 99, W [ 0.30052426 -0.7012269   0.66327117  1.28844369], err 0.5202099204174199\n",
      "Final eta 0.01, iterations 99, W [ 0.30052426 -0.7012269   0.66327117  1.28844369], err 0.5202099204174199\n",
      "Final eta 0.01, iterations 99, W [ 0.30052426 -0.7012269   0.66327117  1.28844369], err 0.5202099204174199\n",
      "Final eta 0.01, iterations 99, W [ 0.30052426 -0.7012269   0.66327117  1.28844369], err 0.5202099204174199\n",
      "Final eta 0.1, iterations 99, W [-0.16766678 -0.75425021  0.95413376  1.46442203], err 0.47660345824649475\n",
      "Final eta 0.1, iterations 99, W [-0.16766678 -0.75425021  0.95413376  1.46442203], err 0.47660345824649475\n",
      "Final eta 0.1, iterations 99, W [-0.16766678 -0.75425021  0.95413376  1.46442203], err 0.47660345824649475\n",
      "Final eta 0.1, iterations 99, W [-0.16766678 -0.75425021  0.95413376  1.46442203], err 0.47660345824649475\n",
      "Final eta 1, iterations 99, W [-2.62974838 -0.95037163  0.44181566  3.36145341], err 0.38056089678810423\n",
      "Final eta 1, iterations 99, W [-2.62974838 -0.95037163  0.44181566  3.36145341], err 0.38056089678810423\n",
      "Final eta 1, iterations 99, W [-2.62974838 -0.95037163  0.44181566  3.36145341], err 0.38056089678810423\n",
      "Final eta 1, iterations 99, W [-2.62974838 -0.95037163  0.44181566  3.36145341], err 0.38056089678810423\n",
      "Final eta 10, iterations 99, W [-29.59084907 -11.32665473   3.41392564  40.73710771], err 1.5291420406719307\n",
      "Final eta 100, iterations 99, W [-308.19827888  -96.73853875   24.05359943  419.47415995], err 3.853126269558401\n",
      "Final eta 1000, iterations 99, W [-3387.38477635 -2067.04644946   -53.6268326   3419.3445972 ], err 3.684196151790718\n",
      "Final eta 10000, iterations 99, W [-31793.37210393 -10508.89816326   1067.33465621  41340.06034356], err 30.370324091160864\n",
      "Final eta 0.001, iterations 149, W [ 0.44433076 -0.3396128   0.64152998  1.44403357], err 0.8493208016539795\n",
      "Final eta 0.01, iterations 149, W [ 0.25659568 -0.71570269  0.69646602  1.28000058], err 0.5133598917489355\n",
      "Final eta 0.1, iterations 149, W [-0.33594732 -0.79075581  0.98410115  1.61099305], err 0.466134847694969\n",
      "Final eta 1, iterations 149, W [-3.60267571 -0.95456531  0.0127993   3.87643375], err 0.34527805951390805\n",
      "Final eta 1, iterations 149, W [-3.60267571 -0.95456531  0.0127993   3.87643375], err 0.34527805951390805\n",
      "Final eta 1, iterations 149, W [-3.60267571 -0.95456531  0.0127993   3.87643375], err 0.34527805951390805\n",
      "Final eta 1, iterations 149, W [-3.60267571 -0.95456531  0.0127993   3.87643375], err 0.34527805951390805\n",
      "Final eta 10, iterations 149, W [-42.4478067  -11.73718359  -7.98605045  36.80166003], err 0.49534400166994186\n",
      "Final eta 100, iterations 149, W [-454.99417328 -108.18700696  -30.312767    477.73899573], err 1.6569950629344277\n",
      "Final eta 1000, iterations 149, W [-4704.08275018 -2081.3069311   -624.85125713  4305.08388404], err 3.684196151790718\n",
      "Final eta 10000, iterations 149, W [-43793.37210393 -10508.89816326  -3985.28584706  53340.06034356], err 41.73132610642561\n",
      "Final eta 0.001, iterations 199, W [ 0.42910026 -0.39765478  0.63900544  1.42101292], err 0.766289073525106\n",
      "Final eta 0.01, iterations 199, W [ 0.21855551 -0.71712255  0.72770923  1.28034932], err 0.5084820542970339\n",
      "Final eta 0.1, iterations 199, W [-0.49194372 -0.82173406  0.98780915  1.74829144], err 0.45727517096454073\n",
      "Final eta 1, iterations 199, W [-4.39742857 -0.98698246 -0.31157235  4.35178196], err 0.324141992088549\n",
      "Final eta 1, iterations 199, W [-4.39742857 -0.98698246 -0.31157235  4.35178196], err 0.324141992088549\n",
      "Final eta 1, iterations 199, W [-4.39742857 -0.98698246 -0.31157235  4.35178196], err 0.324141992088549\n",
      "Final eta 1, iterations 199, W [-4.39742857 -0.98698246 -0.31157235  4.35178196], err 0.324141992088549\n",
      "Final eta 10, iterations 199, W [-47.21925094  -5.19865836 -12.47184329  40.42193798], err 0.11481200957187834\n",
      "Final eta 10, iterations 199, W [-47.21925094  -5.19865836 -12.47184329  40.42193798], err 0.11481200957187834\n",
      "Final eta 10, iterations 199, W [-47.21925094  -5.19865836 -12.47184329  40.42193798], err 0.11481200957187834\n",
      "Final eta 10, iterations 199, W [-47.21925094  -5.19865836 -12.47184329  40.42193798], err 0.11481200957187834\n",
      "Final eta 100, iterations 199, W [-545.79661824 -104.29871738  -86.79013338  533.77070922], err 0.9377893556410763\n",
      "Final eta 1000, iterations 199, W [-5476.50950509 -1124.4750462   -927.33365887  5258.22073638], err 1.8421380778954923\n",
      "Final eta 10000, iterations 199, W [-54793.37210393  -7508.89816326 -11151.75778536  55340.06034356], err 3.684196151790674\n",
      "Final eta 0.001, iterations 249, W [ 0.41509697 -0.44974268  0.63671699  1.40016651], err 0.6989875016496278\n",
      "Final eta 0.01, iterations 249, W [ 0.18377326 -0.71644717  0.75595614  1.28415181], err 0.5044227002338322\n",
      "Final eta 0.1, iterations 249, W [-0.64214108 -0.84661774  0.97692858  1.87424159], err 0.4494255504543118\n",
      "Final eta 1, iterations 249, W [-5.06800697 -1.01070391 -0.56223149  4.80484113], err 0.30968562704112795\n",
      "Final eta 10, iterations 249, W [-52.26177478  -6.40365324 -12.82441609  44.7349626 ], err 0.10133705491345871\n",
      "Final eta 10, iterations 249, W [-52.26177478  -6.40365324 -12.82441609  44.7349626 ], err 0.10133705491345871\n",
      "Final eta 10, iterations 249, W [-52.26177478  -6.40365324 -12.82441609  44.7349626 ], err 0.10133705491345871\n",
      "Final eta 10, iterations 249, W [-52.26177478  -6.40365324 -12.82441609  44.7349626 ], err 0.10133705491345871\n",
      "Final eta 100, iterations 249, W [-584.93892381  -77.28302644 -123.36079393  534.53182533], err 0.000710942445318106\n",
      "Final eta 100, iterations 249, W [-584.93892381  -77.28302644 -123.36079393  534.53182533], err 0.000710942445318106\n",
      "Final eta 100, iterations 249, W [-584.93892381  -77.28302644 -123.36079393  534.53182533], err 0.000710942445318106\n",
      "Final eta 100, iterations 249, W [-584.93892381  -77.28302644 -123.36079393  534.53182533], err 0.000710942445318106\n",
      "Final eta 1000, iterations 249, W [-5980.68686111  -824.36407759 -1436.32392796  5454.04338036], err 21.311891138004185\n",
      "Final eta 10000, iterations 249, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 10000, iterations 249, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206865/2870899410.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final eta 10000, iterations 249, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 10000, iterations 249, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 299, W [ 0.40235336 -0.49509105  0.63498579  1.38177368], err 0.6474600652646159\n",
      "Final eta 0.01, iterations 299, W [ 0.15143647 -0.7160177   0.7812503   1.29001551], err 0.5009718677659235\n",
      "Final eta 0.1, iterations 299, W [-0.7882581  -0.86637805  0.95643186  1.99019315], err 0.4422921962931354\n",
      "Final eta 1, iterations 299, W [-5.65658596 -1.03642183 -0.77175696  5.22032262], err 0.2983635572917686\n",
      "Final eta 10, iterations 299, W [-53.2098757   -5.49721159 -14.24394916  44.01354415], err 0.08173134457901446\n",
      "Final eta 100, iterations 299, W [-585.32191802  -76.68099122 -123.73932109  534.14461965], err 0.0005410793459875407\n",
      "Final eta 1000, iterations 299, W [-6024.57318899  -824.36407759 -1678.27204833  5410.15705249], err 3.8933274198939136\n",
      "Final eta 10000, iterations 299, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 309, W [ 0.39995432 -0.50331713  0.63472762  1.37840219], err 0.6389316648653399\n",
      "Final eta 0.01, iterations 309, W [ 0.14522633 -0.71600944  0.7859769   1.29138776], err 0.5003425637095121\n",
      "Final eta 0.1, iterations 309, W [-0.81704665 -0.86981079  0.95144317  2.01233647], err 0.44093482924765937\n",
      "Final eta 1, iterations 309, W [-5.76649618 -1.04174953 -0.81017773  5.29922886], err 0.2963763932393591\n",
      "Final eta 10, iterations 309, W [-53.34712675  -5.4205009  -14.36207533  43.95985525], err 0.08130045916236853\n",
      "Final eta 100, iterations 309, W [-585.37744382  -76.60911084 -123.7994948   534.08603515], err 0.0005255212162354976\n",
      "Final eta 1000, iterations 309, W [-6083.10836088  -875.86282181 -1671.53202671  5351.62188059], err 0.06643433100507841\n",
      "Final eta 10000, iterations 309, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 319, W [ 0.39760399 -0.51126243  0.63450153  1.37513308], err 0.6309516740426924\n",
      "Final eta 0.01, iterations 319, W [ 0.13909625 -0.71602919  0.79059815  1.29282038], err 0.4997313571769924\n",
      "Final eta 0.1, iterations 319, W [-0.84569634 -0.87308899  0.9462002   2.0341614 ], err 0.43959794682798786\n",
      "Final eta 1, iterations 319, W [-5.87412693 -1.04710807 -0.84761746  5.37686362], err 0.29446655321369325\n",
      "Final eta 10, iterations 319, W [-53.47177629  -5.3616368  -14.46010432  43.92561397], err 0.08099646584044524\n",
      "Final eta 100, iterations 319, W [-585.42797997  -76.54922266 -123.85842631  534.03132314], err 0.00051272594675571\n",
      "Final eta 1000, iterations 319, W [-6183.10836088  -775.86282181 -1511.70423529  5451.6218806 ], err 7.000350054340622e-05\n",
      "Final eta 1000, iterations 319, W [-6183.10836088  -775.86282181 -1511.70423529  5451.6218806 ], err 7.000350054340622e-05\n",
      "Final eta 1000, iterations 319, W [-6183.10836088  -775.86282181 -1511.70423529  5451.6218806 ], err 7.000350054340622e-05\n",
      "Final eta 1000, iterations 319, W [-6183.10836088  -775.86282181 -1511.70423529  5451.6218806 ], err 7.000350054340622e-05\n",
      "Final eta 10000, iterations 319, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 349, W [ 0.39083718 -0.53344402  0.63402047  1.36593069], err 0.6100648219587799\n",
      "Final eta 0.01, iterations 349, W [ 0.12116535 -0.71625518  0.80385304  1.29746006], err 0.4979980263936671\n",
      "Final eta 0.1, iterations 349, W [-0.93082987 -0.88206794  0.92909513  2.09784493], err 0.4357012823177423\n",
      "Final eta 1, iterations 349, W [-6.18448477 -1.06329689 -0.9546264   5.60264817], err 0.2891501466687526\n",
      "Final eta 10, iterations 349, W [-53.81229498  -5.29996138 -14.65125007  43.88549976], err 0.0809245761246303\n",
      "Final eta 100, iterations 349, W [-585.55537058  -76.4225077  -124.03150549  533.88625191], err 0.00048450292630494707\n",
      "Final eta 1000, iterations 349, W [-6183.10836089  -775.86282182 -1511.70423528  5451.62188059], err 7.000350054340622e-05\n",
      "Final eta 10000, iterations 349, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 399, W [ 0.38044466 -0.56521473  0.63387051  1.35250795], err 0.5838935337255935\n",
      "Final eta 0.01, iterations 399, W [ 0.09269686 -0.71715644  0.82405016  1.30622658], err 0.4953993238885827\n",
      "Final eta 0.1, iterations 399, W [-1.07008185 -0.89456191  0.89676256  2.19865248], err 0.42954320212927516\n",
      "Final eta 1, iterations 399, W [-6.66573761 -1.09038244 -1.11803294  5.9579673 ], err 0.2814212443028739\n",
      "Final eta 10, iterations 399, W [-56.50818757  -6.848792   -13.9048592   48.71300949], err 0.08868099785478947\n",
      "Final eta 100, iterations 399, W [-585.71790365  -76.29716266 -124.29715804  533.69024784], err 0.0004539148332662101\n",
      "Final eta 1000, iterations 399, W [-6183.1083609   -775.86282184 -1511.70423526  5451.62188057], err 7.000350054340622e-05\n",
      "Final eta 10000, iterations 399, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n",
      "Final eta 0.001, iterations 499, W [ 0.36243745 -0.61258084  0.63568405  1.33174524], err 0.5533458057511683\n",
      "Final eta 0.01, iterations 499, W [ 0.04031921 -0.720604    0.858267    1.32697244], err 0.4910268478489977\n",
      "Final eta 0.1, iterations 499, W [-1.33914489 -0.91256512  0.82212931  2.38413361], err 0.4182588453390704\n",
      "Final eta 1, iterations 499, W [-7.52525459 -1.14394508 -1.40331733  6.606205  ], err 0.26894623669681555\n",
      "Final eta 10, iterations 499, W [-58.13873791  -5.74270023 -15.81415889  47.60391305], err 0.07567487950361694\n",
      "Final eta 100, iterations 499, W [-585.96219754  -76.13919206 -124.71919184  533.39468794], err 0.0004184280660935572\n",
      "Final eta 1000, iterations 499, W [-6183.10836093  -775.86282187 -1511.70423523  5451.62188054], err 7.000350054340622e-05\n",
      "Final eta 10000, iterations 499, W [-59793.37210821  -7508.89816326 -13574.9533313   53340.06033928], err 9.000450030001259e-05\n"
     ]
    }
   ],
   "source": [
    "#подбор оптимальных eta и iterations\n",
    "err_eta_iter_w_list = [10000,0,0,0]\n",
    "for i in [100, 150, 200, 250, 300, 310, 320, 350, 400, 500]:\n",
    "    for j in [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "        if eval_model(X_st, y, iterations=i, eta=j)[0]<err_eta_iter_w_list[0]:\n",
    "            err_eta_iter_w_list = [eval_model(X_st, y, iterations=i, eta=j)[0], j, eval_model(X_st, y, iterations=i, eta=j)[2], eval_model(X_st, y, iterations=i, eta=j)[1]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Оптимальные аргументы функции, при которых ошибка минимальна: eta 1000, iterations 320\n"
     ]
    }
   ],
   "source": [
    "print(f' Оптимальные аргументы функции, при которых ошибка минимальна: eta {err_eta_iter_w_list[1]}, iterations {err_eta_iter_w_list[2]+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "oqX7loklBmYZ",
    "outputId": "f4849295-1f14-40d8-c8f2-d1b002e130c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final eta 1000, iterations 319, W [-6183.10836088  -775.86282181 -1511.70423529  5451.6218806 ], err 7.000350054340622e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206865/2870899410.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=320, eta=1000)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6183.10836088,  -775.86282181, -1511.70423529,  5451.6218806 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(X, W):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred_proba = 1 / (1 + np.exp(-z))\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.97958969,  1.        ],\n",
       "       [ 1.        ,  1.        , -0.56713087,  1.        ],\n",
       "       [ 1.        ,  2.        , -0.46401617,  2.        ],\n",
       "       [ 1.        ,  5.        , -0.77336028,  1.        ],\n",
       "       [ 1.        ,  3.        ,  0.97958969,  2.        ],\n",
       "       [ 1.        ,  0.        , -0.36090146,  1.        ],\n",
       "       [ 1.        ,  5.        ,  1.08270439,  3.        ],\n",
       "       [ 1.        , 10.        ,  2.11385144,  3.        ],\n",
       "       [ 1.        ,  1.        , -1.08270439,  1.        ],\n",
       "       [ 1.        ,  2.        ,  0.05155735,  2.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6183.10836088,  -775.86282181, -1511.70423529,  5451.6218806 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -26.49941977,  -650.01515969,  3869.86496411, -3441.70857698,\n",
       "         911.69705256,  -185.91020784,  4655.71435455,  -782.38910432,\n",
       "         129.37951521,  3090.4702892 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(X_st, W)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим линию, разделяющую на классы полученные с помощью весов W <w,x>. Так как у нас 4 признака в модели, то эта линия по сути - гиперплоскость, но мы можем визуализировать ее с помощью обучения логистической регрессии на z и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(z.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.498365729243186e-02 -4.885756863178683\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.coef_[0][0], log_reg.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_line = [log_reg.intercept_[0]+log_reg.coef_[0][0]*el for el in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x = np.linspace(0,10,10),y = z, hue = y)\n",
    "sns.lineplot(x = np.linspace(-1,12,13),y = log_reg_line, color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном графике хорошо видно разделяющую классы линию, веса подобраны таким образом, что модель на обучающих данных не ошибается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.10061769e-012 5.03504077e-283 1.00000000e+000 0.00000000e+000\n",
      " 1.00000000e+000 1.82063381e-081 1.00000000e+000 0.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206865/3100612240.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_pred_proba = 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "#Полученные вероятности\n",
    "print(calc_pred_proba(X_st, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, W):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred_proba = 1 / (1 + np.exp(-z))\n",
    "    y_pred = np.around(y_pred_proba,0) #порог отнесения к классу берем 0,5, поэтому для отнесения к классу воспользуемся функкцией округления вероятности до целого\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206865/1811465241.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  y_pred_proba = 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(X_st, W)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred==y].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    return y_pred[y_pred==y].shape[0]/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_matrix(y, y_pred):\n",
    "    return np.array([[y_pred[(y_pred==y)&(y==1)].shape[0], y_pred[(y_pred!=y)&(y==0)].shape[0]],[y_pred[(y_pred!=y)&(y==1)].shape[0],y_pred[(y_pred==y)&(y==0)].shape[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [0, 5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preсision(y, y_pred):\n",
    "    return y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preсision(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y, y_pred):\n",
    "    return y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y, y_pred):\n",
    "    return 2 * y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==0)].shape[0]) * y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==1)].shape[0])/(y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==0)].shape[0]) + y_pred[(y_pred==y)&(y==1)].shape[0]/(y_pred[(y_pred==y)&(y==1)].shape[0]+y_pred[(y_pred!=y)&(y==1)].shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей обучающей выборке всего 10 объектов, регуляризация не проводилась, веса при минимальной ошибке имеют большое значение. Тестовой выборки в данной задаче нет. Возможно модель переобучилась на тех данных, которые у нас есть, но верное заключение о переобучении можно сделать лишь получив тестовую выборку и проверив работу модели на тестовых данных. Для тех данных, которые имеются, не имеет смысла проводить регуляризацию и искуственно занижать веса и соответственно упрощать модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
